{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "#!python -m pip install ujson\n",
    "import ujson as json\n",
    "\n",
    "#!python -m pip install matplotlib\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "#!conda install pandas=1.0.5 --yes\n",
    " \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from pandas.core.common import flatten\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "#import importlib.util \n",
    "#print(sys.modules)\n",
    "#import pandas as pd\n",
    "pd.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.8/site-packages') \n",
    "\n",
    "import os\n",
    "os.chdir('/xdisk/msurdeanu/fanluo/hotpotQA/') \n",
    "from util import get_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def _normalize_text(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "import re\n",
    "import string\n",
    "# def findWholeWord(w):\n",
    "#     return re.compile(r'\\b({0})\\b'.format(re.escape(w.strip(string.punctuation))), flags=re.IGNORECASE).search\n",
    "#     # strip(string.punctuation) to remove heading and ending punctuations in the answer, otherwise can not found correctly if heading or ending punctuations appears\n",
    "    \n",
    "def findWord(w, context):\n",
    "    if(w == ''):\n",
    "        return False\n",
    "    if(len(list(re.finditer(str(w), str(context), re.IGNORECASE))) > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HopotQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/xdisk/msurdeanu/fanluo/hotpotQA/Data/hotpot_train_v1.1.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    data = list(map(json.loads, data)) \n",
    "train_question_df = pd.DataFrame(data[0])\n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    supporting_facts   level  \\\n",
       "0     [[Arthur's Magazine, 0], [First for Women, 0]]  medium   \n",
       "1        [[Oberoi family, 0], [The Oberoi Group, 0]]  medium   \n",
       "2  [[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...    hard   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "\n",
       "                                             context                   answer  \\\n",
       "0  [[Radio City (Indian radio station), [Radio Ci...        Arthur's Magazine   \n",
       "1  [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...                    Delhi   \n",
       "2  [[Lisa Simpson, [Lisa Marie Simpson is a ficti...  President Richard Nixon   \n",
       "\n",
       "                        _id        type  \n",
       "0  5a7a06935542990198eaf050  comparison  \n",
       "1  5a879ab05542996e4f30887e      bridge  \n",
       "2  5a8d7341554299441c6b9fe5      bridge  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)   # show all columns\n",
    "train_question_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90447 entries, 0 to 90446\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   supporting_facts  90447 non-null  object\n",
      " 1   level             90447 non-null  object\n",
      " 2   question          90447 non-null  object\n",
      " 3   context           90447 non-null  object\n",
      " 4   answer            90447 non-null  object\n",
      " 5   _id               90447 non-null  object\n",
      " 6   type              90447 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_question_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "easy      17972\n",
       "hard      15661\n",
       "medium    56814\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of difficulty levels\n",
    "grouped = train_question_df.groupby(['level'])\n",
    "level_counts = grouped.size()  # count of each \n",
    "level_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      90447\n",
       "unique         2\n",
       "top       bridge\n",
       "freq       72991\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.type.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "bridge        72991\n",
       "comparison    17456\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of type\n",
    "grouped = train_question_df.groupby(['type'])\n",
    "type_counts = grouped.size()  # count of each \n",
    "type_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df['context_flattened'] = train_question_df['context'].map(lambda x: list(flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df['context_joint'] = train_question_df['context_flattened'].map(lambda x: \" \".join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df.context_joint  = train_question_df.context_joint.map(_normalize_text)  \n",
    "# train_question_df.context_joint  = train_question_df.context_joint.str.lower().map(lambda x:  \" \".join(re.sub(r'\"', r'', x).split()) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Radio City (Indian radio station), Radio City...</td>\n",
       "      <td>radio city indian radio station radio city is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 supporting_facts   level  \\\n",
       "0  [[Arthur's Magazine, 0], [First for Women, 0]]  medium   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "\n",
       "                                             context             answer  \\\n",
       "0  [[Radio City (Indian radio station), [Radio Ci...  Arthur's Magazine   \n",
       "\n",
       "                        _id        type  \\\n",
       "0  5a7a06935542990198eaf050  comparison   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Radio City (Indian radio station), Radio City...   \n",
       "\n",
       "                                       context_joint  \n",
       "0  radio city indian radio station radio city is ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean        50.891804\n",
       "std         11.363687\n",
       "min          4.000000\n",
       "25%         44.000000\n",
       "50%         50.000000\n",
       "75%         57.000000\n",
       "max        154.000000\n",
       "Name: context_flattened, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.context_flattened.str.len().describe()  # statistic of number of context sentences, including title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_flattened\n",
       "4       8\n",
       "5      35\n",
       "6      49\n",
       "7      44\n",
       "8      49\n",
       "       ..\n",
       "143     2\n",
       "144     1\n",
       "146     4\n",
       "152     1\n",
       "154     2\n",
       "Length: 142, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = train_question_df.groupby(train_question_df.context_flattened.str.len())\n",
    "num_of_context_sentences = grouped.size()  # count of each \n",
    "num_of_context_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3788"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_context_sentences.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of number of context sentences\n",
    "plot = num_of_context_sentences.plot(kind = 'bar', figsize=(15, 7))\n",
    "plt.xticks(rotation=0)                                    # show label text horizontally\n",
    "plt.setp(plot.axes.get_xticklabels(), visible=False)      # hide all labels\n",
    "plt.setp(plot.axes.get_xticklabels()[::5], visible=True)  # set every 5 labels visible\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df.answer = train_question_df.answer.map(_normalize_text)  # apply _normalize_text(answer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean         2.144328\n",
       "std          1.641551\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max         76.000000\n",
       "Name: answer, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.answer.str.split(' ').str.len().describe()  # statistic of number of words in the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer\n",
       "1     32984\n",
       "2     32024\n",
       "3     16665\n",
       "4      4980\n",
       "5      2003\n",
       "6       663\n",
       "7       328\n",
       "8       159\n",
       "9       112\n",
       "10       85\n",
       "11       70\n",
       "12       42\n",
       "13       45\n",
       "14       42\n",
       "15       30\n",
       "16       34\n",
       "17       23\n",
       "18       27\n",
       "19       18\n",
       "20       17\n",
       "21       11\n",
       "22       14\n",
       "23       12\n",
       "24       11\n",
       "25       12\n",
       "26        5\n",
       "27        4\n",
       "28        3\n",
       "29        3\n",
       "30        5\n",
       "31        2\n",
       "32        3\n",
       "33        3\n",
       "34        1\n",
       "35        2\n",
       "38        1\n",
       "40        1\n",
       "57        1\n",
       "72        1\n",
       "76        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = train_question_df.groupby(train_question_df.answer.str.split(' ').str.len())\n",
    "num_of_answer_words = grouped.size()  \n",
    "num_of_answer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of questions with answer 'yes'\n",
    "train_question_df.loc[train_question_df['answer'] == 'yes'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of comparison questions with answer 'yes'\n",
    "train_question_df.loc[(train_question_df['answer'] == 'yes') & (train_question_df['type'] == 'comparison')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of questions with answer 'no'\n",
    "train_question_df.loc[train_question_df['answer'] == 'no'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2735"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of comparison questions with answer 'no'\n",
    "train_question_df.loc[(train_question_df['answer'] == 'no') & (train_question_df['type'] == 'comparison')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "questions with answer yes/no are all comparison questions, and (17456-2735-2748) = 68.6% comparison questions have span answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_question_df[\"normalized_answer_in_context\"] = train_question_df.apply(lambda row: row['answer'] in row['context_joint'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df['normalized_answer_in_context'] = train_question_df.apply(lambda row:  findWord(row['answer'], row['context_joint']) == True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     90447\n",
       "unique        2\n",
       "top        True\n",
       "freq      87837\n",
       "Name: normalized_answer_in_context, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.normalized_answer_in_context.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "87837 questions' answer in the context, 90447-87837 = 2610 questions' answer are not in the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [supporting_facts, level, question, context, answer, _id, type, context_flattened, context_joint, normalized_answer_in_context]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.loc[(train_question_df['normalized_answer_in_context'] == False) & (train_question_df['answer'] != 'yes') & (train_question_df['answer'] != 'no')  & (train_question_df['answer'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2610\n",
       "unique       3\n",
       "top        yes\n",
       "freq      2586\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.loc[(train_question_df['normalized_answer_in_context'] == False)].answer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those answers are not in the context, most normalized_answer are 'yes', some are 'no' and '', only one exception is train_question_df.iloc[38543]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3oh3'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.iloc[38543].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regina spektor regina ilyinichna spektor russian реги́нa ильи́нична спе́ктор born february 18 1980 is russianborn american singersongwriter and pianist she was born in moscow former soviet union now russia and began classical training on piano at age of six when she was nine years old her family emigrated from soviet union to united states where she continued her classical training into her teenage years she began to write original songs shortly thereafter 3oh3 3oh 3 pronounced three oh three is american electronic music duo from boulder colorado made up of sean foreman and nathaniel motte they are best known for their single dont trust me from their album want which reached number seven on billboard hot 100 their second single remix of starstrukk featuring katy perry from want was top ten hit in united kingdom ireland finland poland and australia they gained further recognition by featuring kesha on song my first kiss which was made lead single from their album streets of gold album later peaked at number seven on billboard 200 dont leave me ne me quitte pas dont leave me ne me quitte pas is song by regina spektor from her 2012 album what we saw from cheap seats it was released as albums second single on march 26 2012 although handful of critics assumed this was englishlanguage cover version of jacques brels song ne me quitte pas spektor’s song is different in every way except title chord structure melody and lyrics are all completely different brel’s song was written in key of minor in 34 time it is slow haunting story of man trying to win back his former lover— song about cowardice of men according to brel in contrast spektor’s song is lively in 44 time and in major key its lyrics evoke carefree jaunt through various neighborhoods of new york city narrator describing all beautiful and interesting things encountered along way somehow narrator ends up in cafés and gardens of paris and song ends with repeated declarations of love for paris in rain reptilia song reptilia is song by indie rock band strokes and second single from their second album room on fire singles bside contains modern girls old fashion men where lead singer julian casablancas duets with regina spektor official release date was delayed slightly after casablancas objected to song being credited as strokes and regina spektor claiming that it should read regina spektor and strokes shoplifter records shoplifter records was originally english record company created by producer gordon raphael and paul harrisondisambiguation needed as partnership in 2003 raphael has acted as producer for many bands but most notably for strokes albums is this it and room on fire ↵shoplifter signed regina spektor to her first contract and released album soviet kitsch after teaming up with sony sine for international licensing ↵ ↵other artists to pass through shoplifters doors are satellites anna mercedes miss machine who were actually first release on shoplifter absinthee black light and kill kenada and char johnsonthe following year saw merger of sony music and bmg which also coincided with raphael relocating to berlin labels first single your honour by regina spektor was nme single of week beating brian wilson robbie williams and rem amongst others ↵ album soviet kitsch was voted into top 50 albums in majority of that years music press and broadsheet reviews raphael is currently producing bands internationally but based in berlin since 2005 what we saw from cheap seats what we saw from cheap seats is sixth studio album by american alternative singersongwriter regina spektor on november 21 2011 spektor posted on her facebook page that album had been recorded with mike elizondo in los angeles during summer of 2011 it was released on may 29 2012 album is collection of new material along with very first studio recordings of several of spektors older live songs remember us to life remember us to life is seventh studio album by singersongwriter regina spektor on july 22 2016 spektor announced that it would be released on september 30 2016 lead single of album is bleeding heart which is available to listen in full via soundcloud via spektor herself far album far is fifth studio album by american alternative singersongwriter regina spektor released in europe through sire records on june 22 2009 and north america on june 23 2009 albums first single laughing with was uploaded to spektors myspace page on may 8 and was released as digital download on may 18 in united states and parts of europe along with bside blue lips two viral videos for dance anthem of 80s and eet were also released on spektors myspace account official music video for laughing with was released on itunes on may 26 2009 special edition of album was released with two bonus tracks and dvd which included four music videos us regina spektor song us is fifth track from american singer regina spektors major label debut soviet kitsch it was officially released as single in 2006 for her uk compilation album mary ann meets gravediggers and other short stories by regina spektor song is notable for its use of string quartet in addition to spektors usual piano and vocals song was also used in uefa champions league final montage by itv this song was used in film 500 days of summer fidelity song fidelity is song by american singersongwriter regina spektor released as second single from her fourth album begin to hope song marked spektors first and only billboard 100 entry and is her most successful track to date despite release date of september 25 its popular music video was released even earlier song did not hit charts until december song was released in uk as twopart single on march 12 2007 song making it spektors highestcharting single across world'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.iloc[38543].context_joint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supporting facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df['invalid_supporting_facts_ids'] = train_question_df.apply(lambda row: True in [sp_idx >= len(dict(row['context'])[sp_t]) for (sp_t, sp_idx) in row['supporting_facts']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     90447\n",
       "unique        2\n",
       "top       False\n",
       "freq      90425\n",
       "Name: invalid_supporting_facts_ids, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df['invalid_supporting_facts_ids'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22 questions have at least a supporting fact id out of range. That is, supporting fact id >= total num of sentence in the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>[[Pro Wrestling Fujiwara Gumi, 0], [Pro Wrestl...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What wrestling promotion was formed by the cur...</td>\n",
       "      <td>[[NEVER Openweight Championship, [The NEVER Op...</td>\n",
       "      <td>pro wrestling fujiwara group</td>\n",
       "      <td>5a7b23ca554299042af8f703</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[NEVER Openweight Championship, The NEVER Open...</td>\n",
       "      <td>never openweight championship never openweight...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>[[The Lion King, 0], [Jonathan Taylor Thomas, ...</td>\n",
       "      <td>easy</td>\n",
       "      <td>In the 1994 American animated musical film The...</td>\n",
       "      <td>[[Timon &amp;amp; Pumbaa (TV series), [The Lion Ki...</td>\n",
       "      <td>simba</td>\n",
       "      <td>5abed6d45542990832d3a0ef</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Timon &amp;amp; Pumbaa (TV series), The Lion King...</td>\n",
       "      <td>timon amp pumbaa tv series lion kings timon pu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>[[Suite française (Poulenc), 0], [Francis Poul...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Suite francaise is by what French composer and...</td>\n",
       "      <td>[[Trois morceaux dans le genre pathétique, [Tr...</td>\n",
       "      <td>francis jean marcel poulenc</td>\n",
       "      <td>5ab6b2fb5542995eadef0060</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Trois morceaux dans le genre pathétique, Troi...</td>\n",
       "      <td>trois morceaux dans le genre pathétique trois ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13415</th>\n",
       "      <td>[[Guillermo del Toro, 1], [Pan's Labyrinth, 0]...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which two companies produced the 2006 film dir...</td>\n",
       "      <td>[[The Shape of Water (film), [The Shape of Wat...</td>\n",
       "      <td>esperanto filmoj and warner bros</td>\n",
       "      <td>5ae0e2df5542990adbacf6b1</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[The Shape of Water (film), The Shape of Water...</td>\n",
       "      <td>shape of water film shape of water is 2017 ame...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>[[Harry Potter and the Chamber of Secrets (fil...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which character was played by Rupert Grint in ...</td>\n",
       "      <td>[[Harry Potter and the Deathly Hallows, [Harry...</td>\n",
       "      <td>ron weasley</td>\n",
       "      <td>5a8d6138554299585d9e37c7</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Harry Potter and the Deathly Hallows, Harry P...</td>\n",
       "      <td>harry potter and deathly hallows harry potter ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22896</th>\n",
       "      <td>[[Division of Adelaide, 1], [Walkerville, Sout...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Division of Adelaide includes which one of Ade...</td>\n",
       "      <td>[[Parnell, New Zealand, [Parnell is an upmarke...</td>\n",
       "      <td>walkerville</td>\n",
       "      <td>5ab740165542992aa3b8c7fa</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Parnell, New Zealand, Parnell is an upmarket ...</td>\n",
       "      <td>parnell new zealand parnell is upmarket suburb...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27436</th>\n",
       "      <td>[[Ron Shelton, 0], [Khady Sylla, 0], [Khady Sy...</td>\n",
       "      <td>easy</td>\n",
       "      <td>While Ron Shelton is a film director, what is ...</td>\n",
       "      <td>[[The Best of Times (film), [The Best of Times...</td>\n",
       "      <td>writer of two novels short work and film</td>\n",
       "      <td>5ab2f812554299545a2cfaee</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[The Best of Times (film), The Best of Times i...</td>\n",
       "      <td>best of times film best of times is 1986 ameri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37004</th>\n",
       "      <td>[[Teenage Mutant Ninja Turtles (1990 film), 2]...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Teenage Mutant Ninja Turtles starred the voice...</td>\n",
       "      <td>[[Teenage Mutant Ninja Turtles III: Radical Re...</td>\n",
       "      <td>robert anthony robbie rist</td>\n",
       "      <td>5ae7e8ef5542994a481bbe05</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Teenage Mutant Ninja Turtles III: Radical Res...</td>\n",
       "      <td>teenage mutant ninja turtles iii radical rescu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38579</th>\n",
       "      <td>[[Gaz Coombes, 0], [Gaz Coombes, 2], [Harry St...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Who has played in more bands Gaz Coombes or Ha...</td>\n",
       "      <td>[[Here Come the Bombs, [Here Come the Bombs is...</td>\n",
       "      <td>harry edward styles</td>\n",
       "      <td>5ab273ee5542997061209606</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Here Come the Bombs, Here Come the Bombs is t...</td>\n",
       "      <td>here come bombs here come bombs is debut solo ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41267</th>\n",
       "      <td>[[Samuel P. Cox, 0], [William T. Anderson, 1],...</td>\n",
       "      <td>hard</td>\n",
       "      <td>In what battle did businessman and farmer lead...</td>\n",
       "      <td>[[The Outlaw Josey Wales, [The Outlaw Josey Wa...</td>\n",
       "      <td>battle of albany</td>\n",
       "      <td>5a84517355429933447460d5</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[The Outlaw Josey Wales, The Outlaw Josey Wale...</td>\n",
       "      <td>outlaw josey wales outlaw josey wales is 1976 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45705</th>\n",
       "      <td>[[Elementary School Musical (South Park), 0], ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is the American animated television seari...</td>\n",
       "      <td>[[South Park (season 9), [Season nine of \"Sout...</td>\n",
       "      <td>south park</td>\n",
       "      <td>5a7e5b2455429934daa2fc10</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[South Park (season 9), Season nine of \"South ...</td>\n",
       "      <td>south park season 9 season nine of south park ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49355</th>\n",
       "      <td>[[Altona Christian Community, 0], [Altona Chri...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Who founded the tradition of the Anabaptist co...</td>\n",
       "      <td>[[Community of Jesus, [The Community of Jesus ...</td>\n",
       "      <td>jakob hutter</td>\n",
       "      <td>5a846921554299123d8c2243</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Community of Jesus, The Community of Jesus is...</td>\n",
       "      <td>community of jesus community of jesus is monas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50651</th>\n",
       "      <td>[[Plaza Towers Elementary School, 0], [2013 Mo...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Plaza Towers Elementary School's previous faci...</td>\n",
       "      <td>[[1968 Tracy tornado, [The 1968 Tracy tornado....</td>\n",
       "      <td>377</td>\n",
       "      <td>5add66475542992200553af1</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[1968 Tracy tornado, The 1968 Tracy tornado., ...</td>\n",
       "      <td>1968 tracy tornado 1968 tracy tornado was f5 t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52080</th>\n",
       "      <td>[[Exotic felines as pets, 0], [Exotic felines ...</td>\n",
       "      <td>hard</td>\n",
       "      <td>What generation of a hybrid cat which is a cro...</td>\n",
       "      <td>[[Highlander cat, [The Highlander (also known ...</td>\n",
       "      <td>f5</td>\n",
       "      <td>5a847c91554299123d8c2268</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Highlander cat, The Highlander (also known as...</td>\n",
       "      <td>highlander cat highlander also known as highla...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60885</th>\n",
       "      <td>[[George William Featherstonhaugh, 1], [George...</td>\n",
       "      <td>hard</td>\n",
       "      <td>One of the proposers of the first railroad bui...</td>\n",
       "      <td>[[United New Jersey Railroad and Canal Company...</td>\n",
       "      <td>louisiana purchase</td>\n",
       "      <td>5a7b629555429927d897bfa4</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[United New Jersey Railroad and Canal Company,...</td>\n",
       "      <td>united new jersey railroad and canal company u...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67475</th>\n",
       "      <td>[[Bentley compounds, 1], [Bentley compounds, 2...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Which opioid along with Subutex makes up the t...</td>\n",
       "      <td>[[2018 Campeonato Carioca, [The 2018 Campeonat...</td>\n",
       "      <td>etorphine</td>\n",
       "      <td>5a80577a5542996402f6a4e9</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[2018 Campeonato Carioca, The 2018 Campeonato ...</td>\n",
       "      <td>2018 campeonato carioca 2018 campeonato carioc...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77109</th>\n",
       "      <td>[[Jiminy Glick in Lalawood, 0], [Jiminy Glick ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What festival is the film in which the actress...</td>\n",
       "      <td>[[List of Saturday Night Live episodes, [&lt;sect...</td>\n",
       "      <td>toronto international film festival</td>\n",
       "      <td>5a8164fb5542995ce29dcbf6</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[List of Saturday Night Live episodes, &lt;sectio...</td>\n",
       "      <td>list of saturday night live episodes section b...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85934</th>\n",
       "      <td>[[Carlos Davis, 1], [Drop Dead Fred, 0], [Drop...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which Phoebe Cates film included emotional abuse?</td>\n",
       "      <td>[[Drop Dead Fred, [Drop Dead Fred is a 1991 Br...</td>\n",
       "      <td>drop dead fred</td>\n",
       "      <td>5abe4bb855429965af743eb8</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Drop Dead Fred, Drop Dead Fred is a 1991 Brit...</td>\n",
       "      <td>drop dead fred drop dead fred is 1991 britisha...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86118</th>\n",
       "      <td>[[1989 Valvettiturai massacre, 0], [1989 Valve...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What name did the man who eventually became Ch...</td>\n",
       "      <td>[[Chancellor of Norway, [The Chancellor of Nor...</td>\n",
       "      <td>india’s my lai</td>\n",
       "      <td>5a90abc355429933b8a2058a</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Chancellor of Norway, The Chancellor of Norwa...</td>\n",
       "      <td>chancellor of norway chancellor of norway mode...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86193</th>\n",
       "      <td>[[Rochester College, 0], [Rochester Hills, Mic...</td>\n",
       "      <td>medium</td>\n",
       "      <td>This four-year liberal arts college is located...</td>\n",
       "      <td>[[Coker College, [Coker College is a private, ...</td>\n",
       "      <td>70995</td>\n",
       "      <td>5ab6460b5542995eadeeff96</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Coker College, Coker College is a private, co...</td>\n",
       "      <td>coker college coker college is private coeduca...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88641</th>\n",
       "      <td>[[Ahtyba Rubin, 0], [Ahtyba Rubin, 2], [Iowa S...</td>\n",
       "      <td>easy</td>\n",
       "      <td>American football defensive end Ahtyba Rubin, ...</td>\n",
       "      <td>[[Dwight Nichols, [Dwight Edward Nichols (Octo...</td>\n",
       "      <td>iowa state cyclones football</td>\n",
       "      <td>5a8c7b125542995e66a47614</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Dwight Nichols, Dwight Edward Nichols (Octobe...</td>\n",
       "      <td>dwight nichols dwight edward nichols october 2...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89961</th>\n",
       "      <td>[[Venus (film), 0], [Jodie Whittaker, 0], [Jod...</td>\n",
       "      <td>medium</td>\n",
       "      <td>This British comedy-drama film starred Peter O...</td>\n",
       "      <td>[[Venus (film), [Venus is a 2006 British comed...</td>\n",
       "      <td>broadchurch</td>\n",
       "      <td>5a8a317455429930ff3c0cef</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Venus (film), Venus is a 2006 British comedy-...</td>\n",
       "      <td>venus film venus is 2006 british comedydrama f...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "514    [[Pro Wrestling Fujiwara Gumi, 0], [Pro Wrestl...  medium   \n",
       "8332   [[The Lion King, 0], [Jonathan Taylor Thomas, ...    easy   \n",
       "9548   [[Suite française (Poulenc), 0], [Francis Poul...  medium   \n",
       "13415  [[Guillermo del Toro, 1], [Pan's Labyrinth, 0]...  medium   \n",
       "20594  [[Harry Potter and the Chamber of Secrets (fil...  medium   \n",
       "22896  [[Division of Adelaide, 1], [Walkerville, Sout...  medium   \n",
       "27436  [[Ron Shelton, 0], [Khady Sylla, 0], [Khady Sy...    easy   \n",
       "37004  [[Teenage Mutant Ninja Turtles (1990 film), 2]...  medium   \n",
       "38579  [[Gaz Coombes, 0], [Gaz Coombes, 2], [Harry St...    easy   \n",
       "41267  [[Samuel P. Cox, 0], [William T. Anderson, 1],...    hard   \n",
       "45705  [[Elementary School Musical (South Park), 0], ...  medium   \n",
       "49355  [[Altona Christian Community, 0], [Altona Chri...  medium   \n",
       "50651  [[Plaza Towers Elementary School, 0], [2013 Mo...  medium   \n",
       "52080  [[Exotic felines as pets, 0], [Exotic felines ...    hard   \n",
       "60885  [[George William Featherstonhaugh, 1], [George...    hard   \n",
       "67475  [[Bentley compounds, 1], [Bentley compounds, 2...    hard   \n",
       "77109  [[Jiminy Glick in Lalawood, 0], [Jiminy Glick ...  medium   \n",
       "85934  [[Carlos Davis, 1], [Drop Dead Fred, 0], [Drop...  medium   \n",
       "86118  [[1989 Valvettiturai massacre, 0], [1989 Valve...  medium   \n",
       "86193  [[Rochester College, 0], [Rochester Hills, Mic...  medium   \n",
       "88641  [[Ahtyba Rubin, 0], [Ahtyba Rubin, 2], [Iowa S...    easy   \n",
       "89961  [[Venus (film), 0], [Jodie Whittaker, 0], [Jod...  medium   \n",
       "\n",
       "                                                question  \\\n",
       "514    What wrestling promotion was formed by the cur...   \n",
       "8332   In the 1994 American animated musical film The...   \n",
       "9548   Suite francaise is by what French composer and...   \n",
       "13415  Which two companies produced the 2006 film dir...   \n",
       "20594  Which character was played by Rupert Grint in ...   \n",
       "22896  Division of Adelaide includes which one of Ade...   \n",
       "27436  While Ron Shelton is a film director, what is ...   \n",
       "37004  Teenage Mutant Ninja Turtles starred the voice...   \n",
       "38579  Who has played in more bands Gaz Coombes or Ha...   \n",
       "41267  In what battle did businessman and farmer lead...   \n",
       "45705  What is the American animated television seari...   \n",
       "49355  Who founded the tradition of the Anabaptist co...   \n",
       "50651  Plaza Towers Elementary School's previous faci...   \n",
       "52080  What generation of a hybrid cat which is a cro...   \n",
       "60885  One of the proposers of the first railroad bui...   \n",
       "67475  Which opioid along with Subutex makes up the t...   \n",
       "77109  What festival is the film in which the actress...   \n",
       "85934  Which Phoebe Cates film included emotional abuse?   \n",
       "86118  What name did the man who eventually became Ch...   \n",
       "86193  This four-year liberal arts college is located...   \n",
       "88641  American football defensive end Ahtyba Rubin, ...   \n",
       "89961  This British comedy-drama film starred Peter O...   \n",
       "\n",
       "                                                 context  \\\n",
       "514    [[NEVER Openweight Championship, [The NEVER Op...   \n",
       "8332   [[Timon &amp; Pumbaa (TV series), [The Lion Ki...   \n",
       "9548   [[Trois morceaux dans le genre pathétique, [Tr...   \n",
       "13415  [[The Shape of Water (film), [The Shape of Wat...   \n",
       "20594  [[Harry Potter and the Deathly Hallows, [Harry...   \n",
       "22896  [[Parnell, New Zealand, [Parnell is an upmarke...   \n",
       "27436  [[The Best of Times (film), [The Best of Times...   \n",
       "37004  [[Teenage Mutant Ninja Turtles III: Radical Re...   \n",
       "38579  [[Here Come the Bombs, [Here Come the Bombs is...   \n",
       "41267  [[The Outlaw Josey Wales, [The Outlaw Josey Wa...   \n",
       "45705  [[South Park (season 9), [Season nine of \"Sout...   \n",
       "49355  [[Community of Jesus, [The Community of Jesus ...   \n",
       "50651  [[1968 Tracy tornado, [The 1968 Tracy tornado....   \n",
       "52080  [[Highlander cat, [The Highlander (also known ...   \n",
       "60885  [[United New Jersey Railroad and Canal Company...   \n",
       "67475  [[2018 Campeonato Carioca, [The 2018 Campeonat...   \n",
       "77109  [[List of Saturday Night Live episodes, [<sect...   \n",
       "85934  [[Drop Dead Fred, [Drop Dead Fred is a 1991 Br...   \n",
       "86118  [[Chancellor of Norway, [The Chancellor of Nor...   \n",
       "86193  [[Coker College, [Coker College is a private, ...   \n",
       "88641  [[Dwight Nichols, [Dwight Edward Nichols (Octo...   \n",
       "89961  [[Venus (film), [Venus is a 2006 British comed...   \n",
       "\n",
       "                                         answer                       _id  \\\n",
       "514                pro wrestling fujiwara group  5a7b23ca554299042af8f703   \n",
       "8332                                      simba  5abed6d45542990832d3a0ef   \n",
       "9548                francis jean marcel poulenc  5ab6b2fb5542995eadef0060   \n",
       "13415          esperanto filmoj and warner bros  5ae0e2df5542990adbacf6b1   \n",
       "20594                               ron weasley  5a8d6138554299585d9e37c7   \n",
       "22896                               walkerville  5ab740165542992aa3b8c7fa   \n",
       "27436  writer of two novels short work and film  5ab2f812554299545a2cfaee   \n",
       "37004                robert anthony robbie rist  5ae7e8ef5542994a481bbe05   \n",
       "38579                       harry edward styles  5ab273ee5542997061209606   \n",
       "41267                          battle of albany  5a84517355429933447460d5   \n",
       "45705                                south park  5a7e5b2455429934daa2fc10   \n",
       "49355                              jakob hutter  5a846921554299123d8c2243   \n",
       "50651                                       377  5add66475542992200553af1   \n",
       "52080                                        f5  5a847c91554299123d8c2268   \n",
       "60885                        louisiana purchase  5a7b629555429927d897bfa4   \n",
       "67475                                 etorphine  5a80577a5542996402f6a4e9   \n",
       "77109       toronto international film festival  5a8164fb5542995ce29dcbf6   \n",
       "85934                            drop dead fred  5abe4bb855429965af743eb8   \n",
       "86118                            india’s my lai  5a90abc355429933b8a2058a   \n",
       "86193                                     70995  5ab6460b5542995eadeeff96   \n",
       "88641              iowa state cyclones football  5a8c7b125542995e66a47614   \n",
       "89961                               broadchurch  5a8a317455429930ff3c0cef   \n",
       "\n",
       "             type                                  context_flattened  \\\n",
       "514        bridge  [NEVER Openweight Championship, The NEVER Open...   \n",
       "8332       bridge  [Timon &amp; Pumbaa (TV series), The Lion King...   \n",
       "9548       bridge  [Trois morceaux dans le genre pathétique, Troi...   \n",
       "13415      bridge  [The Shape of Water (film), The Shape of Water...   \n",
       "20594      bridge  [Harry Potter and the Deathly Hallows, Harry P...   \n",
       "22896      bridge  [Parnell, New Zealand, Parnell is an upmarket ...   \n",
       "27436  comparison  [The Best of Times (film), The Best of Times i...   \n",
       "37004      bridge  [Teenage Mutant Ninja Turtles III: Radical Res...   \n",
       "38579  comparison  [Here Come the Bombs, Here Come the Bombs is t...   \n",
       "41267      bridge  [The Outlaw Josey Wales, The Outlaw Josey Wale...   \n",
       "45705      bridge  [South Park (season 9), Season nine of \"South ...   \n",
       "49355      bridge  [Community of Jesus, The Community of Jesus is...   \n",
       "50651      bridge  [1968 Tracy tornado, The 1968 Tracy tornado., ...   \n",
       "52080      bridge  [Highlander cat, The Highlander (also known as...   \n",
       "60885      bridge  [United New Jersey Railroad and Canal Company,...   \n",
       "67475      bridge  [2018 Campeonato Carioca, The 2018 Campeonato ...   \n",
       "77109      bridge  [List of Saturday Night Live episodes, <sectio...   \n",
       "85934      bridge  [Drop Dead Fred, Drop Dead Fred is a 1991 Brit...   \n",
       "86118      bridge  [Chancellor of Norway, The Chancellor of Norwa...   \n",
       "86193      bridge  [Coker College, Coker College is a private, co...   \n",
       "88641      bridge  [Dwight Nichols, Dwight Edward Nichols (Octobe...   \n",
       "89961      bridge  [Venus (film), Venus is a 2006 British comedy-...   \n",
       "\n",
       "                                           context_joint  \\\n",
       "514    never openweight championship never openweight...   \n",
       "8332   timon amp pumbaa tv series lion kings timon pu...   \n",
       "9548   trois morceaux dans le genre pathétique trois ...   \n",
       "13415  shape of water film shape of water is 2017 ame...   \n",
       "20594  harry potter and deathly hallows harry potter ...   \n",
       "22896  parnell new zealand parnell is upmarket suburb...   \n",
       "27436  best of times film best of times is 1986 ameri...   \n",
       "37004  teenage mutant ninja turtles iii radical rescu...   \n",
       "38579  here come bombs here come bombs is debut solo ...   \n",
       "41267  outlaw josey wales outlaw josey wales is 1976 ...   \n",
       "45705  south park season 9 season nine of south park ...   \n",
       "49355  community of jesus community of jesus is monas...   \n",
       "50651  1968 tracy tornado 1968 tracy tornado was f5 t...   \n",
       "52080  highlander cat highlander also known as highla...   \n",
       "60885  united new jersey railroad and canal company u...   \n",
       "67475  2018 campeonato carioca 2018 campeonato carioc...   \n",
       "77109  list of saturday night live episodes section b...   \n",
       "85934  drop dead fred drop dead fred is 1991 britisha...   \n",
       "86118  chancellor of norway chancellor of norway mode...   \n",
       "86193  coker college coker college is private coeduca...   \n",
       "88641  dwight nichols dwight edward nichols october 2...   \n",
       "89961  venus film venus is 2006 british comedydrama f...   \n",
       "\n",
       "       normalized_answer_in_context  invalid_supporting_facts_ids  \n",
       "514                            True                          True  \n",
       "8332                           True                          True  \n",
       "9548                           True                          True  \n",
       "13415                          True                          True  \n",
       "20594                          True                          True  \n",
       "22896                          True                          True  \n",
       "27436                          True                          True  \n",
       "37004                          True                          True  \n",
       "38579                          True                          True  \n",
       "41267                          True                          True  \n",
       "45705                          True                          True  \n",
       "49355                          True                          True  \n",
       "50651                          True                          True  \n",
       "52080                          True                          True  \n",
       "60885                          True                          True  \n",
       "67475                          True                          True  \n",
       "77109                          True                          True  \n",
       "85934                          True                          True  \n",
       "86118                          True                          True  \n",
       "86193                          True                          True  \n",
       "88641                          True                          True  \n",
       "89961                          True                          True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.loc[train_question_df['invalid_supporting_facts_ids']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Minoru Suzuki', ['Minoru Suzuki (鈴木 実 , Suzuki Minoru , ring name: 鈴木 みのる) (born June 17, 1968) is a Japanese professional wrestler and mixed martial artist who is currently working for New Japan Pro Wrestling (NJPW) as a freelancer.', ' He is the current NEVER Openweight Champion in his first reign.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_question_df.iloc[514].context[7])\n",
    "len(train_question_df.iloc[514].context[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_df['supporting_fact_text'] = train_question_df.apply(lambda row: [_normalize_text(dict(row['context'])[sp_t][sp_idx]) for (sp_t, sp_idx) in row['supporting_facts'] if(sp_idx < len(dict(row['context'])[sp_t])) ], axis = 1)\n",
    "\n",
    "# train_question_df['supporting_fact_text'] = train_question_df.apply(lambda row: ['<t> ' + _normalize_text(sp_t) + ' </t> ' + _normalize_text(dict(row['context'])[sp_t][sp_idx]) + ' [/sent]' for (sp_t, sp_idx) in row['supporting_facts'] if(sp_idx < len(dict(row['context'])[sp_t])) ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>arthurs magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Radio City (Indian radio station), Radio City...</td>\n",
       "      <td>radio city indian radio station radio city is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[arthurs magazine 1844–1846 was american liter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "      <td>delhi</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Ritz-Carlton Jakarta, The Ritz-Carlton Jakart...</td>\n",
       "      <td>ritzcarlton jakarta ritzcarlton jakarta is hot...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[oberoi family is indian family that is famous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>president richard nixon</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Lisa Simpson, Lisa Marie Simpson is a fiction...</td>\n",
       "      <td>lisa simpson lisa marie simpson is fictional c...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[allison beth allie goertz born march 2 1991 i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    supporting_facts   level  \\\n",
       "0     [[Arthur's Magazine, 0], [First for Women, 0]]  medium   \n",
       "1        [[Oberoi family, 0], [The Oberoi Group, 0]]  medium   \n",
       "2  [[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...    hard   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "\n",
       "                                             context                   answer  \\\n",
       "0  [[Radio City (Indian radio station), [Radio Ci...         arthurs magazine   \n",
       "1  [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...                    delhi   \n",
       "2  [[Lisa Simpson, [Lisa Marie Simpson is a ficti...  president richard nixon   \n",
       "\n",
       "                        _id        type  \\\n",
       "0  5a7a06935542990198eaf050  comparison   \n",
       "1  5a879ab05542996e4f30887e      bridge   \n",
       "2  5a8d7341554299441c6b9fe5      bridge   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Radio City (Indian radio station), Radio City...   \n",
       "1  [Ritz-Carlton Jakarta, The Ritz-Carlton Jakart...   \n",
       "2  [Lisa Simpson, Lisa Marie Simpson is a fiction...   \n",
       "\n",
       "                                       context_joint  \\\n",
       "0  radio city indian radio station radio city is ...   \n",
       "1  ritzcarlton jakarta ritzcarlton jakarta is hot...   \n",
       "2  lisa simpson lisa marie simpson is fictional c...   \n",
       "\n",
       "   normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "0                          True                         False   \n",
       "1                          True                         False   \n",
       "2                          True                         False   \n",
       "\n",
       "                                supporting_fact_text  \n",
       "0  [arthurs magazine 1844–1846 was american liter...  \n",
       "1  [oberoi family is indian family that is famous...  \n",
       "2  [allison beth allie goertz born march 2 1991 i...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to count the number of supporting facts\n",
    "train_question_df['num_of_supporting_facts'] = train_question_df.supporting_fact_text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean         2.384402\n",
       "std          0.672601\n",
       "min          2.000000\n",
       "25%          2.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max         12.000000\n",
       "Name: num_of_supporting_facts, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts\n",
    "train_question_df.num_of_supporting_facts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_supporting_facts\n",
       "2     63685\n",
       "3     20019\n",
       "4      5805\n",
       "5       722\n",
       "6       141\n",
       "7        52\n",
       "8        17\n",
       "9         4\n",
       "11        1\n",
       "12        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts\n",
    "grouped = train_question_df.groupby(['num_of_supporting_facts'])\n",
    "num_of_supporting_facts_counts = grouped.size()  # count of each \n",
    "num_of_supporting_facts_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>[[Kazuo Ishiguro, 0], [Kazuo Ishiguro, 1], [Ka...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Did Kazuo Ishiguro and Yukio Mishima both move...</td>\n",
       "      <td>[[Five Modern Noh Plays, [Five Modern Nō Plays...</td>\n",
       "      <td>no</td>\n",
       "      <td>5a7f6b0a5542992097ad2f5e</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Five Modern Noh Plays, Five Modern Nō Plays i...</td>\n",
       "      <td>five modern noh plays five modern nō plays is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kazuo ishiguro obe frsa frsl japanese カズオ・イシグ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>[[Margaret MacDonald (visionary), 3], [Margare...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Apart from the founder of the Exclusive Brethr...</td>\n",
       "      <td>[[Behind the Exclusive Brethren, [Behind the E...</td>\n",
       "      <td>benjamin wills newton</td>\n",
       "      <td>5a8299e255429954d2e2eb76</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Behind the Exclusive Brethren, Behind the Exc...</td>\n",
       "      <td>behind exclusive brethren behind exclusive bre...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[in response isabella and mary campbell of par...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>[[Rowland Brown, 0], [Rowland Brown, 1], [Rowl...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Who won more Grammy Awards, Mike Nichols or Ro...</td>\n",
       "      <td>[[Mike Nichols: American Masters, [Mike Nichol...</td>\n",
       "      <td>mike nichols</td>\n",
       "      <td>5a82f46255429966c78a6ab2</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Mike Nichols: American Masters, Mike Nichols:...</td>\n",
       "      <td>mike nichols american masters mike nichols ame...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[rowland brown november 6 1900 – may 6 1963 bo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55922</th>\n",
       "      <td>[[Mental Floss, 0], [Mental Floss, 1], [Mental...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Is the Mental Floss paragraph related to the D...</td>\n",
       "      <td>[[Mental Floss, [Mental Floss (stylized mental...</td>\n",
       "      <td>no</td>\n",
       "      <td>5ab2b513554299340b525549</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Mental Floss, Mental Floss (stylized mental_f...</td>\n",
       "      <td>mental floss mental floss stylized mentalfloss...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[mental floss stylized mentalfloss is american...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61537</th>\n",
       "      <td>[[The Final Solution (novel), 0], [The Final S...</td>\n",
       "      <td>hard</td>\n",
       "      <td>The Final Solution pays homage to a series whe...</td>\n",
       "      <td>[[Sherlock Holmes (1951 TV series), [Sherlock ...</td>\n",
       "      <td>crime</td>\n",
       "      <td>5a8f2b2f55429918e830d1b7</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Sherlock Holmes (1951 TV series), Sherlock Ho...</td>\n",
       "      <td>sherlock holmes 1951 tv series sherlock holmes...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[final solution story of detection is 2004 nov...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72623</th>\n",
       "      <td>[[Too Weird to Live, Too Rare to Die!, 0], [To...</td>\n",
       "      <td>hard</td>\n",
       "      <td>What was the name of the drummer on the Panic ...</td>\n",
       "      <td>[[Jake Sinclair (musician), [Jake Sinclair (bo...</td>\n",
       "      <td>spencer smith</td>\n",
       "      <td>5ab523a055429942dd415ff9</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Jake Sinclair (musician), Jake Sinclair (born...</td>\n",
       "      <td>jake sinclair musician jake sinclair born marc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[too weird to live too rare to die, is fourth ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "1722   [[Kazuo Ishiguro, 0], [Kazuo Ishiguro, 1], [Ka...  medium   \n",
       "2061   [[Margaret MacDonald (visionary), 3], [Margare...    hard   \n",
       "11275  [[Rowland Brown, 0], [Rowland Brown, 1], [Rowl...  medium   \n",
       "55922  [[Mental Floss, 0], [Mental Floss, 1], [Mental...    easy   \n",
       "61537  [[The Final Solution (novel), 0], [The Final S...    hard   \n",
       "72623  [[Too Weird to Live, Too Rare to Die!, 0], [To...    hard   \n",
       "\n",
       "                                                question  \\\n",
       "1722   Did Kazuo Ishiguro and Yukio Mishima both move...   \n",
       "2061   Apart from the founder of the Exclusive Brethr...   \n",
       "11275  Who won more Grammy Awards, Mike Nichols or Ro...   \n",
       "55922  Is the Mental Floss paragraph related to the D...   \n",
       "61537  The Final Solution pays homage to a series whe...   \n",
       "72623  What was the name of the drummer on the Panic ...   \n",
       "\n",
       "                                                 context  \\\n",
       "1722   [[Five Modern Noh Plays, [Five Modern Nō Plays...   \n",
       "2061   [[Behind the Exclusive Brethren, [Behind the E...   \n",
       "11275  [[Mike Nichols: American Masters, [Mike Nichol...   \n",
       "55922  [[Mental Floss, [Mental Floss (stylized mental...   \n",
       "61537  [[Sherlock Holmes (1951 TV series), [Sherlock ...   \n",
       "72623  [[Jake Sinclair (musician), [Jake Sinclair (bo...   \n",
       "\n",
       "                      answer                       _id        type  \\\n",
       "1722                      no  5a7f6b0a5542992097ad2f5e  comparison   \n",
       "2061   benjamin wills newton  5a8299e255429954d2e2eb76      bridge   \n",
       "11275           mike nichols  5a82f46255429966c78a6ab2  comparison   \n",
       "55922                     no  5ab2b513554299340b525549  comparison   \n",
       "61537                  crime  5a8f2b2f55429918e830d1b7      bridge   \n",
       "72623          spencer smith  5ab523a055429942dd415ff9      bridge   \n",
       "\n",
       "                                       context_flattened  \\\n",
       "1722   [Five Modern Noh Plays, Five Modern Nō Plays i...   \n",
       "2061   [Behind the Exclusive Brethren, Behind the Exc...   \n",
       "11275  [Mike Nichols: American Masters, Mike Nichols:...   \n",
       "55922  [Mental Floss, Mental Floss (stylized mental_f...   \n",
       "61537  [Sherlock Holmes (1951 TV series), Sherlock Ho...   \n",
       "72623  [Jake Sinclair (musician), Jake Sinclair (born...   \n",
       "\n",
       "                                           context_joint  \\\n",
       "1722   five modern noh plays five modern nō plays is ...   \n",
       "2061   behind exclusive brethren behind exclusive bre...   \n",
       "11275  mike nichols american masters mike nichols ame...   \n",
       "55922  mental floss mental floss stylized mentalfloss...   \n",
       "61537  sherlock holmes 1951 tv series sherlock holmes...   \n",
       "72623  jake sinclair musician jake sinclair born marc...   \n",
       "\n",
       "       normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "1722                           True                         False   \n",
       "2061                           True                         False   \n",
       "11275                          True                         False   \n",
       "55922                          True                         False   \n",
       "61537                          True                         False   \n",
       "72623                          True                         False   \n",
       "\n",
       "                                    supporting_fact_text  \\\n",
       "1722   [kazuo ishiguro obe frsa frsl japanese カズオ・イシグ...   \n",
       "2061   [in response isabella and mary campbell of par...   \n",
       "11275  [rowland brown november 6 1900 – may 6 1963 bo...   \n",
       "55922  [mental floss stylized mentalfloss is american...   \n",
       "61537  [final solution story of detection is 2004 nov...   \n",
       "72623  [too weird to live too rare to die, is fourth ...   \n",
       "\n",
       "       num_of_supporting_facts  \n",
       "1722                        12  \n",
       "2061                         9  \n",
       "11275                        9  \n",
       "55922                       11  \n",
       "61537                        9  \n",
       "72623                        9  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check thoese questions with more than 8 supportiing facts\n",
    "train_question_df.loc[train_question_df.num_of_supporting_facts > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [True, False]\n",
       "1                      [False, True]\n",
       "2        [False, False, False, True]\n",
       "3               [True, False, False]\n",
       "4                       [True, True]\n",
       "                    ...             \n",
       "90442                  [False, True]\n",
       "90443            [False, True, True]\n",
       "90444                  [False, True]\n",
       "90445                   [True, True]\n",
       "90446            [False, True, True]\n",
       "Name: normalized_answer_in_supporting_fact, Length: 90447, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column: whether each supporting fact contains the answer string or not\n",
    "train_question_df['normalized_answer_in_supporting_fact'] = train_question_df.apply(lambda row: [ findWord(row['answer'], f) == True for f in row['supporting_fact_text']], axis = 1)\n",
    "train_question_df['normalized_answer_in_supporting_fact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>arthurs magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Radio City (Indian radio station), Radio City...</td>\n",
       "      <td>radio city indian radio station radio city is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[arthurs magazine 1844–1846 was american liter...</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "      <td>delhi</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Ritz-Carlton Jakarta, The Ritz-Carlton Jakart...</td>\n",
       "      <td>ritzcarlton jakarta ritzcarlton jakarta is hot...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[oberoi family is indian family that is famous...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>president richard nixon</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Lisa Simpson, Lisa Marie Simpson is a fiction...</td>\n",
       "      <td>lisa simpson lisa marie simpson is fictional c...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[allison beth allie goertz born march 2 1991 i...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    supporting_facts   level  \\\n",
       "0     [[Arthur's Magazine, 0], [First for Women, 0]]  medium   \n",
       "1        [[Oberoi family, 0], [The Oberoi Group, 0]]  medium   \n",
       "2  [[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...    hard   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "\n",
       "                                             context                   answer  \\\n",
       "0  [[Radio City (Indian radio station), [Radio Ci...         arthurs magazine   \n",
       "1  [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...                    delhi   \n",
       "2  [[Lisa Simpson, [Lisa Marie Simpson is a ficti...  president richard nixon   \n",
       "\n",
       "                        _id        type  \\\n",
       "0  5a7a06935542990198eaf050  comparison   \n",
       "1  5a879ab05542996e4f30887e      bridge   \n",
       "2  5a8d7341554299441c6b9fe5      bridge   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Radio City (Indian radio station), Radio City...   \n",
       "1  [Ritz-Carlton Jakarta, The Ritz-Carlton Jakart...   \n",
       "2  [Lisa Simpson, Lisa Marie Simpson is a fiction...   \n",
       "\n",
       "                                       context_joint  \\\n",
       "0  radio city indian radio station radio city is ...   \n",
       "1  ritzcarlton jakarta ritzcarlton jakarta is hot...   \n",
       "2  lisa simpson lisa marie simpson is fictional c...   \n",
       "\n",
       "   normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "0                          True                         False   \n",
       "1                          True                         False   \n",
       "2                          True                         False   \n",
       "\n",
       "                                supporting_fact_text  num_of_supporting_facts  \\\n",
       "0  [arthurs magazine 1844–1846 was american liter...                        2   \n",
       "1  [oberoi family is indian family that is famous...                        2   \n",
       "2  [allison beth allie goertz born march 2 1991 i...                        4   \n",
       "\n",
       "  normalized_answer_in_supporting_fact  \n",
       "0                        [True, False]  \n",
       "1                        [False, True]  \n",
       "2          [False, False, False, True]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[[Jane (magazine), 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are Jane and First for Women both women's maga...</td>\n",
       "      <td>[[List of magazines in Malaysia, [The first wo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5ac061ab554299294b218fac</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[List of magazines in Malaysia, The first wome...</td>\n",
       "      <td>list of magazines in malaysia first womens mag...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[jane was american magazine created to appeal ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[[Gin and tonic, 0], [Paloma (cocktail), 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are Gin and tonic and Paloma both cocktails ba...</td>\n",
       "      <td>[[Parallel key, [In music, a major scale and a...</td>\n",
       "      <td>no</td>\n",
       "      <td>5ac3ad225542995ef918c1da</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Parallel key, In music, a major scale and a m...</td>\n",
       "      <td>parallel key in music major scale and minor sc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[gin and tonic is highball cocktail made with ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[[Tim McIlrath, 0], [Spike Slawson, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are both Tim McIlrath and Spike Slawson Americ...</td>\n",
       "      <td>[[Give It All, [\"Give It All\" is a song by Ame...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5ae3345f55429928c4239682</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Give It All, \"Give It All\" is a song by Ameri...</td>\n",
       "      <td>give it all give it all is song by american ro...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[timothy james tim mcilrath born november 3 19...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[[Pam Veasey, 0], [Jon Jost, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are Pam Veasey and Jon Jost both American?</td>\n",
       "      <td>[[Pam Veasey, [Pamela Renea Veasey (born May 2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5abb1f745542996cc5e49fb5</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Pam Veasey, Pamela Renea Veasey (born May 25,...</td>\n",
       "      <td>pam veasey pamela renea veasey born may 25 196...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[pamela renea veasey born may 25 1962 is ameri...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[Augusta Canal, 1], [New Orleans Outfall Cana...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Are the New Orleans Outfall Canals the same le...</td>\n",
       "      <td>[[Augusta Canal, [The Augusta Canal is a histo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5ac3e8c65542997ea680c993</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Augusta Canal, The Augusta Canal is a histori...</td>\n",
       "      <td>augusta canal augusta canal is historic canal ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[canal is fed by savannah river and passes thr...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90368</th>\n",
       "      <td>[[Daniel Vacek, 0], [Patty Fendick, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are Daniel Vacek and Patty Fendick both former...</td>\n",
       "      <td>[[Patty Fendick, [Patty Fendick (born March 31...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5a8f73b0554299458435d62b</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Patty Fendick, Patty Fendick (born March 31, ...</td>\n",
       "      <td>patty fendick patty fendick born march 31 1965...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[daniel vacek born 1 april 1971 is former tenn...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90377</th>\n",
       "      <td>[[Garo Yepremian, 0], [Edward Manukyan, 0]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>Garo Yepremian and Edward Manukyan, live in th...</td>\n",
       "      <td>[[2013 International Champions Cup, [The 2013 ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5ae36d6d5542992e3233c3f9</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[2013 International Champions Cup, The 2013 In...</td>\n",
       "      <td>2013 international champions cup 2013 internat...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[garabed sarkis garo yepremian june 2 1944 – m...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90388</th>\n",
       "      <td>[[Philippe Perrin, 0], [Umberto Guidoni, 0], [...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Are both Philippe Perrin and Umberto Guidoni c...</td>\n",
       "      <td>[[Philippe Perrin (artist), [Philippe Perrin, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5a8db41c554299068b959dc8</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Philippe Perrin (artist), Philippe Perrin, (L...</td>\n",
       "      <td>philippe perrin artist philippe perrin la tron...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[philippe perrin colonel french air force born...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90434</th>\n",
       "      <td>[[Aglaia, 0], [Valeriana, 0]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>Does Aglaia belongs to Mahogany family and Val...</td>\n",
       "      <td>[[Valeriana celtica, [Valeriana celtica is a s...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5a858b9c5542994c784ddb23</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Valeriana celtica, Valeriana celtica is a spe...</td>\n",
       "      <td>valeriana celtica valeriana celtica is species...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[aglaia is genus of more than 390 species belo...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90437</th>\n",
       "      <td>[[Fraxinus, 0], [Fraxinus, 2], [Onoclea, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Can Fraxinus and Onoclea both be found in Nort...</td>\n",
       "      <td>[[Fraxinus, [Fraxinus , English name ash, is a...</td>\n",
       "      <td>yes</td>\n",
       "      <td>5ac304bb5542990b17b154dd</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Fraxinus, Fraxinus , English name ash, is a g...</td>\n",
       "      <td>fraxinus fraxinus english name ash is genus of...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[fraxinus english name ash is genus of floweri...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3964 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "32          [[Jane (magazine), 0], [First for Women, 0]]  medium   \n",
       "49          [[Gin and tonic, 0], [Paloma (cocktail), 0]]  medium   \n",
       "67               [[Tim McIlrath, 0], [Spike Slawson, 0]]  medium   \n",
       "87                      [[Pam Veasey, 0], [Jon Jost, 0]]  medium   \n",
       "89     [[Augusta Canal, 1], [New Orleans Outfall Cana...    hard   \n",
       "...                                                  ...     ...   \n",
       "90368            [[Daniel Vacek, 0], [Patty Fendick, 0]]  medium   \n",
       "90377        [[Garo Yepremian, 0], [Edward Manukyan, 0]]    easy   \n",
       "90388  [[Philippe Perrin, 0], [Umberto Guidoni, 0], [...  medium   \n",
       "90434                      [[Aglaia, 0], [Valeriana, 0]]    easy   \n",
       "90437       [[Fraxinus, 0], [Fraxinus, 2], [Onoclea, 0]]  medium   \n",
       "\n",
       "                                                question  \\\n",
       "32     Are Jane and First for Women both women's maga...   \n",
       "49     Are Gin and tonic and Paloma both cocktails ba...   \n",
       "67     Are both Tim McIlrath and Spike Slawson Americ...   \n",
       "87            Are Pam Veasey and Jon Jost both American?   \n",
       "89     Are the New Orleans Outfall Canals the same le...   \n",
       "...                                                  ...   \n",
       "90368  Are Daniel Vacek and Patty Fendick both former...   \n",
       "90377  Garo Yepremian and Edward Manukyan, live in th...   \n",
       "90388  Are both Philippe Perrin and Umberto Guidoni c...   \n",
       "90434  Does Aglaia belongs to Mahogany family and Val...   \n",
       "90437  Can Fraxinus and Onoclea both be found in Nort...   \n",
       "\n",
       "                                                 context answer  \\\n",
       "32     [[List of magazines in Malaysia, [The first wo...    yes   \n",
       "49     [[Parallel key, [In music, a major scale and a...     no   \n",
       "67     [[Give It All, [\"Give It All\" is a song by Ame...    yes   \n",
       "87     [[Pam Veasey, [Pamela Renea Veasey (born May 2...    yes   \n",
       "89     [[Augusta Canal, [The Augusta Canal is a histo...    yes   \n",
       "...                                                  ...    ...   \n",
       "90368  [[Patty Fendick, [Patty Fendick (born March 31...    yes   \n",
       "90377  [[2013 International Champions Cup, [The 2013 ...    yes   \n",
       "90388  [[Philippe Perrin (artist), [Philippe Perrin, ...    yes   \n",
       "90434  [[Valeriana celtica, [Valeriana celtica is a s...    yes   \n",
       "90437  [[Fraxinus, [Fraxinus , English name ash, is a...    yes   \n",
       "\n",
       "                            _id        type  \\\n",
       "32     5ac061ab554299294b218fac  comparison   \n",
       "49     5ac3ad225542995ef918c1da  comparison   \n",
       "67     5ae3345f55429928c4239682  comparison   \n",
       "87     5abb1f745542996cc5e49fb5  comparison   \n",
       "89     5ac3e8c65542997ea680c993  comparison   \n",
       "...                         ...         ...   \n",
       "90368  5a8f73b0554299458435d62b  comparison   \n",
       "90377  5ae36d6d5542992e3233c3f9  comparison   \n",
       "90388  5a8db41c554299068b959dc8  comparison   \n",
       "90434  5a858b9c5542994c784ddb23  comparison   \n",
       "90437  5ac304bb5542990b17b154dd  comparison   \n",
       "\n",
       "                                       context_flattened  \\\n",
       "32     [List of magazines in Malaysia, The first wome...   \n",
       "49     [Parallel key, In music, a major scale and a m...   \n",
       "67     [Give It All, \"Give It All\" is a song by Ameri...   \n",
       "87     [Pam Veasey, Pamela Renea Veasey (born May 25,...   \n",
       "89     [Augusta Canal, The Augusta Canal is a histori...   \n",
       "...                                                  ...   \n",
       "90368  [Patty Fendick, Patty Fendick (born March 31, ...   \n",
       "90377  [2013 International Champions Cup, The 2013 In...   \n",
       "90388  [Philippe Perrin (artist), Philippe Perrin, (L...   \n",
       "90434  [Valeriana celtica, Valeriana celtica is a spe...   \n",
       "90437  [Fraxinus, Fraxinus , English name ash, is a g...   \n",
       "\n",
       "                                           context_joint  \\\n",
       "32     list of magazines in malaysia first womens mag...   \n",
       "49     parallel key in music major scale and minor sc...   \n",
       "67     give it all give it all is song by american ro...   \n",
       "87     pam veasey pamela renea veasey born may 25 196...   \n",
       "89     augusta canal augusta canal is historic canal ...   \n",
       "...                                                  ...   \n",
       "90368  patty fendick patty fendick born march 31 1965...   \n",
       "90377  2013 international champions cup 2013 internat...   \n",
       "90388  philippe perrin artist philippe perrin la tron...   \n",
       "90434  valeriana celtica valeriana celtica is species...   \n",
       "90437  fraxinus fraxinus english name ash is genus of...   \n",
       "\n",
       "       normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "32                            False                         False   \n",
       "49                             True                         False   \n",
       "67                            False                         False   \n",
       "87                            False                         False   \n",
       "89                            False                         False   \n",
       "...                             ...                           ...   \n",
       "90368                         False                         False   \n",
       "90377                         False                         False   \n",
       "90388                         False                         False   \n",
       "90434                         False                         False   \n",
       "90437                         False                         False   \n",
       "\n",
       "                                    supporting_fact_text  \\\n",
       "32     [jane was american magazine created to appeal ...   \n",
       "49     [gin and tonic is highball cocktail made with ...   \n",
       "67     [timothy james tim mcilrath born november 3 19...   \n",
       "87     [pamela renea veasey born may 25 1962 is ameri...   \n",
       "89     [canal is fed by savannah river and passes thr...   \n",
       "...                                                  ...   \n",
       "90368  [daniel vacek born 1 april 1971 is former tenn...   \n",
       "90377  [garabed sarkis garo yepremian june 2 1944 – m...   \n",
       "90388  [philippe perrin colonel french air force born...   \n",
       "90434  [aglaia is genus of more than 390 species belo...   \n",
       "90437  [fraxinus english name ash is genus of floweri...   \n",
       "\n",
       "       num_of_supporting_facts normalized_answer_in_supporting_fact  \n",
       "32                           2                       [False, False]  \n",
       "49                           2                       [False, False]  \n",
       "67                           2                       [False, False]  \n",
       "87                           2                       [False, False]  \n",
       "89                           2                       [False, False]  \n",
       "...                        ...                                  ...  \n",
       "90368                        2                       [False, False]  \n",
       "90377                        2                       [False, False]  \n",
       "90388                        3                [False, False, False]  \n",
       "90434                        2                       [False, False]  \n",
       "90437                        3                [False, False, False]  \n",
       "\n",
       "[3964 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions that none of its supporting facts contains the answer string\n",
    "# that is, rows that train_question_df['supporting_fact_contain_answer'] is a list of false\n",
    "train_question_df[train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x)))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, there are 3964 such questions that the answer string is not in any of the supporting facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions that none of its supporting facts contains the answer string, and its answer is neither 'yes' nor 'no'\n",
    "train_question_df.loc[train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x))) & (train_question_df['answer'] != 'yes') & (train_question_df['answer'] != 'no') & (train_question_df['answer'] != '') ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>[[Skillet (band), 1], [Portugal. The Man, 2]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>Which rock band has more members, Skillet or P...</td>\n",
       "      <td>[[Alien Youth, [Alien Youth is the fifth album...</td>\n",
       "      <td>portugal man</td>\n",
       "      <td>5a7a870d55429941d65f2688</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Alien Youth, Alien Youth is the fifth album r...</td>\n",
       "      <td>alien youth alien youth is fifth album release...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[band currently consists of husband john lead ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>[[Tax Reduction and Simplification Act of 1977...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Was the president who signed the The Tax Reduc...</td>\n",
       "      <td>[[Tax Reduction and Simplification Act of 1977...</td>\n",
       "      <td>james earl carter jr born october 1 1924 is am...</td>\n",
       "      <td>5ac2a89c55429921a00ab022</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Tax Reduction and Simplification Act of 1977,...</td>\n",
       "      <td>tax reduction and simplification act of 1977 t...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[tax reduction and simplification act of 1977 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>[[Kirsty MacColl, 0], [Portugal. The Man, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Who is more likely to visit alaska,  Portugal....</td>\n",
       "      <td>[[Hallelujah (EP), [Hallelujah is a 7-track EP...</td>\n",
       "      <td>portugal man</td>\n",
       "      <td>5abbf2475542993f40c73c25</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Hallelujah (EP), Hallelujah is a 7-track EP b...</td>\n",
       "      <td>hallelujah ep hallelujah is 7track ep by madch...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kirsty anna maccoll 10 october 1959 – 18 dece...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>[[Ivan Allen Jr. Prize for Progress and Servic...</td>\n",
       "      <td>easy</td>\n",
       "      <td>What award is issued by the Georgia Institute ...</td>\n",
       "      <td>[[Gary Pomerantz, [Gary M. Pomerantz (born Nov...</td>\n",
       "      <td>ivan allen jr prize for social courage</td>\n",
       "      <td>5a7e43155542991319bc9457</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Gary Pomerantz, Gary M. Pomerantz (born Novem...</td>\n",
       "      <td>gary pomerantz gary m pomerantz born november ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[prior to ivan allen jr, prize for progress se...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15236</th>\n",
       "      <td>[[Lego DC Super Hero Girls: Brain Drain, 0], [...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is the name of this animation division of...</td>\n",
       "      <td>[[Lego Batman 2: DC Super Heroes, [Lego Batman...</td>\n",
       "      <td>warner bros animation</td>\n",
       "      <td>5ab856dd55429934fafe6d6e</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Lego Batman 2: DC Super Heroes, Lego Batman 2...</td>\n",
       "      <td>lego batman 2 dc super heroes lego batman 2 dc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[lego dc super hero girls brain drain is upcom...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17033</th>\n",
       "      <td>[[Patrick Stump, 0], [Jun. K, 0]]</td>\n",
       "      <td>hard</td>\n",
       "      <td>Who is younger, Patrick Stump or Jun. K?</td>\n",
       "      <td>[[Soul Punk, [Soul Punk is the first full-leng...</td>\n",
       "      <td>jun k</td>\n",
       "      <td>5a7939fd55429970f5fffe7e</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Soul Punk, Soul Punk is the first full-length...</td>\n",
       "      <td>soul punk soul punk is first fulllength solo s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[patrick martin stumph born april 27 1984 know...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24309</th>\n",
       "      <td>[[Paul Norris (visual effects), 1], [Harry Pot...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Paul Norris is a British visual effects superv...</td>\n",
       "      <td>[[Harry Potter and the Chamber of Secrets (fil...</td>\n",
       "      <td>warner bros pictures</td>\n",
       "      <td>5a8f3aac55429918e830d1db</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Harry Potter and the Chamber of Secrets (film...</td>\n",
       "      <td>harry potter and chamber of secrets film harry...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[best known for his works in harry potter and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>[[Alshard, 4], [Standard RPG System, 1], [Stan...</td>\n",
       "      <td>hard</td>\n",
       "      <td>What is the newest game that uses the game sys...</td>\n",
       "      <td>[[3d20 system, [The 3d20 system is the role-pl...</td>\n",
       "      <td>full metal panic rpg</td>\n",
       "      <td>5abc573d55429959677d6a8a</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[3d20 system, The 3d20 system is the role-play...</td>\n",
       "      <td>3d20 system 3d20 system is roleplaying game sy...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[alshards game system is named standard rpg sy...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31461</th>\n",
       "      <td>[[American Chopper, 3], [Paul Jr. Designs, 1]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>What lifestyle brand motorcycle customizer and...</td>\n",
       "      <td>[[Paul Jr. Designs, [Paul Jr.,  Designs (PJD) ...</td>\n",
       "      <td>paul jr designs</td>\n",
       "      <td>5a87255c5542996432c5722f</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Paul Jr. Designs, Paul Jr.,  Designs (PJD) is...</td>\n",
       "      <td>paul jr designs paul jr designs pjd is lifesty...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[contrasting work and creative styles of fathe...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32827</th>\n",
       "      <td>[[Scooby-Doo! and the Samurai Sword, 1], [Supe...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Which of these is from the series that has rel...</td>\n",
       "      <td>[[Hengdang, [The Hengdang is a single edged sw...</td>\n",
       "      <td>scoobydoo and samurai sword</td>\n",
       "      <td>5a7392f755429905862fe063</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Hengdang, The Hengdang is a single edged swor...</td>\n",
       "      <td>hengdang hengdang is single edged sword with l...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[and samurai sword is 2009 directtodvd animate...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37124</th>\n",
       "      <td>[[Lewis Downing Jr. House, 0], [Lewis Downing ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What historic house at 33 Pleasant Street in C...</td>\n",
       "      <td>[[Governor John Langdon House, [The Governor J...</td>\n",
       "      <td>lewis downing jr house</td>\n",
       "      <td>5a8317575542990548d0b175</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Governor John Langdon House, The Governor Joh...</td>\n",
       "      <td>governor john langdon house governor john lang...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[lewis downing jr, house is historic house at ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37183</th>\n",
       "      <td>[[Der Zwerg, 1], [Billy Budd (opera), 1]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>Which opera has more acts, Der Zwerg or Billy ...</td>\n",
       "      <td>[[Hervey Alan, [Hervey Alan (22 February 1910 ...</td>\n",
       "      <td>billy budd op 50 is opera by benjamin britten ...</td>\n",
       "      <td>5ae0e421554299422ee99543</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Hervey Alan, Hervey Alan (22 February 1910 – ...</td>\n",
       "      <td>hervey alan hervey alan 22 february 1910 – 12 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[17 is opera in one act by austrian composer a...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38543</th>\n",
       "      <td>[[3OH!3, 0], [3OH!3, 1], [Regina Spektor, 0]]</td>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician or group is from the US, 3OH!3 ...</td>\n",
       "      <td>[[Regina Spektor, [Regina Ilyinichna Spektor (...</td>\n",
       "      <td>3oh3</td>\n",
       "      <td>5ac447385542991943173964</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Regina Spektor, Regina Ilyinichna Spektor ( ,...</td>\n",
       "      <td>regina spektor regina ilyinichna spektor russi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[3oh, 3 pronounced three oh three is american ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43949</th>\n",
       "      <td>[[Sambomaster, 0], [Godspeed You! Black Empero...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which is from Canada, Sambomaster and Godspeed...</td>\n",
       "      <td>[[Mauro Pezzente, [Mauro Pezzente is a Canadia...</td>\n",
       "      <td>godspeed you black emperor</td>\n",
       "      <td>5abe38ec5542993f32c2a099</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Mauro Pezzente, Mauro Pezzente is a Canadian ...</td>\n",
       "      <td>mauro pezzente mauro pezzente is canadian musi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[sambomaster サンボマスター sanbomasutā is japanese r...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44580</th>\n",
       "      <td>[[Letting in the Jungle, 1], [Tiger! Tiger! (K...</td>\n",
       "      <td>easy</td>\n",
       "      <td>\"Letting In the Jungle\" is a short story by Ru...</td>\n",
       "      <td>[[Kaa's Hunting, [\"Kaa's Hunting\" is an 1893 s...</td>\n",
       "      <td>tiger tiger</td>\n",
       "      <td>5abaa6cb55429901930fa879</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Kaa's Hunting, \"Kaa's Hunting\" is an 1893 sho...</td>\n",
       "      <td>kaas hunting kaas hunting is 1893 short story ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[tiger, tiger]</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50514</th>\n",
       "      <td>[[Dave King (Irish singer), 0], [Get Cape. Wea...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which of the following had an original stage n...</td>\n",
       "      <td>[[Get Cape. Wear Cape. Fly, [Sam Duckworth is ...</td>\n",
       "      <td>get cape wear cape fly</td>\n",
       "      <td>5abec0045542994516f4541a</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Get Cape. Wear Cape. Fly, Sam Duckworth is an...</td>\n",
       "      <td>get cape wear cape fly sam duckworth is englis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[dave king born 11 december 1961 is irish voca...</td>\n",
       "      <td>5</td>\n",
       "      <td>[False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52911</th>\n",
       "      <td>[[Dynamite!! 2010, 4], [Nozomi Sasaki (model),...</td>\n",
       "      <td>easy</td>\n",
       "      <td>What even aired on TBS in Japan and HDNet in N...</td>\n",
       "      <td>[[Kaya Wittenburg, [Kaya Wittenburg (born Augu...</td>\n",
       "      <td>dynamite 2010</td>\n",
       "      <td>5a77218b55429937353601e2</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Kaya Wittenburg, Kaya Wittenburg (born August...</td>\n",
       "      <td>kaya wittenburg kaya wittenburg born august 24...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[2009 with official commentator nozomi sasaki ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54177</th>\n",
       "      <td>[[Mina and the Count, 2], [Oh Yeah! Cartoons, 1]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Mina and the count animated series appeared on...</td>\n",
       "      <td>[[Liquid Television, [Liquid Television is an ...</td>\n",
       "      <td>oh yeah cartoons</td>\n",
       "      <td>5abc54525542996583600444</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Liquid Television, Liquid Television is an an...</td>\n",
       "      <td>liquid television liquid television is animati...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[and nickelodeons oh yeah, cartoons is america...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55459</th>\n",
       "      <td>[[Small World (board game), 0], [Hey Pa! There...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which game was released first , 'Hey Pa! There...</td>\n",
       "      <td>[[Letters (Jimmy Webb album), [Letters is the ...</td>\n",
       "      <td>hey pa theres goat on roof</td>\n",
       "      <td>5a721b5955429971e9dc9275</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Letters (Jimmy Webb album), Letters is the fo...</td>\n",
       "      <td>letters jimmy webb album letters is fourth alb...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[small world is board game designed by philipp...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56275</th>\n",
       "      <td>[[Yoshirō Muraki, 1], [Tora! Tora! Tora!, 3]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>What 1970 Japanese-American war film was nomin...</td>\n",
       "      <td>[[Donald Graham Burt, [Donald Graham Burt is a...</td>\n",
       "      <td>tora tora tora</td>\n",
       "      <td>5a7a525055429941d65f25ae</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Donald Graham Burt, Donald Graham Burt is a f...</td>\n",
       "      <td>donald graham burt donald graham burt is film ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[he was nominated three times for academy awar...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64801</th>\n",
       "      <td>[[João Pedro Rodrigues, 0], [João Pedro Rodrig...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Which film director is considered to be a part...</td>\n",
       "      <td>[[Vítor Gonçalves, [Vítor Gonçalves (born 14 o...</td>\n",
       "      <td>joão pedro rodrigues is portuguese film direct...</td>\n",
       "      <td>5adc0cc855429947ff1738e1</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Vítor Gonçalves, Vítor Gonçalves (born 14 of ...</td>\n",
       "      <td>vítor gonçalves vítor gonçalves born 14 of mar...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[joão pedro rodrigues is portuguese film direc...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65204</th>\n",
       "      <td>[[Harry Potter and the Philosopher's Stone (fi...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Who distributed the film which featured a boy ...</td>\n",
       "      <td>[[Harry Potter and the Philosopher's Stone (fi...</td>\n",
       "      <td>warner bros pictures</td>\n",
       "      <td>5abd1b995542992ac4f381db</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Harry Potter and the Philosopher's Stone (fil...</td>\n",
       "      <td>harry potter and philosophers stone film harry...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[harry potter and philosophers stone released ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67725</th>\n",
       "      <td>[[Lee Ranaldo, 0], [Lee Ranaldo, 1], [Ozzy Osb...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Which of these two musicians, Lee Ranaldo or O...</td>\n",
       "      <td>[[Last Night on Earth (Lee Ranaldo album), [La...</td>\n",
       "      <td>john michael ozzy osbourne born 3 december 194...</td>\n",
       "      <td>5a74781355429929fddd843c</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Last Night on Earth (Lee Ranaldo album), Last...</td>\n",
       "      <td>last night on earth lee ranaldo album last nig...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[lee mark ranaldo born february 3 1956 is amer...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69442</th>\n",
       "      <td>[[Feiyu Show, 0], [Anvil! The Story of Anvil, 2]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>What film  is directed by screenwriter Sacha G...</td>\n",
       "      <td>[[Feiyu Show, [Feiyu Show () is a 2014 Chinese...</td>\n",
       "      <td>anvil story of anvil</td>\n",
       "      <td>5a746d6555429979e288294d</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Feiyu Show, Feiyu Show () is a 2014 Chinese d...</td>\n",
       "      <td>feiyu show feiyu show is 2014 chinese document...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[feiyu show is 2014 chinese documentary film d...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70143</th>\n",
       "      <td>[[Feiyu Show, 0], [Anvil! The Story of Anvil, ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which film - Feiyu Show or Anvil! The Story of...</td>\n",
       "      <td>[[Feiyu Show, [Feiyu Show () is a 2014 Chinese...</td>\n",
       "      <td>anvil story of anvil</td>\n",
       "      <td>5a71262c5542994082a3e5d7</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Feiyu Show, Feiyu Show () is a 2014 Chinese d...</td>\n",
       "      <td>feiyu show feiyu show is 2014 chinese document...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[feiyu show is 2014 chinese documentary film d...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75908</th>\n",
       "      <td>[[Troy Olsen, 0], [Blake Shelton, 4], [Blake S...</td>\n",
       "      <td>hard</td>\n",
       "      <td>What record company was the album which includ...</td>\n",
       "      <td>[[Troy Olsen, [Troy Olsen (born July 12, 1973)...</td>\n",
       "      <td>warner bros records</td>\n",
       "      <td>5ab2b7c45542992953946852</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Troy Olsen, Troy Olsen (born July 12, 1973) i...</td>\n",
       "      <td>troy olsen troy olsen born july 12 1973 is ame...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[troy olsen born july 12 1973 is american coun...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76227</th>\n",
       "      <td>[[Amélie Mauresmo, 0], [Corina Morariu, 0]]</td>\n",
       "      <td>easy</td>\n",
       "      <td>Who had a fuller tennis carrer, Amélie Mauresm...</td>\n",
       "      <td>[[Corina Morariu, [Corina Morariu (born Januar...</td>\n",
       "      <td>amélie simone mauresmo born 5 july 1979 is fre...</td>\n",
       "      <td>5abfedab5542997d6429594b</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Corina Morariu, Corina Morariu (born January ...</td>\n",
       "      <td>corina morariu corina morariu born january 26 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[amélie simone mauresmo born 5 july 1979 is fr...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79792</th>\n",
       "      <td>[[Spencer Ludwig, 2], [Spencer Ludwig, 3], [Po...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Spencer Ludwig has performed with which rock b...</td>\n",
       "      <td>[[The Cult, [The Cult are a British rock band ...</td>\n",
       "      <td>portugal man</td>\n",
       "      <td>5a8c6466554299240d9c2151</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[The Cult, The Cult are a British rock band fo...</td>\n",
       "      <td>cult cult are british rock band formed in 1983...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[records and has also performed with foster pe...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80370</th>\n",
       "      <td>[[Mister Miracle (Shilo Norman), 0], [DC Comic...</td>\n",
       "      <td>hard</td>\n",
       "      <td>The American comic book publisher known for ch...</td>\n",
       "      <td>[[Mister Miracle (Shilo Norman), [Shilo Norman...</td>\n",
       "      <td>warner bros entertainment inc</td>\n",
       "      <td>5a84b67c5542991dd0999da7</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Mister Miracle (Shilo Norman), Shilo Norman i...</td>\n",
       "      <td>mister miracle shilo norman shilo norman is fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[shilo norman is fictional character superhero...</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85937</th>\n",
       "      <td>[[Kolejka (game), 0], [Bailout! The Game, 1]]</td>\n",
       "      <td>hard</td>\n",
       "      <td>Which was released earlier, Kolejka or Bailout...</td>\n",
       "      <td>[[Thunder Ceptor, [Thunder Ceptor (サンダーセプター , ...</td>\n",
       "      <td>bailout game</td>\n",
       "      <td>5ab55d725542992aa134a2cf</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Thunder Ceptor, Thunder Ceptor (サンダーセプター , Sa...</td>\n",
       "      <td>thunder ceptor thunder ceptor サンダーセプター sandā s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kolejka polish for queue or line of people is...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "2347       [[Skillet (band), 1], [Portugal. The Man, 2]]    easy   \n",
       "6081   [[Tax Reduction and Simplification Act of 1977...    easy   \n",
       "7750       [[Kirsty MacColl, 0], [Portugal. The Man, 0]]  medium   \n",
       "12703  [[Ivan Allen Jr. Prize for Progress and Servic...    easy   \n",
       "15236  [[Lego DC Super Hero Girls: Brain Drain, 0], [...  medium   \n",
       "17033                  [[Patrick Stump, 0], [Jun. K, 0]]    hard   \n",
       "24309  [[Paul Norris (visual effects), 1], [Harry Pot...    easy   \n",
       "28027  [[Alshard, 4], [Standard RPG System, 1], [Stan...    hard   \n",
       "31461     [[American Chopper, 3], [Paul Jr. Designs, 1]]    easy   \n",
       "32827  [[Scooby-Doo! and the Samurai Sword, 1], [Supe...    hard   \n",
       "37124  [[Lewis Downing Jr. House, 0], [Lewis Downing ...  medium   \n",
       "37183          [[Der Zwerg, 1], [Billy Budd (opera), 1]]    easy   \n",
       "38543      [[3OH!3, 0], [3OH!3, 1], [Regina Spektor, 0]]    hard   \n",
       "43949  [[Sambomaster, 0], [Godspeed You! Black Empero...  medium   \n",
       "44580  [[Letting in the Jungle, 1], [Tiger! Tiger! (K...    easy   \n",
       "50514  [[Dave King (Irish singer), 0], [Get Cape. Wea...  medium   \n",
       "52911  [[Dynamite!! 2010, 4], [Nozomi Sasaki (model),...    easy   \n",
       "54177  [[Mina and the Count, 2], [Oh Yeah! Cartoons, 1]]  medium   \n",
       "55459  [[Small World (board game), 0], [Hey Pa! There...  medium   \n",
       "56275      [[Yoshirō Muraki, 1], [Tora! Tora! Tora!, 3]]  medium   \n",
       "64801  [[João Pedro Rodrigues, 0], [João Pedro Rodrig...    easy   \n",
       "65204  [[Harry Potter and the Philosopher's Stone (fi...    hard   \n",
       "67725  [[Lee Ranaldo, 0], [Lee Ranaldo, 1], [Ozzy Osb...    easy   \n",
       "69442  [[Feiyu Show, 0], [Anvil! The Story of Anvil, 2]]    easy   \n",
       "70143  [[Feiyu Show, 0], [Anvil! The Story of Anvil, ...  medium   \n",
       "75908  [[Troy Olsen, 0], [Blake Shelton, 4], [Blake S...    hard   \n",
       "76227        [[Amélie Mauresmo, 0], [Corina Morariu, 0]]    easy   \n",
       "79792  [[Spencer Ludwig, 2], [Spencer Ludwig, 3], [Po...  medium   \n",
       "80370  [[Mister Miracle (Shilo Norman), 0], [DC Comic...    hard   \n",
       "85937      [[Kolejka (game), 0], [Bailout! The Game, 1]]    hard   \n",
       "\n",
       "                                                question  \\\n",
       "2347   Which rock band has more members, Skillet or P...   \n",
       "6081   Was the president who signed the The Tax Reduc...   \n",
       "7750   Who is more likely to visit alaska,  Portugal....   \n",
       "12703  What award is issued by the Georgia Institute ...   \n",
       "15236  What is the name of this animation division of...   \n",
       "17033           Who is younger, Patrick Stump or Jun. K?   \n",
       "24309  Paul Norris is a British visual effects superv...   \n",
       "28027  What is the newest game that uses the game sys...   \n",
       "31461  What lifestyle brand motorcycle customizer and...   \n",
       "32827  Which of these is from the series that has rel...   \n",
       "37124  What historic house at 33 Pleasant Street in C...   \n",
       "37183  Which opera has more acts, Der Zwerg or Billy ...   \n",
       "38543  Which musician or group is from the US, 3OH!3 ...   \n",
       "43949  Which is from Canada, Sambomaster and Godspeed...   \n",
       "44580  \"Letting In the Jungle\" is a short story by Ru...   \n",
       "50514  Which of the following had an original stage n...   \n",
       "52911  What even aired on TBS in Japan and HDNet in N...   \n",
       "54177  Mina and the count animated series appeared on...   \n",
       "55459  Which game was released first , 'Hey Pa! There...   \n",
       "56275  What 1970 Japanese-American war film was nomin...   \n",
       "64801  Which film director is considered to be a part...   \n",
       "65204  Who distributed the film which featured a boy ...   \n",
       "67725  Which of these two musicians, Lee Ranaldo or O...   \n",
       "69442  What film  is directed by screenwriter Sacha G...   \n",
       "70143  Which film - Feiyu Show or Anvil! The Story of...   \n",
       "75908  What record company was the album which includ...   \n",
       "76227  Who had a fuller tennis carrer, Amélie Mauresm...   \n",
       "79792  Spencer Ludwig has performed with which rock b...   \n",
       "80370  The American comic book publisher known for ch...   \n",
       "85937  Which was released earlier, Kolejka or Bailout...   \n",
       "\n",
       "                                                 context  \\\n",
       "2347   [[Alien Youth, [Alien Youth is the fifth album...   \n",
       "6081   [[Tax Reduction and Simplification Act of 1977...   \n",
       "7750   [[Hallelujah (EP), [Hallelujah is a 7-track EP...   \n",
       "12703  [[Gary Pomerantz, [Gary M. Pomerantz (born Nov...   \n",
       "15236  [[Lego Batman 2: DC Super Heroes, [Lego Batman...   \n",
       "17033  [[Soul Punk, [Soul Punk is the first full-leng...   \n",
       "24309  [[Harry Potter and the Chamber of Secrets (fil...   \n",
       "28027  [[3d20 system, [The 3d20 system is the role-pl...   \n",
       "31461  [[Paul Jr. Designs, [Paul Jr.,  Designs (PJD) ...   \n",
       "32827  [[Hengdang, [The Hengdang is a single edged sw...   \n",
       "37124  [[Governor John Langdon House, [The Governor J...   \n",
       "37183  [[Hervey Alan, [Hervey Alan (22 February 1910 ...   \n",
       "38543  [[Regina Spektor, [Regina Ilyinichna Spektor (...   \n",
       "43949  [[Mauro Pezzente, [Mauro Pezzente is a Canadia...   \n",
       "44580  [[Kaa's Hunting, [\"Kaa's Hunting\" is an 1893 s...   \n",
       "50514  [[Get Cape. Wear Cape. Fly, [Sam Duckworth is ...   \n",
       "52911  [[Kaya Wittenburg, [Kaya Wittenburg (born Augu...   \n",
       "54177  [[Liquid Television, [Liquid Television is an ...   \n",
       "55459  [[Letters (Jimmy Webb album), [Letters is the ...   \n",
       "56275  [[Donald Graham Burt, [Donald Graham Burt is a...   \n",
       "64801  [[Vítor Gonçalves, [Vítor Gonçalves (born 14 o...   \n",
       "65204  [[Harry Potter and the Philosopher's Stone (fi...   \n",
       "67725  [[Last Night on Earth (Lee Ranaldo album), [La...   \n",
       "69442  [[Feiyu Show, [Feiyu Show () is a 2014 Chinese...   \n",
       "70143  [[Feiyu Show, [Feiyu Show () is a 2014 Chinese...   \n",
       "75908  [[Troy Olsen, [Troy Olsen (born July 12, 1973)...   \n",
       "76227  [[Corina Morariu, [Corina Morariu (born Januar...   \n",
       "79792  [[The Cult, [The Cult are a British rock band ...   \n",
       "80370  [[Mister Miracle (Shilo Norman), [Shilo Norman...   \n",
       "85937  [[Thunder Ceptor, [Thunder Ceptor (サンダーセプター , ...   \n",
       "\n",
       "                                                  answer  \\\n",
       "2347                                        portugal man   \n",
       "6081   james earl carter jr born october 1 1924 is am...   \n",
       "7750                                        portugal man   \n",
       "12703             ivan allen jr prize for social courage   \n",
       "15236                              warner bros animation   \n",
       "17033                                              jun k   \n",
       "24309                               warner bros pictures   \n",
       "28027                               full metal panic rpg   \n",
       "31461                                    paul jr designs   \n",
       "32827                        scoobydoo and samurai sword   \n",
       "37124                             lewis downing jr house   \n",
       "37183  billy budd op 50 is opera by benjamin britten ...   \n",
       "38543                                               3oh3   \n",
       "43949                         godspeed you black emperor   \n",
       "44580                                        tiger tiger   \n",
       "50514                             get cape wear cape fly   \n",
       "52911                                      dynamite 2010   \n",
       "54177                                   oh yeah cartoons   \n",
       "55459                         hey pa theres goat on roof   \n",
       "56275                                     tora tora tora   \n",
       "64801  joão pedro rodrigues is portuguese film direct...   \n",
       "65204                               warner bros pictures   \n",
       "67725  john michael ozzy osbourne born 3 december 194...   \n",
       "69442                               anvil story of anvil   \n",
       "70143                               anvil story of anvil   \n",
       "75908                                warner bros records   \n",
       "76227  amélie simone mauresmo born 5 july 1979 is fre...   \n",
       "79792                                       portugal man   \n",
       "80370                      warner bros entertainment inc   \n",
       "85937                                       bailout game   \n",
       "\n",
       "                            _id        type  \\\n",
       "2347   5a7a870d55429941d65f2688  comparison   \n",
       "6081   5ac2a89c55429921a00ab022      bridge   \n",
       "7750   5abbf2475542993f40c73c25  comparison   \n",
       "12703  5a7e43155542991319bc9457      bridge   \n",
       "15236  5ab856dd55429934fafe6d6e      bridge   \n",
       "17033  5a7939fd55429970f5fffe7e  comparison   \n",
       "24309  5a8f3aac55429918e830d1db      bridge   \n",
       "28027  5abc573d55429959677d6a8a      bridge   \n",
       "31461  5a87255c5542996432c5722f      bridge   \n",
       "32827  5a7392f755429905862fe063  comparison   \n",
       "37124  5a8317575542990548d0b175      bridge   \n",
       "37183  5ae0e421554299422ee99543  comparison   \n",
       "38543  5ac447385542991943173964  comparison   \n",
       "43949  5abe38ec5542993f32c2a099  comparison   \n",
       "44580  5abaa6cb55429901930fa879      bridge   \n",
       "50514  5abec0045542994516f4541a  comparison   \n",
       "52911  5a77218b55429937353601e2      bridge   \n",
       "54177  5abc54525542996583600444      bridge   \n",
       "55459  5a721b5955429971e9dc9275  comparison   \n",
       "56275  5a7a525055429941d65f25ae      bridge   \n",
       "64801  5adc0cc855429947ff1738e1  comparison   \n",
       "65204  5abd1b995542992ac4f381db      bridge   \n",
       "67725  5a74781355429929fddd843c  comparison   \n",
       "69442  5a746d6555429979e288294d  comparison   \n",
       "70143  5a71262c5542994082a3e5d7  comparison   \n",
       "75908  5ab2b7c45542992953946852      bridge   \n",
       "76227  5abfedab5542997d6429594b  comparison   \n",
       "79792  5a8c6466554299240d9c2151      bridge   \n",
       "80370  5a84b67c5542991dd0999da7      bridge   \n",
       "85937  5ab55d725542992aa134a2cf  comparison   \n",
       "\n",
       "                                       context_flattened  \\\n",
       "2347   [Alien Youth, Alien Youth is the fifth album r...   \n",
       "6081   [Tax Reduction and Simplification Act of 1977,...   \n",
       "7750   [Hallelujah (EP), Hallelujah is a 7-track EP b...   \n",
       "12703  [Gary Pomerantz, Gary M. Pomerantz (born Novem...   \n",
       "15236  [Lego Batman 2: DC Super Heroes, Lego Batman 2...   \n",
       "17033  [Soul Punk, Soul Punk is the first full-length...   \n",
       "24309  [Harry Potter and the Chamber of Secrets (film...   \n",
       "28027  [3d20 system, The 3d20 system is the role-play...   \n",
       "31461  [Paul Jr. Designs, Paul Jr.,  Designs (PJD) is...   \n",
       "32827  [Hengdang, The Hengdang is a single edged swor...   \n",
       "37124  [Governor John Langdon House, The Governor Joh...   \n",
       "37183  [Hervey Alan, Hervey Alan (22 February 1910 – ...   \n",
       "38543  [Regina Spektor, Regina Ilyinichna Spektor ( ,...   \n",
       "43949  [Mauro Pezzente, Mauro Pezzente is a Canadian ...   \n",
       "44580  [Kaa's Hunting, \"Kaa's Hunting\" is an 1893 sho...   \n",
       "50514  [Get Cape. Wear Cape. Fly, Sam Duckworth is an...   \n",
       "52911  [Kaya Wittenburg, Kaya Wittenburg (born August...   \n",
       "54177  [Liquid Television, Liquid Television is an an...   \n",
       "55459  [Letters (Jimmy Webb album), Letters is the fo...   \n",
       "56275  [Donald Graham Burt, Donald Graham Burt is a f...   \n",
       "64801  [Vítor Gonçalves, Vítor Gonçalves (born 14 of ...   \n",
       "65204  [Harry Potter and the Philosopher's Stone (fil...   \n",
       "67725  [Last Night on Earth (Lee Ranaldo album), Last...   \n",
       "69442  [Feiyu Show, Feiyu Show () is a 2014 Chinese d...   \n",
       "70143  [Feiyu Show, Feiyu Show () is a 2014 Chinese d...   \n",
       "75908  [Troy Olsen, Troy Olsen (born July 12, 1973) i...   \n",
       "76227  [Corina Morariu, Corina Morariu (born January ...   \n",
       "79792  [The Cult, The Cult are a British rock band fo...   \n",
       "80370  [Mister Miracle (Shilo Norman), Shilo Norman i...   \n",
       "85937  [Thunder Ceptor, Thunder Ceptor (サンダーセプター , Sa...   \n",
       "\n",
       "                                           context_joint  \\\n",
       "2347   alien youth alien youth is fifth album release...   \n",
       "6081   tax reduction and simplification act of 1977 t...   \n",
       "7750   hallelujah ep hallelujah is 7track ep by madch...   \n",
       "12703  gary pomerantz gary m pomerantz born november ...   \n",
       "15236  lego batman 2 dc super heroes lego batman 2 dc...   \n",
       "17033  soul punk soul punk is first fulllength solo s...   \n",
       "24309  harry potter and chamber of secrets film harry...   \n",
       "28027  3d20 system 3d20 system is roleplaying game sy...   \n",
       "31461  paul jr designs paul jr designs pjd is lifesty...   \n",
       "32827  hengdang hengdang is single edged sword with l...   \n",
       "37124  governor john langdon house governor john lang...   \n",
       "37183  hervey alan hervey alan 22 february 1910 – 12 ...   \n",
       "38543  regina spektor regina ilyinichna spektor russi...   \n",
       "43949  mauro pezzente mauro pezzente is canadian musi...   \n",
       "44580  kaas hunting kaas hunting is 1893 short story ...   \n",
       "50514  get cape wear cape fly sam duckworth is englis...   \n",
       "52911  kaya wittenburg kaya wittenburg born august 24...   \n",
       "54177  liquid television liquid television is animati...   \n",
       "55459  letters jimmy webb album letters is fourth alb...   \n",
       "56275  donald graham burt donald graham burt is film ...   \n",
       "64801  vítor gonçalves vítor gonçalves born 14 of mar...   \n",
       "65204  harry potter and philosophers stone film harry...   \n",
       "67725  last night on earth lee ranaldo album last nig...   \n",
       "69442  feiyu show feiyu show is 2014 chinese document...   \n",
       "70143  feiyu show feiyu show is 2014 chinese document...   \n",
       "75908  troy olsen troy olsen born july 12 1973 is ame...   \n",
       "76227  corina morariu corina morariu born january 26 ...   \n",
       "79792  cult cult are british rock band formed in 1983...   \n",
       "80370  mister miracle shilo norman shilo norman is fi...   \n",
       "85937  thunder ceptor thunder ceptor サンダーセプター sandā s...   \n",
       "\n",
       "       normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "2347                           True                         False   \n",
       "6081                           True                         False   \n",
       "7750                           True                         False   \n",
       "12703                          True                         False   \n",
       "15236                          True                         False   \n",
       "17033                          True                         False   \n",
       "24309                          True                         False   \n",
       "28027                          True                         False   \n",
       "31461                          True                         False   \n",
       "32827                          True                         False   \n",
       "37124                          True                         False   \n",
       "37183                          True                         False   \n",
       "38543                          True                         False   \n",
       "43949                          True                         False   \n",
       "44580                          True                         False   \n",
       "50514                          True                         False   \n",
       "52911                          True                         False   \n",
       "54177                          True                         False   \n",
       "55459                          True                         False   \n",
       "56275                          True                         False   \n",
       "64801                          True                         False   \n",
       "65204                          True                         False   \n",
       "67725                          True                         False   \n",
       "69442                          True                         False   \n",
       "70143                          True                         False   \n",
       "75908                          True                         False   \n",
       "76227                          True                         False   \n",
       "79792                          True                         False   \n",
       "80370                          True                         False   \n",
       "85937                          True                         False   \n",
       "\n",
       "                                    supporting_fact_text  \\\n",
       "2347   [band currently consists of husband john lead ...   \n",
       "6081   [tax reduction and simplification act of 1977 ...   \n",
       "7750   [kirsty anna maccoll 10 october 1959 – 18 dece...   \n",
       "12703  [prior to ivan allen jr, prize for progress se...   \n",
       "15236  [lego dc super hero girls brain drain is upcom...   \n",
       "17033  [patrick martin stumph born april 27 1984 know...   \n",
       "24309  [best known for his works in harry potter and ...   \n",
       "28027  [alshards game system is named standard rpg sy...   \n",
       "31461  [contrasting work and creative styles of fathe...   \n",
       "32827  [and samurai sword is 2009 directtodvd animate...   \n",
       "37124  [lewis downing jr, house is historic house at ...   \n",
       "37183  [17 is opera in one act by austrian composer a...   \n",
       "38543  [3oh, 3 pronounced three oh three is american ...   \n",
       "43949  [sambomaster サンボマスター sanbomasutā is japanese r...   \n",
       "44580                                     [tiger, tiger]   \n",
       "50514  [dave king born 11 december 1961 is irish voca...   \n",
       "52911  [2009 with official commentator nozomi sasaki ...   \n",
       "54177  [and nickelodeons oh yeah, cartoons is america...   \n",
       "55459  [small world is board game designed by philipp...   \n",
       "56275  [he was nominated three times for academy awar...   \n",
       "64801  [joão pedro rodrigues is portuguese film direc...   \n",
       "65204  [harry potter and philosophers stone released ...   \n",
       "67725  [lee mark ranaldo born february 3 1956 is amer...   \n",
       "69442  [feiyu show is 2014 chinese documentary film d...   \n",
       "70143  [feiyu show is 2014 chinese documentary film d...   \n",
       "75908  [troy olsen born july 12 1973 is american coun...   \n",
       "76227  [amélie simone mauresmo born 5 july 1979 is fr...   \n",
       "79792  [records and has also performed with foster pe...   \n",
       "80370  [shilo norman is fictional character superhero...   \n",
       "85937  [kolejka polish for queue or line of people is...   \n",
       "\n",
       "       num_of_supporting_facts  \\\n",
       "2347                         2   \n",
       "6081                         3   \n",
       "7750                         2   \n",
       "12703                        4   \n",
       "15236                        4   \n",
       "17033                        2   \n",
       "24309                        2   \n",
       "28027                        3   \n",
       "31461                        2   \n",
       "32827                        2   \n",
       "37124                        4   \n",
       "37183                        2   \n",
       "38543                        3   \n",
       "43949                        2   \n",
       "44580                        2   \n",
       "50514                        5   \n",
       "52911                        2   \n",
       "54177                        2   \n",
       "55459                        3   \n",
       "56275                        2   \n",
       "64801                        3   \n",
       "65204                        7   \n",
       "67725                        4   \n",
       "69442                        2   \n",
       "70143                        4   \n",
       "75908                        3   \n",
       "76227                        2   \n",
       "79792                        4   \n",
       "80370                        4   \n",
       "85937                        2   \n",
       "\n",
       "                    normalized_answer_in_supporting_fact  \n",
       "2347                                      [False, False]  \n",
       "6081                               [False, False, False]  \n",
       "7750                                      [False, False]  \n",
       "12703                       [False, False, False, False]  \n",
       "15236                       [False, False, False, False]  \n",
       "17033                                     [False, False]  \n",
       "24309                                     [False, False]  \n",
       "28027                              [False, False, False]  \n",
       "31461                                     [False, False]  \n",
       "32827                                     [False, False]  \n",
       "37124                       [False, False, False, False]  \n",
       "37183                                     [False, False]  \n",
       "38543                              [False, False, False]  \n",
       "43949                                     [False, False]  \n",
       "44580                                     [False, False]  \n",
       "50514                [False, False, False, False, False]  \n",
       "52911                                     [False, False]  \n",
       "54177                                     [False, False]  \n",
       "55459                              [False, False, False]  \n",
       "56275                                     [False, False]  \n",
       "64801                              [False, False, False]  \n",
       "65204  [False, False, False, False, False, False, False]  \n",
       "67725                       [False, False, False, False]  \n",
       "69442                                     [False, False]  \n",
       "70143                       [False, False, False, False]  \n",
       "75908                              [False, False, False]  \n",
       "76227                                     [False, False]  \n",
       "79792                       [False, False, False, False]  \n",
       "80370                       [False, False, False, False]  \n",
       "85937                                     [False, False]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_df.loc[train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x))) & (train_question_df['answer'] != 'yes') & (train_question_df['answer'] != 'no') & (train_question_df['answer'] != '') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, there are only 30 questions that the answer string is not in any of the supporting facts and the answer is not 'yes', 'no', or ''. <br> \n",
    "Other cases:\n",
    "\n",
    "- answer in the title\n",
    "    - [2347]\n",
    "        - answer: portugal man\n",
    "        - sp title: Portugal. The Man\n",
    "        \n",
    "- answer cross sp sentences\n",
    "    - [6081]\n",
    "        - answer: james earl carter jr born october 1 1924 is american politician who served as 39th president of united states from 1977 to 1981 member of democratic party\n",
    "        - sp contains: \n",
    "            - james earl carter jr born october 1 1924 is american politician who served as 39th president of united states from 1977 to 1981\n",
    "            - member of democratic party he also served as governor of georgia prior to his election as president\n",
    "    - [12703]\n",
    "        - answer: ivan allen jr prize for social courage\n",
    "        - sp contains:\n",
    "            - prior to ivan allen jr  \n",
    "            - prize for social courage is international award established in 2010\n",
    "    - [28027]\n",
    "        - answer: full metal panic rpg\n",
    "        - sp contains: \n",
    "            - newest 14th game that use srs are full metal panic \n",
    "            - rpg based upon anime and light novels of same title\n",
    "    - [15236]\n",
    "        - answer: warner bros animation\n",
    "        - sp contains:\n",
    "            - film based on dc super hero girls franchise produced by warner bros\n",
    "            - animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean         1.185954\n",
       "std          0.504775\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          6.000000\n",
       "Name: normalized_answer_in_supporting_fact, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many supporting facts contains the answer string, that is, the count of 'True'\n",
    "train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_answer_in_supporting_fact\n",
       "0     3964\n",
       "1    66304\n",
       "2    19654\n",
       "3      469\n",
       "4       40\n",
       "5        9\n",
       "6        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = train_question_df.groupby(train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)))\n",
    "num_of_supporting_fact_contain_answer = grouped.size()  # count of each \n",
    "num_of_supporting_fact_contain_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>[[Nemesis (rap crew), 0], [Run-DMC, 0], [Run-D...</td>\n",
       "      <td>easy</td>\n",
       "      <td>What hip hop group from Hollis, Queens, New Yo...</td>\n",
       "      <td>[[Nemesis (rap crew), [Nemesis is the first ra...</td>\n",
       "      <td>rundmc</td>\n",
       "      <td>5a777aaf5542997042120a85</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Nemesis (rap crew), Nemesis is the first rap ...</td>\n",
       "      <td>nemesis rap crew nemesis is first rap crew fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[nemesis is first rap crew from dallas texas t...</td>\n",
       "      <td>7</td>\n",
       "      <td>[True, True, False, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>[[Kazuo Ishiguro, 0], [Kazuo Ishiguro, 1], [Ka...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Did Kazuo Ishiguro and Yukio Mishima both move...</td>\n",
       "      <td>[[Five Modern Noh Plays, [Five Modern Nō Plays...</td>\n",
       "      <td>no</td>\n",
       "      <td>5a7f6b0a5542992097ad2f5e</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Five Modern Noh Plays, Five Modern Nō Plays i...</td>\n",
       "      <td>five modern noh plays five modern nō plays is ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kazuo ishiguro obe frsa frsl japanese カズオ・イシグ...</td>\n",
       "      <td>12</td>\n",
       "      <td>[True, False, False, True, False, True, True, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18114</th>\n",
       "      <td>[[Hot Stuff (Let's Dance), 0], [Hot Stuff (Let...</td>\n",
       "      <td>easy</td>\n",
       "      <td>\"Hot Stuff (Let's Dance)\" is a song by British...</td>\n",
       "      <td>[[Don't Love You No More (I'm Sorry), [\"Don't ...</td>\n",
       "      <td>kano</td>\n",
       "      <td>5a7a78055542990783324f57</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Don't Love You No More (I'm Sorry), \"Don't Lo...</td>\n",
       "      <td>dont love you no more im sorry dont love you n...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[hot stuff lets dance is song by british singe...</td>\n",
       "      <td>8</td>\n",
       "      <td>[False, True, True, False, True, True, True, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26083</th>\n",
       "      <td>[[Manzanita Sol, 1], [Manzanita Sol, 2], [H-E-...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is the name of  Grocery Company based in ...</td>\n",
       "      <td>[[San Antonio Opera, [The San Antonio Opera wa...</td>\n",
       "      <td>heb</td>\n",
       "      <td>5a78b2b3554299148911f942</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[San Antonio Opera, The San Antonio Opera was ...</td>\n",
       "      <td>san antonio opera san antonio opera was americ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[in united states it is sold in 12pack cans 2l...</td>\n",
       "      <td>7</td>\n",
       "      <td>[False, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42377</th>\n",
       "      <td>[[Niki Juusela, 3], [Niki Juusela, 4], [Footba...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Niki Juusela has commentary for what family of...</td>\n",
       "      <td>[[Football (disambiguation), [Football is a fa...</td>\n",
       "      <td>football</td>\n",
       "      <td>5ade1ac75542997c77aded49</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Football (disambiguation), Football is a fami...</td>\n",
       "      <td>football disambiguation football is family of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[in yle he has commentary on television ice ho...</td>\n",
       "      <td>6</td>\n",
       "      <td>[True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42899</th>\n",
       "      <td>[[Adavi Ramudu (2004 film), 1], [Adavi Ramudu ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Who is the actor who appeared in the Hindi act...</td>\n",
       "      <td>[[Action Jackson (soundtrack), [Action Jackson...</td>\n",
       "      <td>prabhas</td>\n",
       "      <td>5ae7a7565542993210983ed6</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[Action Jackson (soundtrack), Action Jackson: ...</td>\n",
       "      <td>action jackson soundtrack action jackson origi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[prabhas and aarti agarwal played lead roles, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[True, True, True, False, True, True, True, Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87878</th>\n",
       "      <td>[[Gos Rater Valencià, 1], [Briard, 0], [Briard...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which breed of dog has a longer history compet...</td>\n",
       "      <td>[[Briard, [The Briard is an ancient breed of l...</td>\n",
       "      <td>briard</td>\n",
       "      <td>5abaf3b65542992ccd8e7e72</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[Briard, The Briard is an ancient breed of lar...</td>\n",
       "      <td>briard briard is ancient breed of large herdin...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[recognised by real sociedad canina de españa ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[False, True, True, True, True, False, True, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "1072   [[Nemesis (rap crew), 0], [Run-DMC, 0], [Run-D...    easy   \n",
       "1722   [[Kazuo Ishiguro, 0], [Kazuo Ishiguro, 1], [Ka...  medium   \n",
       "18114  [[Hot Stuff (Let's Dance), 0], [Hot Stuff (Let...    easy   \n",
       "26083  [[Manzanita Sol, 1], [Manzanita Sol, 2], [H-E-...  medium   \n",
       "42377  [[Niki Juusela, 3], [Niki Juusela, 4], [Footba...  medium   \n",
       "42899  [[Adavi Ramudu (2004 film), 1], [Adavi Ramudu ...  medium   \n",
       "87878  [[Gos Rater Valencià, 1], [Briard, 0], [Briard...  medium   \n",
       "\n",
       "                                                question  \\\n",
       "1072   What hip hop group from Hollis, Queens, New Yo...   \n",
       "1722   Did Kazuo Ishiguro and Yukio Mishima both move...   \n",
       "18114  \"Hot Stuff (Let's Dance)\" is a song by British...   \n",
       "26083  What is the name of  Grocery Company based in ...   \n",
       "42377  Niki Juusela has commentary for what family of...   \n",
       "42899  Who is the actor who appeared in the Hindi act...   \n",
       "87878  Which breed of dog has a longer history compet...   \n",
       "\n",
       "                                                 context    answer  \\\n",
       "1072   [[Nemesis (rap crew), [Nemesis is the first ra...    rundmc   \n",
       "1722   [[Five Modern Noh Plays, [Five Modern Nō Plays...        no   \n",
       "18114  [[Don't Love You No More (I'm Sorry), [\"Don't ...      kano   \n",
       "26083  [[San Antonio Opera, [The San Antonio Opera wa...       heb   \n",
       "42377  [[Football (disambiguation), [Football is a fa...  football   \n",
       "42899  [[Action Jackson (soundtrack), [Action Jackson...   prabhas   \n",
       "87878  [[Briard, [The Briard is an ancient breed of l...    briard   \n",
       "\n",
       "                            _id        type  \\\n",
       "1072   5a777aaf5542997042120a85      bridge   \n",
       "1722   5a7f6b0a5542992097ad2f5e  comparison   \n",
       "18114  5a7a78055542990783324f57      bridge   \n",
       "26083  5a78b2b3554299148911f942      bridge   \n",
       "42377  5ade1ac75542997c77aded49      bridge   \n",
       "42899  5ae7a7565542993210983ed6      bridge   \n",
       "87878  5abaf3b65542992ccd8e7e72  comparison   \n",
       "\n",
       "                                       context_flattened  \\\n",
       "1072   [Nemesis (rap crew), Nemesis is the first rap ...   \n",
       "1722   [Five Modern Noh Plays, Five Modern Nō Plays i...   \n",
       "18114  [Don't Love You No More (I'm Sorry), \"Don't Lo...   \n",
       "26083  [San Antonio Opera, The San Antonio Opera was ...   \n",
       "42377  [Football (disambiguation), Football is a fami...   \n",
       "42899  [Action Jackson (soundtrack), Action Jackson: ...   \n",
       "87878  [Briard, The Briard is an ancient breed of lar...   \n",
       "\n",
       "                                           context_joint  \\\n",
       "1072   nemesis rap crew nemesis is first rap crew fro...   \n",
       "1722   five modern noh plays five modern nō plays is ...   \n",
       "18114  dont love you no more im sorry dont love you n...   \n",
       "26083  san antonio opera san antonio opera was americ...   \n",
       "42377  football disambiguation football is family of ...   \n",
       "42899  action jackson soundtrack action jackson origi...   \n",
       "87878  briard briard is ancient breed of large herdin...   \n",
       "\n",
       "       normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "1072                           True                         False   \n",
       "1722                           True                         False   \n",
       "18114                          True                         False   \n",
       "26083                          True                         False   \n",
       "42377                          True                         False   \n",
       "42899                          True                         False   \n",
       "87878                          True                         False   \n",
       "\n",
       "                                    supporting_fact_text  \\\n",
       "1072   [nemesis is first rap crew from dallas texas t...   \n",
       "1722   [kazuo ishiguro obe frsa frsl japanese カズオ・イシグ...   \n",
       "18114  [hot stuff lets dance is song by british singe...   \n",
       "26083  [in united states it is sold in 12pack cans 2l...   \n",
       "42377  [in yle he has commentary on television ice ho...   \n",
       "42899  [prabhas and aarti agarwal played lead roles, ...   \n",
       "87878  [recognised by real sociedad canina de españa ...   \n",
       "\n",
       "       num_of_supporting_facts  \\\n",
       "1072                         7   \n",
       "1722                        12   \n",
       "18114                        8   \n",
       "26083                        7   \n",
       "42377                        6   \n",
       "42899                        8   \n",
       "87878                        8   \n",
       "\n",
       "                    normalized_answer_in_supporting_fact  \n",
       "1072         [True, True, False, True, True, True, True]  \n",
       "1722   [True, False, False, True, False, True, True, ...  \n",
       "18114  [False, True, True, False, True, True, True, T...  \n",
       "26083        [False, True, True, True, True, True, True]  \n",
       "42377               [True, True, True, True, True, True]  \n",
       "42899  [True, True, True, False, True, True, True, Fa...  \n",
       "87878  [False, True, True, True, True, False, True, T...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check thoese questions with more than 5 supporting facts contain the answer\n",
    "train_question_df.loc[train_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)) > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/xdisk/msurdeanu/fanluo/hotpotQA/Data/hotpot_dev_distractor_v1.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    data = list(map(json.loads, data)) \n",
    "dev_question_df = pd.DataFrame(data[0])\n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7405 entries, 0 to 7404\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   _id               7405 non-null   object\n",
      " 1   answer            7405 non-null   object\n",
      " 2   question          7405 non-null   object\n",
      " 3   supporting_facts  7405 non-null   object\n",
      " 4   context           7405 non-null   object\n",
      " 5   type              7405 non-null   object\n",
      " 6   level             7405 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 405.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_question_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "hard    7405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of difficulty levels\n",
    "grouped = dev_question_df.groupby(['level'])\n",
    "level_counts = grouped.size()  # count of each \n",
    "level_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       7405\n",
       "unique         2\n",
       "top       bridge\n",
       "freq        5918\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.type.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "bridge        5918\n",
       "comparison    1487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of type\n",
    "grouped = dev_question_df.groupby(['type'])\n",
    "type_counts = grouped.size()  # count of each \n",
    "type_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df['context_flattened'] = dev_question_df['context'].map(lambda x: list(flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df['context_joint'] = dev_question_df['context_flattened'].map(lambda x: \" \".join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df.context_joint  = dev_question_df.context_joint.map(_normalize_text)  \n",
    "# dev_question_df.context_joint  = dev_question_df.context_joint.str.lower().map(lambda x:  \" \".join(re.sub(r'\"', r'', x).split()) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>[[Scott Derrickson, 0], [Ed Wood, 0]]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Ed Wood (film), Ed Wood is a 1994 American bi...</td>\n",
       "      <td>ed wood film ed wood is 1994 american biograph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id answer  \\\n",
       "0  5a8b57f25542995d1e6f1371    yes   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "\n",
       "                        supporting_facts  \\\n",
       "0  [[Scott Derrickson, 0], [Ed Wood, 0]]   \n",
       "\n",
       "                                             context        type level  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...  comparison  hard   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Ed Wood (film), Ed Wood is a 1994 American bi...   \n",
       "\n",
       "                                       context_joint  \n",
       "0  ed wood film ed wood is 1994 american biograph...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.000000\n",
       "mean       51.341931\n",
       "std        11.433978\n",
       "min         4.000000\n",
       "25%        44.000000\n",
       "50%        50.000000\n",
       "75%        57.000000\n",
       "max       157.000000\n",
       "Name: context_flattened, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.context_flattened.str.len().describe()  # statistic of number of context sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_flattened\n",
       "4      1\n",
       "5      1\n",
       "6      4\n",
       "7      3\n",
       "8      6\n",
       "      ..\n",
       "133    1\n",
       "136    1\n",
       "137    1\n",
       "144    1\n",
       "157    1\n",
       "Length: 107, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = dev_question_df.groupby(dev_question_df.context_flattened.str.len())\n",
    "num_of_context_sentences = grouped.size()  # count of each \n",
    "num_of_context_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_context_sentences.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of number of context sentences\n",
    "plot = num_of_context_sentences.plot(kind = 'bar', figsize=(15, 7))\n",
    "plt.xticks(rotation=0)                                    # show label text horizontally\n",
    "plt.setp(plot.axes.get_xticklabels(), visible=False)      # hide all labels\n",
    "plt.setp(plot.axes.get_xticklabels()[::5], visible=True)  # set every 5 labels visible\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df.answer = dev_question_df.answer.map(_normalize_text)  # apply _normalize_text(answer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.000000\n",
       "mean        2.360837\n",
       "std         1.659080\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        28.000000\n",
       "Name: answer, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.answer.str.split(' ').str.len().describe()  # statistic of number of words in the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer\n",
       "1     2441\n",
       "2     2403\n",
       "3     1442\n",
       "4      577\n",
       "5      247\n",
       "6      103\n",
       "7       71\n",
       "8       44\n",
       "9       20\n",
       "10      12\n",
       "11      11\n",
       "12      13\n",
       "13       6\n",
       "14       5\n",
       "15       5\n",
       "16       2\n",
       "17       1\n",
       "22       1\n",
       "28       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = dev_question_df.groupby(dev_question_df.answer.str.split(' ').str.len())\n",
    "num_of_answer_words = grouped.size()  # count of each \n",
    "num_of_answer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of questions with answer 'yes'\n",
    "dev_question_df.loc[dev_question_df['answer'] == 'yes'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of comparison questions with answer 'yes'\n",
    "dev_question_df.loc[(dev_question_df['answer'] == 'yes') & (dev_question_df['type'] == 'comparison')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of questions with answer 'no'\n",
    "dev_question_df.loc[dev_question_df['answer'] == 'no'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of comparison questions with answer 'no'\n",
    "dev_question_df.loc[(dev_question_df['answer'] == 'no') & (dev_question_df['type'] == 'comparison')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "questions with answer yes/no are all comparison questions, and (1487-225-233) = 69.2% comparison questions have span answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_question_df[\"normalized_answer_in_context\"] = dev_question_df.apply(lambda row: row['answer'] in row['context_joint'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df['normalized_answer_in_context'] = dev_question_df.apply(lambda row:  findWord(row['answer'], row['context_joint']) == True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7405\n",
       "unique       2\n",
       "top       True\n",
       "freq      7191\n",
       "Name: normalized_answer_in_context, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.normalized_answer_in_context.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7191 questions' answer in the context, 7405-7191 = 214 questions' answer are not in the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, answer, question, supporting_facts, context, type, level, context_flattened, context_joint, normalized_answer_in_context]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.loc[(dev_question_df['normalized_answer_in_context'] == False) & (dev_question_df['answer'] != 'yes') & (dev_question_df['answer'] != 'no') & (dev_question_df['answer'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     214\n",
       "unique      2\n",
       "top       yes\n",
       "freq      212\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.loc[(dev_question_df['normalized_answer_in_context'] == False)].answer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2\n",
       "unique    1\n",
       "top        \n",
       "freq      2\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.loc[(dev_question_df['normalized_answer_in_context'] == False) & (dev_question_df['answer'] != 'yes') & (dev_question_df['answer'] != 'no')].answer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supporting facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df['invalid_supporting_facts_ids'] = dev_question_df.apply(lambda row: True in [sp_idx >= len(dict(row['context'])[sp_t]) for (sp_t, sp_idx) in row['supporting_facts']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      7405\n",
       "unique        2\n",
       "top       False\n",
       "freq       7404\n",
       "Name: invalid_supporting_facts_ids, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df['invalid_supporting_facts_ids'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 questions have at least a supporting fact id out of range. That is, supporting fact id >= total num of sentence in the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>5ae61bfd5542992663a4f261</td>\n",
       "      <td>swingman</td>\n",
       "      <td>Which teams did Jimmy Butler play and what rol...</td>\n",
       "      <td>[[Shooting guard, 4], [Shooting guard, 5], [Ji...</td>\n",
       "      <td>[[Jimmy Butler (actor), [Jimmy Butler (Februar...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Jimmy Butler (actor), Jimmy Butler (February ...</td>\n",
       "      <td>jimmy butler actor jimmy butler february 20 19...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id    answer  \\\n",
       "5059  5ae61bfd5542992663a4f261  swingman   \n",
       "\n",
       "                                               question  \\\n",
       "5059  Which teams did Jimmy Butler play and what rol...   \n",
       "\n",
       "                                       supporting_facts  \\\n",
       "5059  [[Shooting guard, 4], [Shooting guard, 5], [Ji...   \n",
       "\n",
       "                                                context    type level  \\\n",
       "5059  [[Jimmy Butler (actor), [Jimmy Butler (Februar...  bridge  hard   \n",
       "\n",
       "                                      context_flattened  \\\n",
       "5059  [Jimmy Butler (actor), Jimmy Butler (February ...   \n",
       "\n",
       "                                          context_joint  \\\n",
       "5059  jimmy butler actor jimmy butler february 20 19...   \n",
       "\n",
       "      normalized_answer_in_context  invalid_supporting_facts_ids  \n",
       "5059                          True                          True  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.loc[dev_question_df['invalid_supporting_facts_ids']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dev_question_df.iloc[514].context[7])\n",
    "# len(dev_question_df.iloc[514].context[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_question_df['supporting_fact_text'] = dev_question_df.apply(lambda row: [_normalize_text(dict(row['context'])[sp_t][sp_idx]) for (sp_t, sp_idx) in row['supporting_facts'] if(sp_idx < len(dict(row['context'])[sp_t])) ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>[[Scott Derrickson, 0], [Ed Wood, 0]]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Ed Wood (film), Ed Wood is a 1994 American bi...</td>\n",
       "      <td>ed wood film ed wood is 1994 american biograph...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[scott derrickson born july 16 1966 is america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>chief of protocol</td>\n",
       "      <td>What government position was held by the woman...</td>\n",
       "      <td>[[Kiss and Tell (1945 film), 0], [Shirley Temp...</td>\n",
       "      <td>[[Meet Corliss Archer, [Meet Corliss Archer, a...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Meet Corliss Archer, Meet Corliss Archer, a p...</td>\n",
       "      <td>meet corliss archer meet corliss archer progra...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kiss and tell is 1945 american comedy film st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>animorphs</td>\n",
       "      <td>What science fantasy young adult series, told ...</td>\n",
       "      <td>[[The Hork-Bajir Chronicles, 0], [The Hork-Baj...</td>\n",
       "      <td>[[Andre Norton Award, [The Andre Norton Award ...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Andre Norton Award, The Andre Norton Award fo...</td>\n",
       "      <td>andre norton award andre norton award for youn...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[horkbajir chronicles is second companion book...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id             answer  \\\n",
       "0  5a8b57f25542995d1e6f1371                yes   \n",
       "1  5a8c7595554299585d9e36b6  chief of protocol   \n",
       "2  5a85ea095542994775f606a8          animorphs   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "1  What government position was held by the woman...   \n",
       "2  What science fantasy young adult series, told ...   \n",
       "\n",
       "                                    supporting_facts  \\\n",
       "0              [[Scott Derrickson, 0], [Ed Wood, 0]]   \n",
       "1  [[Kiss and Tell (1945 film), 0], [Shirley Temp...   \n",
       "2  [[The Hork-Bajir Chronicles, 0], [The Hork-Baj...   \n",
       "\n",
       "                                             context        type level  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...  comparison  hard   \n",
       "1  [[Meet Corliss Archer, [Meet Corliss Archer, a...      bridge  hard   \n",
       "2  [[Andre Norton Award, [The Andre Norton Award ...      bridge  hard   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Ed Wood (film), Ed Wood is a 1994 American bi...   \n",
       "1  [Meet Corliss Archer, Meet Corliss Archer, a p...   \n",
       "2  [Andre Norton Award, The Andre Norton Award fo...   \n",
       "\n",
       "                                       context_joint  \\\n",
       "0  ed wood film ed wood is 1994 american biograph...   \n",
       "1  meet corliss archer meet corliss archer progra...   \n",
       "2  andre norton award andre norton award for youn...   \n",
       "\n",
       "   normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "0                         False                         False   \n",
       "1                          True                         False   \n",
       "2                          True                         False   \n",
       "\n",
       "                                supporting_fact_text  \n",
       "0  [scott derrickson born july 16 1966 is america...  \n",
       "1  [kiss and tell is 1945 american comedy film st...  \n",
       "2  [horkbajir chronicles is second companion book...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to count the number of supporting facts\n",
    "dev_question_df['num_of_supporting_facts'] = dev_question_df.supporting_fact_text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.000000\n",
       "mean        2.431330\n",
       "std         0.711328\n",
       "min         2.000000\n",
       "25%         2.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max         8.000000\n",
       "Name: num_of_supporting_facts, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts\n",
    "dev_question_df.num_of_supporting_facts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_supporting_facts\n",
       "2    4990\n",
       "3    1775\n",
       "4     536\n",
       "5      80\n",
       "6      14\n",
       "7       9\n",
       "8       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts\n",
    "grouped = dev_question_df.groupby(['num_of_supporting_facts'])\n",
    "num_of_supporting_facts_counts = grouped.size()  # count of each \n",
    "num_of_supporting_facts_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>5abab18d55429901930fa89e</td>\n",
       "      <td>lola dee</td>\n",
       "      <td>The man Tony Bennet called \"The Father of Rock...</td>\n",
       "      <td>[[Lola Dee, 0], [Lola Dee, 1], [Lola Dee, 2], ...</td>\n",
       "      <td>[[Peter Clack, [Peter Clack is an Australian d...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Peter Clack, Peter Clack is an Australian dru...</td>\n",
       "      <td>peter clack peter clack is australian drummer ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[lola dee is american singer and recording art...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id    answer  \\\n",
       "5262  5abab18d55429901930fa89e  lola dee   \n",
       "\n",
       "                                               question  \\\n",
       "5262  The man Tony Bennet called \"The Father of Rock...   \n",
       "\n",
       "                                       supporting_facts  \\\n",
       "5262  [[Lola Dee, 0], [Lola Dee, 1], [Lola Dee, 2], ...   \n",
       "\n",
       "                                                context    type level  \\\n",
       "5262  [[Peter Clack, [Peter Clack is an Australian d...  bridge  hard   \n",
       "\n",
       "                                      context_flattened  \\\n",
       "5262  [Peter Clack, Peter Clack is an Australian dru...   \n",
       "\n",
       "                                          context_joint  \\\n",
       "5262  peter clack peter clack is australian drummer ...   \n",
       "\n",
       "      normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "5262                          True                         False   \n",
       "\n",
       "                                   supporting_fact_text  \\\n",
       "5262  [lola dee is american singer and recording art...   \n",
       "\n",
       "      num_of_supporting_facts  \n",
       "5262                        8  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check thoese questions with more than 8 supportiing facts\n",
    "dev_question_df.loc[dev_question_df.num_of_supporting_facts == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          [False, False]\n",
       "1                    [False, False, True]\n",
       "2       [True, False, False, True, False]\n",
       "3                          [False, False]\n",
       "4                           [False, True]\n",
       "                      ...                \n",
       "7400                  [False, True, True]\n",
       "7401                         [True, True]\n",
       "7402                       [False, False]\n",
       "7403                       [False, False]\n",
       "7404                        [False, True]\n",
       "Name: normalized_answer_in_supporting_fact, Length: 7405, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column: whether each supporting fact contains the answer string or not\n",
    "dev_question_df['normalized_answer_in_supporting_fact'] = dev_question_df.apply(lambda row: [ findWord(row['answer'], f) == True for f in row['supporting_fact_text']], axis = 1)\n",
    "dev_question_df['normalized_answer_in_supporting_fact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>[[Scott Derrickson, 0], [Ed Wood, 0]]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Ed Wood (film), Ed Wood is a 1994 American bi...</td>\n",
       "      <td>ed wood film ed wood is 1994 american biograph...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[scott derrickson born july 16 1966 is america...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>chief of protocol</td>\n",
       "      <td>What government position was held by the woman...</td>\n",
       "      <td>[[Kiss and Tell (1945 film), 0], [Shirley Temp...</td>\n",
       "      <td>[[Meet Corliss Archer, [Meet Corliss Archer, a...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Meet Corliss Archer, Meet Corliss Archer, a p...</td>\n",
       "      <td>meet corliss archer meet corliss archer progra...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[kiss and tell is 1945 american comedy film st...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>animorphs</td>\n",
       "      <td>What science fantasy young adult series, told ...</td>\n",
       "      <td>[[The Hork-Bajir Chronicles, 0], [The Hork-Baj...</td>\n",
       "      <td>[[Andre Norton Award, [The Andre Norton Award ...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Andre Norton Award, The Andre Norton Award fo...</td>\n",
       "      <td>andre norton award andre norton award for youn...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[horkbajir chronicles is second companion book...</td>\n",
       "      <td>5</td>\n",
       "      <td>[True, False, False, True, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id             answer  \\\n",
       "0  5a8b57f25542995d1e6f1371                yes   \n",
       "1  5a8c7595554299585d9e36b6  chief of protocol   \n",
       "2  5a85ea095542994775f606a8          animorphs   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "1  What government position was held by the woman...   \n",
       "2  What science fantasy young adult series, told ...   \n",
       "\n",
       "                                    supporting_facts  \\\n",
       "0              [[Scott Derrickson, 0], [Ed Wood, 0]]   \n",
       "1  [[Kiss and Tell (1945 film), 0], [Shirley Temp...   \n",
       "2  [[The Hork-Bajir Chronicles, 0], [The Hork-Baj...   \n",
       "\n",
       "                                             context        type level  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...  comparison  hard   \n",
       "1  [[Meet Corliss Archer, [Meet Corliss Archer, a...      bridge  hard   \n",
       "2  [[Andre Norton Award, [The Andre Norton Award ...      bridge  hard   \n",
       "\n",
       "                                   context_flattened  \\\n",
       "0  [Ed Wood (film), Ed Wood is a 1994 American bi...   \n",
       "1  [Meet Corliss Archer, Meet Corliss Archer, a p...   \n",
       "2  [Andre Norton Award, The Andre Norton Award fo...   \n",
       "\n",
       "                                       context_joint  \\\n",
       "0  ed wood film ed wood is 1994 american biograph...   \n",
       "1  meet corliss archer meet corliss archer progra...   \n",
       "2  andre norton award andre norton award for youn...   \n",
       "\n",
       "   normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "0                         False                         False   \n",
       "1                          True                         False   \n",
       "2                          True                         False   \n",
       "\n",
       "                                supporting_fact_text  num_of_supporting_facts  \\\n",
       "0  [scott derrickson born july 16 1966 is america...                        2   \n",
       "1  [kiss and tell is 1945 american comedy film st...                        3   \n",
       "2  [horkbajir chronicles is second companion book...                        5   \n",
       "\n",
       "  normalized_answer_in_supporting_fact  \n",
       "0                       [False, False]  \n",
       "1                 [False, False, True]  \n",
       "2    [True, False, False, True, False]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>[[Scott Derrickson, 0], [Ed Wood, 0]]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Ed Wood (film), Ed Wood is a 1994 American bi...</td>\n",
       "      <td>ed wood film ed wood is 1994 american biograph...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[scott derrickson born july 16 1966 is america...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adbf0a255429947ff17385a</td>\n",
       "      <td>no</td>\n",
       "      <td>Are the Laleli Mosque and Esma Sultan Mansion ...</td>\n",
       "      <td>[[Laleli Mosque, 0], [Esma Sultan Mansion, 0]]</td>\n",
       "      <td>[[Esma Sultan (daughter of Abdülaziz), [Esma S...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Esma Sultan (daughter of Abdülaziz), Esma Sul...</td>\n",
       "      <td>esma sultan daughter of abdülaziz esma sultan ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[laleli mosque turkish laleli camii or tulip m...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5a8db19d5542994ba4e3dd00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are Local H and For Against both from the Unit...</td>\n",
       "      <td>[[Local H, 0], [For Against, 0]]</td>\n",
       "      <td>[[Mendocino County GMO Ban, [Mendocino County,...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Mendocino County GMO Ban, Mendocino County, C...</td>\n",
       "      <td>mendocino county gmo ban mendocino county cali...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[local h is american rock band originally form...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5ab29c24554299449642c932</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are Giuseppe Verdi and Ambroise Thomas both Op...</td>\n",
       "      <td>[[Giuseppe Verdi, 0], [Ambroise Thomas, 0]]</td>\n",
       "      <td>[[Bernhard Bötel, [Bernhard Bötel (1883–1953) ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Bernhard Bötel, Bernhard Bötel (1883–1953) wa...</td>\n",
       "      <td>bernhard bötel bernhard bötel 1883–1953 was ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[giuseppe fortunino francesco verdi 9 or 10 oc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5abd259d55429924427fcf1a</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are both Dictyosperma, and Huernia described a...</td>\n",
       "      <td>[[Dictyosperma, 0], [Huernia, 0]]</td>\n",
       "      <td>[[Dictyosperma, [Dictyosperma is a monotypic g...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Dictyosperma, Dictyosperma is a monotypic gen...</td>\n",
       "      <td>dictyosperma dictyosperma is monotypic genus o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[dictyosperma is monotypic genus of flowering ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>5ae3d0bb5542990afbd1e1e5</td>\n",
       "      <td>yes</td>\n",
       "      <td>are Dee Dee Ramone and Alex Band both singers,...</td>\n",
       "      <td>[[Dee Dee Ramone, 0], [Alex Band, 0]]</td>\n",
       "      <td>[[The Ramainz, [The Ramainz were a U.S. tribut...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[The Ramainz, The Ramainz were a U.S. tribute ...</td>\n",
       "      <td>ramainz ramainz were us tribute band to ramone...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[douglas glenn colvin september 18 1951 – june...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>5a7fe0b55542994857a76818</td>\n",
       "      <td>no</td>\n",
       "      <td>Are The Maine and Black both from Tempe, Arizona?</td>\n",
       "      <td>[[The Maine (band), 0], [Black (Bangladeshi ba...</td>\n",
       "      <td>[[Arizona State University Tempe campus, [Ariz...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Arizona State University Tempe campus, Arizon...</td>\n",
       "      <td>arizona state university tempe campus arizona ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[maine is american rock band from tempe arizon...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>5ab8736455429916710eb058</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are Yut and Tsuro both board games?</td>\n",
       "      <td>[[Yut, 0], [Tsuro, 0]]</td>\n",
       "      <td>[[Days of Wonder, [Days of Wonder is a board g...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Days of Wonder, Days of Wonder is a board gam...</td>\n",
       "      <td>days of wonder days of wonder is board game pu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[yut nori also known as yunnori nyout and yoot...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>5a8173fa554299260e20a28e</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are Billy and Barak both breeds of scenthound?...</td>\n",
       "      <td>[[Bosnian Coarse-haired Hound, 0], [Billy (dog...</td>\n",
       "      <td>[[Styrian Coarse-haired Hound, [The Styrian Co...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Styrian Coarse-haired Hound, The Styrian Coar...</td>\n",
       "      <td>styrian coarsehaired hound styrian coarsehaire...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[bosnian coarsehaired hound or bosanski oštrod...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>5a8caf1d554299585d9e3720</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were both of the following rock groups formed ...</td>\n",
       "      <td>[[Dig (band), 0], [Thinking Fellers Union Loca...</td>\n",
       "      <td>[[Strangers from the Universe, [Strangers from...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Strangers from the Universe, Strangers from t...</td>\n",
       "      <td>strangers from universe strangers from univers...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[dig is american alternative rock band from lo...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id answer  \\\n",
       "0     5a8b57f25542995d1e6f1371    yes   \n",
       "3     5adbf0a255429947ff17385a     no   \n",
       "9     5a8db19d5542994ba4e3dd00    yes   \n",
       "17    5ab29c24554299449642c932    yes   \n",
       "27    5abd259d55429924427fcf1a    yes   \n",
       "...                        ...    ...   \n",
       "7339  5ae3d0bb5542990afbd1e1e5    yes   \n",
       "7349  5a7fe0b55542994857a76818     no   \n",
       "7373  5ab8736455429916710eb058    yes   \n",
       "7402  5a8173fa554299260e20a28e    yes   \n",
       "7403  5a8caf1d554299585d9e3720    yes   \n",
       "\n",
       "                                               question  \\\n",
       "0     Were Scott Derrickson and Ed Wood of the same ...   \n",
       "3     Are the Laleli Mosque and Esma Sultan Mansion ...   \n",
       "9     Are Local H and For Against both from the Unit...   \n",
       "17    Are Giuseppe Verdi and Ambroise Thomas both Op...   \n",
       "27    Are both Dictyosperma, and Huernia described a...   \n",
       "...                                                 ...   \n",
       "7339  are Dee Dee Ramone and Alex Band both singers,...   \n",
       "7349  Are The Maine and Black both from Tempe, Arizona?   \n",
       "7373                Are Yut and Tsuro both board games?   \n",
       "7402  Are Billy and Barak both breeds of scenthound?...   \n",
       "7403  Were both of the following rock groups formed ...   \n",
       "\n",
       "                                       supporting_facts  \\\n",
       "0                 [[Scott Derrickson, 0], [Ed Wood, 0]]   \n",
       "3        [[Laleli Mosque, 0], [Esma Sultan Mansion, 0]]   \n",
       "9                      [[Local H, 0], [For Against, 0]]   \n",
       "17          [[Giuseppe Verdi, 0], [Ambroise Thomas, 0]]   \n",
       "27                    [[Dictyosperma, 0], [Huernia, 0]]   \n",
       "...                                                 ...   \n",
       "7339              [[Dee Dee Ramone, 0], [Alex Band, 0]]   \n",
       "7349  [[The Maine (band), 0], [Black (Bangladeshi ba...   \n",
       "7373                             [[Yut, 0], [Tsuro, 0]]   \n",
       "7402  [[Bosnian Coarse-haired Hound, 0], [Billy (dog...   \n",
       "7403  [[Dig (band), 0], [Thinking Fellers Union Loca...   \n",
       "\n",
       "                                                context        type level  \\\n",
       "0     [[Ed Wood (film), [Ed Wood is a 1994 American ...  comparison  hard   \n",
       "3     [[Esma Sultan (daughter of Abdülaziz), [Esma S...  comparison  hard   \n",
       "9     [[Mendocino County GMO Ban, [Mendocino County,...  comparison  hard   \n",
       "17    [[Bernhard Bötel, [Bernhard Bötel (1883–1953) ...  comparison  hard   \n",
       "27    [[Dictyosperma, [Dictyosperma is a monotypic g...  comparison  hard   \n",
       "...                                                 ...         ...   ...   \n",
       "7339  [[The Ramainz, [The Ramainz were a U.S. tribut...  comparison  hard   \n",
       "7349  [[Arizona State University Tempe campus, [Ariz...  comparison  hard   \n",
       "7373  [[Days of Wonder, [Days of Wonder is a board g...  comparison  hard   \n",
       "7402  [[Styrian Coarse-haired Hound, [The Styrian Co...  comparison  hard   \n",
       "7403  [[Strangers from the Universe, [Strangers from...  comparison  hard   \n",
       "\n",
       "                                      context_flattened  \\\n",
       "0     [Ed Wood (film), Ed Wood is a 1994 American bi...   \n",
       "3     [Esma Sultan (daughter of Abdülaziz), Esma Sul...   \n",
       "9     [Mendocino County GMO Ban, Mendocino County, C...   \n",
       "17    [Bernhard Bötel, Bernhard Bötel (1883–1953) wa...   \n",
       "27    [Dictyosperma, Dictyosperma is a monotypic gen...   \n",
       "...                                                 ...   \n",
       "7339  [The Ramainz, The Ramainz were a U.S. tribute ...   \n",
       "7349  [Arizona State University Tempe campus, Arizon...   \n",
       "7373  [Days of Wonder, Days of Wonder is a board gam...   \n",
       "7402  [Styrian Coarse-haired Hound, The Styrian Coar...   \n",
       "7403  [Strangers from the Universe, Strangers from t...   \n",
       "\n",
       "                                          context_joint  \\\n",
       "0     ed wood film ed wood is 1994 american biograph...   \n",
       "3     esma sultan daughter of abdülaziz esma sultan ...   \n",
       "9     mendocino county gmo ban mendocino county cali...   \n",
       "17    bernhard bötel bernhard bötel 1883–1953 was ge...   \n",
       "27    dictyosperma dictyosperma is monotypic genus o...   \n",
       "...                                                 ...   \n",
       "7339  ramainz ramainz were us tribute band to ramone...   \n",
       "7349  arizona state university tempe campus arizona ...   \n",
       "7373  days of wonder days of wonder is board game pu...   \n",
       "7402  styrian coarsehaired hound styrian coarsehaire...   \n",
       "7403  strangers from universe strangers from univers...   \n",
       "\n",
       "      normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "0                            False                         False   \n",
       "3                             True                         False   \n",
       "9                            False                         False   \n",
       "17                           False                         False   \n",
       "27                           False                         False   \n",
       "...                            ...                           ...   \n",
       "7339                         False                         False   \n",
       "7349                          True                         False   \n",
       "7373                         False                         False   \n",
       "7402                         False                         False   \n",
       "7403                         False                         False   \n",
       "\n",
       "                                   supporting_fact_text  \\\n",
       "0     [scott derrickson born july 16 1966 is america...   \n",
       "3     [laleli mosque turkish laleli camii or tulip m...   \n",
       "9     [local h is american rock band originally form...   \n",
       "17    [giuseppe fortunino francesco verdi 9 or 10 oc...   \n",
       "27    [dictyosperma is monotypic genus of flowering ...   \n",
       "...                                                 ...   \n",
       "7339  [douglas glenn colvin september 18 1951 – june...   \n",
       "7349  [maine is american rock band from tempe arizon...   \n",
       "7373  [yut nori also known as yunnori nyout and yoot...   \n",
       "7402  [bosnian coarsehaired hound or bosanski oštrod...   \n",
       "7403  [dig is american alternative rock band from lo...   \n",
       "\n",
       "      num_of_supporting_facts normalized_answer_in_supporting_fact  \n",
       "0                           2                       [False, False]  \n",
       "3                           2                       [False, False]  \n",
       "9                           2                       [False, False]  \n",
       "17                          2                       [False, False]  \n",
       "27                          2                       [False, False]  \n",
       "...                       ...                                  ...  \n",
       "7339                        2                       [False, False]  \n",
       "7349                        2                       [False, False]  \n",
       "7373                        2                       [False, False]  \n",
       "7402                        2                       [False, False]  \n",
       "7403                        2                       [False, False]  \n",
       "\n",
       "[341 rows x 14 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions that none of its supporting facts contains the answer string\n",
    "# that is, rows that dev_question_df['supporting_fact_contain_answer'] is a list of false\n",
    "dev_question_df[dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x)))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, there are 341 such questions that the answer string is not in any of the supporting facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# questions that none of its supporting facts contains the answer string, and its answer is neither 'yes' nor 'no'\n",
    "dev_question_df.loc[dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x))) & (dev_question_df['answer'] != 'yes') & (dev_question_df['answer'] != 'no') & (dev_question_df['answer'] != '') ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>5a7555215542996c70cfaee1</td>\n",
       "      <td>hey pa theres goat on roof</td>\n",
       "      <td>Which came to market first, \"Hey Pa! There's a...</td>\n",
       "      <td>[[Hey Pa! There's a Goat on the Roof, 1], [Pol...</td>\n",
       "      <td>[[Pashmina, [Pashmina is a fine type of cashme...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Pashmina, Pashmina is a fine type of cashmere...</td>\n",
       "      <td>pashmina pashmina is fine type of cashmere woo...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[theres goat on roof was childrens board game ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>5abdd08d5542991f6610604c</td>\n",
       "      <td>guardians of galaxy vol 2</td>\n",
       "      <td>Which movie directed by James Gunn portrayed t...</td>\n",
       "      <td>[[Ego the Living Planet, 2], [Guardians of the...</td>\n",
       "      <td>[[Paul Williams (The Young and the Restless), ...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Paul Williams (The Young and the Restless), P...</td>\n",
       "      <td>paul williams young and restless paul williams...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[ego is portrayed by kurt russell in guardians...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>5adde6535542990dbb2f7ef9</td>\n",
       "      <td>hail hail rock n roll</td>\n",
       "      <td>Which documentary was filmed first, Almost Sun...</td>\n",
       "      <td>[[Almost Sunrise, 0], [Hail! Hail! Rock 'n' Ro...</td>\n",
       "      <td>[[Almost Sunrise, [Almost Sunrise is a 2016 Am...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Almost Sunrise, Almost Sunrise is a 2016 Amer...</td>\n",
       "      <td>almost sunrise almost sunrise is 2016 american...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[almost sunrise is 2016 american documentary f...</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>5ab4b9f75542990594ba9ca4</td>\n",
       "      <td>people and carnabeats</td>\n",
       "      <td>Who covered the song I Love You by Chris Write?</td>\n",
       "      <td>[[I Love You (The Zombies song), 0], [I Love Y...</td>\n",
       "      <td>[[Spontaneous Combustion (album), [Spontaneous...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[Spontaneous Combustion (album), Spontaneous C...</td>\n",
       "      <td>spontaneous combustion album spontaneous combu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[i love you is 1965 song by zombies written by...</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                      answer  \\\n",
       "289   5a7555215542996c70cfaee1  hey pa theres goat on roof   \n",
       "520   5abdd08d5542991f6610604c   guardians of galaxy vol 2   \n",
       "1785  5adde6535542990dbb2f7ef9       hail hail rock n roll   \n",
       "2211  5ab4b9f75542990594ba9ca4       people and carnabeats   \n",
       "\n",
       "                                               question  \\\n",
       "289   Which came to market first, \"Hey Pa! There's a...   \n",
       "520   Which movie directed by James Gunn portrayed t...   \n",
       "1785  Which documentary was filmed first, Almost Sun...   \n",
       "2211    Who covered the song I Love You by Chris Write?   \n",
       "\n",
       "                                       supporting_facts  \\\n",
       "289   [[Hey Pa! There's a Goat on the Roof, 1], [Pol...   \n",
       "520   [[Ego the Living Planet, 2], [Guardians of the...   \n",
       "1785  [[Almost Sunrise, 0], [Hail! Hail! Rock 'n' Ro...   \n",
       "2211  [[I Love You (The Zombies song), 0], [I Love Y...   \n",
       "\n",
       "                                                context        type level  \\\n",
       "289   [[Pashmina, [Pashmina is a fine type of cashme...  comparison  hard   \n",
       "520   [[Paul Williams (The Young and the Restless), ...      bridge  hard   \n",
       "1785  [[Almost Sunrise, [Almost Sunrise is a 2016 Am...  comparison  hard   \n",
       "2211  [[Spontaneous Combustion (album), [Spontaneous...      bridge  hard   \n",
       "\n",
       "                                      context_flattened  \\\n",
       "289   [Pashmina, Pashmina is a fine type of cashmere...   \n",
       "520   [Paul Williams (The Young and the Restless), P...   \n",
       "1785  [Almost Sunrise, Almost Sunrise is a 2016 Amer...   \n",
       "2211  [Spontaneous Combustion (album), Spontaneous C...   \n",
       "\n",
       "                                          context_joint  \\\n",
       "289   pashmina pashmina is fine type of cashmere woo...   \n",
       "520   paul williams young and restless paul williams...   \n",
       "1785  almost sunrise almost sunrise is 2016 american...   \n",
       "2211  spontaneous combustion album spontaneous combu...   \n",
       "\n",
       "      normalized_answer_in_context  invalid_supporting_facts_ids  \\\n",
       "289                           True                         False   \n",
       "520                           True                         False   \n",
       "1785                          True                         False   \n",
       "2211                          True                         False   \n",
       "\n",
       "                                   supporting_fact_text  \\\n",
       "289   [theres goat on roof was childrens board game ...   \n",
       "520   [ego is portrayed by kurt russell in guardians...   \n",
       "1785  [almost sunrise is 2016 american documentary f...   \n",
       "2211  [i love you is 1965 song by zombies written by...   \n",
       "\n",
       "      num_of_supporting_facts normalized_answer_in_supporting_fact  \n",
       "289                         2                       [False, False]  \n",
       "520                         2                       [False, False]  \n",
       "1785                        2                       [False, False]  \n",
       "2211                        3                [False, False, False]  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_question_df.loc[dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: not(any(x))) & (dev_question_df['answer'] != 'yes') & (dev_question_df['answer'] != 'no') & (dev_question_df['answer'] != '') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, there are only 4 questions that the answer string is not in any of the supporting facts and the answer is not 'yes', 'no', or ''.\n",
    "This caused by \n",
    "    - answer in sp title\n",
    "    - answer cross sp sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[289]\n",
    "- answer: hey pa theres goat on roof\n",
    "- sp contains:\n",
    "    - theres goat on roof\n",
    "- sp tilte:\n",
    "    - Hey Pa! There's a Goat on the Roof\n",
    "    \n",
    "[2211]\n",
    "- answr: people and carnabeats\n",
    "- sp contains:\n",
    "    - which was covered by people\n",
    "    - and carnabeats and by several other artists including foreign translations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.00000\n",
       "mean        1.12181\n",
       "std         0.46372\n",
       "min         0.00000\n",
       "25%         1.00000\n",
       "50%         1.00000\n",
       "75%         1.00000\n",
       "max         4.00000\n",
       "Name: normalized_answer_in_supporting_fact, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many supporting facts contains the answer string, that is, the count of 'True'\n",
    "dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalized_answer_in_supporting_fact\n",
       "0     341\n",
       "1    5875\n",
       "2    1140\n",
       "3      44\n",
       "4       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = dev_question_df.groupby(dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)))\n",
    "num_of_supporting_fact_contain_answer = grouped.size()  # count of each \n",
    "num_of_supporting_fact_contain_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>context_flattened</th>\n",
       "      <th>context_joint</th>\n",
       "      <th>normalized_answer_in_context</th>\n",
       "      <th>invalid_supporting_facts_ids</th>\n",
       "      <th>supporting_fact_text</th>\n",
       "      <th>num_of_supporting_facts</th>\n",
       "      <th>normalized_answer_in_supporting_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, answer, question, supporting_facts, context, type, level, context_flattened, context_joint, normalized_answer_in_context, invalid_supporting_facts_ids, supporting_fact_text, num_of_supporting_facts, normalized_answer_in_supporting_fact]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check thoese questions with 5 supporting facts contain the answer\n",
    "dev_question_df.loc[dev_question_df['normalized_answer_in_supporting_fact'].map(lambda x: sum(x)) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7405 entries, 0 to 7404\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   _id                                   7405 non-null   object\n",
      " 1   answer                                7405 non-null   object\n",
      " 2   question                              7405 non-null   object\n",
      " 3   supporting_facts                      7405 non-null   object\n",
      " 4   context                               7405 non-null   object\n",
      " 5   type                                  7405 non-null   object\n",
      " 6   level                                 7405 non-null   object\n",
      " 7   context_flattened                     7405 non-null   object\n",
      " 8   context_joint                         7405 non-null   object\n",
      " 9   normalized_answer_in_context          7405 non-null   bool  \n",
      " 10  invalid_supporting_facts_ids          7405 non-null   bool  \n",
      " 11  supporting_fact_text                  7405 non-null   object\n",
      " 12  num_of_supporting_facts               7405 non-null   int64 \n",
      " 13  normalized_answer_in_supporting_fact  7405 non-null   object\n",
      "dtypes: bool(2), int64(1), object(11)\n",
      "memory usage: 708.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_question_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced context with phrase Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_reduced_context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/hotpot_train_reduced_context.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    data = list(map(json.loads, data))    \n",
    "train_reduced_context_df = pd.json_normalize(data[0])\n",
    " \n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>question_phrases</th>\n",
       "      <th>paras_phrases</th>\n",
       "      <th>common_phrases</th>\n",
       "      <th>path_phrases</th>\n",
       "      <th>extended_phrases</th>\n",
       "      <th>reduced_context</th>\n",
       "      <th>kept_para_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[[first arthurs magazine, 0.3102452893989036],...</td>\n",
       "      <td>[[[['radio city indian radio station', 0.34992...</td>\n",
       "      <td>[woman, magazine, first]</td>\n",
       "      <td>[woman, magazine, first]</td>\n",
       "      <td>[woman, magazine, first, first arthurs, first ...</td>\n",
       "      <td>[[Radio City (Indian radio station), [ It broa...</td>\n",
       "      <td>[[1], [1, 2], [2], [0, 1, 2], [0, 1, 3], [2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[[hotel company, 0.2213744591115701], [head of...</td>\n",
       "      <td>[[[['ritzcarlton jakarta', 0.4330127018922193]...</td>\n",
       "      <td>[head office, oberoi, hotel company, oberoi fa...</td>\n",
       "      <td>[head office, oberoi, hotel company, oberoi gr...</td>\n",
       "      <td>[head office, oberoi, hotel company, oberoi gr...</td>\n",
       "      <td>[[Oberoi family, [The Oberoi family is an Indi...</td>\n",
       "      <td>[[0], [2], [0, 4], [0], [1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Milhouse Van Houten, 0]]</td>\n",
       "      <td>hard</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>bridge</td>\n",
       "      <td>[[satirist allie goertz, 0.20768020626775763],...</td>\n",
       "      <td>[[[['lisa simpson', 0.4330127018922193]], [['a...</td>\n",
       "      <td>[matt groening, song, simpsons, allie goertz]</td>\n",
       "      <td>[matt groening, song, los angeles reader, simp...</td>\n",
       "      <td>[matt groening, song, los angeles reader, simp...</td>\n",
       "      <td>[[Lisa Simpson, [ Cartoonist Matt Groening cre...</td>\n",
       "      <td>[[3], [2], [2], [3], [0], [0, 7], [2], [0], [4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              supporting_facts   level  \\\n",
       "0                       [[First for Women, 0]]  medium   \n",
       "1  [[Oberoi family, 0], [The Oberoi Group, 0]]  medium   \n",
       "2                   [[Milhouse Van Houten, 0]]    hard   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "\n",
       "                                             context                   answer  \\\n",
       "0  [[Radio City (Indian radio station), [Radio Ci...        Arthur's Magazine   \n",
       "1  [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...                    Delhi   \n",
       "2  [[Lisa Simpson, [Lisa Marie Simpson is a ficti...  President Richard Nixon   \n",
       "\n",
       "                        _id        type  \\\n",
       "0  5a7a06935542990198eaf050  comparison   \n",
       "1  5a879ab05542996e4f30887e      bridge   \n",
       "2  5a8d7341554299441c6b9fe5      bridge   \n",
       "\n",
       "                                    question_phrases  \\\n",
       "0  [[first arthurs magazine, 0.3102452893989036],...   \n",
       "1  [[hotel company, 0.2213744591115701], [head of...   \n",
       "2  [[satirist allie goertz, 0.20768020626775763],...   \n",
       "\n",
       "                                       paras_phrases  \\\n",
       "0  [[[['radio city indian radio station', 0.34992...   \n",
       "1  [[[['ritzcarlton jakarta', 0.4330127018922193]...   \n",
       "2  [[[['lisa simpson', 0.4330127018922193]], [['a...   \n",
       "\n",
       "                                      common_phrases  \\\n",
       "0                           [woman, magazine, first]   \n",
       "1  [head office, oberoi, hotel company, oberoi fa...   \n",
       "2      [matt groening, song, simpsons, allie goertz]   \n",
       "\n",
       "                                        path_phrases  \\\n",
       "0                           [woman, magazine, first]   \n",
       "1  [head office, oberoi, hotel company, oberoi gr...   \n",
       "2  [matt groening, song, los angeles reader, simp...   \n",
       "\n",
       "                                    extended_phrases  \\\n",
       "0  [woman, magazine, first, first arthurs, first ...   \n",
       "1  [head office, oberoi, hotel company, oberoi gr...   \n",
       "2  [matt groening, song, los angeles reader, simp...   \n",
       "\n",
       "                                     reduced_context  \\\n",
       "0  [[Radio City (Indian radio station), [ It broa...   \n",
       "1  [[Oberoi family, [The Oberoi family is an Indi...   \n",
       "2  [[Lisa Simpson, [ Cartoonist Matt Groening cre...   \n",
       "\n",
       "                                      kept_para_sent  \n",
       "0  [[1], [1, 2], [2], [0, 1, 2], [0, 1, 3], [2], ...  \n",
       "1                       [[0], [2], [0, 4], [0], [1]]  \n",
       "2  [[3], [2], [2], [3], [0], [0, 7], [2], [0], [4...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reduced_context_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90447 entries, 0 to 90446\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   supporting_facts  90447 non-null  object\n",
      " 1   level             90447 non-null  object\n",
      " 2   question          90447 non-null  object\n",
      " 3   context           90447 non-null  object\n",
      " 4   answer            90447 non-null  object\n",
      " 5   _id               90447 non-null  object\n",
      " 6   type              90447 non-null  object\n",
      " 7   question_phrases  90447 non-null  object\n",
      " 8   paras_phrases     90447 non-null  object\n",
      " 9   common_phrases    90447 non-null  object\n",
      " 10  path_phrases      90447 non-null  object\n",
      " 11  extended_phrases  90447 non-null  object\n",
      " 12  reduced_context   90447 non-null  object\n",
      " 13  kept_para_sent    90447 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_reduced_context_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduced Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joint_df = train_question_df.join(train_reduced_context_df, rsuffix='_reduced_context')\n",
    "train_joint_df = train_joint_df.loc[:, ['_id', 'question', 'answer', 'level', 'type', 'context', 'supporting_facts', 'reduced_context', 'supporting_facts_reduced_context', 'question_phrases', 'paras_phrases', 'common_phrases', 'path_phrases', 'extended_phrases', 'kept_para_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                                          5a879ab05542996e4f30887e\n",
       "question                            The Oberoi family is part of a hotel company t...\n",
       "answer                                                                          delhi\n",
       "level                                                                          medium\n",
       "type                                                                           bridge\n",
       "context                             [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...\n",
       "supporting_facts                          [[Oberoi family, 0], [The Oberoi Group, 0]]\n",
       "reduced_context                     [[Oberoi family, [The Oberoi family is an Indi...\n",
       "supporting_facts_reduced_context          [[Oberoi family, 0], [The Oberoi Group, 0]]\n",
       "question_phrases                    [[hotel company, 0.2213744591115701], [head of...\n",
       "paras_phrases                       [[[['ritzcarlton jakarta', 0.4330127018922193]...\n",
       "common_phrases                      [head office, oberoi, hotel company, oberoi fa...\n",
       "path_phrases                        [head office, oberoi, hotel company, oberoi gr...\n",
       "extended_phrases                    [head office, oberoi, hotel company, oberoi gr...\n",
       "kept_para_sent                                           [[0], [2], [0, 4], [0], [1]]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joint_df['reduced_context_joint'] = train_joint_df['reduced_context'].map(lambda x: \" \".join(list(flatten(x)) ))\n",
    "train_joint_df['reduced_context_joint'] = train_joint_df['reduced_context_joint'].map(_normalize_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean        18.877464\n",
       "std          9.125716\n",
       "min          0.000000\n",
       "25%         13.000000\n",
       "50%         19.000000\n",
       "75%         25.000000\n",
       "max         75.000000\n",
       "Name: reduced_context, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df['reduced_context'].map(lambda x: list(flatten(x)) ).str.len().describe()  # statistic of number of context sentences, including tilte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = train_joint_df.groupby(train_joint_df['reduced_context'].map(lambda x: list(flatten(x)) ).str.len())\n",
    "num_of_context_sentences = grouped.size()  # count of each  \n",
    "\n",
    "# distribution of number of context sentences\n",
    "plot = num_of_context_sentences.plot(kind = 'bar', figsize=(15, 7))\n",
    "plt.xticks(rotation=0)                                    # show label text horizontally \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joint_df['normalized_answer_in_reduced_context'] = train_joint_df.apply(lambda row:  findWord(row['answer'], row['reduced_context_joint']) == True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     90447\n",
       "unique        2\n",
       "top        True\n",
       "freq      63793\n",
       "Name: normalized_answer_in_reduced_context, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.normalized_answer_in_reduced_context.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "63793 questions' answer in the context, 90447-63793 = 26654 questions' answer are not in the reduced context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66935"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[(train_joint_df['normalized_answer_in_reduced_context'] == True) | (train_joint_df['answer'] == 'yes') | (train_joint_df['answer'] == 'no')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66942"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[(train_joint_df['normalized_answer_in_reduced_context'] == True) | (train_joint_df['answer'] == 'yes') | (train_joint_df['answer'] == 'no') | (train_joint_df['answer'] == '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23505"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[(train_joint_df['normalized_answer_in_reduced_context'] == False) & (train_joint_df['answer'] != 'yes') & (train_joint_df['answer'] != 'no') & (train_joint_df['answer'] != '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[train_joint_df['answer'] == ''].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supporting facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_sp_in_reduced_context\n",
       "0    10412\n",
       "1    30195\n",
       "2    40172\n",
       "3     8274\n",
       "4     1285\n",
       "5       93\n",
       "6       14\n",
       "7        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts in reduced_context\n",
    "train_joint_df['num_of_sp_in_reduced_context'] = train_joint_df['supporting_facts_reduced_context'].map(lambda x: len(x))\n",
    "grouped = train_joint_df.groupby(['num_of_sp_in_reduced_context'])\n",
    "num_of_sp_in_reduced_context_counts = grouped.size()  # count of each \n",
    "num_of_sp_in_reduced_context_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.500000\n",
       "1        1.000000\n",
       "2        0.250000\n",
       "3        0.000000\n",
       "4        0.000000\n",
       "           ...   \n",
       "90442    0.500000\n",
       "90443    0.666667\n",
       "90444    0.000000\n",
       "90445    0.500000\n",
       "90446    1.000000\n",
       "Name: sp_in_reduced_context_ratio, Length: 90447, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio of supporting facts remained in the reduced context \n",
    "train_joint_df['sp_in_reduced_context_ratio'] = train_joint_df.apply(lambda row: len(row['supporting_facts_reduced_context']) / len(row['supporting_facts'])  , axis=1)\n",
    "\n",
    "#train_joint_df['sp_in_reduced_context'].map(lambda x: sum(x) / len(x)) \n",
    "train_joint_df['sp_in_reduced_context_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean         0.660098\n",
       "std          0.337404\n",
       "min          0.000000\n",
       "25%          0.500000\n",
       "50%          0.666667\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: sp_in_reduced_context_ratio, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df['sp_in_reduced_context_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for questions whose answer in reduced_context, the ratio of supporting facts remained in the reduced context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1774"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_context contains the answer, even though does not contain any supporting fact\n",
    "train_joint_df.loc[(train_joint_df.num_of_sp_in_reduced_context == 0) & (train_joint_df.normalized_answer_in_reduced_context == True)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>context</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>reduced_context</th>\n",
       "      <th>supporting_facts_reduced_context</th>\n",
       "      <th>question_phrases</th>\n",
       "      <th>paras_phrases</th>\n",
       "      <th>common_phrases</th>\n",
       "      <th>path_phrases</th>\n",
       "      <th>extended_phrases</th>\n",
       "      <th>kept_para_sent</th>\n",
       "      <th>reduced_context_joint</th>\n",
       "      <th>normalized_answer_in_reduced_context</th>\n",
       "      <th>num_of_sp_in_reduced_context</th>\n",
       "      <th>sp_in_reduced_context_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5ae3918b5542994393b9e709</td>\n",
       "      <td>Were Pavel Urysohn and Leonid Levin known for ...</td>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[[Leonid Ramzin, [Leonid Konstantinovich Ramzi...</td>\n",
       "      <td>[[Pavel Urysohn, 0], [Leonid Levin, 0]]</td>\n",
       "      <td>[[Kate Dillon Levin, [Kate Dillon Levin (born ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[leonid levin, 0.23639070780118254], [same ty...</td>\n",
       "      <td>[[[['leonid ramzin', 0.4330127018922193], ['le...</td>\n",
       "      <td>[leonid levin, work, pavel urysohn]</td>\n",
       "      <td>[many mass medium outlet, leonid levin, work, ...</td>\n",
       "      <td>[many mass medium outlet, leonid levin, work, ...</td>\n",
       "      <td>[[0, 1], [2], [], [], [1]]</td>\n",
       "      <td>kate dillon levin kate dillon levin born march...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5ab9672655429970cfb8eabd</td>\n",
       "      <td>Which industry do Richard Hawley and Chicago's...</td>\n",
       "      <td>rock band</td>\n",
       "      <td>easy</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[[Late Night Final, [Late Night Final is the s...</td>\n",
       "      <td>[[Catherine (alternative rock band), 0], [Rich...</td>\n",
       "      <td>[[Late Night Final, [Late Night Final is the s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[richard hawley, 0.26763402048270435], [chica...</td>\n",
       "      <td>[[[['late night', 0.35355339059327373]], [['mi...</td>\n",
       "      <td>[richard hawley]</td>\n",
       "      <td>[richard hawley]</td>\n",
       "      <td>[richard hawley, chicagos catherine, industry]</td>\n",
       "      <td>[[0], [0], [0], [], [0], [0], [2], [1], [0]]</td>\n",
       "      <td>late night final late night final is second st...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>5abaebab55429939ce03dd66</td>\n",
       "      <td>In between Memphis International Airport and S...</td>\n",
       "      <td>memphis international airport</td>\n",
       "      <td>medium</td>\n",
       "      <td>comparison</td>\n",
       "      <td>[[Southwest Georgia Regional Airport, [Southwe...</td>\n",
       "      <td>[[Memphis International Airport, 0], [Southwes...</td>\n",
       "      <td>[[FedEx Express Flight 1406, [FedEx Express Fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[memphis international airport, 0.25978557794...</td>\n",
       "      <td>[[[['southwest georgia regional airport', 0.37...</td>\n",
       "      <td>[one, memphis international airport, tennessee...</td>\n",
       "      <td>[one, tennessee, georgia, airport, memphis int...</td>\n",
       "      <td>[one, tennessee, georgia, airport, memphis int...</td>\n",
       "      <td>[[0], [], [0], [2, 5], [2], [0, 1], [0], [2, 3]]</td>\n",
       "      <td>fedex express flight 1406 fedex express flight...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  \\\n",
       "27   5ae3918b5542994393b9e709   \n",
       "86   5ab9672655429970cfb8eabd   \n",
       "225  5abaebab55429939ce03dd66   \n",
       "\n",
       "                                              question  \\\n",
       "27   Were Pavel Urysohn and Leonid Levin known for ...   \n",
       "86   Which industry do Richard Hawley and Chicago's...   \n",
       "225  In between Memphis International Airport and S...   \n",
       "\n",
       "                            answer   level        type  \\\n",
       "27                              no  medium  comparison   \n",
       "86                       rock band    easy  comparison   \n",
       "225  memphis international airport  medium  comparison   \n",
       "\n",
       "                                               context  \\\n",
       "27   [[Leonid Ramzin, [Leonid Konstantinovich Ramzi...   \n",
       "86   [[Late Night Final, [Late Night Final is the s...   \n",
       "225  [[Southwest Georgia Regional Airport, [Southwe...   \n",
       "\n",
       "                                      supporting_facts  \\\n",
       "27             [[Pavel Urysohn, 0], [Leonid Levin, 0]]   \n",
       "86   [[Catherine (alternative rock band), 0], [Rich...   \n",
       "225  [[Memphis International Airport, 0], [Southwes...   \n",
       "\n",
       "                                       reduced_context  \\\n",
       "27   [[Kate Dillon Levin, [Kate Dillon Levin (born ...   \n",
       "86   [[Late Night Final, [Late Night Final is the s...   \n",
       "225  [[FedEx Express Flight 1406, [FedEx Express Fl...   \n",
       "\n",
       "    supporting_facts_reduced_context  \\\n",
       "27                                []   \n",
       "86                                []   \n",
       "225                               []   \n",
       "\n",
       "                                      question_phrases  \\\n",
       "27   [[leonid levin, 0.23639070780118254], [same ty...   \n",
       "86   [[richard hawley, 0.26763402048270435], [chica...   \n",
       "225  [[memphis international airport, 0.25978557794...   \n",
       "\n",
       "                                         paras_phrases  \\\n",
       "27   [[[['leonid ramzin', 0.4330127018922193], ['le...   \n",
       "86   [[[['late night', 0.35355339059327373]], [['mi...   \n",
       "225  [[[['southwest georgia regional airport', 0.37...   \n",
       "\n",
       "                                        common_phrases  \\\n",
       "27                 [leonid levin, work, pavel urysohn]   \n",
       "86                                    [richard hawley]   \n",
       "225  [one, memphis international airport, tennessee...   \n",
       "\n",
       "                                          path_phrases  \\\n",
       "27   [many mass medium outlet, leonid levin, work, ...   \n",
       "86                                    [richard hawley]   \n",
       "225  [one, tennessee, georgia, airport, memphis int...   \n",
       "\n",
       "                                      extended_phrases  \\\n",
       "27   [many mass medium outlet, leonid levin, work, ...   \n",
       "86      [richard hawley, chicagos catherine, industry]   \n",
       "225  [one, tennessee, georgia, airport, memphis int...   \n",
       "\n",
       "                                       kept_para_sent  \\\n",
       "27                         [[0, 1], [2], [], [], [1]]   \n",
       "86       [[0], [0], [0], [], [0], [0], [2], [1], [0]]   \n",
       "225  [[0], [], [0], [2, 5], [2], [0, 1], [0], [2, 3]]   \n",
       "\n",
       "                                 reduced_context_joint  \\\n",
       "27   kate dillon levin kate dillon levin born march...   \n",
       "86   late night final late night final is second st...   \n",
       "225  fedex express flight 1406 fedex express flight...   \n",
       "\n",
       "     normalized_answer_in_reduced_context  num_of_sp_in_reduced_context  \\\n",
       "27                                   True                             0   \n",
       "86                                   True                             0   \n",
       "225                                  True                             0   \n",
       "\n",
       "     sp_in_reduced_context_ratio  \n",
       "27                           0.0  \n",
       "86                           0.0  \n",
       "225                          0.0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[(train_joint_df.num_of_sp_in_reduced_context == 0) & (train_joint_df.normalized_answer_in_reduced_context == True)].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Catherine (alternative rock band)', 0], ['Richard Hawley', 0]]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[train_joint_df._id=='5ab9672655429970cfb8eabd'].supporting_facts.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Late Night Final',\n",
       "   ['Late Night Final is the second studio album (and first full-length album after the mini-album \"Richard Hawley\" released six months earlier) from musician Richard Hawley, released in the UK in October 2001 by Setanta Records.']],\n",
       "  [\"Lady's Bridge (album)\",\n",
       "   [\"Lady's Bridge is the fifth studio album from musician Richard Hawley, released on 20 August 2007 in the UK and on 9 October 2007 in the US.\"]],\n",
       "  [\"Standing at the Sky's Edge\",\n",
       "   [\"Standing at the Sky's Edge is the seventh studio album from English musician Richard Hawley, released in the UK on 7 May 2012 and in the US on 28 August 2012.\"]],\n",
       "  ['Richard Hawley', []],\n",
       "  [\"Truelove's Gutter\",\n",
       "   [\"Truelove's Gutter is the sixth studio album from musician Richard Hawley, released on 21 September 2009 in the UK and on 22 September 2009 in the US.\"]],\n",
       "  ['Lowedges',\n",
       "   ['Lowedges is the third studio album from musician Richard Hawley.']],\n",
       "  ['A Heavy Nite With...',\n",
       "   [' It has been alleged that Jason Buckle is a pseudonym for Pulp guitarist Richard Hawley, but this is not the case - Hawley does contribute guitar to the album, however, under the pseudonym Wayne Marsden.']],\n",
       "  ['Broken (Soulsavers album)',\n",
       "   [' As with their 2007 album \"It\\'s Not How Far You Fall, It\\'s the Way You Land\", a collaboration with Mark Lanegan and a host of guest vocalists, \"Broken\" once again features Lanegan as the primary vocalist, as well as contributions from Bonnie \"Prince\" Billy (Will Oldham), Jason Pierce (of Spiritualized and Spacemen 3), Mike Patton (of Faith No More), Richard Hawley, and Gibby Haynes (of Butthole Surfers).']],\n",
       "  ['Longpigs',\n",
       "   ['Longpigs were a British alternative rock band who rose to fame on the fringe of Britpop in the 1990s, comprising Crispin Hunt (vocals), Richard Hawley (guitar), Simon Stafford (bass guitar) and former Cabaret Voltaire member Dee Boyle (drums) who was replaced by Andy Cook for their second album.']]]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[train_joint_df._id=='5ab9672655429970cfb8eabd'].reduced_context.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [first for women is womans magazine published ...\n",
       "1        [oberoi family is indian family that is famous...\n",
       "2        [milhouse mussolini van houten is fictional ch...\n",
       "3                                                       []\n",
       "4                                                       []\n",
       "                               ...                        \n",
       "90442    [she is daughter of actor bert remsen and cast...\n",
       "90443    [liberty tree mall is shopping mall in danvers...\n",
       "90444                                                   []\n",
       "90445    [mv wilhelm gustloff was german military trans...\n",
       "90446    [vietnam national cricket team represents viet...\n",
       "Name: sp_text_reduced_context, Length: 90447, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df['sp_text_reduced_context'] = train_joint_df.apply(lambda row: [_normalize_text(dict(row['reduced_context'])[sp_t][sp_idx]) for (sp_t, sp_idx) in row['supporting_facts_reduced_context'] if(sp_idx < len(dict(row['reduced_context'])[sp_t])) ], axis = 1)\n",
    "\n",
    "train_joint_df['sp_text_reduced_context']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "90442    False\n",
       "90443     True\n",
       "90444    False\n",
       "90445     True\n",
       "90446     True\n",
       "Name: normalized_answer_in_reduced_sp_text, Length: 90447, dtype: bool"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df['normalized_answer_in_reduced_sp_text'] = train_joint_df.apply(lambda row: any([ findWord(row['answer'], f) == True for f in row['sp_text_reduced_context']]), axis = 1)\n",
    "train_joint_df['normalized_answer_in_reduced_sp_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     90447\n",
       "unique        2\n",
       "top        True\n",
       "freq      56471\n",
       "Name: normalized_answer_in_reduced_sp_text, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.normalized_answer_in_reduced_sp_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29511"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joint_df.loc[(train_joint_df['normalized_answer_in_reduced_sp_text'] == False) & (train_joint_df['answer'] != 'yes') & (train_joint_df['answer'] != 'no') & (train_joint_df['answer'] != '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7322"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_context contain the answer, but the sp in reduced context does not contain the answer\n",
    "train_joint_df.loc[(train_joint_df.normalized_answer_in_reduced_context == True) & (train_joint_df.normalized_answer_in_reduced_sp_text == False) ].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save \n",
    "To train longformer on context vs reduced_context, compare run time and performance  \n",
    "just over the questions has answer in the reduced_context\n",
    "Thus save file contains only the questions has answer in the reduced_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90447 entries, 0 to 90446\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   _id                                   90447 non-null  object \n",
      " 1   question                              90447 non-null  object \n",
      " 2   answer                                90447 non-null  object \n",
      " 3   level                                 90447 non-null  object \n",
      " 4   type                                  90447 non-null  object \n",
      " 5   context                               90447 non-null  object \n",
      " 6   supporting_facts                      90447 non-null  object \n",
      " 7   reduced_context                       90447 non-null  object \n",
      " 8   supporting_facts_reduced_context      90447 non-null  object \n",
      " 9   question_phrases                      90447 non-null  object \n",
      " 10  paras_phrases                         90447 non-null  object \n",
      " 11  common_phrases                        90447 non-null  object \n",
      " 12  path_phrases                          90447 non-null  object \n",
      " 13  extended_phrases                      90447 non-null  object \n",
      " 14  kept_para_sent                        90447 non-null  object \n",
      " 15  reduced_context_joint                 90447 non-null  object \n",
      " 16  normalized_answer_in_reduced_context  90447 non-null  bool   \n",
      " 17  num_of_sp_in_reduced_context          90447 non-null  int64  \n",
      " 18  sp_in_reduced_context_ratio           90447 non-null  float64\n",
      " 19  sp_text_reduced_context               90447 non-null  object \n",
      " 20  normalized_answer_in_reduced_sp_text  90447 non-null  bool   \n",
      "dtypes: bool(2), float64(1), int64(1), object(17)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_joint_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66872"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotpot_reduced_train_df = train_joint_df.loc[(train_joint_df.reduced_context.str.len() > 0) & ((train_joint_df['normalized_answer_in_reduced_context'] == True) | (train_joint_df['answer'] == 'yes') | (train_joint_df['answer'] == 'no')) , ['supporting_facts', 'context', 'answer', '_id', 'question']]\n",
    "hotpot_reduced_train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_reduced_train_df.to_json(\"/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/context/hotpot_reduced_train.json\", orient=\"records\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66872"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save file contains only the questions with reduced_context has answer in the reduced_context\n",
    "hotpot_train_reduced_context_df = train_joint_df.loc[(train_joint_df.reduced_context.str.len() > 0) & ((train_joint_df['normalized_answer_in_reduced_context'] == True) | (train_joint_df['answer'] == 'yes') | (train_joint_df['answer'] == 'no')) , ['supporting_facts_reduced_context', 'reduced_context', 'answer', '_id', 'question']] \n",
    "\n",
    "hotpot_train_reduced_context_df.rename(columns={'supporting_facts_reduced_context': 'supporting_facts', \"reduced_context\": \"context\"}, inplace=True)\n",
    "hotpot_train_reduced_context_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_train_reduced_context_df.to_json(\"/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/reduced_context/hotpot_reduced_train_reduced_context.json\", orient=\"records\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev_reduced_context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16953"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/hotpot_dev_distractor_reduced_context.json') as json_file:      \n",
    "    data = json_file.readlines()\n",
    "    data = list(map(json.loads, data))    \n",
    "dev_reduced_context_df = pd.json_normalize(data[0])\n",
    " \n",
    "del data\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>question_phrases</th>\n",
       "      <th>paras_phrases</th>\n",
       "      <th>common_phrases</th>\n",
       "      <th>path_phrases</th>\n",
       "      <th>extended_phrases</th>\n",
       "      <th>reduced_context</th>\n",
       "      <th>kept_para_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>yes</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>[[Scott Derrickson, 0]]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>[[ed wood, 0.2841758924319113], [scott derrick...</td>\n",
       "      <td>[[[['ed wood film', 0.4], ['ed wood', 0.353553...</td>\n",
       "      <td>[ed wood, scott derrickson]</td>\n",
       "      <td>[ed wood, scott derrickson]</td>\n",
       "      <td>[ed wood, scott derrickson, same nationality]</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>[[0], [0], [], [0], [0], [3], [2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>Chief of Protocol</td>\n",
       "      <td>What government position was held by the woman...</td>\n",
       "      <td>[[Kiss and Tell (1945 film), 0]]</td>\n",
       "      <td>[[Meet Corliss Archer, [Meet Corliss Archer, a...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[[corliss archer, 0.21343307099261227], [film ...</td>\n",
       "      <td>[[[['meet corliss archer', 0.4], ['corliss arc...</td>\n",
       "      <td>[corliss archer]</td>\n",
       "      <td>[corliss archer]</td>\n",
       "      <td>[corliss archer, film kiss, woman, government ...</td>\n",
       "      <td>[[Meet Corliss Archer, [Meet Corliss Archer, a...</td>\n",
       "      <td>[[0], [1], [0], [0], [5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>Animorphs</td>\n",
       "      <td>What science fantasy young adult series, told ...</td>\n",
       "      <td>[[The Hork-Bajir Chronicles, 0], [The Hork-Baj...</td>\n",
       "      <td>[[Andre Norton Award, [The Andre Norton Award ...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>[[science fantasy young adult series, 0.192038...</td>\n",
       "      <td>[[[['andre norton award', 0.4], ['andre norton...</td>\n",
       "      <td>[first person, companion book, first, story]</td>\n",
       "      <td>[first person, companion book, book, first, st...</td>\n",
       "      <td>[first person, companion book, book, first, st...</td>\n",
       "      <td>[[Victoria Hanley, [ Her first three books, \"T...</td>\n",
       "      <td>[[1], [1, 2], [0, 1, 3, 5], [2, 3], [1], [1], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id             answer  \\\n",
       "0  5a8b57f25542995d1e6f1371                yes   \n",
       "1  5a8c7595554299585d9e36b6  Chief of Protocol   \n",
       "2  5a85ea095542994775f606a8          Animorphs   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "1  What government position was held by the woman...   \n",
       "2  What science fantasy young adult series, told ...   \n",
       "\n",
       "                                    supporting_facts  \\\n",
       "0                            [[Scott Derrickson, 0]]   \n",
       "1                   [[Kiss and Tell (1945 film), 0]]   \n",
       "2  [[The Hork-Bajir Chronicles, 0], [The Hork-Baj...   \n",
       "\n",
       "                                             context        type level  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...  comparison  hard   \n",
       "1  [[Meet Corliss Archer, [Meet Corliss Archer, a...      bridge  hard   \n",
       "2  [[Andre Norton Award, [The Andre Norton Award ...      bridge  hard   \n",
       "\n",
       "                                    question_phrases  \\\n",
       "0  [[ed wood, 0.2841758924319113], [scott derrick...   \n",
       "1  [[corliss archer, 0.21343307099261227], [film ...   \n",
       "2  [[science fantasy young adult series, 0.192038...   \n",
       "\n",
       "                                       paras_phrases  \\\n",
       "0  [[[['ed wood film', 0.4], ['ed wood', 0.353553...   \n",
       "1  [[[['meet corliss archer', 0.4], ['corliss arc...   \n",
       "2  [[[['andre norton award', 0.4], ['andre norton...   \n",
       "\n",
       "                                 common_phrases  \\\n",
       "0                   [ed wood, scott derrickson]   \n",
       "1                              [corliss archer]   \n",
       "2  [first person, companion book, first, story]   \n",
       "\n",
       "                                        path_phrases  \\\n",
       "0                        [ed wood, scott derrickson]   \n",
       "1                                   [corliss archer]   \n",
       "2  [first person, companion book, book, first, st...   \n",
       "\n",
       "                                    extended_phrases  \\\n",
       "0      [ed wood, scott derrickson, same nationality]   \n",
       "1  [corliss archer, film kiss, woman, government ...   \n",
       "2  [first person, companion book, book, first, st...   \n",
       "\n",
       "                                     reduced_context  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...   \n",
       "1  [[Meet Corliss Archer, [Meet Corliss Archer, a...   \n",
       "2  [[Victoria Hanley, [ Her first three books, \"T...   \n",
       "\n",
       "                                      kept_para_sent  \n",
       "0                 [[0], [0], [], [0], [0], [3], [2]]  \n",
       "1                          [[0], [1], [0], [0], [5]]  \n",
       "2  [[1], [1, 2], [0, 1, 3, 5], [2, 3], [1], [1], ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_reduced_context_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7405 entries, 0 to 7404\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   _id               7405 non-null   object\n",
      " 1   answer            7405 non-null   object\n",
      " 2   question          7405 non-null   object\n",
      " 3   supporting_facts  7405 non-null   object\n",
      " 4   context           7405 non-null   object\n",
      " 5   type              7405 non-null   object\n",
      " 6   level             7405 non-null   object\n",
      " 7   question_phrases  7405 non-null   object\n",
      " 8   paras_phrases     7405 non-null   object\n",
      " 9   common_phrases    7405 non-null   object\n",
      " 10  path_phrases      7405 non-null   object\n",
      " 11  extended_phrases  7405 non-null   object\n",
      " 12  reduced_context   7405 non-null   object\n",
      " 13  kept_para_sent    7405 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 810.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_reduced_context_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_joint_df = dev_question_df.join(dev_reduced_context_df, rsuffix='_reduced_context')\n",
    "dev_joint_df = dev_joint_df.loc[:, ['_id', 'question', 'answer', 'level', 'type', 'context', 'supporting_facts', 'reduced_context', 'supporting_facts_reduced_context', 'question_phrases', 'paras_phrases', 'common_phrases', 'path_phrases', 'extended_phrases', 'kept_para_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                                          5a8c7595554299585d9e36b6\n",
       "question                            What government position was held by the woman...\n",
       "answer                                                              chief of protocol\n",
       "level                                                                            hard\n",
       "type                                                                           bridge\n",
       "context                             [[Meet Corliss Archer, [Meet Corliss Archer, a...\n",
       "supporting_facts                    [[Kiss and Tell (1945 film), 0], [Shirley Temp...\n",
       "reduced_context                     [[Meet Corliss Archer, [Meet Corliss Archer, a...\n",
       "supporting_facts_reduced_context                     [[Kiss and Tell (1945 film), 0]]\n",
       "question_phrases                    [[corliss archer, 0.21343307099261227], [film ...\n",
       "paras_phrases                       [[[['meet corliss archer', 0.4], ['corliss arc...\n",
       "common_phrases                                                       [corliss archer]\n",
       "path_phrases                                                         [corliss archer]\n",
       "extended_phrases                    [corliss archer, film kiss, woman, government ...\n",
       "kept_para_sent                                              [[0], [1], [0], [0], [5]]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corliss archer', 0.21343307099261227],\n",
       " ['film kiss', 0.20244191004132744],\n",
       " ['woman', 0.1488362798886544],\n",
       " ['government position', 0.10321032895191254]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].question_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pharse extraction is not perfect, *'film'* and *'Kiss and Tell'* will be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['meet corliss archer', 0.4],\n",
       "   ['corliss archer', 0.35355339059327373],\n",
       "   ['meet', 0.2721655269759087]],\n",
       "  [['radio golden age', 0.18985858955553894],\n",
       "   ['corliss archer program', 0.18684782617842577],\n",
       "   ['corliss archer', 0.15621424412498358],\n",
       "   ['january 7 1943 september 30 1956', 0.15579934502414455],\n",
       "   ['september', 0.13357184551206308],\n",
       "   ['january', 0.12678315856422756]],\n",
       "  [['nbcs popular date', 0.19198525167644231],\n",
       "   ['summer replacement', 0.16580379501120182],\n",
       "   ['cbss answer', 0.1444268279716055],\n",
       "   ['bob', 0.1364196795586348],\n",
       "   ['nbc', 0.12360261951351523],\n",
       "   ['judy', 0.12033112796952505],\n",
       "   ['1948', 0.12033112796952505],\n",
       "   ['summer', 0.1191137760776727],\n",
       "   ['cbss', 0.10134688565547174]],\n",
       "  [['october 3 1952 june 26 1953', 0.17914880475830236],\n",
       "   ['june', 0.1534888043994956],\n",
       "   ['abc', 0.13744661667703784],\n",
       "   ['cbs', 0.11768707508805853],\n",
       "   ['october', 0.11618382875642504]],\n",
       "  [['few 24 episode', 0.17046104059250225],\n",
       "   ['program', 0.15700425736401472],\n",
       "   ['few 24', 0.14636300265993493]]],\n",
       " [[['shirley temple', 0.4330127018922193]],\n",
       "  [['american actress singer dancer businesswoman', 0.16957491006778433],\n",
       "   ['hollywoods number one boxoffice draw', 0.16865711484071017],\n",
       "   ['february 10 2014', 0.13015908350854372],\n",
       "   ['child actress', 0.12548211481381255],\n",
       "   ['shirley temple', 0.11781560982914524],\n",
       "   ['american', 0.10712402609415861],\n",
       "   ['hollywoods', 0.09691878843488261],\n",
       "   ['1935', 0.0968542640732322],\n",
       "   ['one', 0.09679641024395458],\n",
       "   ['april 23 1928', 0.09021097956087902],\n",
       "   ['diplomat', 0.08507963913971629]],\n",
       "  [['united states ambassador', 0.2402147368579998],\n",
       "   ['united states', 0.2215304844117066],\n",
       "   ['czechoslovakia', 0.13710651854806583],\n",
       "   ['chief', 0.13693242055700217],\n",
       "   ['ghana', 0.13230194931696881],\n",
       "   ['protocol', 0.13166406112092144],\n",
       "   ['adult', 0.08959649599027408]]],\n",
       " [[['janet waldo', 0.4330127018922193]],\n",
       "  [['janet marie waldo', 0.18900358153351413],\n",
       "   ['february 4 1920 june 12 2016', 0.16602839428430993],\n",
       "   ['american radio voice actress', 0.13977131156292244],\n",
       "   ['american', 0.11833282780198631]],\n",
       "  [['judy jetson nancy', 0.1743689830691715],\n",
       "   ['shazzan penelope pitstop', 0.1630350193976179],\n",
       "   ['title character', 0.15092623687034581],\n",
       "   ['corliss archer', 0.13163989270594398],\n",
       "   ['meet', 0.12429777527950867],\n",
       "   ['animation', 0.12226534731255029],\n",
       "   ['josie', 0.1190082176057416],\n",
       "   ['radio', 0.10919369781700253],\n",
       "   ['pussycats', 0.09077308164143533]]],\n",
       " [[['meet corliss archer tv series', 0.34992710611188255],\n",
       "   ['corliss archer tv series', 0.33948988986890993],\n",
       "   ['meet', 0.1944654357594038]],\n",
       "  [['cbs july 13 1951', 0.1885714499732703],\n",
       "   ['american television sitcom', 0.1591886663656914],\n",
       "   ['meet corliss archer', 0.15095557597925902],\n",
       "   ['american television', 0.14685800309084313],\n",
       "   ['corliss archer', 0.14240897098876557],\n",
       "   ['cbs july', 0.13959341072444006],\n",
       "   ['ziv company', 0.13603577180252438],\n",
       "   ['april', 0.12409874392428666],\n",
       "   ['syndication', 0.09997720082818554],\n",
       "   ['april december 1954', 0.09815640353951477],\n",
       "   ['december', 0.09350367543645767]],\n",
       "  [['radio series', 0.21698105332661788],\n",
       "   ['series', 0.19481058068308493],\n",
       "   ['f hugh herbert', 0.19448974284090864],\n",
       "   ['short story', 0.18073009012272045],\n",
       "   ['same name', 0.17185411418768828],\n",
       "   ['adaptation', 0.13964631376999337],\n",
       "   ['program', 0.0911210583945985]]],\n",
       " [[['lord high treasurer', 0.4]],\n",
       "  [['lord high treasurer', 0.23836861196003667],\n",
       "   ['english government position', 0.23168732920441745],\n",
       "   ['lord treasurer', 0.22562483558384844],\n",
       "   ['british government position', 0.22000944017156],\n",
       "   ['english', 0.13770702851849254],\n",
       "   ['act', 0.1376131894012893],\n",
       "   ['union', 0.13105990113445137],\n",
       "   ['british', 0.10787504188984666],\n",
       "   ['post', 0.10329639360652543],\n",
       "   ['1707', 0.10163989504501655]],\n",
       "  [['lord high steward', 0.23613110651033264],\n",
       "   ['lord high chancellor', 0.22477434418410436],\n",
       "   ['great officer', 0.17917098906570916],\n",
       "   ['state', 0.13984001124711287],\n",
       "   ['post', 0.13517411872541135],\n",
       "   ['holder', 0.11453829487217326]]],\n",
       " [[['corliss', 0.3333333333333333]],\n",
       "  [['1949 american comedy film', 0.23322910017121595],\n",
       "   ['american comedy film', 0.21964544015417156],\n",
       "   ['richard wallace', 0.17485348947721713],\n",
       "   ['howard dimsdale', 0.14981452546387572],\n",
       "   ['1949', 0.14151883162620835],\n",
       "   ['corliss', 0.1334070822985507]],\n",
       "  [['shirley temple', 0.18411415481676172],\n",
       "   ['final starring role', 0.16132770842430955],\n",
       "   ['final film appearance', 0.14482972789599038]],\n",
       "  [['1945 film kiss', 0.33511356453722757], ['1945', 0.21726008945965164]],\n",
       "  [['almost bride', 0.21912914291846536],\n",
       "   ['title sequence', 0.2128644792828132],\n",
       "   ['corliss', 0.16597964987587016],\n",
       "   ['release', 0.15439004805609052],\n",
       "   ['kiss', 0.10728170890239026],\n",
       "   ['title', 0.10211178938934089]],\n",
       "  [['november 25 1949', 0.28983186591904736],\n",
       "   ['united artist', 0.21561066531426237],\n",
       "   ['november', 0.18081720983112098],\n",
       "   ['film', 0.1218610562773177]]],\n",
       " [[['1945 film', 0.30618621784789724], ['1945', 0.2561306370643219]],\n",
       "  [['1945 american comedy film', 0.21894889843973683],\n",
       "   ['17yearold shirley temple', 0.20288361698880442],\n",
       "   ['shirley temple', 0.18093167392553705],\n",
       "   ['american', 0.14043643876659098],\n",
       "   ['corliss archer', 0.13926541758372488],\n",
       "   ['1945', 0.1284893446563067]],\n",
       "  [['two teenage girl', 0.18751772716956946],\n",
       "   ['two', 0.12336987307235638],\n",
       "   ['film', 0.10943881858356827],\n",
       "   ['boy', 0.10388763207320373],\n",
       "   ['respective parent', 0.10323638804008303]],\n",
       "  [['bad influence', 0.2333668624104014],\n",
       "   ['more problem', 0.22295371890690896],\n",
       "   ['parent', 0.11409485751150897],\n",
       "   ['girl', 0.0842239636386126]]],\n",
       " [[['constitutional affair', 0.30368238303033623],\n",
       "   ['state', 0.2854763267293529],\n",
       "   ['state constitutional affair', 0.23642729850331476],\n",
       "   ['secretary', 0.1772686320214733]],\n",
       "  [['british government position', 0.24119071022816538],\n",
       "   ['constitutional affair', 0.19936809680509532],\n",
       "   ['british', 0.17546266686994852],\n",
       "   ['state', 0.15268722987759725],\n",
       "   ['state constitutional affair', 0.14363620009719125],\n",
       "   ['secretary', 0.14140480486841117],\n",
       "   ['2003', 0.11842207161367797],\n",
       "   ['office', 0.10877323619538279]],\n",
       "  [['lord chancellors department', 0.2532866334570669],\n",
       "   ['lord chancellor', 0.22825215734537843],\n",
       "   ['certain function', 0.16966205671503887],\n",
       "   ['secretary', 0.14123086448883418],\n",
       "   ['state', 0.10867484551851495]],\n",
       "  [['further function', 0.15904671786501995],\n",
       "   ['deputy prime minister', 0.15677282477533477],\n",
       "   ['secretary', 0.14249313259446159],\n",
       "   ['state', 0.14229001315822226],\n",
       "   ['constitutional affair', 0.13562461606988369],\n",
       "   ['later date', 0.134061956197432],\n",
       "   ['government', 0.11432522324519442],\n",
       "   ['first', 0.11044165835126937]]],\n",
       " [[['village accountant', 0.4330127018922193]],\n",
       "  [['patwari talati patel karnam adhikari shanbogarupatnaik etc',\n",
       "    0.19827165726842746],\n",
       "   ['patwari talati patel karnam', 0.17957432782840413],\n",
       "   ['administrative government position', 0.15867593371634275],\n",
       "   ['rural part', 0.14427986658505138],\n",
       "   ['adhikari shanbogarupatnaik', 0.14352426011834635],\n",
       "   ['village accountant', 0.12330061872119483],\n",
       "   ['indian', 0.10050119804628745]],\n",
       "  [['telangana bengal north india', 0.24420107380218248],\n",
       "   ['patwari', 0.1575064985324983],\n",
       "   ['officeholder', 0.14744239509323168],\n",
       "   ['sindh', 0.12173344029620649],\n",
       "   ['pakistan', 0.12042008883145874],\n",
       "   ['office', 0.09586360798048307],\n",
       "   ['tapedar', 0.09303871809080629]],\n",
       "  [['andhra pradesh patnaik', 0.18722016418846088],\n",
       "   ['karnataka gujarat', 0.1629773652917834],\n",
       "   ['tamil nadu', 0.1435202806583365],\n",
       "   ['talati', 0.1426309447509821],\n",
       "   ['adhikari', 0.13010629592591103],\n",
       "   ['orissa', 0.12361988330942077],\n",
       "   ['karnam', 0.12235822917999618],\n",
       "   ['tamil', 0.11048196356301496],\n",
       "   ['nadu', 0.11048196356301496],\n",
       "   ['maharashtra', 0.10555416609787788],\n",
       "   ['position', 0.0820219431021646]],\n",
       "  [['northern karnataka', 0.27263412757673366],\n",
       "   ['kulkarni', 0.21455004183821716],\n",
       "   ['karnataka', 0.2098738492622746],\n",
       "   ['maharashtra', 0.17468678456075815],\n",
       "   ['position', 0.14516130100050617]],\n",
       "  [['south karnataka', 0.26820370045189323],\n",
       "   ['shanbogaru', 0.25095481772180467],\n",
       "   ['position', 0.16354006955611122]]],\n",
       " [[['charles craft', 0.4330127018922193]],\n",
       "  [['9 1902 september 19 1968', 0.15999196000596402],\n",
       "   ['charles craft', 0.15943792049487238],\n",
       "   ['englishborn american film television editor', 0.1506446430849907],\n",
       "   ['englishborn american film television', 0.14274438579047555],\n",
       "   ['september', 0.13019573775185583]],\n",
       "  [['may 9 1902 craft', 0.21571101861343145],\n",
       "   ['may 9 1902', 0.19541158161995012],\n",
       "   ['film industry', 0.1714161275079143],\n",
       "   ['county', 0.1251275367654618],\n",
       "   ['england', 0.12076556106860721],\n",
       "   ['hollywood', 0.12035990276091316],\n",
       "   ['hampshire', 0.11475144837477083],\n",
       "   ['1927', 0.08053232075738935]],\n",
       "  [['universal picture silent film painting town', 0.2977201194703125],\n",
       "   ['universal picture silent', 0.2538569299092652],\n",
       "   ['first film', 0.22359145126936725],\n",
       "   ['first', 0.12340760938242282]],\n",
       "  [['next 25 year craft', 0.24473214817056607],\n",
       "   ['90 featurelength film', 0.2164266319110285],\n",
       "   ['next 25 year', 0.2164266319110285],\n",
       "   ['90', 0.16192282742164948]],\n",
       "  [['racket squad', 0.14786057044569226],\n",
       "   ['small screen', 0.14451235777202942],\n",
       "   ['main editor', 0.13689823617149394],\n",
       "   ['93', 0.1337845614197434],\n",
       "   ['early 1950', 0.1309936606993744],\n",
       "   ['98 episode', 0.12840868134708155],\n",
       "   ['first', 0.11813531714030029],\n",
       "   ['98', 0.10683536725349088],\n",
       "   ['first show', 0.09078635273407638],\n",
       "   ['1951–53', 0.09036232451595091],\n",
       "   ['focus', 0.06351349882618189]],\n",
       "  [['several other series', 0.16430337805584627],\n",
       "   ['corliss archer', 0.1571172731092809],\n",
       "   ['1954', 0.12083862973271843],\n",
       "   ['1950', 0.11580254364206069]],\n",
       "  [['lloyd bridge', 0.17452009693180803],\n",
       "   ['sea hunt', 0.17372956086359267],\n",
       "   ['early 1960', 0.15929900572410305],\n",
       "   ['main editor', 0.1532808779991482],\n",
       "   ['late 1950', 0.1490885188147983],\n",
       "   ['half', 0.11753608143692358],\n",
       "   ['one', 0.11476626420440934],\n",
       "   ['episode', 0.07833483711566333]],\n",
       "  [['1963s flipper', 0.18964184544714371],\n",
       "   ['new adventure', 0.18825596120574323],\n",
       "   ['flipper', 0.16996604805458473],\n",
       "   ['sequel', 0.14549599712693967],\n",
       "   ['1964', 0.14549599712693967],\n",
       "   ['final film work', 0.12149375852864777],\n",
       "   ['1963s', 0.11719888021874122]],\n",
       "  [['television series craft', 0.17922110493275753],\n",
       "   ['28 episode', 0.15543984504131786],\n",
       "   ['first', 0.11630040045940712],\n",
       "   ['28', 0.11630040045940712],\n",
       "   ['duty', 0.11219804457088009],\n",
       "   ['film', 0.09690214156096605],\n",
       "   ['1966', 0.08236808782440555],\n",
       "   ['show', 0.06066193958348488]],\n",
       "  [['september 19 1968', 0.26698130156975136],\n",
       "   ['los angeles california', 0.23749891556054822],\n",
       "   ['los angeles', 0.22433361038783023],\n",
       "   ['september', 0.1829180340600043],\n",
       "   ['craft', 0.13673397508895443]]]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].paras_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corliss archer']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].common_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corliss archer', 'film kiss', 'woman', 'government position']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].extended_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Kiss and Tell (1945 film)', 0],\n",
       " ['Shirley Temple', 0],\n",
       " ['Shirley Temple', 1]]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].supporting_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Kiss and Tell (1945 film)', 0]]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.iloc[1].supporting_facts_reduced_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ['Meet Corliss Archer',\n",
       "   [\"Meet Corliss Archer, a program from radio's Golden Age, ran from January 7, 1943 to September 30, 1956.\",\n",
       "    ' Although it was CBS\\'s answer to NBC\\'s popular \"A Date with Judy\", it was also broadcast by NBC in 1948 as a summer replacement for \"The Bob Hope Show\".',\n",
       "    ' From October 3, 1952 to June 26, 1953, it aired on ABC, finally returning to CBS.',\n",
       "    \" Despite the program's long run, fewer than 24 episodes are known to exist.\"]]),\n",
       " (1,\n",
       "  ['Shirley Temple',\n",
       "   [\"Shirley Temple Black (April 23, 1928 – February 10, 2014) was an American actress, singer, dancer, businesswoman, and diplomat who was Hollywood's number one box-office draw as a child actress from 1935 to 1938.\",\n",
       "    ' As an adult, she was named United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States.']]),\n",
       " (2,\n",
       "  ['Janet Waldo',\n",
       "   ['Janet Marie Waldo (February 4, 1920 – June 12, 2016) was an American radio and voice actress.',\n",
       "    ' She is best known in animation for voicing Judy Jetson, Nancy in \"Shazzan\", Penelope Pitstop, and Josie in \"Josie and the Pussycats\", and on radio as the title character in \"Meet Corliss Archer\".']]),\n",
       " (3,\n",
       "  ['Meet Corliss Archer (TV series)',\n",
       "   ['Meet Corliss Archer is an American television sitcom that aired on CBS (July 13, 1951 - August 10, 1951) and in syndication via the Ziv Company from April to December 1954.',\n",
       "    ' The program was an adaptation of the radio series of the same name, which was based on a series of short stories by F. Hugh Herbert.']]),\n",
       " (4,\n",
       "  ['Lord High Treasurer',\n",
       "   ['The post of Lord High Treasurer or Lord Treasurer was an English government position and has been a British government position since the Acts of Union of 1707.',\n",
       "    ' A holder of the post would be the third-highest-ranked Great Officer of State, below the Lord High Steward and the Lord High Chancellor.']]),\n",
       " (5,\n",
       "  ['A Kiss for Corliss',\n",
       "   ['A Kiss for Corliss is a 1949 American comedy film directed by Richard Wallace and written by Howard Dimsdale.',\n",
       "    ' It stars Shirley Temple in her final starring role as well as her final film appearance.',\n",
       "    ' It is a sequel to the 1945 film \"Kiss and Tell\".',\n",
       "    ' \"A Kiss for Corliss\" was retitled \"Almost a Bride\" before release and this title appears in the title sequence.',\n",
       "    ' The film was released on November 25, 1949, by United Artists.']]),\n",
       " (6,\n",
       "  ['Kiss and Tell (1945 film)',\n",
       "   ['Kiss and Tell is a 1945 American comedy film starring then 17-year-old Shirley Temple as Corliss Archer.',\n",
       "    ' In the film, two teenage girls cause their respective parents much concern when they start to become interested in boys.',\n",
       "    \" The parents' bickering about which girl is the worse influence causes more problems than it solves.\"]]),\n",
       " (7,\n",
       "  ['Secretary of State for Constitutional Affairs',\n",
       "   ['The office of Secretary of State for Constitutional Affairs was a British Government position, created in 2003.',\n",
       "    \" Certain functions of the Lord Chancellor which related to the Lord Chancellor's Department were transferred to the Secretary of State.\",\n",
       "    ' At a later date further functions were also transferred to the Secretary of State for Constitutional Affairs from the First Secretary of State, a position within the government held by the Deputy Prime Minister.']]),\n",
       " (8,\n",
       "  ['Village accountant',\n",
       "   ['The Village Accountant (variously known as \"Patwari\", \"Talati\", \"Patel\", \"Karnam\", \"Adhikari\", \"Shanbogaru\",\"Patnaik\" etc.) is an administrative government position found in rural parts of the Indian sub-continent.',\n",
       "    ' The office and the officeholder are called the \"patwari\" in Telangana, Bengal, North India and in Pakistan while in Sindh it is called \"tapedar\".',\n",
       "    ' The position is known as the \"karnam\" in Andhra Pradesh, \"patnaik\" in Orissa or \"adhikari\" in Tamil Nadu, while it is commonly known as the \"talati\" in Karnataka, Gujarat and Maharashtra.',\n",
       "    ' The position was known as the \"kulkarni\" in Northern Karnataka and Maharashtra.',\n",
       "    ' The position was known as the \"shanbogaru\" in South Karnataka.']]),\n",
       " (9,\n",
       "  ['Charles Craft',\n",
       "   ['Charles Craft (May 9, 1902 – September 19, 1968) was an English-born American film and television editor.',\n",
       "    ' Born in the county of Hampshire in England on May 9, 1902, Craft would enter the film industry in Hollywood in 1927.',\n",
       "    ' The first film he edited was the Universal Pictures silent film, \"Painting the Town\".',\n",
       "    ' Over the next 25 years, Craft would edit 90 feature-length films.',\n",
       "    ' In the early 1950s he would switch his focus to the small screen, his first show being \"Racket Squad\", from 1951–53, for which he was the main editor, editing 93 of the 98 episodes.',\n",
       "    ' He would work on several other series during the 1950s, including \"Meet Corliss Archer\" (1954), \"Science Fiction Theatre\" (1955–56), and \"Highway Patrol\" (1955–57).',\n",
       "    ' In the late 1950s and early 1960s he was one of the main editors on \"Sea Hunt\", starring Lloyd Bridges, editing over half of the episodes.',\n",
       "    ' His final film work would be editing \"Flipper\\'s New Adventure\" (1964, the sequel to 1963\\'s \"Flipper\".',\n",
       "    ' When the film was made into a television series, Craft would begin the editing duties on that show, editing the first 28 episodes before he retired in 1966.',\n",
       "    ' Craft died on September 19, 1968 in Los Angeles, California.']])]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(dev_joint_df.iloc[1].context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [['1945 film', 0.30618621784789724], ['1945', 0.2561306370643219]]),\n",
       " (1,\n",
       "  [['1945 american comedy film', 0.21894889843973683],\n",
       "   ['17yearold shirley temple', 0.20288361698880442],\n",
       "   ['shirley temple', 0.18093167392553705],\n",
       "   ['american', 0.14043643876659098],\n",
       "   ['corliss archer', 0.13926541758372488],\n",
       "   ['1945', 0.1284893446563067]]),\n",
       " (2,\n",
       "  [['two teenage girl', 0.18751772716956946],\n",
       "   ['two', 0.12336987307235638],\n",
       "   ['film', 0.10943881858356827],\n",
       "   ['boy', 0.10388763207320373],\n",
       "   ['respective parent', 0.10323638804008303]]),\n",
       " (3,\n",
       "  [['bad influence', 0.2333668624104014],\n",
       "   ['more problem', 0.22295371890690896],\n",
       "   ['parent', 0.11409485751150897],\n",
       "   ['girl', 0.0842239636386126]])]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(dev_joint_df.iloc[1].paras_phrases[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though 'Kiss and Tell (1945 film)' is found based on *'corliss archer'*, and even find the sentence that contains *'shirley temple'*, but it failed to identify *'shirley temple'* as an extended phrase to further explore other sentences that contains *'shirley temple'*. This is mainly because *'Kiss and Tell'* is not recognized in question, and thus *'shirley temple'* is not included in the path when there is only one common phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduced Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_joint_df['reduced_context_joint'] = dev_joint_df['reduced_context'].map(lambda x: \" \".join(list(flatten(x)) ))\n",
    "dev_joint_df['reduced_context_joint'] = dev_joint_df['reduced_context_joint'].map(_normalize_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.000000\n",
       "mean       18.439838\n",
       "std         9.087830\n",
       "min         0.000000\n",
       "25%        12.000000\n",
       "50%        19.000000\n",
       "75%        24.000000\n",
       "max        71.000000\n",
       "Name: reduced_context, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df['reduced_context'].map(lambda x: list(flatten(x)) ).str.len().describe()  # statistic of number of context sentences, including tilte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = dev_joint_df.groupby(dev_joint_df['reduced_context'].map(lambda x: list(flatten(x)) ).str.len())\n",
    "num_of_context_sentences = grouped.size()  # count of each  \n",
    "\n",
    "# distribution of number of context sentences\n",
    "plot = num_of_context_sentences.plot(kind = 'bar', figsize=(15, 7))\n",
    "plt.xticks(rotation=0)                                    # show label text horizontally \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_joint_df['normalized_answer_in_reduced_context'] = dev_joint_df.apply(lambda row:  findWord(row['answer'], row['reduced_context_joint']) == True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7405\n",
       "unique       2\n",
       "top       True\n",
       "freq      4824\n",
       "Name: normalized_answer_in_reduced_context, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.normalized_answer_in_reduced_context.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4824 questions' answer in the context, 7405-4824 = 2581 questions' answer are not in the reduced context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5083"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[(dev_joint_df['normalized_answer_in_reduced_context'] == True) | (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5085"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[(dev_joint_df['normalized_answer_in_reduced_context'] == True) | (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no') | (dev_joint_df['answer'] == '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2320"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[(dev_joint_df['normalized_answer_in_reduced_context'] == False) & (dev_joint_df['answer'] != 'yes') & (dev_joint_df['answer'] != 'no') & (dev_joint_df['answer'] != '')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supporting facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_sp_in_reduced_context\n",
       "0     976\n",
       "1    2702\n",
       "2    2943\n",
       "3     670\n",
       "4     105\n",
       "5       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of number of supporting facts in reduced_context\n",
    "dev_joint_df['num_of_sp_in_reduced_context'] = dev_joint_df['supporting_facts_reduced_context'].map(lambda x: len(x))\n",
    "grouped = dev_joint_df.groupby(['num_of_sp_in_reduced_context'])\n",
    "num_of_sp_in_reduced_context_counts = grouped.size()  # count of each \n",
    "num_of_sp_in_reduced_context_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.500000\n",
       "1       0.333333\n",
       "2       0.600000\n",
       "3       0.500000\n",
       "4       0.500000\n",
       "          ...   \n",
       "7400    0.666667\n",
       "7401    0.500000\n",
       "7402    1.000000\n",
       "7403    0.500000\n",
       "7404    0.500000\n",
       "Name: sp_in_reduced_context_ratio, Length: 7405, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio of supporting facts remained in the reduced context \n",
    "dev_joint_df['sp_in_reduced_context_ratio'] = dev_joint_df.apply(lambda row: len(row['supporting_facts_reduced_context']) / len(row['supporting_facts'])  , axis=1)\n",
    "\n",
    "#dev_joint_df['sp_in_reduced_context'].map(lambda x: sum(x) / len(x)) \n",
    "dev_joint_df['sp_in_reduced_context_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7405.000000\n",
       "mean        0.619735\n",
       "std         0.340262\n",
       "min         0.000000\n",
       "25%         0.500000\n",
       "50%         0.500000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: sp_in_reduced_context_ratio, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df['sp_in_reduced_context_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for questions whose answer in reduced_context, the ratio of supporting facts remained in the reduced context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_context contains the answer, even though does not contain any supporting fact\n",
    "dev_joint_df.loc[(dev_joint_df.num_of_sp_in_reduced_context == 0) & (dev_joint_df.normalized_answer_in_reduced_context == True)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [scott derrickson born july 16 1966 is america...\n",
       "1       [kiss and tell is 1945 american comedy film st...\n",
       "2       [with respect to continuity within series it t...\n",
       "3       [laleli mosque turkish laleli camii or tulip m...\n",
       "4       [adriana trigiani is italian american bestsell...\n",
       "                              ...                        \n",
       "7400    [coke kahani urdu کوک کہانی‎ is 2012 pakistani...\n",
       "7401    [canfields diet chocolate fudge soda is zeroca...\n",
       "7402    [billy is large scenthound originating from ce...\n",
       "7403    [thinking fellers union local 282 is experimen...\n",
       "7404    [blackfin is family of 16 or 32bit microproces...\n",
       "Name: sp_text_reduced_context, Length: 7405, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df['sp_text_reduced_context'] = dev_joint_df.apply(lambda row: [_normalize_text(dict(row['reduced_context'])[sp_t][sp_idx]) for (sp_t, sp_idx) in row['supporting_facts_reduced_context'] if(sp_idx < len(dict(row['reduced_context'])[sp_t])) ], axis = 1)\n",
    "\n",
    "dev_joint_df['sp_text_reduced_context']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4        True\n",
       "        ...  \n",
       "7400     True\n",
       "7401     True\n",
       "7402    False\n",
       "7403    False\n",
       "7404    False\n",
       "Name: normalized_answer_in_reduced_sp_text, Length: 7405, dtype: bool"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df['normalized_answer_in_reduced_sp_text'] = dev_joint_df.apply(lambda row: any([ findWord(row['answer'], f) == True for f in row['sp_text_reduced_context']]), axis = 1)\n",
    "dev_joint_df['normalized_answer_in_reduced_sp_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7405\n",
       "unique       2\n",
       "top       True\n",
       "freq      4152\n",
       "Name: normalized_answer_in_reduced_sp_text, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.normalized_answer_in_reduced_sp_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2877"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[(dev_joint_df['normalized_answer_in_reduced_sp_text'] == False) & (dev_joint_df['answer'] != 'yes') & (dev_joint_df['answer'] != 'no') & (dev_joint_df['answer'] != '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[ (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no') | (dev_joint_df['answer'] == '')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_joint_df.loc[(dev_joint_df['normalized_answer_in_reduced_sp_text'] == True) & ( (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no') |(dev_joint_df['answer'] == ''))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_context contain the answer, but the sp in reduced context does not contain the answer\n",
    "dev_joint_df.loc[(dev_joint_df.normalized_answer_in_reduced_context == True) & (dev_joint_df.normalized_answer_in_reduced_sp_text == False) ].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save \n",
    "To train longformer on context vs reduced_context, compare run time and performance  \n",
    "just over the questions has answer in the reduced_context\n",
    "Thus save file contains only the questions has answer in the reduced_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7405 entries, 0 to 7404\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   _id                                   7405 non-null   object \n",
      " 1   question                              7405 non-null   object \n",
      " 2   answer                                7405 non-null   object \n",
      " 3   level                                 7405 non-null   object \n",
      " 4   type                                  7405 non-null   object \n",
      " 5   context                               7405 non-null   object \n",
      " 6   supporting_facts                      7405 non-null   object \n",
      " 7   reduced_context                       7405 non-null   object \n",
      " 8   supporting_facts_reduced_context      7405 non-null   object \n",
      " 9   question_phrases                      7405 non-null   object \n",
      " 10  paras_phrases                         7405 non-null   object \n",
      " 11  common_phrases                        7405 non-null   object \n",
      " 12  path_phrases                          7405 non-null   object \n",
      " 13  extended_phrases                      7405 non-null   object \n",
      " 14  kept_para_sent                        7405 non-null   object \n",
      " 15  reduced_context_joint                 7405 non-null   object \n",
      " 16  normalized_answer_in_reduced_context  7405 non-null   bool   \n",
      " 17  num_of_sp_in_reduced_context          7405 non-null   int64  \n",
      " 18  sp_in_reduced_context_ratio           7405 non-null   float64\n",
      " 19  sp_text_reduced_context               7405 non-null   object \n",
      " 20  normalized_answer_in_reduced_sp_text  7405 non-null   bool   \n",
      "dtypes: bool(2), float64(1), int64(1), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dev_joint_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5075"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotpot_reduced_dev_df = dev_joint_df.loc[(dev_joint_df.reduced_context.str.len() > 0) & ((dev_joint_df['normalized_answer_in_reduced_context'] == True) | (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no')) , ['supporting_facts', 'context', 'answer', '_id', 'question']]\n",
    "hotpot_reduced_dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_reduced_dev_df.to_json(\"/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/context/hotpot_reduced_dev.json\", orient=\"records\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5075"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save file contains only the questions with reduced_context has answer in the reduced_context\n",
    "hotpot_dev_reduced_context_df = dev_joint_df.loc[(dev_joint_df.reduced_context.str.len() > 0) & ((dev_joint_df['normalized_answer_in_reduced_context'] == True) | (dev_joint_df['answer'] == 'yes') | (dev_joint_df['answer'] == 'no')) , ['supporting_facts_reduced_context', 'reduced_context', 'answer', '_id', 'question']] \n",
    "\n",
    "hotpot_dev_reduced_context_df.rename(columns={'supporting_facts_reduced_context': 'supporting_facts', \"reduced_context\": \"context\"}, inplace=True)\n",
    "hotpot_dev_reduced_context_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_dev_reduced_context_df.to_json(\"/xdisk/msurdeanu/fanluo/hotpotQA/Data/reduced_questions/reduced_context/hotpot_reduced_dev_reduced_context.json\", orient=\"records\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal: (10~12 pages)\n",
    "    - intro and motivation\n",
    "       - reasoning system without logic, approx instead, roubst with graph-based method\n",
    "    - related works \n",
    "        -  qa \n",
    "        - KG based\n",
    "        - multi-hop reasoning   \n",
    "        - graph-based\n",
    "        \n",
    "    - pre results (analysis)\n",
    "    - plan for the dissertation\n",
    "       - refer to mithun's proposal under github's paper\n",
    "        - 3 works\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "reduced_context_ratios = loadtxt(\"graph_reduced_context_ratios.txt\", delimiter=\",\")\n",
    "reduced_context_ratios_df = pd.DataFrame(reduced_context_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_context_ratios_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_context_ratios_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_df = reduced_context_ratios_df[0] ! = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glove embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### flair embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transformer embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from transformers import LongformerTokenizer, LongformerForQuestionAnswering\n",
    ">>> import torch\n",
    "\n",
    ">>> tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")\n",
    ">>> model = LongformerForQuestionAnswering.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install flair\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from flair.data import Sentence, Corpus\n",
    "from flair.embeddings import DocumentRNNEmbeddings, BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotpotqa",
   "language": "python",
   "name": "hotpotqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "220px",
    "width": "267px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
