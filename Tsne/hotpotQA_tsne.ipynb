{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '/xdisk/msurdeanu/fanluo/hotpotQA/')\n",
    "from util import get_buckets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_file = \"/xdisk/msurdeanu/fanluo/hotpotQA/word_emb.json\"\n",
    "with open(word_emb_file, \"r\") as fh:\n",
    "    word_mat = np.array(json.load(fh), dtype=np.float32)\n",
    "with open('/xdisk/msurdeanu/fanluo/hotpotQA/idx2word.json', 'r') as fh:\t\n",
    "    idx2word_dict = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buckets = get_buckets('/xdisk/msurdeanu/fanluo/hotpotQA/train_record.pkl')\n",
    "X_train = train_buckets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = {}    \n",
    "question_avg_embedding = np.array([])\n",
    "question_list = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    ques_idxs = X_train[i]['ques_idxs']\n",
    "    ques_idxs = ques_idxs[ques_idxs > 1]  # 0 is padding, 1 is unknown, questions longer than ques_limit already been discarded in prepro.py\n",
    "    ques_words = ' '.join([idx2word_dict[str(int(idx))] for idx in ques_idxs])\t\n",
    "    question_list.append(ques_words)\n",
    "    question_word_embedding_mat = word_mat[ques_idxs]\n",
    "    question_embedding = np.mean(question_word_embedding_mat, 0)  # average of word embedding as question embedding\n",
    "\n",
    "    if i == 0:\n",
    "        question_avg_embedding = question_embedding \n",
    "    else:\n",
    "        question_avg_embedding = np.vstack((question_avg_embedding, question_embedding))\n",
    "\n",
    "    \n",
    "question_data['text'] = question_list\n",
    "question_data['emb'] = question_avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref to https://www.kaggle.com/colinmorris/visualizing-embeddings-with-t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=1, n_iter=15000, metric=\"cosine\")\n",
    "\n",
    "embs = tsne.fit_transform(question_data['emb'])\n",
    "# Add to dataframe for convenience\n",
    "df['x'] = embs[:, 0]\n",
    "df['y'] = embs[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotpotqa",
   "language": "python",
   "name": "hotpotqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
