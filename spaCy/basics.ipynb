{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href='https://spacy.io/models' style='text-decoration:none'>Spacy model</a>\n",
    "<a href='https://spacy.io/usage/models' style='text-decoration:none'>A list of models</a> <br>\n",
    "A spaCy model consists of three components: \n",
    "- The weights, i.e. binary data loaded in from a directory\n",
    "- A pipeline of functions called in order\n",
    "- Language data like the tokenization rules and annotation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.5\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip uninstall -y spacy\n",
    "# !conda install spacy --yes          #fix issue 'No module named 'spacy.symbols'', https://github.com/explosion/spaCy/issues/3791\n",
    "import sys\n",
    "sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.7/site-packages') \n",
    "import spacy   \n",
    "print(spacy.__version__)\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading pretrained models: \n",
    "- The model’s meta.json tells spaCy to use the language \"en\" and the pipeline [\"tagger\", \"parser\", \"ner\"]. \n",
    "- spaCy initializes a spacy.lang.en.English instance, and creates each pipeline component and add it to the processing pipeline. \n",
    "- It’ll then load in the model’s data and return the modified Language class as the nlp object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en \n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "\n",
    "# !python -m spacy download en_core_web_sm     # download model\n",
    "# import en_core_web_sm                        # a small English model trained on written web text \n",
    "# nlp = en_core_web_sm.load()                  # load pretrained models \n",
    "\n",
    "#!python -m spacy download en_core_web_lg \n",
    "import en_core_web_lg                         \n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processe text\n",
    "- Tokenize \n",
    "- Each pipeline component access to the model to assign annotations to the Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a text\")                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13\n",
      "13 33\n",
      "33 61\n",
      "61 91\n"
     ]
    }
   ],
   "source": [
    "text = \"Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(sent.start, sent.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process large volumes of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To process large volumes of text\n",
    "texts = [\"This is a text\", \"These are lots of texts\", \"...\"]  \n",
    "docs = list(nlp.pipe(texts))                    # much faster than docs = [nlp(text) for text in texts] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process text with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"This is a text\", {\"id\": 1, \"page_number\": 15}),\n",
    "    (\"And another text\", {\"id\": 2, \"page_number\": 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    # Print the text and custom attribute data\n",
    "    print(doc.text, context[\"id\"], context[\"page_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "Doc.set_extension(\"id\", default=None)\n",
    "Doc.set_extension(\"page_number\", default=None)\n",
    "\n",
    "data = [\n",
    "    (\"This is a text\", {\"id\": 1, \"page_number\": 15}),\n",
    "    (\"And another text\", {\"id\": 2, \"page_number\": 16}),\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    # Set the attributes from the context\n",
    "    doc._.id = context[\"id\"]\n",
    "    doc._.page_number = context[\"page_number\"]\n",
    "\n",
    "    # Print the text and custom attribute data\n",
    "    print(doc.text, doc._.id, doc._.page_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href='https://spacy.io/usage/linguistic-features' style='text-decoration:none'>Linguistic Features</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc, Token,  Span, and Sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lily ate the pizza this afternoon.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Lily ate the pizza this afternoon.\")  # Process the text: Tokenize and apply pipeline components\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"150\"\n",
       "            src=\"https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7f67c9a358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg', width=600, height=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only tokenize and return a doc object\n",
    "doc = nlp.make_doc(\"Lily ate the pizza this afternoon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a doc object manually\n",
    "words = [\"Lily\", \"ate\", \"the\", \"pizza\", \"this\", \"afternoon\", \".\"]\n",
    "spaces = [True, True, True, True, True, False, False]         # is there a space after each word\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Token\n",
    "Token and Span objects are created lazily, and don’t own any data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th token:  Lily\n",
      "1 th token:  ate\n",
      "2 th token:  the\n",
      "3 th token:  pizza\n",
      "4 th token:  this\n",
      "5 th token:  afternoon\n",
      "6 th token:  .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.i, \"th token: \", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Span\n",
    "a view of doc, itself does not contain data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pizza\n",
      "the pizza\n",
      "pizza\n"
     ]
    }
   ],
   "source": [
    "# Two ways to create a span\n",
    "from spacy.tokens import Span\n",
    "span = Span(doc, 2, 4)\n",
    "print(span.text)\n",
    "\n",
    "span = doc[2:4]      \n",
    "print(span.text)\n",
    "print(span[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"230\"\n",
       "            src=\"https://pasteboard.co/JtQDWNr.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7fe0bd9d68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('https://pasteboard.co/JtQDWNr.png', width=400, height=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pizza Food\n",
      "[('the pizza', 'Food')]\n"
     ]
    }
   ],
   "source": [
    "# create a span with a label\n",
    "span = Span(doc, 2, 4, label=\"Food\")\n",
    "print(span.text, span.label_)\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = list(doc.ents) + [span]\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th token:  Lily\n",
      "1 th token:  ate\n",
      "2 th token:  the pizza\n",
      "3 th token:  this\n",
      "4 th token:  afternoon\n",
      "5 th token:  .\n"
     ]
    }
   ],
   "source": [
    "# merge span and retokenize\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(span)\n",
    "    \n",
    "for token in doc:\n",
    "    print(token.i, \"th token: \", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In ancient Rome, some neighbors live in three adjacent houses.,\n",
       " In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus.,\n",
       " A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom.,\n",
       " One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates).,\n",
       " One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero.,\n",
       " Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\"\"\n",
    "doc = nlp(text)\n",
    "list(doc.sents)   # A list of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href='https://spacy.io/api/token#attributes' style='text-decoration:none'>Token attributes</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(\"Credit and mortgage account holders must submit their requests.\")  \n",
    "doc = nlp(\"Alphabet, Facebook, Apple and Amazon reported a combined $28 billion in profits on Thursday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+----------+-----+------------+-------+-------+-------+-------+\n",
      "|   TEXT   |  LEMMA   | SHAPE |  LOWER   | IDX | SENT START | ALPHA |  NUM  | PUNCT |  STOP |\n",
      "+----------+----------+-------+----------+-----+------------+-------+-------+-------+-------+\n",
      "| Alphabet | Alphabet | Xxxxx | alphabet |  0  |    True    |  True | False | False | False |\n",
      "|    ,     |    ,     |   ,   |    ,     |  8  |    None    | False | False |  True | False |\n",
      "| Facebook | Facebook | Xxxxx | facebook |  10 |    None    |  True | False | False | False |\n",
      "|    ,     |    ,     |   ,   |    ,     |  18 |    None    | False | False |  True | False |\n",
      "|  Apple   |  Apple   | Xxxxx |  apple   |  20 |    None    |  True | False | False | False |\n",
      "|   and    |   and    |  xxx  |   and    |  26 |    None    |  True | False | False |  True |\n",
      "|  Amazon  |  Amazon  | Xxxxx |  amazon  |  30 |    None    |  True | False | False | False |\n",
      "| reported |  report  |  xxxx | reported |  37 |    None    |  True | False | False | False |\n",
      "|    a     |    a     |   x   |    a     |  46 |    None    |  True | False | False |  True |\n",
      "| combined | combined |  xxxx | combined |  48 |    None    |  True | False | False | False |\n",
      "|    $     |    $     |   $   |    $     |  57 |    None    | False | False | False | False |\n",
      "|    28    |    28    |   dd  |    28    |  58 |    None    | False |  True | False | False |\n",
      "| billion  | billion  |  xxxx | billion  |  61 |    None    |  True |  True | False | False |\n",
      "|    in    |    in    |   xx  |    in    |  69 |    None    |  True | False | False |  True |\n",
      "| profits  |  profit  |  xxxx | profits  |  72 |    None    |  True | False | False | False |\n",
      "|    on    |    on    |   xx  |    on    |  80 |    None    |  True | False | False |  True |\n",
      "| Thursday | Thursday | Xxxxx | thursday |  83 |    None    |  True | False | False | False |\n",
      "|    .     |    .     |   .   |    .     |  91 |    None    | False | False |  True | False |\n",
      "+----------+----------+-------+----------+-----+------------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Text: The original word text.\n",
    "# Lemma: The base form of the word.\n",
    "# Shape: The word shape – capitalization, punctuation, digits \n",
    "# Lower: Lowercase form of the token text. Equivalent to token.text.lower()\n",
    "# idx: The character offset of the token \n",
    "# is_sent_start:  whether the token starts a sentence\n",
    "# is_title: Is the token in titlecase? Equivalent to token.text.istitle().\n",
    "# is_alpha: Is the token an alpha character?\n",
    "# like_num: Does the token represent a number? e.g. “10.9”, “10”, “ten”, etc.\n",
    "# is_punct: Is the token a punctuation? \n",
    "# is_stop: Is the token part of a stop list?\n",
    "# Sentiment: positivity or negativity of the token\n",
    "table = PrettyTable()  \n",
    "table.field_names = [\"TEXT\", \"LEMMA\", \"SHAPE\", \"LOWER\", \"IDX\", \"SENT START\", \"TITLECASE\", \"ALPHA\", \"NUM\", \"PUNCT\", \"STOP\"]    \n",
    "for token in doc: \n",
    "    table.add_row([token.text, token.lemma_, token.shape_, token.lower_, token.idx, token.is_sent_start, token.is_title, token.is_alpha, token.like_num, token.is_punct, token.is_stop])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part-of-speech tag\n",
    "POS: <a href='https://spacy.io/api/annotation#pos-universal' style='text-decoration:none'>Universal Part-of-speech Tags</a> (UPOS) <br>\n",
    "Tag: <a href='https://spacy.io/api/annotation#pos-en' style='text-decoration:none'>OntoNotes 5 version of the Penn Treebank tag set</a>: more detail, including info of MORPHOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+\n",
      "|   TEXT   |  POS  | TAG |\n",
      "+----------+-------+-----+\n",
      "| Alphabet | PROPN | NNP |\n",
      "|    ,     | PUNCT |  ,  |\n",
      "| Facebook | PROPN | NNP |\n",
      "|    ,     | PUNCT |  ,  |\n",
      "|  Apple   | PROPN | NNP |\n",
      "|   and    | CCONJ |  CC |\n",
      "|  Amazon  | PROPN | NNP |\n",
      "| reported |  VERB | VBD |\n",
      "|    a     |  DET  |  DT |\n",
      "| combined |  ADJ  |  JJ |\n",
      "|    $     |  SYM  |  $  |\n",
      "|    28    |  NUM  |  CD |\n",
      "| billion  |  NUM  |  CD |\n",
      "|    in    |  ADP  |  IN |\n",
      "| profits  |  NOUN | NNS |\n",
      "|    on    |  ADP  |  IN |\n",
      "| Thursday | PROPN | NNP |\n",
      "|    .     | PUNCT |  .  |\n",
      "+----------+-------+-----+\n"
     ]
    }
   ],
   "source": [
    "# POS: The simple  part-of-speech tag.\n",
    "# Tag: The detailed part-of-speech tag.\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"POS\", \"TAG\"]\n",
    "for token in doc: \n",
    "    table.add_row([token.text, token.pos_, token.tag_])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Syntactic dependency\n",
    "<a href='https://spacy.io/api/annotation#dependency-parsing-universal' style='text-decoration:none'>Universal Dependency Labels</a> <br>\n",
    "<a href='https://spacy.io/api/annotation#dependency-parsing-english' style='text-decoration:none'>English Dependency Labels</a>, used by the *en_core_web_sm* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------------------------------+\n",
      "|   TEXT   |   DEP    |   HEAD   |            ANCESTORS             |\n",
      "+----------+----------+----------+----------------------------------+\n",
      "| Alphabet |  nsubj   | reported |             reported             |\n",
      "|    ,     |  punct   | Alphabet |        Alphabet,reported         |\n",
      "| Facebook |   conj   | Alphabet |        Alphabet,reported         |\n",
      "|    ,     |  punct   | Facebook |    Facebook,Alphabet,reported    |\n",
      "|  Apple   |   conj   | Facebook |    Facebook,Alphabet,reported    |\n",
      "|   and    |    cc    |  Apple   | Apple,Facebook,Alphabet,reported |\n",
      "|  Amazon  |   conj   |  Apple   | Apple,Facebook,Alphabet,reported |\n",
      "| reported |   ROOT   | reported |                                  |\n",
      "|    a     |   det    | billion  |         billion,reported         |\n",
      "| combined |   amod   | billion  |         billion,reported         |\n",
      "|    $     | quantmod | billion  |         billion,reported         |\n",
      "|    28    | compound | billion  |         billion,reported         |\n",
      "| billion  |   dobj   | reported |             reported             |\n",
      "|    in    |   prep   | billion  |         billion,reported         |\n",
      "| profits  |   pobj   |    in    |       in,billion,reported        |\n",
      "|    on    |   prep   | reported |             reported             |\n",
      "| Thursday |   pobj   |    on    |           on,reported            |\n",
      "|    .     |  punct   | reported |             reported             |\n",
      "+----------+----------+----------+----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Dep: Syntactic dependency relation of (token, its Head); ROOT means its head is itself.\n",
    "# HEAD: Syntactic head, every word has exactly one head.\n",
    "# ANCESTORS: Token's direct and indirect ancestors\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"DEP\", \"HEAD\", \"ANCESTORS\"]  \n",
    "for token in doc: \n",
    "    table.add_row( [token.text, token.dep_, token.head.text, ','.join([ancestor.text for ancestor in token.ancestors]) ])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+-----------------+----------------+--------------------------------------------------------------------------------------------------+-----------+------------+\n",
      "|   TEXT   |        CHILDREN       |  LEFT CHILDREN  | RIGHT CHILDREN |                                             SUBTREE                                              | LEFT EDGE | RIGHT EDGE |\n",
      "+----------+-----------------------+-----------------+----------------+--------------------------------------------------------------------------------------------------+-----------+------------+\n",
      "| Alphabet |       ,,Facebook      |                 |   ,,Facebook   |                              Alphabet,,,Facebook,,,Apple,and,Amazon                              |  Alphabet |   Amazon   |\n",
      "|    ,     |                       |                 |                |                                                ,                                                 |     ,     |     ,      |\n",
      "| Facebook |        ,,Apple        |                 |    ,,Apple     |                                   Facebook,,,Apple,and,Amazon                                    |  Facebook |   Amazon   |\n",
      "|    ,     |                       |                 |                |                                                ,                                                 |     ,     |     ,      |\n",
      "|  Apple   |       and,Amazon      |                 |   and,Amazon   |                                         Apple,and,Amazon                                         |   Apple   |   Amazon   |\n",
      "|   and    |                       |                 |                |                                               and                                                |    and    |    and     |\n",
      "|  Amazon  |                       |                 |                |                                              Amazon                                              |   Amazon  |   Amazon   |\n",
      "| reported | Alphabet,billion,on,. |     Alphabet    |  billion,on,.  | Alphabet,,,Facebook,,,Apple,and,Amazon,reported,a,combined,$,28,billion,in,profits,on,Thursday,. |  Alphabet |     .      |\n",
      "|    a     |                       |                 |                |                                                a                                                 |     a     |     a      |\n",
      "| combined |                       |                 |                |                                             combined                                             |  combined |  combined  |\n",
      "|    $     |                       |                 |                |                                                $                                                 |     $     |     $      |\n",
      "|    28    |                       |                 |                |                                                28                                                |     28    |     28     |\n",
      "| billion  |   a,combined,$,28,in  | a,combined,$,28 |       in       |                                a,combined,$,28,billion,in,profits                                |     a     |  profits   |\n",
      "|    in    |        profits        |                 |    profits     |                                            in,profits                                            |     in    |  profits   |\n",
      "| profits  |                       |                 |                |                                             profits                                              |  profits  |  profits   |\n",
      "|    on    |        Thursday       |                 |    Thursday    |                                           on,Thursday                                            |     on    |  Thursday  |\n",
      "| Thursday |                       |                 |                |                                             Thursday                                             |  Thursday |  Thursday  |\n",
      "|    .     |                       |                 |                |                                                .                                                 |     .     |     .      |\n",
      "+----------+-----------------------+-----------------+----------------+--------------------------------------------------------------------------------------------------+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# CHILDREN: A sequence of the token’s immediate syntactic dependents.\n",
    "# LEFT CHILDREN: A sequence of the token’s immediate syntactic dependents that occur before the token.\n",
    "# RIGHT CHILDREN: A sequence of the token’s immediate syntactic dependents that occur after the token.\n",
    "# SUBTREE: token and all its direct and indirect dependents in the original order\n",
    "# LEFT EDGE: first token of the token's subtree\n",
    "# RIGHT EDGE: last token of the token's subtree\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"CHILDREN\" , \"LEFT CHILDREN\" , \"RIGHT CHILDREN\", \"SUBTREE\", \"LEFT EDGE\", \"RIGHT EDGE\"]  \n",
    "for token in doc: \n",
    "    table.add_row([token.text, \n",
    "                   ','.join([child.text for child in token.children]),\n",
    "                   ','.join([child.text for child in token.lefts]),\n",
    "                   ','.join([child.text for child in token.rights]),\n",
    "                   ','.join([child.text for child in token.subtree]),\n",
    "                   token.left_edge.text,\n",
    "                   token.right_edge.text\n",
    "                  ])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amod:  adjectival modifier\n",
      "prep:  prepositional modifier\n",
      "pobj:  object of preposition\n",
      "pcomp:  complement of preposition\n"
     ]
    }
   ],
   "source": [
    "# Get definition of common tags and labels\n",
    "print(\"amod: \", spacy.explain(\"amod\"))  \n",
    "print(\"prep: \", spacy.explain(\"prep\")) \n",
    "print(\"pobj: \", spacy.explain(\"pobj\"))\n",
    "print(\"pcomp: \", spacy.explain(\"pcomp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{reported}\n"
     ]
    }
   ],
   "source": [
    "# Finding a verb with a subject \n",
    "from spacy.symbols import nsubj, VERB\n",
    "verbs = set()\n",
    "for token in doc:\n",
    "    if token.dep == nsubj and token.head.pos == VERB:  # same as: if token.dep_ == 'nsubj' and token.head.pos_ == 'VERB'\n",
    "        verbs.add(token.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found proper noun before a verb: Amazon\n"
     ]
    }
   ],
   "source": [
    "# Finding a proper noun before a verb\n",
    "for token in doc:\n",
    "    # Check if the current token is a proper noun\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        # Check if the next token is a verb\n",
    "        if doc[token.i + 1].pos_ == \"VERB\":\n",
    "            print(\"Found proper noun before a verb:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Named Entity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+----------+\n",
      "|   TEXT   | Named Entity Type | IOB Code |\n",
      "+----------+-------------------+----------+\n",
      "| Alphabet |        GPE        |    B     |\n",
      "|    ,     |                   |    O     |\n",
      "| Facebook |        ORG        |    B     |\n",
      "|    ,     |                   |    O     |\n",
      "|  Apple   |        ORG        |    B     |\n",
      "|   and    |                   |    O     |\n",
      "|  Amazon  |        ORG        |    B     |\n",
      "| reported |                   |    O     |\n",
      "|    a     |                   |    O     |\n",
      "| combined |                   |    O     |\n",
      "|    $     |       MONEY       |    B     |\n",
      "|    28    |       MONEY       |    I     |\n",
      "| billion  |       MONEY       |    I     |\n",
      "|    in    |                   |    O     |\n",
      "| profits  |                   |    O     |\n",
      "|    on    |                   |    O     |\n",
      "| Thursday |        DATE       |    B     |\n",
      "|    .     |                   |    O     |\n",
      "+----------+-------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Type\n",
    "# IOB Code: “B” means the token begins an entity, “I” means it is inside an entity, “O” means it is outside an entity, and \"\" means no entity tag is set.   \n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"Named Entity Type\" , \"IOB Code\"]  \n",
    "for token in doc: \n",
    "    table.add_row([token.text, token.ent_type_, token.ent_iob_ ])\n",
    "print(table)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href='https://spacy.io/usage/visualizers#dep' style='text-decoration:none'>Visualizing POS and Dependencies</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3462b46dfec3403f9ba0fffbe950ef11-0\" class=\"displacy\" width=\"2675\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alphabet,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Facebook,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Amazon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">reported</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">combined</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">28</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">profits</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Thursday.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,89.5 920.0,89.5 920.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-1\" stroke-width=\"2px\" d=\"M70,527.0 C70,439.5 200.0,439.5 200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M200.0,529.0 L208.0,517.0 192.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-2\" stroke-width=\"2px\" d=\"M245,527.0 C245,439.5 375.0,439.5 375.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M375.0,529.0 L383.0,517.0 367.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-3\" stroke-width=\"2px\" d=\"M420,527.0 C420,439.5 550.0,439.5 550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,529.0 L558.0,517.0 542.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-4\" stroke-width=\"2px\" d=\"M420,527.0 C420,352.0 730.0,352.0 730.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,529.0 L738.0,517.0 722.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-5\" stroke-width=\"2px\" d=\"M1120,527.0 C1120,177.0 1790.0,177.0 1790.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,529.0 L1112,517.0 1128,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-6\" stroke-width=\"2px\" d=\"M1295,527.0 C1295,264.5 1785.0,264.5 1785.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,529.0 L1287,517.0 1303,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-7\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,352.0 1780.0,352.0 1780.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,529.0 L1462,517.0 1478,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-8\" stroke-width=\"2px\" d=\"M1645,527.0 C1645,439.5 1775.0,439.5 1775.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,529.0 L1637,517.0 1653,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-9\" stroke-width=\"2px\" d=\"M945,527.0 C945,89.5 1795.0,89.5 1795.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1795.0,529.0 L1803.0,517.0 1787.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-10\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,439.5 1950.0,439.5 1950.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1950.0,529.0 L1958.0,517.0 1942.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-11\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,439.5 2125.0,439.5 2125.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2125.0,529.0 L2133.0,517.0 2117.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-12\" stroke-width=\"2px\" d=\"M945,527.0 C945,2.0 2325.0,2.0 2325.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2325.0,529.0 L2333.0,517.0 2317.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3462b46dfec3403f9ba0fffbe950ef11-0-13\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,439.5 2475.0,439.5 2475.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3462b46dfec3403f9ba0fffbe950ef11-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2475.0,529.0 L2483.0,517.0 2467.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "# displacy.serve(doc, style=\"dep\")    # open a server when running outside of notebook\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj:  nominal subject\n",
      "dobj:  direct object\n",
      "pcomp:  complement of preposition\n",
      "pobj:  object of preposition\n"
     ]
    }
   ],
   "source": [
    "# Get definition of common tags and labels\n",
    "print(\"nsubj: \", spacy.explain(\"nsubj\"))\n",
    "print(\"dobj: \", spacy.explain(\"dobj\"))\n",
    "print(\"pcomp: \", spacy.explain(\"pcomp\"))\n",
    "print(\"pobj: \", spacy.explain(\"pobj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing long texts:  Visualize per sentence\n",
    "text = \"\"\"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\"\"\n",
    "doc = nlp(text)\n",
    "sentence_spans = list(doc.sents)\n",
    "displacy.serve(sentence_spans, style=\"dep\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href='https://spacy.io/usage/visualizers#ent' style='text-decoration:none'>Named Entities</a>\n",
    "- Named Entities: real world objects <br>\n",
    "- <a href='https://spacy.io/api/annotation#named-entities' style='text-decoration:none'>Named Entity Types</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-------+-----+------------+----------+\n",
      "|     TEXT    | Named Entity Label | Start | End | Start Char | End Char |\n",
      "+-------------+--------------------+-------+-----+------------+----------+\n",
      "|   Alphabet  |        GPE         |   0   |  1  |     0      |    8     |\n",
      "|   Facebook  |        ORG         |   2   |  3  |     10     |    18    |\n",
      "|    Apple    |        ORG         |   4   |  5  |     20     |    25    |\n",
      "|    Amazon   |        ORG         |   6   |  7  |     30     |    36    |\n",
      "| $28 billion |       MONEY        |   10  |  13 |     57     |    68    |\n",
      "|   Thursday  |        DATE        |   16  |  17 |     83     |    91    |\n",
      "+-------------+--------------------+-------+-----+------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Start: The word offset of start of entity in the Doc.\n",
    "# End: The word offset of end of entity in the Doc.\n",
    "# Start Char: The character offset of start of entity in the Doc.\n",
    "# End Char: The character offset of end of entity in the Doc.\n",
    "# Label: Entity label, i.e. type.\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"Named Entity Label\", \"Start\" , \"End\", \"Start Char\" , \"End Char\"]  \n",
    "for entity in doc.ents:    # each entity is a span\n",
    "    table.add_row([entity.text, entity.label_, entity.start, entity.end, entity.start_char, entity.end_char])\n",
    "print(table)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alphabet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " reported a combined \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $28 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in profits on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New entity [('fb', 0, 1, 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# manually set new named entity\n",
    "from spacy.tokens import Span\n",
    "doc = nlp(\"fb is hiring a new vice president of global policy\")\n",
    "fb_ent = Span(doc, 0, 1, label=\"ORG\") # create a Span for the new entity\n",
    "doc.ents = list(doc.ents) + [fb_ent]\n",
    "\n",
    "ents = [(e.text, e.start, e.end, e.label_) for e in doc.ents]\n",
    "print('New entity', ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun Phrases / Chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------+-------+--------------+\n",
      "|         TEXT         | CHUNK's ROOT |  DEP  | CHUNK's HEAD |\n",
      "+----------------------+--------------+-------+--------------+\n",
      "|          fb          |      fb      | nsubj |    hiring    |\n",
      "| a new vice president |  president   |  dobj |    hiring    |\n",
      "|    global policy     |    policy    |  pobj |      of      |\n",
      "+----------------------+--------------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Noun Chunks: flat phrases that have a noun as their head. Basically, a noun plus the words describing the noun \n",
    "table = PrettyTable()\n",
    "table.field_names = [\"TEXT\", \"CHUNK's ROOT\", \"DEP\", \"CHUNK's HEAD\"]  \n",
    "for chunk in doc.noun_chunks:\n",
    "    table.add_row([chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "text = \"brown state fishing lake is in country that has population of how many inhabitants\"\n",
    "doc = nlp(text)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('chunk: ', chunk.text) \n",
    "    print('root: ',  chunk.root.text)\n",
    "    span = Span(doc, chunk.root.i, chunk.root.i+1)\n",
    "    print(span)\n",
    "    print(span.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href='https://spacy.io/api/entitylinker' style='text-decoration:none'>EntityLinker</a> \n",
    "- An EntityLinker component disambiguates textual mentions (tagged as named entities) to unique identifiers, grounding the named entities into the “real world”. (need spacy 3.0)\n",
    "- <a href='https://drive.google.com/file/d/1EuGxcQLcXvjjkZ-KRUlwpr_doBVyEBEG/view' style='text-decoration:none'> Slides: Entity linking functionality in spaCy</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline.entity_linker import DEFAULT_NEL_MODEL\n",
    "config = {\n",
    "   \"labels_discard\": [],\n",
    "   \"n_sents\": 0,\n",
    "   \"incl_prior\": True,\n",
    "   \"incl_context\": True,\n",
    "   \"model\": DEFAULT_NEL_MODEL,\n",
    "   \"entity_vector_length\": 64,\n",
    "   \"get_candidates\": {'@misc': 'spacy.CandidateGenerator.v1'},\n",
    "}\n",
    "nlp.add_pipe(\"entity_linker\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href='https://github.com/huggingface/neuralcoref' style='text-decoration:none'>Coreference Resolution</a>\n",
    "- <a href='https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30' style='text-decoration:none'>blog</a>\n",
    "- <a href='https://github.com/huggingface/neuralcoref-viz' style='text-decoration:none'>NeuralCoref-Viz</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "## had to install neuralcoref from source because of 'segament fault' issue:  https://github.com/huggingface/neuralcoref/issues/164\n",
    "\n",
    "# !git clone https://github.com/huggingface/neuralcoref.git\n",
    "# import os\n",
    "# os.chdir('/home/u32/fanluo/Jupyter/experiments/spaCy/neuralcoref')\n",
    "# !pip install -r requirements.txt \n",
    "# !pip install -e .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fa740b85c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuralCoref is made of two sub-modules:\n",
    "- a rule-based mentions-detection module which uses SpaCy's tagger, parser and NER annotations to identify a set of potential coreference mentions \n",
    "- a feed-forward neural-network which compute a coreference score for each pair of potential mentions.\n",
    "\n",
    "|Attribute|Type\t|Description|\n",
    "|:---|:---|:---|\n",
    "|doc._.has_coref\t|boolean\t|Has any coreference has been resolved in the Doc|\n",
    "|doc._.coref_clusters\t|list of Cluster\t|All the clusters of corefering mentions in the doc|\n",
    "|**doc._.coref_resolved**\t|unicode\t|Unicode representation of the doc where each corefering mention is replaced by the main mention in the associated cluster.|\n",
    "|doc._.coref_scores\t|Dict of Dict\t|Scores of the coreference resolution between mentions.|\n",
    "|span._.is_coref\t|boolean\t|Whether the span has at least one corefering mention|\n",
    "|span._.coref_cluster\t|Cluster\t|Cluster of mentions that corefer with the span|\n",
    "|span._.coref_scores\t|Dict\t|Scores of the coreference resolution of & span with other mentions (if applicable).|\n",
    "|token._.in_coref\t|boolean\t|Whether the token is inside at least one corefering mention|\n",
    "|token._.coref_clusters\t|list of Cluster\t|All the clusters of corefering mentions that contains the token|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"My sister has a dog. She loves him.\")  \n",
    "doc._.has_coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My sister has a dog. My sister loves a dog.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------------------+\n",
      "| Idx |  Referent | Corefering Mentions |\n",
      "+-----+-----------+---------------------+\n",
      "|  0  | My sister |    My sister, She   |\n",
      "|  1  |   a dog   |      a dog, him     |\n",
      "+-----+-----------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Idx\", \"Referent\", \"Corefering Mentions\"]  \n",
    "for coref_cluster in doc._.coref_clusters: \n",
    "    table.add_row([coref_cluster.i, coref_cluster.main.text, ', '.join([m.text for m in coref_cluster.mentions]) ])\n",
    "print(table)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My sister | {My sister: 1.3110305070877075}\n",
      "a dog | {a dog: 1.804752230644226, My sister: -1.6715972423553467}\n",
      "She | {She: -0.10834169387817383, My sister: 8.058427810668945, a dog: -1.0625176429748535}\n",
      "him | {him: -1.8707444667816162, My sister: 3.1147196292877197, a dog: 4.356405258178711, She: -3.1379525661468506}\n"
     ]
    }
   ],
   "source": [
    "for mention, mention_scores in doc._.coref_scores.items(): \n",
    "    print(mention, '|', str(mention_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+-------------------------------+\n",
      "| Token  | In Corefering Mention |     Coreferrence Clusters     |\n",
      "+--------+-----------------------+-------------------------------+\n",
      "|   My   |          True         | [My sister: [My sister, She]] |\n",
      "| sister |          True         | [My sister: [My sister, She]] |\n",
      "|  has   |         False         |               []              |\n",
      "|   a    |          True         |     [a dog: [a dog, him]]     |\n",
      "|  dog   |          True         |     [a dog: [a dog, him]]     |\n",
      "|   .    |         False         |               []              |\n",
      "|  She   |          True         | [My sister: [My sister, She]] |\n",
      "| loves  |         False         |               []              |\n",
      "|  him   |          True         |     [a dog: [a dog, him]]     |\n",
      "|   .    |         False         |               []              |\n",
      "+--------+-----------------------+-------------------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Token\", \"In Corefering Mention\", \"Coreferrence Clusters\"]  \n",
    "for token in doc: \n",
    "    table.add_row([token.text, token._.in_coref, str(token._.coref_clusters)])\n",
    "print(table) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors and similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word vectors\n",
    "- Small models such as *en_core_web_**sm*** does not include word vectors，needs larger models: *en_core_web_**md*** or *en_core_web_**lg***\n",
    "- Doc.vector and Span.vector will default to an average of their token vectors.\n",
    "- out-of-vocabulary – so its vector representation consists of 300 dimensions of 0.\n",
    "- <a href='https://spacy.io/usage/vectors-similarity#custom' style='text-decoration:none'>Customizing word vectors</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()       # load pretrained models \n",
    "doc = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.7022e-01  2.7832e-02  3.3726e-01 -6.0538e-01  1.1151e+00  6.1317e-01\n",
      "  4.4317e-01 -4.4356e-01  1.7839e-01  2.5339e+00 -6.6669e-01  1.1980e-01\n",
      " -3.7354e-01 -1.2704e-01 -2.5155e-01 -2.0857e-01 -2.7643e-02  9.6150e-01\n",
      "  1.2078e-01 -4.7681e-01 -4.1337e-01 -2.9158e-01  2.9513e-01 -6.5193e-01\n",
      "  3.1126e-01  4.4229e-02 -8.5315e-01  5.2994e-02 -1.5573e-01  8.3080e-02\n",
      "  5.0069e-01 -1.6684e-01  5.6950e-01 -3.2449e-01 -5.8970e-01  1.9531e-01\n",
      "  6.2275e-02  7.3909e-02 -1.0965e-01  1.9190e-01 -3.3088e-01 -1.0520e-01\n",
      "  2.5342e-01 -8.1830e-02 -9.4465e-02  4.1847e-01 -9.9957e-02 -2.7197e-01\n",
      " -1.4081e-01  2.1018e-02 -1.7947e-01 -4.2881e-01  5.5106e-01  3.5615e-01\n",
      " -1.9499e-01 -2.2572e-01  1.6898e-01 -3.1127e-01  3.6404e-01  2.2121e-01\n",
      "  4.1063e-01 -6.7738e-01  1.8249e-02  3.5553e-01 -6.6892e-02 -8.3799e-01\n",
      " -6.6448e-02  2.2761e-02  4.7108e-01  8.5194e-01 -1.8790e-01  2.3339e-01\n",
      " -3.2439e-01 -1.7117e-01  1.9239e-01  8.3423e-02  1.5147e-03 -7.8561e-01\n",
      " -1.8561e-01  2.3470e-01 -1.4797e-01 -4.0575e-01  5.4777e-01 -5.1787e-01\n",
      " -2.5407e-01  2.7536e-01 -8.6775e-02  1.2309e+00 -6.4050e-01 -3.5442e-01\n",
      " -7.6228e-01 -4.3757e-01 -1.7718e-01 -4.9399e-01  5.2476e-01 -3.5813e-03\n",
      " -4.0243e-01 -3.0351e-01  3.9857e-01  4.6971e-01 -7.3956e-01  1.2866e-01\n",
      "  2.5458e-01  8.0872e-02 -7.5632e-02 -2.1235e-01  9.4518e-01  4.9665e-01\n",
      " -8.9495e-03 -2.7185e-01  1.3640e-01 -2.2274e-01 -2.5572e-01  5.0555e-01\n",
      "  4.2666e-01 -4.4665e-01  2.5063e-01 -1.0627e-01 -4.8452e-01 -1.1759e-01\n",
      " -6.2215e-02  3.1204e-01  8.8995e-02 -2.6948e-01  1.4721e-01 -1.0408e+00\n",
      "  3.0650e-01 -5.6515e-01  4.2239e-02  2.8717e-01 -1.7016e-01 -4.4452e-01\n",
      "  5.1696e-01  1.5695e-01 -4.5797e-01 -4.2261e-01 -1.0088e-01 -1.9730e-01\n",
      "  1.7327e-01 -5.0364e-01 -1.3190e+00 -3.9363e-01  2.2696e-01 -3.6405e-01\n",
      "  1.1948e-01 -6.6139e-01 -2.9480e-01  3.3773e-01  7.4158e-01 -1.4436e-01\n",
      "  3.3648e-01  1.6178e-01 -1.0519e-01  1.7602e-01  5.6731e-01  7.6762e-02\n",
      "  1.8438e-01 -2.5927e-01  4.4204e-01  2.9258e-01 -2.0809e-01 -4.7884e-01\n",
      "  1.8789e-01 -2.6493e-01  5.1166e-01 -4.2334e-01  1.7931e-01  1.8394e-03\n",
      "  5.0430e-01 -2.5641e-01  2.6774e-01 -8.1802e-02 -4.7457e-01 -6.3738e-01\n",
      " -5.0039e-01 -5.3703e-02  2.1196e-01  2.6705e-01 -1.3801e-01 -4.0785e-01\n",
      "  2.5876e-01 -6.2391e-01 -1.3245e-01 -1.9158e-01 -2.4054e-01  5.6984e-02\n",
      "  1.9736e-01  4.1039e-01 -3.6431e-02 -5.8613e-01 -3.1476e-01 -3.8515e-01\n",
      " -6.7145e-01 -9.0964e-02 -4.6065e-01 -1.4622e-02  1.5800e-01  3.9345e-01\n",
      "  2.3131e-01  2.3227e-01  1.8112e-01  2.2860e-01 -4.9113e-01  2.0263e-01\n",
      "  5.7032e-01 -3.9259e-02  1.8501e-01  7.6000e-01  2.0462e-01 -4.3842e-01\n",
      " -2.6686e-01  8.7400e-02 -7.4222e-02  4.2587e-02  4.8604e-01  1.5344e-01\n",
      "  3.8893e-01 -1.8508e-01  3.0748e-01  1.8603e-01 -3.8404e-01  1.7227e-01\n",
      "  1.9538e-02  4.6628e-01 -2.8991e-01 -5.4144e-01 -2.0244e-01 -2.2003e-01\n",
      " -1.8527e-01 -5.1756e-02  4.3349e-02  1.6416e-01  5.8087e-01 -3.6140e-01\n",
      "  3.1216e-01 -2.2359e-01 -2.9844e-02 -4.1332e-01 -4.0889e-02  8.6748e-02\n",
      "  1.9677e-01  1.2597e-01  2.6661e-02  3.1076e-01 -9.9180e-02  1.9563e-01\n",
      "  1.0977e-01 -3.7651e-01 -7.2256e-01 -5.5982e-01  9.2939e-02  2.4184e-01\n",
      " -2.8770e-01 -2.6496e-02 -1.4631e-01  8.1320e-01  5.7852e-02 -8.8785e-02\n",
      "  1.2620e-01 -1.2858e-01 -4.3569e-01 -2.6213e-01 -1.1773e-01 -2.5297e-01\n",
      " -2.3151e-01 -2.3069e-02 -4.4819e-02 -3.3420e-01 -1.1817e+00 -3.1501e-02\n",
      " -1.1791e+00 -1.5416e-01  2.7799e-01 -9.3840e-02  4.5915e-01 -9.0295e-02\n",
      " -5.6949e-02 -2.6255e-01  6.5256e-01  7.4910e-01  5.8875e-02  1.6764e-01\n",
      " -1.6774e-01 -6.2449e-03 -3.1804e-02  3.2708e-01  6.5773e-01  8.3055e-01\n",
      " -4.6930e-02  1.3442e-01  6.2665e-01  3.1272e-01 -2.6372e-01  8.2534e-01\n",
      " -1.7638e-01  7.8502e-02  3.3387e-01 -2.0473e-01  7.5751e-01  2.0240e-01]\n"
     ]
    }
   ],
   "source": [
    "# Get the vector for the token \"restaurant\"\n",
    "restaurant_vector = doc[4].vector\n",
    "print(restaurant_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurant bar\n",
      "0.6205604\n"
     ]
    }
   ],
   "source": [
    "token1, token2 = doc[4], doc[14]\n",
    "print(token1.text, token2.text)\n",
    "\n",
    "# Get the similarity of the tokens \"restaurant\" and \"bar\"\n",
    "similarity = token1.similarity(token2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75173926\n"
     ]
    }
   ],
   "source": [
    "# Create spans for \"great restaurant\" and \"really nice bar\"\n",
    "span1 = doc[3:5]\n",
    "span2 = doc[12:15]\n",
    "\n",
    "# Get the similarity of the spans\n",
    "similarity = span1.similarity(span2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8789265574516525\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"It's a warm summer day\")\n",
    "doc2 = nlp(\"It's sunny outside\")\n",
    "\n",
    "# Get the similarity of doc1 and doc2\n",
    "similarity = doc1.similarity(doc2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://course.spacy.io/en/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7fc18d6128>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('https://course.spacy.io/en/', width=800, height=450)   # spaCy tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
