{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase the cell width \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; } </style>\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert hotpotqa to squard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Longformer: use the following input format with special tokens:  “[CLS] [q] question [/q] [p] sent1,1 [s] sent1,2 [s] ... [p] sent2,1 [s] sent2,2 [s] ...” \n",
    "where [s] and [p] are special tokens representing sentences and paragraphs. The special tokens were added to the RoBERTa vocabulary and randomly initialized before task finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to convert hotpotqa to squard format modified from  https://github.com/chiayewken/bert-qa/blob/master/run_hotpot.py\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def create_example_dict(context, answers, id, is_impossible, question, is_sup_fact, is_supporting_para):\n",
    "    return {\n",
    "        \"context\": context,\n",
    "        \"qas\": [                        # each context corresponds to only one qa in hotpotqa\n",
    "            {\n",
    "                \"answers\": answers,\n",
    "                \"id\": id,\n",
    "                \"is_impossible\": is_impossible,\n",
    "                \"question\": question,\n",
    "                \"is_sup_fact\": is_sup_fact,\n",
    "                \"is_supporting_para\": is_supporting_para\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def create_para_dict(example_dicts):\n",
    "    if type(example_dicts) == dict:\n",
    "        example_dicts = [example_dicts]   # each paragraph corresponds to only one [context, qas] in hotpotqa\n",
    "    return {\"paragraphs\": example_dicts}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7f0076326cc0>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7f00766e13a8>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7f00766e1528>), ('textrank', <bound method TextRank.PipelineComponent of <pytextrank.pytextrank.TextRank object at 0x7f0076326c88>>)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.7/site-packages')\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import spacy   \n",
    "import en_core_web_lg                         \n",
    "nlp = en_core_web_lg.load() \n",
    "#!python -m pip install pytextrank\n",
    "# Fan: make 3 changes in pytextrank.py \n",
    "# 1. phrase_text = ' '.join(key[0] for key in phrase_key) \n",
    "#  p.text are the joint of lemma tokens with pos_ in kept_pos, and maintain the order when join    \n",
    "# 2. add argumrnt 'chunk_type' to only consider named entity ('ner') or noun_chunks ('noun'), besides the default ('both') \n",
    "# 3. replace token.lemma_ with token.lemma_.lower().strip()\n",
    "import pytextrank\n",
    "tr = pytextrank.TextRank(pos_kept=[\"ADJ\", \"NOUN\", \"PROPN\", \"VERB\", \"NUM\", \"ADV\"], chunk_type='both')  \n",
    "nlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)\n",
    "print(nlp.pipeline)   \n",
    "# import neuralcoref\n",
    "# neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "\n",
    "#!conda install networkx --yes\n",
    "import networkx as nx\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_para_graph(paras_phrases):\n",
    "    G = nx.Graph()    \n",
    "    top_para_phrases = []                     # node of the first (top ranked) phrases from each para \n",
    "    for para_phrases in paras_phrases:        # each para\n",
    "        top_sent_phrases = []                 # node of the first (top ranked) phrases from each sent \n",
    "        for sent_phrases in para_phrases:     # each sent\n",
    "            \n",
    "            # complete graph for each sent\n",
    "            sent_G = nx.Graph()\n",
    "            sent_G.add_nodes_from([phrase[0] for phrase in sent_phrases])  \n",
    "            sent_G.add_edges_from(itertools.combinations([phrase[0] for phrase in sent_phrases], 2)) \n",
    "            G = nx.compose(G, sent_G)         # union of the node sets and edge sets\n",
    "            \n",
    "            \n",
    "            # add an edge between the top ranked phrases from each sent to bridge sents\n",
    "            if(sent_phrases):\n",
    "                for top_sent_phrase in top_sent_phrases:\n",
    "                    G.add_edge(top_sent_phrase[0], sent_phrases[0][0])  # sent_phrases[0] is the top ranked phrase of the sentence\n",
    "                top_sent_phrases.append(sent_phrases[0])     \n",
    "            \n",
    "        top_sent_phrases = sorted(top_sent_phrases, key=lambda x: x[1], reverse=True)      # x[0]: phrase text,  x[1]: phrase rank\n",
    "        \n",
    "        \n",
    "        # add an edge between the top ranked phrases from each para to bridge paras\n",
    "        if(top_sent_phrases):\n",
    "            for top_para_phrase in top_para_phrases: \n",
    "                G.add_edge(top_para_phrase[0], top_sent_phrases[0][0])  # top_sent_phrases[0] is the top ranked phrase of current para\n",
    "            top_para_phrases.append(top_sent_phrases[0])\n",
    "     \n",
    "    # Draw\n",
    "#     pos = nx.spring_layout(G)\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     nx.draw(G, pos, with_labels=True, edge_color='black', width=1, linewidths=1,\n",
    "#             node_size=500, node_color='orange', alpha=0.9                           \n",
    "#             )     \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from networkx.algorithms import approximation as approx\n",
    "def convert_hotpot_to_squad_format(json_dict, gold_paras_only=False):\n",
    "    \n",
    "    \"\"\"function to convert hotpotqa to squard format.\n",
    "\n",
    "\n",
    "    Note: A context corresponds to several qas in SQuard. In hotpotqa, one question corresponds to several paragraphs as context. \n",
    "          \"paragraphs\" means different: each paragraph in SQuard contains a context and a list of qas; while 10 paragraphs in hotpotqa concatenated into a context for one question.\n",
    "\n",
    "    Args:\n",
    "        json_dict: The original data load from hotpotqa file.\n",
    "        gold_paras_only: when is true, only use the 2 paragraphs that contain the gold supporting facts; if false, use all the 10 paragraphs\n",
    " \n",
    "\n",
    "    Returns:\n",
    "        new_dict: The converted dict of hotpotqa dataset, use it as a dict would load from SQuAD json file\n",
    "                  usage: input_data = new_dict[\"data\"]   https://github.com/google-research/bert/blob/eedf5716ce1268e56f0a50264a88cafad334ac61/run_squad.py#L230\n",
    "\n",
    "    \"\"\"\n",
    "    noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "    new_dict = {\"data\": []} \n",
    "    common_phrases_num_le2 = 0\n",
    "    extended = 0\n",
    "    answer_in_reduced_context = 0\n",
    "    answer_not_yes_no = 0\n",
    "    reduced_context_ratios = []\n",
    "    for e_id, example in enumerate(json_dict): \n",
    "\n",
    "        support_para = set(\n",
    "            para_title for para_title, _ in example[\"supporting_facts\"]\n",
    "        )\n",
    "        sp_set = set(list(map(tuple, example['supporting_facts'])))\n",
    "        \n",
    "        raw_contexts = example[\"context\"]\n",
    "#         if gold_paras_only: \n",
    "#        raw_contexts = [lst for lst in raw_contexts if lst[0] in support_para]    \n",
    "        \n",
    "        paras_phrases = []                                                # phrases of all 10 paragraghs\n",
    "        for i, para_context in enumerate(raw_contexts):                   # each para\n",
    "            sent_docs = list(nlp.pipe(para_context[1]))   \n",
    "            para_phrases = []                                        \n",
    "            for sent_doc in sent_docs:                                    # each sent in a para\n",
    "                sent_phrases = [(p.text, p.rank) for p in sent_doc._.phrases if(p.text != '')]  # phrases from each sentence \n",
    "                para_phrases.append(sent_phrases)       \n",
    "            paras_phrases.append(para_phrases)    \n",
    "\n",
    "        contexts = [\" <s> \".join(lst[1]) for lst in raw_contexts]         # extra space is fine, which would be ignored latter. \n",
    "                                                                          # most sentences has already have heading space, there are several no heading space                     \n",
    "        paras_phrases_graph = create_para_graph(paras_phrases)\n",
    "        \n",
    "        \n",
    "        question = example[\"question\"]\n",
    "        question_doc = nlp(question)\n",
    "        question_phrases = [(p.text, p.rank) for p in question_doc._.phrases if(p.text != '')] \n",
    "        question_phrases_text = [p[0] for p in question_phrases]\n",
    "        \n",
    "        all_sent_phrases_text =  list(flatten(paras_phrases))[::2]        # every other element is text, others are rank. \n",
    "        common_phrases = list(set(all_sent_phrases_text).intersection(question_phrases_text)) \n",
    "        question_only_phrase = list(set(question_phrases_text).difference(common_phrases)) \n",
    "        \n",
    "        print(\"question id: \",example[\"_id\"]) \n",
    "        print(\"question: \", question)\n",
    "#         print(\"\\n\")\n",
    "        \n",
    "#         for para in contexts:\n",
    "#             print(para)   \n",
    "#         print(\"\\n\")\n",
    "\n",
    "        print(\"question_phrases_text: \", question_phrases_text)\n",
    "        print(\"common_phrases: \", common_phrases)\n",
    "#         print(\"question_only_phrase: \", question_only_phrase)\n",
    "        \n",
    "        if(len(common_phrases) > 1):\n",
    "            common_phrases_num_le2 += 1\n",
    "            path_phrases = list(approx.steinertree.steiner_tree(paras_phrases_graph, common_phrases).nodes) \n",
    "#             paths = list(nx.shortest_simple_paths(paras_phrases_graph, common_phrases[0], common_phrases[-1]))  # all simple paths from source to target, in order from shortest to longest. This is very computationally costly \n",
    "\n",
    "#             # to find the shortest path cover all common_phrases  \n",
    "#             for path in paths:\n",
    "#                 if(all(x in path for x in common_phrases)): \n",
    "#                     extended_phrases = path\n",
    "#                     break\n",
    "\n",
    "#             print(\"path: \", extended_phrases)\n",
    "            extended_phrases = path_phrases + question_only_phrase  \n",
    "            if(len(extended_phrases) > len(question_phrases_text)):\n",
    "                extended += 1\n",
    "        else: #  0 or 1 common phrases\n",
    "            path_phrases = common_phrases             \n",
    "            extended_phrases = question_phrases_text\n",
    "            \n",
    "        print(\"extended_phrases: \", extended_phrases)\n",
    "        \n",
    "        context = \" <p> \" + \" <p> \".join(contexts)\n",
    "        \n",
    "        \n",
    "#         print(\"context: \", context)   \n",
    "        \n",
    "        \n",
    "#         print(\"\\n\\n\")\n",
    "        \n",
    "#         print(\"question_phrases: \", question_phrases)    \n",
    "        print(\"paras_phrases\")\n",
    "        for paras_phrase in paras_phrases:\n",
    "            print(paras_phrase)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "#         print(\"all_sent_phrases_text: \", all_sent_phrases_text)\n",
    "        \n",
    "#         print(\"\\n\\n\")\n",
    "                \n",
    "\n",
    "\n",
    "        answer = example[\"answer\"].strip() \n",
    "        print(\"answer: \", answer)\n",
    "       \n",
    "\n",
    "        is_supporting_para = []  # a boolean list with 10 True/False elements, one for each paragraph\n",
    "        is_sup_fact = []         # a boolean list with True/False elements, one for each context sentence\n",
    "        reduced_context = []     # sentences contain one of the phrases in the path\n",
    "        found_answer = False\n",
    "        number_sentences = 0\n",
    "        number_reduced_sentences = 0\n",
    "#         print(\"supporting facts: \")   \n",
    "        for para_id, (para_title, para_lines) in enumerate(raw_contexts):\n",
    "#             print(\"para_id, para_title, para_lines\",para_id, para_title, para_lines)\n",
    "            is_supporting_para.append(para_title in support_para) \n",
    "#             print(para_title, para_title in support_para)\n",
    "            number_sentences += len(para_lines)\n",
    "            for sent_id, sent in enumerate(para_lines):\n",
    "                is_sup_fact.append( (para_title, sent_id) in sp_set )\n",
    "#                 if((para_title, sent_id) in sp_set):\n",
    "#                     print(para_title, sent) \n",
    "                for phrase in path_phrases:\n",
    "#                     print(\"para_id, sent_id: \", para_id, sent_id)\n",
    "#                     print(\"paras_phrases[para_id][sent_id]: \", paras_phrases[para_id][sent_id])\n",
    "                     \n",
    "                    if(phrase in list(flatten(paras_phrases[para_id][sent_id]))[::2]):  # every other element is text, others are rank\n",
    "                        reduced_context.append(sent)\n",
    "                        number_reduced_sentences += 1\n",
    "                        if(answer in sent):\n",
    "                            found_answer = True\n",
    "                        break\n",
    "        assert number_reduced_sentences <= number_sentences                    \n",
    "        reduced_context_ratios.append(number_reduced_sentences / number_sentences)    \n",
    "        \n",
    "        print(\"number_sentences: \", number_sentences)\n",
    "        print(\"number_reduced_sentences: \", number_reduced_sentences)\n",
    "        \n",
    "        if(answer.lower() != 'yes' and answer.lower() != 'no'):\n",
    "            answer_not_yes_no += 1\n",
    "            if(found_answer):\n",
    "                answer_in_reduced_context += 1\n",
    "        \n",
    "#         print(\"reduced_context: \", reduced_context)\n",
    "#         print(\"\\n\\n\\n\")\n",
    "#         if(e_id > 4):\n",
    "#             assert(1==2)    # exit for debug\n",
    "\n",
    "#         if answer.lower() == 'yes':\n",
    "#             answers = [{\"answer_start\": -1, \"answer_end\": -1, \"text\": answer}] \n",
    "#         elif answer.lower() == 'no':\n",
    "#             answers = [{\"answer_start\": -2, \"answer_end\": -2, \"text\": answer}] \n",
    "#         else:\n",
    "#             answers = []          # keep all the occurences of answer in the context\n",
    "#             for m in re.finditer(re.escape(answer), context):    \n",
    "#                 answer_start, answer_end = m.span() \n",
    "#                 answers.append({\"answer_start\": answer_start, \"answer_end\": answer_end, \"text\": answer})\n",
    "             \n",
    "#         if(len(answers) > 0): \n",
    "#             new_dict[\"data\"].append(\n",
    "#                 create_para_dict(\n",
    "#                     create_example_dict(\n",
    "#                         context=context,\n",
    "#                         answers=answers,\n",
    "#                         id = example[\"_id\"],\n",
    "#                         is_impossible=(answers == []),\n",
    "#                         question=question,\n",
    "#                         is_sup_fact = is_sup_fact,\n",
    "#                         is_supporting_para = is_supporting_para \n",
    "#                     )\n",
    "#                 )\n",
    "#             ) \n",
    "        print(\"number of questions: \", e_id+1)\n",
    "        print(\"number of questions with answer neither yes nor no: \", answer_not_yes_no)\n",
    "        print(\"common_phrases_num_le2: \", common_phrases_num_le2) \n",
    "        print(\"extended: \", extended)\n",
    "        print(\"answer_in_reduced_context: \", answer_in_reduced_context)\n",
    "        print(\"reduced_context_ratios: \", reduced_context_ratios)\n",
    "        print(\"ratio of reduced context: \", sum(reduced_context_ratios)/len(reduced_context_ratios))\n",
    "#     return new_dict\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a8d7341554299441c6b9fe5\n",
      "question:  Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
      "question_phrases_text:  ['satirist allie goertz', 'allie goertz', 'matt groening', 'milhouse', 'musician', 'simpsons character milhouse', 'song', 'simpsons']\n",
      "common_phrases:  ['song', 'allie goertz', 'matt groening', 'milhouse', 'simpsons']\n",
      "extended_phrases:  ['matt groening', 'song', 'milhouse', 'american', 'allie goertz', 'simpsons', 'simpsons character milhouse', 'satirist allie goertz', 'musician']\n",
      "paras_phrases\n",
      "[[('lisa marie simpson', 0.22050065990402112), ('the simpsons', 0.18300159141462016), ('animate television series', 0.15081990034711953), ('fictional character', 0.10478263941846382)], [('simpson', 0.19107370450372602), ('middle child', 0.1480278570296342), ('simpson family', 0.1300836371141533)], [('lisa first', 0.16980450159830326), ('yeardley smith', 0.16065136077942482), ('good night', 0.14753415010808357), ('lisa', 0.13031180398354109), ('april', 0.12781270734712694), ('april 19 1987', 0.10782323620276578), ('television', 0.097633241241849), ('short good night', 0.08687624898244062), ('tracey ullman', 0.0863302336937986), ('tracey ullman show', 0.08204140410845213)], [('james l. brooks', 0.21717059588999518), ('matt groening', 0.1961651855364357), ('cartoonist matt groening', 0.13853050704860775)], [('short', 0.11599704730322398), ('character', 0.10685762350411798), ('new set', 0.09766560208972), ('hell', 0.0955329769292868), ('groening', 0.09553297692928678), ('life hell', 0.08635063739714482), ('series', 0.07466800902475193), ('comic life', 0.07057191938932159)], [('lisa groening', 0.2122372505271652), ('simpson', 0.17096368156624758), ('eld simpson daughter', 0.15927137070217168), ('young sister', 0.1344583917956231)], [('three year', 0.14664107734135312), ('simpson', 0.13184417694209333), ('fox', 0.1273983138265613), ('december', 0.12670166125879298), ('tracey ullman show', 0.11481169388000093), ('december 17 1989', 0.11276472445793405), ('simpson family', 0.09276061137793801), ('own series', 0.09054126629621369)]]\n",
      "\n",
      "\n",
      "[[('née bouvier', 0.14797908710009702), ('american', 0.14175228415067345), ('american animate sitcom', 0.12506207114045761), ('part', 0.12424292196683336), ('bouvier', 0.1139143543622348), ('marjorie jacqueline marge simpson', 0.10347873679258748), ('eponymous family', 0.08746233395837369), ('fictional character', 0.08414823809911076), ('simpsons', 0.06360823725792378)], [('julie kavner', 0.16926666165887744), ('good night', 0.15237261503079277), ('first', 0.13835521754239705), ('april', 0.132004396530428), ('tracey ullman show', 0.11210842900646248), ('april 19 1987', 0.11135935950600015), ('television', 0.10240831708618989), ('short good night', 0.08972540413065642), ('tracey ullman', 0.08916148196540702)], [('cartoonist matt groening', 0.20663854213667163), ('matt groening', 0.17735858492162057), ('james l. brooks office', 0.1516977634266167), ('james l. brooks', 0.13958066808428637), ('marge', 0.10264404174793197), ('lobby', 0.07804147146641648)], [('short', 0.11743377746643971), ('life', 0.11678431774499307), ('hell', 0.11519037418031743), ('character', 0.10991991975029289), ('new set', 0.10031205436497065), ('groening', 0.09843557185381076), ('life hell', 0.08892401573178799), ('series', 0.07581968349371374)], [('margaret groening', 0.26820370045189323), ('mother', 0.13308889003689156), ('character', 0.11527130949343048)], [('three season', 0.14296813808253947), ('simpson', 0.12306961693765751), ('fox', 0.11957875293918607), ('tracey ullman show', 0.11399445956975987), ('december 17 1989', 0.11111569851540355), ('own series', 0.09723556714469303), ('simpson family', 0.09294835076983236)]]\n",
      "\n",
      "\n",
      "[[('the simpsons', 0.1601323166888905), ('simpson', 0.15792600542715712), ('american animate television series', 0.14721322384185515), ('american', 0.13954442051506824), ('bartholomew jojo bart simpson', 0.11028657139998707), ('part', 0.11006828724800734), ('simpson family', 0.09791159315339143), ('fictional character', 0.08518992920527868)], [('nancy cartwright', 0.16926666165887744), ('good night', 0.15237261503079277), ('first', 0.13835521754239705), ('april', 0.132004396530428), ('tracey ullman show', 0.11210842900646248), ('april 19 1987', 0.11135935950600015), ('television', 0.10240831708618989), ('short good night', 0.08972540413065642), ('tracey ullman', 0.08916148196540702)], [('matt groening', 0.1752775281893545), ('james l. brooks office', 0.1446602650509349), ('james l. brooks', 0.13280402395102978), ('bart', 0.12739280010192308), ('cartoonist matt groening', 0.12382142211318768), ('lobby', 0.07052560919648006)], [('short', 0.11176675106226609), ('character', 0.1034644490626932), ('new set', 0.0945643125985285), ('hell', 0.09341094516935773), ('groening', 0.0924058552184754), ('comic strip', 0.09041843670483087), ('life hell', 0.08459934922236827), ('series', 0.07199128687235012)], [('groening', 0.15632096873558965), ('bart', 0.15563904412354135), ('groening family member', 0.1445980266178398), ('bart name', 0.11215375531618561), ('word', 0.07932439046178119), ('character', 0.07770928336751279), ('anagram', 0.07581097432679544), ('brat', 0.05938510890976863), ('rest', 0.05847014696648497)], [('three year', 0.14296813808253947), ('simpson', 0.12306961693765751), ('fox', 0.11957875293918607), ('tracey ullman show', 0.11399445956975987), ('december 17 1989', 0.11111569851540355), ('own series', 0.09723556714469303), ('simpson family', 0.09294835076983236)]]\n",
      "\n",
      "\n",
      "[[('allison beth', 0.17632843520105357), ('american', 0.14907119849998596), ('march 2 1991', 0.14224954493436706), ('allison beth allie goertz', 0.12087748048057519), ('allie goertz', 0.1200362425010001), ('american musician', 0.11428571428571428)], [('various pop culture topic', 0.2590851734246385), ('satirical song', 0.12067351584826558), ('goertz', 0.11485601611128095)], [('youtube', 0.23048479379322753), ('cossbysweater', 0.17290157147431207), ('name', 0.1239822112329578), ('video', 0.06654984588933559)], [('the simpsons', 0.1642021026790228), ('dragons', 0.1259881576697424), ('milhouse', 0.12508685329054137), ('television show', 0.10651387169747255), ('game dungeons', 0.09658905768325902), ('dungeons dragons', 0.09658905768325902), ('song', 0.07409427849393178), ('film', 0.07409427849393178), ('subject', 0.05479768977224037), ('room', 0.05479768977224037), ('character', 0.050397568806028116)], [('bo burnham', 0.30618621784789724), ('style', 0.09072184232530289)], [('sad dance songs', 0.15894388284780525), ('december 2015', 0.12548053463475142), ('goertz', 0.1177795357159346), ('rick', 0.11501200638955257), ('adult swim series', 0.1076144814546328), ('concept album', 0.09422955990303106), ('logo', 0.09153966640916755), ('december', 0.08822651770490543), ('rick morty', 0.07419134556516488), ('morty', 0.07417774488597423), ('album cover', 0.06676446971046059), ('series', 0.06664034778234397), ('animation', 0.05697004988908009)], [('kickstarter', 0.21332652874908856), ('album', 0.08210941919904981)], [('co - host', 0.2290393337255473), ('simpsons', 0.18602194837400943), ('julia prescott', 0.184416456743066), ('simpsons focus podcast', 0.12405954080706592), ('podcast', 0.11596300691757863), ('come', 0.01886161375885803)]]\n",
      "\n",
      "\n",
      "[[('milhouse mussolini van houten', 0.15245860725021826), ('richard nixon', 0.13649401594144456), ('matt groening', 0.12383219272487239), ('the simpsons', 0.12302845206041735), ('pamela hayden', 0.11791124178340698), ('president richard nixon middle name', 0.1118786373855391), ('animate television series', 0.09216065146385569), ('fictional character', 0.0800962486403557), ('character', 0.061340228086535026)], [('milhouse', 0.21470767472357144), ('milhouse middle name', 0.18989371454328305), ('mussolini', 0.13350401896727454), ('series', 0.0944911182523068)]]\n",
      "\n",
      "\n",
      "[[('los angeles reader', 0.24819201935234744), ('los angeles', 0.2361802200534711), ('united states', 0.16797602607308088), ('weekly', 0.14420943732533917), ('1978', 0.14420943732533917), ('weekly paper', 0.11095476671123342)], [('chicago reader', 0.25), ('still active chicago reader', 0.1312975903779549), ('format', 0.10206207261596575)], [('movie', 0.14896327024590844), ('la', 0.14855908087900327), ('lengthy thoughtful review', 0.14785685530705633), ('concert', 0.14134419755716862), ('la area', 0.10066158910865268), ('paper', 0.03746742501921755)], [('james vowell', 0.30618621784789724), ('founding editor', 0.18070158058105024)], [('harry sheehan', 0.09628785612555776), ('henry sheehan', 0.09506716801848425), ('myron meisel', 0.08360050224011421), ('eric mankin', 0.08310398198724452), ('nigey lennon', 0.08291719835248486), ('lionel rolfe', 0.08126910327532977), ('steve appleford', 0.08114635134677135), ('dan sallit', 0.08075616099533478), ('keith fitzgerald', 0.08052745376498416), ('lawrence wechsler', 0.08046587888080584), ('eddie rivera', 0.0803190867388463), ('mick farren', 0.08007684959834255), ('natalie nichols', 0.07995562593275558), ('richard meltzer', 0.07988845028793141), ('heidi dvorak', 0.07979609067518416), ('chris morris', 0.079747974731319), ('jerry stahl', 0.07971680198943834), ('steven kane', 0.07968494167506282), ('andy klein', 0.07963480981619256), ('allen levy', 0.07953872813274976), ('jim goad', 0.07934111705833362), ('paul birchall', 0.07923736460073044), ('samantha dunn', 0.0789396174251171), ('kirk silsbee', 0.07891296538778665), ('also editor', 0.07510811385610211), ('amy steinberg', 0.073439365633482), ('david ehrenstein', 0.06973437822430711), ('first', 0.061230117886340835), ('paper first cover story', 0.050494692303765555), ('writer', 0.02618822193177585)], [('david l. ulin', 0.16959978542142473), ('bruce bebb', 0.1675698621678336), ('erik himmelsbach', 0.16494775805219777), ('stuart goldman', 0.16323367449055023), ('kevin uhrich', 0.16219348253097798), ('ernest hardy', 0.16170579747522484), ('tom davis', 0.13929802762862287)], [('matt groening cartoon strip', 0.1515851906080435), ('april', 0.13878911851517778), ('hell', 0.13619838193006095), ('april 25 1980', 0.12364568721871752), ('matt groening', 0.11161320423551875), ('first', 0.11049238918048311), ('life hell', 0.10258829256796462), ('first newspaper', 0.09276520000335106)], [('matt groening', 0.23096496876473038), ('james vowell', 0.21511786504928698), ('1979', 0.14770696196149738), ('assistant editor', 0.12288845352266826)], [('reader music critic', 0.18042195912175804), ('groening', 0.1619219055672653)], [('david lynch', 0.13281789243490852), ('blue velvet', 0.12830684105968115), ('exactly same drawing panel', 0.11522810514994654), ('director', 0.11047362463571328), ('cartoon strip', 0.09731302820794897), ('entire run', 0.06693961659210276), ('world', 0.04437928497202422)], [('codette wallace', 0.19732447431530836), ('reader', 0.19316869157997812), ('february 1989', 0.1710239368607692), ('james vowell', 0.16025640714541958), ('february', 0.14246336050891353), ('chicago reader', 0.1293918581454119), ('wife', 0.0889852387321626)], [('new times media', 0.25000609316169775), ('new times la', 0.24176456522115863), ('1996', 0.1409519151352901), ('los angeles view', 0.09238628772116106), ('reader', 0.06656166941745591)]]\n",
      "\n",
      "\n",
      "[[('homer jay simpson', 0.17605447915900463), ('american animate television series', 0.13863581603600184), ('the simpsons', 0.13721320389147998), ('american', 0.1317117014311417), ('eponymous family', 0.09539828655357646), ('fictional character', 0.08574686176609003), ('main protagonist', 0.08204257799948063), ('patriarch', 0.054854064060326904)], [('dan castellaneta', 0.15899834280252065), ('good night', 0.14312919498913634), ('first', 0.12996209703512895), ('april', 0.1239984197751359), ('tracey ullman show', 0.10530614795984829), ('april 19 1987', 0.10460565489873154), ('television', 0.09619586365278351), ('short good night', 0.08428208799761841), ('tracey ullman', 0.0837515202238433), ('rest', 0.06063390625908324), ('family', 0.06063390625908324)], [('cartoonist matt groening', 0.20663854213667163), ('matt groening', 0.17735858492162057), ('james l. brooks office', 0.1516977634266167), ('james l. brooks', 0.13958066808428637), ('lobby', 0.07804147146641648), ('homer', 0.05443522347626834)], [('life', 0.12673892077809648), ('short', 0.10823635703418963), ('hell', 0.10478549973018964), ('character', 0.10252790605550556), ('new set', 0.09350048925803975), ('groening', 0.09180330978036845), ('comic strip', 0.08952708387786164), ('life hell', 0.08914739822560226), ('series', 0.07002706524581932)], [('homer groening', 0.26820370045189323), ('father', 0.13308889003689156), ('character', 0.11527130949343048)], [('three season', 0.15309310892394862), ('fox', 0.12875901812168827), ('tracey ullman show', 0.11048543456039805), ('december 17 1989', 0.10867350864877799), ('simpson', 0.09711929091522543), ('own series', 0.09278103115858367), ('simpson family', 0.08158257286259857)]]\n",
      "\n",
      "\n",
      "[[('matt groening', 0.18152473111389383), ('american animate television sitcom', 0.16221109659876845), ('american', 0.13362426114704687), ('fox broadcasting company', 0.1313289398554863), ('simpsons', 0.030391533692741543)], [('middle class american lifestyle', 0.13845086367123), ('american', 0.1284751703067742), ('lisa', 0.1263974951318181), ('bart', 0.12223794116532312), ('marge', 0.11950202826214362), ('homer', 0.11728848305429482), ('maggie', 0.0941967072193682), ('satirical parody', 0.08656113590292296), ('eponymous family', 0.08289292857534629), ('homer marge bart lisa maggie', 0.07771335398164263), ('series', 0.034324112066060196)], [('american culture', 0.17873783615758582), ('many aspect', 0.17041089356051692), ('springfield', 0.1428770327597394), ('society', 0.14057072513929755), ('american', 0.13759245042660453), ('television', 0.12336691292754126), ('fictional town', 0.10374950735176405), ('human condition', 0.09395313438629722)], [('james l.', 0.18521207369158893), ('animated short', 0.18490449871481837), ('producer james l. brooks', 0.14724197785238435), ('groening', 0.12665581298094125), ('brooks', 0.11259976848081532), ('series', 0.07274465541843615), ('pitch', 0.06389979362309424), ('family', 0.03777606064133238)], [('own family', 0.14144505980030483), ('bart', 0.13772297148513718), ('dysfunctional family', 0.13351000575787633), ('member', 0.12206525239069069), ('groening', 0.1174695796793245), ('own name', 0.10972121656441852), ('character', 0.06486250715376077)], [('april', 0.11228459433991067), ('half hour prime time show', 0.09760316276439887), ('tracey ullman show', 0.09422229518055114), ('april 19 1987', 0.09422229518055114), ('fox', 0.0843793429006589), ('hit series', 0.0762458272491137), ('three season', 0.07218126135560578), ('three season run', 0.07129161274403024), ('half hour', 0.05867691393118829), ('sketch', 0.04874201841645865), ('part', 0.044577288692362695), ('short', 0.03235307004830429)], [('video game', 0.25157718407154894), ('series motivate video game developer', 0.20187660169442134), ('series', 0.0889887584572565), ('grow popularity', 0.06905180592286501)], [('one', 0.1071216288050772), ('simpsons pinball party', 0.10318541386820813), ('first season finale', 0.1030770753983046), ('two pinball machine', 0.09536102172300089), ('1990', 0.09166077977861606), ('two', 0.08994346069393283), ('first season', 0.08440196350576322), ('2003', 0.0773660035591779), ('limited time', 0.07313879989061732)], [('several handheld device game', 0.2037233105555599), ('cupcake crisis', 0.16985548086436403), ('evil', 0.12547444963535356), ('avenger', 0.12080654209389982), ('bartman', 0.11701324094358308), ('bart simpson cupcake crisis', 0.10303447857994719), ('1990', 0.09367397300165298), ('bart simpson', 0.09103979081229331), ('1991', 0.08395089553802682)]]\n",
      "\n",
      "\n",
      "[[('the simpsons', 0.16039466718474085), ('unauthorized history', 0.156033266677711), ('american animate television series', 0.1469557494115784), ('non - fiction book', 0.1418595132766416), ('american', 0.13718546316862995), ('simpsons', 0.06611590540798336)], [('october 2009', 0.22928670499025577), ('john ortved', 0.21426867565972946), ('october', 0.18777125809221956), ('first', 0.168413950106524), ('faber', 0.16420205309040903)], [('world great tv show', 0.102306055252734), ('uncensored totally unauthorised history', 0.09861578713395458), ('united kingdom', 0.07858414639369465), ('simpsons confidential', 0.06939819199893087), ('book', 0.06780225940447278), ('people', 0.06112520478035669)], [('producer', 0.16305834412508036), ('oral history', 0.1318653719268677), ('show', 0.10444530386633563), ('writer', 0.08697812047933615), ('book', 0.0506157671584692)], [('james l. brooks', 0.16618605878771434), ('creator matt groening', 0.1608303992384533), ('entire chapter', 0.14659099783733448), ('matt groening', 0.14263386138912418), ('key figure', 0.13920686040008534), ('sam simon', 0.13509555142495178), ('series', 0.05148977093652128), ('book', 0.03654165229070357)], [('national public radio reviewer linda holmes', 0.16327757844834062), ('national public radio', 0.14100787207317714), ('linda holmes', 0.11903919558443576), ('matt groening', 0.11613679522833471), ('the simpsons', 0.10951043058429509), ('other', 0.09999508783686176), ('people', 0.09574790608581257), ('ortved', 0.07862072841070888), ('lot', 0.07103317951419083), ('sole source', 0.06352554553460756), ('success', 0.04967902749108593), ('detriment', 0.044200419622824005), ('creator', 0.043135969229836944), ('ortved thesis', 0.03809054098133079)]]\n",
      "\n",
      "\n",
      "[[('celebrity guest star', 0.13782625244077248), ('voice actor', 0.13698855118311976), ('the simpsons', 0.13198566102799378), ('matt groening', 0.11804915629142178), ('american animate television sitcom', 0.1054908688007857), ('american', 0.08690004696948789), ('fox broadcasting company', 0.08540338899201047), ('first season', 0.07377111135633174), ('show regular cast', 0.07143850249143718), ('addition', 0.06491629346517973), ('staple', 0.044785731667587765)], [('lisa', 0.16069157521604172), ('bart', 0.15588179987469974), ('marge', 0.15332658406092337), ('homer', 0.1522282138795853), ('maggie', 0.11961489352401816), ('eponymous family', 0.11853164113281897), ('homer marge bart lisa maggie', 0.0994643350024282), ('simpsons', 0.06343537675630508)], [('animated short', 0.1611876941859302), ('groening', 0.12834008198717553), ('tracey ullman show', 0.1203155687528123), ('series', 0.06988525089060169), ('1987 1989', 0.06295817519770287), ('part', 0.050229792570812344), ('family', 0.041367397299319646)], [('december 1989', 0.16576714319174768), ('half hour prime time series', 0.1485679514757265), ('december', 0.12760760632606769), ('half hour', 0.12122646302450962), ('short', 0.04182931637873326)], [('september 2015', 0.20555832144862868), ('the simpsons', 0.18977617563601346), ('september', 0.16769215600833448), ('episode', 0.1547900516632728), ('27th season', 0.12059845658461758), ('series 27th season', 0.08542979805404934)], [('2007', 0.14907119849998596), ('the simpsons movie', 0.10751277346030941), ('feature film adaptation', 0.1022524115863427), ('series', 0.08113161662957487)]]\n",
      "\n",
      "\n",
      "answer:  President Richard Nixon\n",
      "number_sentences:  68\n",
      "number_reduced_sentences:  22\n",
      "number of questions:  1\n",
      "number of questions with answer neither yes nor no:  1\n",
      "common_phrases_num_le2:  1\n",
      "extended:  1\n",
      "answer_in_reduced_context:  1\n",
      "reduced_context_ratios:  [0.3235294117647059]\n",
      "ratio of reduced context:  0.3235294117647059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a82171f5542990a1d231f4a\n",
      "question:   What nationality was James Henry Miller's wife?\n",
      "question_phrases_text:  ['james henry miller wife', 'james henry miller', 'nationality']\n",
      "common_phrases:  ['james henry miller']\n",
      "extended_phrases:  ['james henry miller wife', 'james henry miller', 'nationality']\n",
      "paras_phrases\n",
      "[[('henry miller', 0.15852371192156733), ('semi - autobiographical novel', 0.148489578519458), ('novel', 0.08789421130884313), ('1927 28', 0.08591242270098469), ('june', 0.08464516024892127), ('gentile world', 0.07590333000396024), ('wife', 0.05731781979683547), ('guise', 0.05387284646476187), ('moloch', 0.04690650298201946), ('gentile', 0.04559332659504932)], [('12 year', 0.22736515969713395), ('65 year', 0.21221278065834664), ('1992', 0.17216622253104147), ('miller', 0.1593988900710821), ('miller death', 0.10277205448603946), ('book', 0.04942746692549735)], [('miller', 0.16692995642499733), ('fiction', 0.14213381090374028), ('miller artistic growth', 0.13891384404993395), ('interest', 0.11197513139973939), ('worthy piece', 0.10896715305663911), ('study', 0.07580857791611544)]]\n",
      "\n",
      "\n",
      "[[('3 july 1874', 0.30602347768435106), ('3 july', 0.2554657799068234), ('1874', 0.22961161757750448), ('election', 0.1833839737314266), ('launceston', 0.14088418175255965)], [('james henry deakin', 0.22504646196999883), ('conservative', 0.14182392445265468), ('incumbent conservative mp', 0.14109342487617493), ('void election', 0.09311464553393313), ('byelection', 0.05470732932414788)], [('james henry deakin', 0.2883756195218633), ('conservative', 0.19584693494144317), ('conservative candidate', 0.14740711204809046), ('junior', 0.1409629805850986)]]\n",
      "\n",
      "\n",
      "[[('anaïs nin', 0.20745010905639033), ('1992 non - fiction book', 0.1691489110928514), ('love', 0.1316230713735216), ('1992', 0.12473437618035857), ('unexpurgated diary', 0.10391640814960737), ('journal love unexpurgated diary anaïs nin', 0.09119888124933778), ('journal', 0.05395907004154771)], [('anaïs nin', 0.1846372364689991), ('henry', 0.1363908547313967), ('unexpurgated diary anaïs nin', 0.11725441178024142), ('unexpurgated diary', 0.10896715305663911), ('june', 0.10457840290973774), ('continuation', 0.051164329412194794)], [('writer henry miller', 0.18504182784096324), ('henry miller', 0.17279483534646317), ('hugh parker guiler', 0.16803361008336118), ('june miller', 0.16415668990548324), ('joaquín nin', 0.14941625044143783), ('otto rank', 0.1393946538032964), ('nin', 0.13065830082880764), ('nin relationship', 0.09908233390137827), ('father', 0.06141122954264723), ('psychoanalyst', 0.060750633341686976), ('husband', 0.06063390625908324), ('wife', 0.05868434782934879)], [('people', 0.1350673069414932), ('correspondence', 0.09812446839492296), ('diary', 0.09812446839492296)], [('french', 0.18481694945295712), ('spanish', 0.16086674683860366), ('english', 0.11566716634861221), ('book', 0.08530582745643644), ('letter', 0.06158179174056969)], [('particularly clichy', 0.21211359088161585), ('france', 0.18417601026995226), ('paris', 0.1700794592955313), ('place', 0.1632851183923721), ('clichy', 0.1632851183923721), ('louveciennes', 0.10908541369289505), ('diary', 0.09019825425630869)]]\n",
      "\n",
      "\n",
      "[[('col . james henry deakin', 0.23411839207791166), ('james henry deakin', 0.22055234513637312), ('8 november 1881', 0.16407671315688777), ('8 november', 0.15205936407765835), ('1851', 0.12561930140619265), ('british', 0.10764103841313012), ('british conservative politician', 0.10667580335333533), ('manchester', 0.10534421685139808), ('manchester merchant', 0.07280370682134756), ('son', 0.05976541676523244)]]\n",
      "\n",
      "\n",
      "[[('25 january 1915', 0.14253616881989964), ('22 october 1989', 0.1347063180842618), ('james henry miller', 0.12810435199888476), ('25 january', 0.12594783106088567), ('labour activist', 0.12103651117575848), ('22 october', 0.1204255748321271), ('ewan maccoll', 0.11695915893038344), ('record producer', 0.1097527190740129), ('playwright', 0.10063824208924535), ('actor', 0.09476136861355008), ('songwriter', 0.09333533353907764), ('english folk singer', 0.08391604920700389), ('poet', 0.08153836718867218), ('english', 0.07917448781418107), ('stage name', 0.07438152700778804)]]\n",
      "\n",
      "\n",
      "[[('american', 0.15713484026367722), ('june 17 1935', 0.1533204701966442), ('american folksinger', 0.12046772038736682), ('margaret peggy seeger', 0.10493895217357102)], [('ewan maccoll', 0.16976454093908977), ('songwriter', 0.12938322033213798), ('britain', 0.1266190554561671), ('more 30 year', 0.11155732302077329), ('1989', 0.08905681397022139), ('singer', 0.0703001645636656), ('death', 0.06220925880091256)]]\n",
      "\n",
      "\n",
      "[[('big sur resident henry miller', 0.17541837602919097), ('henry miller', 0.15513662228358788), ('big sur', 0.1290486252433545), ('henry miller memorial library', 0.10998618029184477), ('performance venue', 0.10613219148983824), ('bookstore', 0.08753534414881792), ('artist', 0.08420993191001855), ('nonprofit art center', 0.0805423188636736), ('creative individual', 0.07113378912234648), ('california', 0.07046358305713316), ('late writer', 0.06602929783772044), ('living', 0.0398532440558201)], [('emil white', 0.20915673563545567), ('henry miller', 0.1715896848333315), ('henry miller friend', 0.10569825934564073), ('house', 0.07986714115923259), ('library', 0.07957542747136338), ('mid-1960', 0.06023815051195435)], [('local artist', 0.16835082460232031), ('1980', 0.13114610202528523), ('emil', 0.12817240537641558), ('miller', 0.08882633099639659), ('memorial', 0.06454778594171949), ('property', 0.06092258480805953), ('gallery', 0.05489027807450361), ('friend', 0.048546564437258), ('work', 0.04739217048585989)], [('emil white', 0.17405554132022072), ('big sur land trust', 0.14404387695704476), ('henry miller memorial library', 0.13683638809686133), ('1981', 0.10005391903325203), ('help', 0.04334598129201537)]]\n",
      "\n",
      "\n",
      "[[('henry miller', 0.17275361772009337), ('june miller', 0.16296971607769806), ('second', 0.13602171102234806), ('january', 0.13414126925642453), ('february', 0.12517177831031176), ('february 1 1979', 0.11150202052656621), ('january 7 28 1902', 0.10199205920490931), ('much write about second wife', 0.09340715263220084)]]\n",
      "\n",
      "\n",
      "[[('5 september 1839', 0.15547046994705985), ('23 october 1892', 0.1529735259535442), ('roxburghe', 0.1497943573070476), ('6th duke', 0.1492659781180719), ('james henry robert innes ker', 0.14534271693853917), ('23 october', 0.1382444008700083), ('duke', 0.1366035663045213), ('5 september', 0.13333831989830802), ('7th duke', 0.08809213674768047), ('7th', 0.08801014342242344), ('6th', 0.08801014342242344), ('father', 0.04728361927795762), ('death', 0.04183666759145479)]]\n",
      "\n",
      "\n",
      "[[('30 may 1919', 0.17518274565543687), ('james henry miller', 0.1707052057675552), ('former australian rule footballer', 0.1323201844864642), ('australian', 0.11931330702339915), ('victorian football league', 0.11631788994216831), ('vfl', 0.1051494938140341)]]\n",
      "\n",
      "\n",
      "answer:  American\n",
      "number_sentences:  23\n",
      "number_reduced_sentences:  2\n",
      "number of questions:  2\n",
      "number of questions with answer neither yes nor no:  2\n",
      "common_phrases_num_le2:  1\n",
      "extended:  1\n",
      "answer_in_reduced_context:  1\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043]\n",
      "ratio of reduced context:  0.20524296675191817\n",
      "question id:  5a84dd955542997b5ce3ff79\n",
      "question:  Cadmium Chloride is slightly soluble in this chemical, it is also called what?\n",
      "question_phrases_text:  ['cadmium chloride', 'chemical']\n",
      "common_phrases:  ['cadmium chloride']\n",
      "extended_phrases:  ['cadmium chloride', 'chemical']\n",
      "paras_phrases\n",
      "[[('cadmium chloride', 0.23061136732132892), ('cadmium', 0.20356899384617214), ('cdcl', 0.16666666666666666), ('white crystalline compound', 0.16297764192070643), ('formula cdcl', 0.12777531299998798), ('chlorine', 0.11389751013964619)], [('water', 0.19996108911885074), ('alcohol', 0.1481847734547836)], [('considerable covalent character', 0.30262686851608334), ('bonding', 0.07675968261097386)], [('other crystal structure', 0.2134453593826136), ('cadmium chloride', 0.16121775362361188), ('two', 0.15284707285285118), ('two dimensional layer', 0.1409590488872721), ('ion', 0.1239944798959774), ('crystal structure', 0.08555632359565934), ('reference', 0.05341467125587803)], [('cdcl•5ho', 0.1772686320214733)]]\n",
      "\n",
      "\n",
      "[[('soluble blue 3 m', 0.1808325365110209), ('marine blue v', 0.16631878440827189), ('c.i. 42755', 0.11212819425814513), ('22', 0.09933428759012652), ('c.i.', 0.0963693580015332), ('histology', 0.08177088499119403), ('chemical compound', 0.07914256208168083), ('stain', 0.05763507431743264)], [('tissue section', 0.20484251578543625), ('water blue stain', 0.19465192553109278)], [('water', 0.23406695671148683), ('ethanol', 0.19870868100484185)]]\n",
      "\n",
      "\n",
      "[[('new zealand', 0.12343686385028368), ('japanese ジフルコルトロン', 0.12320425004825272), ('diflucortolone valerate', 0.11458315712468463), ('new zealand topical steroid system', 0.11296201426438299), ('2', 0.10588603159549573), ('japanese', 0.09484267590755288), ('diflucortolone', 0.08820615548071181), ('nerisone', 0.08236906780739442), ('jifurucorutoron', 0.08053524638066986), ('also nerisone cream oily cream ointment', 0.07937101391098615), ('neriderm', 0.07740468093844968), ('100 150', 0.07247134798705097), ('neriderm ointment', 0.05978041766344595), ('corticosteroid', 0.04914269831104295)], [('creamy white crystalline powder', 0.37267799624996495)], [('methyl alcohol', 0.1521432086093819), ('water', 0.1502972610826196), ('ether', 0.14016805804686158), ('dichloromethane', 0.12581568753320627)], [('valeric acid', 0.30060180602107583), ('corticosteroid', 0.11107025089292401)], [('dermatology', 0.21332652874908856)], [('0.1 %', 0.2198709389683071), ('0.3 %', 0.2189918122102002), ('0.1 % 0.3 %', 0.18058167613081288), ('potency', 0.17521171684497266), ('nerisone', 0.1682859111680252), ('cream', 0.08500458471642529), ('brand name', 0.08096901134984617)]]\n",
      "\n",
      "\n",
      "[[('heptanoic acid', 0.18362530417542483), ('seven', 0.1345562820318682), ('carboxylic acid', 0.10999154400844026), ('seven carbon chain', 0.09435227507221076), ('organic compound', 0.09134889956553868)], [('unpleasant rancid odor', 0.157503991536887), ('oily liquid', 0.14745817892163235)], [('rancid oil', 0.18070158058105024), ('odor', 0.14242577063980658)], [('ethanol', 0.20811029502240133), ('water', 0.20023133518675454), ('ether', 0.1335169687246817)]]\n",
      "\n",
      "\n",
      "[[('magnesium chloride', 0.18342046918930058), ('mgcl', 0.14470121216688356), ('mgcl(ho', 0.1426411114088643), ('various hydrate', 0.12106456046248738), ('chemical compound', 0.11553674551783184), ('formula mgcl', 0.11199153896090842), ('name', 0.08220703427379812)], [('typical ionic halide', 0.2765310294691949), ('water', 0.16372713080835927), ('salt', 0.060622961600601086)], [('brine sea water', 0.14937731627838186), ('hydrated magnesium chloride', 0.1193810251086525)], [('great salt lake brine', 0.2373279964470662), ('great salt lake', 0.22690352304186567), ('magnesium chloride', 0.20541224194533253), ('north america', 0.17070075543226232)], [('jordan', 0.19347155904356467), ('similar process', 0.14642868058644296), ('dead sea', 0.14392879387430055), ('jordan valley', 0.1306703267953399)], [('ancient seabed', 0.16852142145040352), ('northwest europe', 0.15264424409773117), ('solution mining', 0.14838454545077004), ('zechstein', 0.12738699718317725), ('natural mineral bischofite', 0.11809170386097267), ('example', 0.10671308327074187), ('europe', 0.10671308327074187), ('magnesium chloride', 0.09331389496316868)], [('solar evaporation', 0.2616585242462876), ('seawater', 0.16895618538601082), ('magnesium chloride', 0.0973246610161333)], [('magnesium metal', 0.21902135519456312), ('anhydrous magnesium chloride', 0.15460015978695718), ('large scale', 0.12719868065793305), ('principal precursor', 0.12018411818809854)], [('hydrated', 0.16046214110602744), ('hydrated magnesium chloride', 0.1595975979749276), ('form', 0.10791045363873636)]]\n",
      "\n",
      "\n",
      "[[('simple alcohol', 0.24315326665359077), ('alcohol', 0.23760585947256588), ('c2h5oh', 0.12532844419668288), ('ethanol', 0.11546837549241751), ('chemical formula', 0.10411754809339224), ('compound', 0.06188241995865519)], [('etoh', 0.13524013765559656), ('ch3', 0.11675335242556874), ('hydroxyl group', 0.10368210551463188), ('c2h5', 0.052378280087892415), ('formula', 0.0449383863011289)], [('slight characteristic odor', 0.15608563426760574), ('volatile flammable colorless liquid', 0.11961196197895373), ('ethanol', 0.06731882884422584)], [('alcoholic drink', 0.20007254511850828), ('alcohol', 0.1894505949546075), ('principal type', 0.11807659204225746), ('drug', 0.08838834764831845)]]\n",
      "\n",
      "\n",
      "[[('tributyltin oxide', 0.16984155512168936), ('tbto', 0.13074409009212268), ('tributyltin', 0.13074409009212268), ('especially wood preservative', 0.12407125752012432), ('molluscicide', 0.1228467562135784), ('organotin compound', 0.10060581415295503), ('fungicide', 0.06457767336320491), ('biocide', 0.062219040605099106)], [('chemical formula', 0.16292449085413446)], [('20 ppm', 0.14917948478983806), ('organic solvent', 0.14765015006880855), ('water', 0.14000079300026363), ('colorless pale yellow liquid', 0.10869759767019818), ('form', 0.04641547041085453)], [('potent skin irritant', 0.2551551815399144)]]\n",
      "\n",
      "\n",
      "[[('chconh', 0.16693033975434995), ('chemical formula', 0.14095784649407914), ('off white solid', 0.13570368526442542), ('benzamide', 0.12925968026610923)], [('benzoic acid', 0.35355339059327373), ('derivative', 0.14433756729740643)], [('many organic solvent', 0.27067897098852123), ('water', 0.19064601316707466)]]\n",
      "\n",
      "\n",
      "[[('gold', 0.20186306073614405), ('chemical compound', 0.12673022482080262), ('chlorine', 0.1253472519847829), ('chloride', 0.07087073785001645)], [('aucl', 0.19616153860779784), ('molecular formula aucl', 0.15903024276969357), ('name gold trichloride', 0.14550302708659024), ('empirical formula', 0.12824190317427164), ('simplification', 0.07421748339364062)], [('gold compound', 0.2160199833014198), ('+3', 0.13897671867159608), ('roman', 0.11756903914135763), ('oxidation state', 0.11720866213100391), ('gold', 0.10083186928014277), ('name', 0.07969607405992042), ('roman numeral', 0.07866296262207453)], [('gold', 0.20141655461832692), ('related chloride', 0.17793944028346473), ('gold(i chloride', 0.16765056041860896), ('aucl', 0.13028745086205556)], [('gold', 0.16360189639769387), ('aqua regia', 0.15065163059236233), ('haucl', 0.12139887441541337), ('acid gold trichloride', 0.11522304314487421), ('chloroauric', 0.10433293408297153), ('gold chloride', 0.09035079029052512), ('chloroauric acid', 0.07998703985195281), ('product', 0.06709914753858334)], [('water', 0.16867009563462276), ('ethanol', 0.1280980907886662), ('chloride', 0.0400306533714582)], [('160 ° c', 0.22468513754275293), ('light', 0.15796441460699462), ('160', 0.13472777958276305)]]\n",
      "\n",
      "\n",
      "[[('negatively charge ion cl', 0.17015273035082518), ('cl', 0.1610486652334418), ('chloride ion', 0.14994689630508193), ('anion', 0.10088914905746005)], [('other polar solvent', 0.16916112217028467), ('hydrogen chloride', 0.15789098897723927), ('water', 0.11900892548617317), ('element', 0.06251276391357265), ('compound', 0.05997225152303693), ('halogen', 0.05530501199742341), ('electron', 0.05428202048037704)], [('sodium chloride', 0.24258130688224314), ('chloride salt', 0.1363714216751546), ('water', 0.13272659023848077)], [('nerve impulse', 0.1660767448427895), ('fluid', 0.14323233334558821), ('acid base balance', 0.1192111314040551), ('body fluid', 0.10103670217142798), ('essential electrolyte', 0.08559279588686047), ('cell', 0.04853568381162902)], [('chemical compound', 0.14387164226739702), ('one more chlorine atom', 0.12670904055235113), ('one', 0.11246073220421321), ('part', 0.10874576088988348), ('chloride', 0.06076221267278577), ('word', 0.05548405997934665), ('common name', 0.04825256493786081)], [('methyl chloride', 0.16193756890782393), ('iupac book', 0.1496457258665677), ('chloromethane', 0.14170107740214005), ('iupac', 0.1246595986677943), ('example', 0.12465959866779427), ('covalent c−cl bond', 0.12322538131950848), ('c−cl', 0.1220839279154169), ('standard name chloromethane', 0.11686837375105714), ('organic compound', 0.08719352628049486), ('chlorine', 0.025604577824959462), ('anion', 0.025604577824959462)]]\n",
      "\n",
      "\n",
      "answer:  alcohol\n",
      "number_sentences:  51\n",
      "number_reduced_sentences:  2\n",
      "number of questions:  3\n",
      "number of questions with answer neither yes nor no:  3\n",
      "common_phrases_num_le2:  1\n",
      "extended:  1\n",
      "answer_in_reduced_context:  1\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098]\n",
      "ratio of reduced context:  0.14990053992611538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a7e36045542991319bc9440\n",
      "question:  Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\n",
      "question_phrases_text:  ['more grand slam title', 'grand slam', 'henri leconte', 'jonathan stark', 'tennis player']\n",
      "common_phrases:  ['henri leconte', 'jonathan stark', 'tennis player', 'grand slam']\n",
      "extended_phrases:  ['two grand slam double title', 'jonathan stark', 'grand slam', 'henri leconte', 'tennis player', 'more grand slam title']\n",
      "paras_phrases\n",
      "[[('26 february 1982', 0.16692417547230295), ('17 february 2014', 0.16156387065239694), ('17 february', 0.1568533019334542), ('no .', 0.1305582419667734), ('retired chinese professional tennis player', 0.1219793063346769), ('li na', 0.1094905014212279), ('chinese', 0.10590773483128266), ('wta', 0.1055835913169378), ('2', 0.08423149203880353), ('career high wta ranking', 0.07247907279188637), ('world', 0.07013720549477123)], [('seven wta single title', 0.21552562052978189), ('two grand slam single title', 0.21407650093606675), ('2014 australian open', 0.17832241809584165), ('seven', 0.11904244966358157), ('wta', 0.11904244966358157), ('2014', 0.11717491977926461), ('two', 0.11462189225880966), ('li', 0.11367401938805255), ('2011 french open', 0.10904100328961305), ('australian', 0.10303636546181512), ('career', 0.05835033346876801), ('course', 0.03937782794054423)], [('east asia', 0.17225026770167065), ('grand slam', 0.16830324417071707), ('asia', 0.14127194292880313), ('first', 0.11603778120948922), ('prominence', 0.1141667550371901), ('li', 0.08822540635398059), ('li rise', 0.06637411156759201), ('victory', 0.05869996845125832), ('whole', 0.03973938147921607)], [('east asian', 0.16710246857652233), ('asian', 0.14396300417477867), ('first', 0.11728987651282818), ('grand slam single', 0.10450715878145536), ('east asian asian country', 0.10400395166262062), ('2011 australian open', 0.10370485583064376), ('first player', 0.08896346324419031), ('milestone', 0.051493053739537456)], [('2013 us open', 0.19575425141239022), ('2013 wta tour championships', 0.19459954033439664), ('2013', 0.17339791057031287), ('beijing olympic games', 0.15543564130112403), ('wta tour championships', 0.14824623011868052), ('2013 australian open', 0.12466730565639739), ('2008 beijing olympic games', 0.11399317194532856), ('2008', 0.1092001119486133), ('wimbledon', 0.10347068316053906), ('three', 0.10018744966765265), ('us', 0.09063476553794665), ('li', 0.08079885009518564), ('three time quarterfinalist', 0.07213311349360522), ('runner up', 0.05371961050554092), ('semifinalist', 0.04510630697323549)], [('first', 0.11141562806715273), ('other most notable accolade', 0.09523809523809523), ('open', 0.08997911937429098), ('first chinese player', 0.08961145961715547), ('wta', 0.08727615155643381), ('grand slam single', 0.08691915889420704), ('chinese', 0.08659201435574054), ('wta tour title', 0.0820571211506704), ('10', 0.082026006964395), ('2006 wimbledon championships', 0.07881069036244588), ('2004', 0.07479670035509492), ('guangzhou international women open', 0.07377656041119396), ('guangzhou international women', 0.06323751014176722)], [('tennis player', 0.2022646291766042), ('east asia', 0.1652803278835312), ('major population growth', 0.12356781381493473), ('trailblazer', 0.10127384913562157), ('region tennis pioneer', 0.1003292785662306), ('reputation', 0.05510505015633736), ('feat', 0.032464039516876)]]\n",
      "\n",
      "\n",
      "[[('venus williams', 0.16034818699451744), ('richard williams', 0.15877008111493163), ('williams', 0.15269291482778355), ('serena williams', 0.15247512258375756), ('two professional american tennis player', 0.15118252946989869), ('grand slam', 0.13827953815007601), ('b.', 0.10510289505942158), ('twenty three time grand slam title winner', 0.10471360908409613), ('seven time grand slam title winner', 0.10037865229355131), ('oracene price', 0.09610076543159776), ('two', 0.0931461428992548), ('williams sister', 0.09220565404552256), ('american', 0.08372205238046293), ('1981', 0.07800885594034043), ('1980', 0.06510641084082106), ('early age', 0.06430241246957134), ('seven', 0.05784388513157491), ('singles', 0.05775410245859359), ('single', 0.05775410245859359), ('twenty three', 0.05294130800397219), ('parent', 0.04523112268363565)], [('nine grand slam single final', 0.20560302844380127), ('us open', 0.170205715202704), ('2017 australian open tournament', 0.14059465060314638), ('2017', 0.12695712716365154), ('nine', 0.12391952164413422), ('note professional rivalry', 0.1141088661469096), ('2001 us open', 0.11382406686204168), ('australian', 0.1119364296924277), ('2001', 0.09943877428247216)], [('4 consecutive grand slam single final', 0.1832113602983327), ('two', 0.13134005801756826), ('serena slam', 0.12921148288875922), ('4', 0.12605894923202896), ('serena', 0.11928015061770006), ('first', 0.11273712122270427), ('first two player', 0.10558016090519047), ('2003 australian open', 0.09683652908035612), ('2002 french open', 0.09421388652081178), ('2003', 0.08757890531258018), ('australian', 0.08753798049661146)], [('12 wimbledon single title', 0.20594834441813387), ('12', 0.13104210533172697), ('wimbledon', 0.13104210533172697), ('2016', 0.12858990132543457), ('17-year', 0.12036636227429762), ('serena', 0.11971439446960125), ('5', 0.11780682219937974), ('venus', 0.1174279457533844), ('7', 0.0904837472100753), ('2000', 0.05144150264836983)], [('career doubles grand slam', 0.19763811381819793), ('career doubles golden slam', 0.19763811381819793), ('2001', 0.11991529247220774), ('australian', 0.11991529247220774), ('2001 australian open woman double title', 0.1177037831439933), ('5th', 0.096448407949228), ('5th pair', 0.08285611686114117), ('only pair', 0.0814267077277946)], [('20 19 year old', 0.1831746915265901), ('serena', 0.16433060619041837), ('venus', 0.15068448818031813), ('time', 0.06128352161166741)], [('two olympic gold medal', 0.15621391836934334), ('two', 0.15115840754535603), ('2012 london olympics', 0.13246229799208983), ('2008 beijing olympics', 0.13221113433888346)], [('4 consecutive grand slam double title', 0.18254707733774242), ('grand slam', 0.1435267433767439), ('roland garros', 0.12107654541214227), ('2010', 0.10343072410891233), ('wimbledon', 0.10112713493649703), ('2009', 0.09910126776679024), ('4', 0.09647569351313934), ('co - no', 0.09245657297250018), ('nearly decade later', 0.09025927497112926), ('duo', 0.05310644709188759)], [('7 june 2010', 0.282842712474619), ('7 june', 0.26763402048270435), ('1 double player', 0.18042195912175804), ('1', 0.1619219055672653)], [('no .', 0.17862142512060675), ('21 june 2010', 0.1621284003863518), ('two week later', 0.1587807565602678), ('no . 1 single ranking', 0.14823177547682032), ('21 june', 0.13908717972938972), ('serena', 0.11302725396581301), ('venus', 0.1082906943366261), ('1', 0.10339818880708376), ('2', 0.09170896492062994)], [('2016 wimbledon event', 0.20956542609166318), ('most recent grand slam double title', 0.1456324080173751), ('2012 wimbledon 2016 wimbledon', 0.1250345636654603), ('2012 wimbledon', 0.11259868771601368)], [('support', 0.14589267171512138), ('one', 0.11505918081562656), ('other match', 0.08255051382504527), ('tournament', 0.03016942450159236)]]\n",
      "\n",
      "\n",
      "[[('4 july 1963', 0.20775200391128978), ('former french professional tennis player', 0.16685595311797866), ('henri leconte', 0.16426097423001326), ('french', 0.14903166716191923)], [('french', 0.14141744042270307), ('french open man double title', 0.12482410929919364), ('1984', 0.10842547249181295), ('french open', 0.10822552218283578), ('france', 0.107448054986938), ('1988', 0.10314591074076238), ('1991', 0.0935069007279425), ('davis cup', 0.08965101852742978), ('man single', 0.07373657757992318)], [('world no .', 0.24432918238897228), ('5', 0.14627341976831315), ('leconte career high single ranking', 0.11828267450702487), ('leconte', 0.10515623096590139)]]\n",
      "\n",
      "\n",
      "[[('14 june 1969', 0.16329931618554522), ('no .', 0.14315671142192837), ('1', 0.13457607839990504), ('german former tennis player', 0.11878277418329972), ('german', 0.1111111111111111), ('stefanie maria steffi graf', 0.09166199015381173), ('1 career', 0.06350526433600437)], [('22 grand slam single title', 0.30515203882451414), ('22', 0.1906614338523508), ('graf', 0.0810970660506749)], [('margaret court', 0.13527726969819903), ('serena williams', 0.13085476009684277), ('major win', 0.12834864182186445), ('1968', 0.10908937774900301), ('24', 0.1049383563708918), ('second', 0.09886590088113074), ('22', 0.09651403219508099), ('23', 0.09200084634077584), ('third', 0.08957458848470808), ('major', 0.08891446291139862), ('open era', 0.07753329700113919), ('22 single title', 0.07176378221332008), ('female competition', 0.07159335110190133), ('list', 0.055460642106909076), ('introduction', 0.049525015391057345)], [('grand slam', 0.1575788019195732), ('four grand slam single title', 0.12874898341656535), ('first', 0.10674231725271802), ('four', 0.0999100070355759), ('same calendar year', 0.09150620114062774), ('olympic gold medal', 0.09096149390573494), ('first only tennis player', 0.0882460270347299), ('golden slam', 0.08643588226879949), ('1988', 0.07435327715740193)], [('grand slam event', 0.14720267012212762), ('only tennis player', 0.13297802735098274), ('least four', 0.11858825149434445)]]\n",
      "\n",
      "\n",
      "[[('outdoor red clay court', 0.17711508873620485), ('1986', 0.16817663850609155), ('nabisco grand prix', 0.15873998629509806), ('1986 ebel german open', 0.14482921248743486), ('1986 german open', 0.1372876700703613), ('1986 nabisco grand prix', 0.13446309770094017), ('german', 0.12917786188525493), ('ebel', 0.09528941479143657), ('man tennis tournament', 0.0727644075683785)], [('77th', 0.23886634470058746), ('77th edition', 0.22031412263175845), ('event', 0.12667800910127155)], [('21 september', 0.21105555327049874), ('15 september', 0.2012306738672972), ('15 september 21 september 1986', 0.17710695519668643), ('west germany', 0.17518105906585135), ('hamburg', 0.17123519680617874), ('place', 0.14015069407639374), ('am rothenbaum', 0.10936079563044072)], [('henri leconte', 0.26033673557220527), ('single title', 0.15364264248032836)], [('henri leconte', 0.24664277008089175), ('fourth seed henri leconte', 0.1478565666468643), ('fourth', 0.14198995055624392), ('single title', 0.12015715387550548)]]\n",
      "\n",
      "\n",
      "[[('jonathan stark', 0.16335849094422328), ('former professional tennis player', 0.1552621525461141), ('april 3 1971', 0.12757759076995717), ('united states', 0.08864520716719808)], [('two grand slam double title', 0.20485078337820506), ('wimbledon championships mixed', 0.1691266201165675), ('grand slam', 0.16599866428482482), ('1995 wimbledon championships mixed doubles', 0.14102018875386577), ('doubles', 0.1384963688468356), ('two', 0.12942824599273958), ('1994', 0.11770966453602971), ('1995', 0.11507608922419979), ('1994 french open men doubles', 0.11030546312338142), ('french', 0.10425827063624246), ('career', 0.047045796804165825)], [('world no . 1 double', 0.20244625021915708), ('1994', 0.11847644620023137), ('stark', 0.06413009319674405)]]\n",
      "\n",
      "\n",
      "[[('former american professional tennis player', 0.11117585526088972), ('pam teeguarden', 0.10890566062948219), ('computer ranking', 0.10749605841930371), ('women tennis ultimate guide', 0.10290562551619128), ('1970–1975', 0.09809501245505792), ('american', 0.09641280747435993), ('john dolan women tennis ultimate guide', 0.09400120975297538), ('april 17 1951', 0.08505172717997145), ('1980', 0.08245025822766541), ('20', 0.08198896138109175), ('john dolan', 0.06684038003526614), ('1970', 0.04177809679503368)], [('two grand slam doubles titles', 0.23083434416166956), ('single', 0.15334269518546886), ('two', 0.13598656991767702), ('quarter', 0.12813051593123456), ('u.s. open', 0.10699271799870742), ('french open', 0.1067913040420391), ('quarter finalist', 0.09823150066778065)], [('grand slam', 0.1552204421713212), ('margaret court', 0.12983989260034687), ('virginia wade', 0.12504281028953235), ('four grand slam title', 0.11900037132004596), ('one year', 0.11811361551598086), ('1977', 0.10871339358716545), ('coveted grand slam', 0.1053630833739902), ('1970', 0.10145413188977001), ('four', 0.0955703815370576), ('well know coach', 0.09455401409408012), ('jerry', 0.09453714091669364), ('wimbledon', 0.09197338361452503), ('1977 wimbledon triumph', 0.09175503732592435), ('father', 0.028057175473229678)], [('madison avenue advertising executive', 0.19175368939606985), ('most watchable player', 0.17559877461705103), ('madison avenue', 0.16146582596136747), ('mad man', 0.135293496851696), ('play', 0.099455445766612), ('appearance', 0.09796086891143099), ('teeguarden', 0.08325946130008785), ('us open', 0.07936053825321267), ('group', 0.05928401215510686)], [('19 consecutive', 0.20018926667476925), ('chris evert', 0.18443078605198915), ('us', 0.14632672265709246), ('20', 0.11158804229847477), ('teeguarden', 0.10987130162132576), ('record', 0.07053814085379982)], [('first', 0.13721592548768305), ('tokyo', 0.1256393236774855), ('bridgestone doubles championships', 0.11696024710303446), ('tennis', 0.11147174414134299), ('today', 0.11112715763112146), ('1975', 0.10889249508690597), ('first black outfit', 0.09093137726592458), ('history', 0.05923979093899655), ('trend', 0.05825533098917303)], [('tennis player', 0.2592799795639937), ('first', 0.19584693494144317), ('first woman', 0.14740711204809046), ('nike', 0.1409629805850986), ('teeguarden', 0.11363317339439834)], [('los angeles strings team tennis', 0.20126932562625408), ('victorious los angeles strings team tennis team', 0.15363719837632975), ('team tennis mixed doubles division', 0.14076023955166464), ('tom gullikson', 0.1270316194092753), ('runner', 0.10074422262677736), ('1981', 0.0856223553167205), ('1977', 0.07908813021810386), ('league', 0.05624776438909036), ('year', 0.042319144515951444)]]\n",
      "\n",
      "\n",
      "[[('kenneth robert rosewall', 0.16873537965495633), ('2 november 1934', 0.15770372957303044), ('am', 0.10730379666327507), ('mbe', 0.10730379666327507), ('former world top rank amateur professional tennis player', 0.10716854166174664), ('australia', 0.08747541527850407), ('3', 0.04155858174616914)], [('8 grand slam single title', 0.19007271920722257), ('record 15 pro slam title', 0.14126830799024753), ('record 35 major final', 0.12055654746464307), ('record 23 tennis majors', 0.11402824209244196), ('8', 0.11147448732958076), ('23', 0.10810180803558456), ('15', 0.10553122597736567), ('35', 0.10121993658592279), ('open era', 0.06356489969579851)], [('pro grand slam', 0.21376490598996029), ('1963', 0.18200064648685815)], [('9 slam', 0.2574550347946673), ('career double grand slam', 0.18845650960891472), ('9', 0.17177325226592405), ('double', 0.1505420940562045), ('rosewall', 0.08020771715795855)], [('great tennis player', 0.20270106243858127), ('time', 0.07594534445657587)], [('early 1950', 0.12946181715620844), ('early 1970', 0.12002966016254381), ('long career', 0.11424121535767795), ('high level', 0.10638048237042225), ('renowned backhand', 0.10401121656339787)], [('about nine year', 0.18073304060385934), ('world no . 1 player', 0.15443598135676911), ('two good male player', 0.14716367857178825), ('year', 0.13287945848219673), ('two', 0.12900239428605845), ('1', 0.12013058511506342), ('world no', 0.08693057379941065), ('rosewall', 0.08367000526255494), ('early 1960', 0.07482788205476615), ('number year early 1960', 0.06279310172730508), ('number', 0.04990016192701481)], [('20', 0.17085783417728234), ('top 20 player', 0.16165691818047678), ('1952 1977', 0.1120775636955087), ('year', 0.08394214940389634)], [('pro grand slam title', 0.22870866575662666), ('three different surface', 0.19261860493305988), ('three', 0.1336777347279358), ('only player', 0.09416229707885342), ('rosewall', 0.051913221251992964)], [('australian', 0.12320740853766876), ('first', 0.12077930114908725), ('grand slam tournament', 0.12058496329709578), ('first male player', 0.11342469240092429), ('1971 australian open', 0.10984402764731363), ('1971', 0.10403922575128101), ('open era', 0.08669332952587301), ('set', 0.044123365143611405)]]\n",
      "\n",
      "\n",
      "[[('2009', 0.21725967876881427), ('medibank international sydney', 0.1970721247173752), ('serena williams 2009 tennis season', 0.18602354712381186), ('2009 medibank international sydney', 0.1699938086105336), ('serena williams', 0.09474754303403639)], [('16 tournament', 0.15727934168899094), ('no .', 0.14852213144650114), ('16', 0.12868829826873165), ('second', 0.11609127591422454), ('williams', 0.09714873074147053), ('world', 0.09714873074147053), ('other year', 0.09528612011414797), ('1', 0.0876822156503235), ('second time', 0.08605008678475602), ('year', 0.07788466229232234), ('career', 0.06325671538008654)], [('one year', 0.13924010107692014), ('justine henin', 0.13668307761940177), ('williams', 0.10721661651486393), ('female tennis player', 0.10460651992949596), ('most prize money', 0.10255565162047678), ('6,545,586', 0.08981259594985344), ('record', 0.06444513569177356)], [('only six tournament', 0.21095658660049438), ('rank world', 0.17113679747606794), ('no .', 0.16984155512168936), ('six', 0.1356616111648501), ('double', 0.09313599244005828), ('3', 0.08875158737635178), ('year', 0.07596830111955923), ('pair', 0.04706763695616655)], [('five grand slam title', 0.30476757350464195), ('grand slam', 0.26923866476897707), ('total grand slam title', 0.2058305656361881), ('five', 0.14838622391654613), ('23', 0.11313691510789856)]]\n",
      "\n",
      "\n",
      "[[('née savchenko', 0.16561027532794903), ('21 july 1966', 0.16466742019994837), ('savchenko', 0.14569094489815806), ('former professional tennis player', 0.1278139040350092), ('larisa savchenko neiland', 0.11386191462008646), ('latvia', 0.09922103384983118), ('soviet union', 0.08972215729565071)], [('four mixed double grand slam title', 0.2025028277783462), ('grand slam title', 0.1913158280918965), ('rank double player', 0.18372578324601174), ('grand slam', 0.17079059753458778), ('one', 0.12230331242890326), ('two woman double', 0.11376174079324773), ('neiland', 0.11109768040633335), ('four', 0.10405263755394548), ('two', 0.10086833639223047)], [('two single title', 0.2697698789697398), ('sixty five double title', 0.17895858662672764), ('two', 0.16581214652432902), ('sixty five', 0.12128972439165489)]]\n",
      "\n",
      "\n",
      "answer:  Jonathan Stark\n",
      "number_sentences:  61\n",
      "number_reduced_sentences:  14\n",
      "number of questions:  4\n",
      "number of questions with answer neither yes nor no:  4\n",
      "common_phrases_num_le2:  2\n",
      "extended:  2\n",
      "answer_in_reduced_context:  2\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148]\n",
      "ratio of reduced context:  0.1698024541249144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5adf44985542993a75d2646d\n",
      "question:  Which genus of moth in the world's seventh-largest country contains only one species?\n",
      "question_phrases_text:  ['only one specie', 'one', 'moth', 'seventh', 'world seventh large country', 'genus']\n",
      "common_phrases:  ['moth', 'only one specie', 'seventh', 'one', 'genus']\n",
      "extended_phrases:  ['south asia', 'only one specie', 'moth', 'seventh', '1.2 billion', 'genus', 'one', 'world seventh large country']\n",
      "paras_phrases\n",
      "[[('south asia', 0.21650635094610965), ('india', 0.1983979520615437), ('bhārat gaṇarājya', 0.19752944933436425), ('officially republic', 0.12513548807794375), ('republic india', 0.10299380055287026), ('country', 0.08838834764831845)], [('1.2 billion', 0.17677669529663687), ('most populous democracy', 0.14330019943025635), ('area', 0.12933665075339193), ('second', 0.1277220647263986), ('1.2 billion people', 0.1275775907699572), ('second most populous country', 0.12670810103456048), ('seventh', 0.11002745631563249), ('seventh large country', 0.09642308792892726), ('world', 0.04736962952065602)], [('bengal', 0.1800894450198638), ('arabian sea', 0.12251102378480302), ('indian ocean', 0.12251102378480301), ('bay bengal', 0.08923733773063022), ('south', 0.0829638847383012), ('southeast', 0.06938458561389206), ('southwest', 0.06379233360558022)], [('land border', 0.18209349348308745), ('pakistan', 0.14178559952506906), ('bangladesh', 0.1405659465297777), ('burma', 0.1361445191815465), ('myanmar', 0.13349089177790868), ('bhutan', 0.1303692789882794), ('nepal', 0.12882987386171968), ('china', 0.12657926142157294), ('northeast', 0.06987721758424081), ('west', 0.06510235208622428), ('east', 0.05552471390240209)], [('sri lanka', 0.25620777144784995), ('india', 0.1781741612749496), ('indian ocean', 0.13659755535250212), ('maldives', 0.13400268795640885), ('vicinity', 0.09371846522492118)], [('nicobar islands', 0.21886958560383987), ('andaman', 0.16503742455408235), ('thailand', 0.16503742455408232), ('maritime border', 0.12917002057676044), ('indonesia', 0.10686926250233104), ('india', 0.10686926250233104), ('india andaman nicobar islands', 0.10538014470679276)]]\n",
      "\n",
      "\n",
      "[[('south asia', 0.30368238303033623), ('india', 0.1772686320214733), ('country', 0.15139668487391394)], [('1.2 billion', 0.17677669529663687), ('most populous democracy', 0.14330019943025635), ('area', 0.12933665075339193), ('second', 0.1277220647263986), ('1.2 billion people', 0.1275775907699572), ('second most populous country', 0.12670810103456048), ('seventh', 0.11002745631563249), ('seventh large country', 0.09642308792892726), ('world', 0.04736962952065602)]]\n",
      "\n",
      "\n",
      "[[('geometridae', 0.23378309949153975), ('moth', 0.23048479379322753), ('eutrapela', 0.17290157147431207), ('geometridae family', 0.1576299380282478), ('genus', 0.1239822112329578)], [('only one specie', 0.15036405489493287), ('north america', 0.13583371403527567), ('nova scotia', 0.13487646691349303), ('one', 0.10659622622694517), ('florida', 0.10544971456642212), ('texas', 0.09680008416038306), ('purplish brown looper', 0.08882342789448461), ('curve toothed geometer moth', 0.08028516455791374), ('saskatchewan', 0.07581830149594558), ('eutrapela', 0.04181900718437449)], [('deciduous mixed woodland', 0.2072339662924147), ('habitat', 0.07484972249556275)]]\n",
      "\n",
      "\n",
      "[[('indian', 0.13247255242507816), ('indian plate', 0.1168636537459635), ('indo australian plate', 0.10344725971216713), ('continental crust', 0.10131368254800038), ('india', 0.1003065580945649), ('indian subcontinent', 0.09374751236394221), ('northern portion', 0.09023490676288864)], [('97 ° 25 east longitude', 0.14302104006754177), ('68', 0.11680519427990967), ('97', 0.11303724635444898), ('37 6 north latitude', 0.09243383020525339), ('8 ° 4 37 6', 0.07129384351679056), ('equator', 0.06060150007150371), ('country', 0.03975594482711915)], [('3287263 km2', 0.21650635094610965), ('seventh', 0.16530348187683502), ('total area', 0.12777531299998796), ('seventh large country', 0.126354916147846), ('world', 0.06647541891115419)], [('3214 km', 0.25312367067708147), ('2933 km', 0.2447537219481371), ('east', 0.15901272337889705), ('south', 0.14904090569172979), ('north', 0.14751900489719888), ('india', 0.1469132649833675), ('west', 0.10424800198444559)], [('15200 km', 0.28434783457484886), ('7516.6 km', 0.26640806263822114), ('land frontier', 0.13744000393145464), ('coastline', 0.10110531653746374)]]\n",
      "\n",
      "\n",
      "[[('subfamily musotiminae', 0.18822977174198388), ('crambidae', 0.1806518509326466), ('grass moth genus', 0.17415166164035517), ('family crambidae', 0.13633281232655692), ('musotiminae', 0.12428967814999965), ('yoshiyasua', 0.11602621304691792)], [('snout moth family', 0.14268025190686306), ('pyralidae', 0.13330872148572767), ('grass moth', 0.12853000737751977), ('error', 0.05431254465936412), ('author', 0.05397624083969538)], [('only one specie', 0.21231098898970693), ('japan', 0.1579483919805557), ('yoshiyasua yasudai', 0.14580497783265894), ('ryukyu islands', 0.1058352753431753), ('genus', 0.04544234236789582)]]\n",
      "\n",
      "\n",
      "[[('moth', 0.23048479379322753), ('nepita', 0.17290157147431207), ('arctiidae', 0.17290157147431207), ('family arctiidae', 0.1576299380282478), ('genus', 0.1239822112329578)], [('only one specie', 0.221905137821337), ('only one', 0.19595983500500122), ('nepita conferta', 0.17624931694814977), ('sri lanka', 0.16595586370694287), ('india', 0.15269854578646336), ('nepita', 0.13351253104996924), ('genus', 0.04337624353242971)], [('specie', 0.07484978112251311)]]\n",
      "\n",
      "\n",
      "[[('geometer moth family', 0.1982288166939987), ('geometridae', 0.17468678456075815), ('parectropis', 0.14516130100050617), ('genus', 0.10133213412076442)], [('new one', 0.15950542808141932), ('old world', 0.15801040538272806), ('only good dozen specie', 0.13972848893693085), ('good dozen', 0.10883338793747348)], [('most other', 0.1916177762091981), ('only one', 0.16633264593193828), ('europe', 0.14208845692198266), ('asia', 0.1417152555277023), ('only one specie', 0.12923973668988784), ('africa', 0.09750116713016617), ('p. similaria', 0.06762784033803515)]]\n",
      "\n",
      "\n",
      "[[('crambidae', 0.23378309949153975), ('moth', 0.23048479379322753), ('indogrammode', 0.17290157147431207), ('crambidae family', 0.1576299380282478), ('genus', 0.1239822112329578)], [('only one specie', 0.26523587488714), ('indogrammode pectinicornali', 0.19261299919268443), ('one', 0.18013649271662793), ('india', 0.16666666666666666)]]\n",
      "\n",
      "\n",
      "[[('moth', 0.23048479379322753), ('eumacaria', 0.17290157147431207), ('geometridae', 0.17290157147431207), ('family geometridae', 0.1576299380282478), ('genus', 0.1239822112329578)], [('north dakota', 0.14734450752144232), ('only one specie', 0.13322265755687665), ('north america', 0.13240790982923378), ('south dakota', 0.12332503779000781), ('northern washington', 0.12029640266475491), ('british columbia', 0.1144579568505956), ('southern saskatchewan', 0.10684953942177179), ('eumacaria madopata', 0.10508907651580698), ('new mexico', 0.10293973099017417), ('colorado', 0.09458956263483848), ('washington', 0.09263794622892083), ('one', 0.0905728101695696), ('saskatchewan', 0.08286062928048776), ('nebraska', 0.08239001913342764), ('florida', 0.08124538534522785), ('idaho', 0.07721273781548003), ('wyoming', 0.07438082610384182), ('maine', 0.06993394421130311), ('brown border geometer moth', 0.06854274981271505)], [('orchard', 0.28547632672935286), ('shrubland', 0.1772686320214733), ('habitat', 0.08997996534232185)]]\n",
      "\n",
      "\n",
      "[[('crambidae', 0.23378309949153975), ('moth', 0.23048479379322753), ('nymphuliella', 0.17290157147431207), ('crambidae family', 0.1576299380282478), ('genus', 0.1239822112329578)], [('only one specie', 0.19019715666254147), ('new jersey', 0.17654087837592147), ('mark moth', 0.15811388300841897), ('one', 0.13483474592587516), ('florida', 0.13118474757975113), ('china', 0.1217161238900369), ('west', 0.1186145592271087), ('china mark moth', 0.1141088661469096), ('colorado', 0.09056528503808836), ('nymphuliella', 0.0528973248862533)]]\n",
      "\n",
      "\n",
      "answer:  Crambidae\n",
      "number_sentences:  32\n",
      "number_reduced_sentences:  18\n",
      "number of questions:  5\n",
      "number of questions with answer neither yes nor no:  5\n",
      "common_phrases_num_le2:  3\n",
      "extended:  3\n",
      "answer_in_reduced_context:  3\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625]\n",
      "ratio of reduced context:  0.24834196329993152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a832c3455429954d2e2ec41\n",
      "question:  Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring.\n",
      "question_phrases_text:  ['crime', 'controversy', 'violence', 'number', 'unsportsmanlike conduct', 'world', 'sport', 'ring']\n",
      "common_phrases:  ['crime', 'sport', 'number', 'controversy', 'unsportsmanlike conduct', 'world', 'ring', 'violence']\n",
      "extended_phrases:  ['crime', 'sport', 'number', 'controversy', 'unsportsmanlike conduct', 'world', 'ring', 'violence']\n",
      "paras_phrases\n",
      "[[('1998 verano de escándalo', 0.14711606907426353), ('spanish', 0.12465724148311061), ('1998', 0.11653542967489117), ('summer', 0.11545414496535802), ('verano escandalo', 0.10723163720104605), ('second', 0.1015384105318507), ('second annual verano escandalo professional wrestling show', 0.10036684955897508), ('aaa', 0.09679427199189462), ('scandal', 0.08880977717873922), ('summer scandal', 0.07896297763547383)], [('september', 0.1802672092833404), ('place', 0.17978995958868305), ('tamaulipas', 0.15982524610044962), ('september 18 1998', 0.15770643338403026), ('madero', 0.14923077334905596), ('mexico', 0.12066566937725472), ('show', 0.05113548876925013)], [('steel cage match', 0.1786546261970512), ('kick boxer', 0.1630173481857176), ('heavy metal blue demon jr.', 0.14087821969453143), ('abismo negro', 0.13530205372064807), ('boxer', 0.12658437131867156), ('kick', 0.12438764128592364), ('main event', 0.06259496099473275), ('team', 0.05708087835069961)], [('referee guicho dominguez', 0.19472467504535187), ('guicho dominguez', 0.1494826727166201), ('heavy metal blue demon jr.', 0.13437064610508415), ('el tirante', 0.13300557340225277), ('main event', 0.09214417401387971), ('el tirante slave', 0.06609916874783399), ('team', 0.0464418581808033), ('stipulation', 0.03845389955690588), ('week', 0.023380488239570615)], [('abismo negro', 0.19465726895867225), ('el tirantes', 0.19234774217725653), ('kick boxer', 0.14805583919771884), ('guicho dominguez slave', 0.12683270847959835), ('boxer', 0.12269916406668724), ('guicho dominguez', 0.10347069557995581), ('week', 0.0474733927801065)]]\n",
      "\n",
      "\n",
      "[[('triplemanía vii', 0.23944147394806373), ('seventh', 0.15614916998624623), ('aaa', 0.15149561708251183), ('seventh triplemanía wrestling show', 0.12867698120644933)], [('june', 0.19192680971855375), ('place', 0.19121221190369345), ('june 11 1999', 0.16812418150869007), ('madero', 0.1607874314682861), ('mexico', 0.12310084538819732), ('show', 0.05434670000228471)], [('perro aguayo jr.', 0.17303047279991168), ('perro aguayo', 0.1623406782340525), ('el cobarde ii', 0.15517914684354567), ('el texano', 0.14318248605527661), ('lucha libre', 0.13141897999528918), ('sangre chicana', 0.11046312832261784), ('six', 0.10273120321334153), ('octagón', 0.09572483084316236), ('team', 0.06374802897398464), ('main event', 0.055086489774288136)], [('referee el tirantes', 0.16817432066615534), ('thai boxer', 0.15304533190178501), ('el felino', 0.15129699692506562), ('kick boxer', 0.14787664490401342), ('heavy metal', 0.14526337064370232), ('el tirantes', 0.13992554083271258), ('boxer', 0.1316316093159865), ('semi - main event', 0.11287777690967674), ('thai', 0.10214481011843397), ('casas', 0.09420697469981465), ('referee pepe tropi casas', 0.08566420905745875), ('pepe tropi', 0.07309402870419356), ('hair', 0.06887969090186488), ('father', 0.04932020698352526)], [('el tirantes', 0.29412489548905435), ('hair', 0.11357980999191693), ('result', 0.10788726874910441), ('match', 0.042666009299143076)]]\n",
      "\n",
      "\n",
      "[[('other group', 0.21894673743707097), ('protection', 0.15088174136417798), ('business', 0.149896560490369), ('violence', 0.14311149969808323), ('group', 0.10409680919306603), ('protection racket', 0.10257321303316339), ('scheme', 0.0716260681192323), ('sanction', 0.07087779540093968), ('law', 0.05465576938391859)], [('violence', 0.14159058980917055), ('people', 0.13578364770675247), ('credible threat', 0.09180074634641817), ('racketeer', 0.07250605871953165), ('client', 0.061512223800640094)], [('black market', 0.1567860595294366), ('legal protection', 0.1484823757368615), ('market', 0.1413732987886097), ('weak fail state', 0.1030193933416968), ('judiciary', 0.09639665255871299), ('protection racket', 0.09256081267378188), ('police', 0.06828705030316426), ('incompetence', 0.044086671417740544)]]\n",
      "\n",
      "\n",
      "[[('elwood gordon gee', 0.16488650100958402), ('west virginia university', 0.16188392413171884), ('second', 0.13102065775735575), ('president', 0.12998207840552162), ('february 2 1944', 0.1051791127464542), ('second term', 0.09415767977295521), ('american', 0.08438814970333752), ('american academic', 0.07524283153228906)], [('ohio state university', 0.2010792600150253), ('several university', 0.18038609491943472), ('chief executive', 0.10595893293237228), ('united states', 0.10408389673658577)], [('ohio state', 0.21281031609271686), ('ohio', 0.15789129576683658), ('ohio state presidency', 0.14464504656144347), ('july', 0.1363207114368139), ('ohio state base think tank', 0.1354494604688639), ('july 1 2013', 0.11371522163124302), ('retirement', 0.061147545724957036), ('gee', 0.044228648956867476)], [('anti - catholic comment', 0.20673213506329458), ('anti - catholic', 0.17895734711515876), ('comment', 0.15459915140471947), ('notre dame', 0.13107633443259525), ('response', 0.10802532449906002), ('controversy', 0.10778835824133172), ('jest', 0.10504123624773493), ('university notre dame', 0.0755478589722888), ('university', 0.06216698253629138), ('series', 0.06162767559582847)], [('ohio state', 0.1826719455537414), ('president', 0.1764606401830237), ('second', 0.13584422609331856), ('second term', 0.10411986061719804), ('1990 1997', 0.09453079184693447), ('resignation', 0.04427232412066851)]]\n",
      "\n",
      "\n",
      "[[('8 december 1984', 0.14973339711998063), ('هاري\\u200e \\u200e', 0.14495486429541282), ('arabic', 0.11847826408958374), ('badr hari', 0.1168136220050746), ('amsterdam', 0.10670117068573776), ('moroccan dutch super heavyweight kickboxer', 0.10166261897223972), ('بدر', 0.09970676889825876), ('moroccan', 0.08551529305745503), ('oostzaan', 0.0823025356319229), ('mike gym', 0.081892295820068)], [('showtime heavyweight world champion', 0.22580814386758838), ('world grand prix', 0.19475056992931114), ('k-1 heavyweight', 0.17781533553149645), ('former k-1 heavyweight champion', 0.14964259797094007), ('k-1 world grand prix 2009 finalist', 0.13159807722194114), ('showtime', 0.10865622630213935), ('2009 2010', 0.09938430877200519)], [('crime', 0.13312268378199113), ('controversy', 0.10929543494140409), ('kickboxing', 0.09992820736794977), ('violence', 0.09671665719545486), ('world', 0.07547710921696296), ('prominent figure', 0.0746090358112841), ('number', 0.07078172666508016), ('unsportsmanlike conduct', 0.06247560023330788), ('sport', 0.051291753117450614), ('hari', 0.042678959977632), ('ring', 0.022633936510629636)]]\n",
      "\n",
      "\n",
      "[[('guerra de titanes', 0.23758891587586503), ('war', 0.13608276348795434), ('second guerra de titanes professional wrestling show', 0.1335132568004125), ('aaa', 0.10463464570408795), ('1998', 0.08070189317655556), ('war titans', 0.07715167498104596), ('titans', 0.07216878364870322)], [('place', 0.18891903402673021), ('december', 0.18870293951911535), ('chihuahua', 0.18298258149131003), ('december 13 1998', 0.16432885054812818), ('mexico', 0.11684837927367137), ('show', 0.05386141370534689)], [('heavy metal', 0.15918346294398808), ('two storyline feud', 0.15354619301377181), ('pentagón', 0.12280766552552494), ('kick boxer', 0.11927043253289199), ('octagón', 0.11105486537958814), ('boxer', 0.10624962824417584), ('two', 0.09599958002392607), ('steel cage match', 0.09484148610869082), ('feud', 0.06407469127375864), ('evil twin pentagón', 0.05590713671932407), ('main event', 0.04957955316407351)]]\n",
      "\n",
      "\n",
      "[[('global fighting championship', 0.18516401995451032), ('mma', 0.13176630233409675), ('gfc', 0.10600267891708694), ('uae', 0.10496806593966718)], [('peter graham', 0.19608538044729187), ('peter aerts', 0.19480175757635393), ('badr hari', 0.1832686458948302), ('dewey cooper', 0.176445625320718), ('zabit samedov', 0.1476990885125739), ('world', 0.11891955969821097), ('roster', 0.07534745894076567), ('fighter', 0.04910825532916352)], [('middle east', 0.2016090861410878), ('mma', 0.1919268097185538), ('big kickboxing mma promotion', 0.15045166595862752)], [('ref name=\"emirates 24/7', 0.4), ('ref', 0.14433756729740643)]]\n",
      "\n",
      "\n",
      "[[('freelance journalist steven pressman', 0.16191252579729595), ('werner erhard', 0.13653035745930156), ('steven pressman', 0.13400173903179352), ('outrageous betrayal', 0.1276884796138123), ('non - fiction book', 0.10770776712139046), ('1993', 0.10546571472466787), ('first', 0.10044797758660176), ('est', 0.09743680646926724), ('st. martin press', 0.08616118904028998), ('exile', 0.07929788936463275), ('dark journey', 0.06987636144847416)], [('werner erhard', 0.1795369498679913), ('erhard seminars training', 0.16480145218604672), ('werner h. erhard early life', 0.13706911033806715), ('various form', 0.12460609999240892), ('werner h. erhard', 0.11871858437518555), ('jack rosenberg', 0.11743710541577795), ('est', 0.09592574384482569), ('est successor course', 0.08993038485452409), ('self improvement technique', 0.0884413160885684), ('associates', 0.07381570658644077), ('account', 0.05574709561536831), ('exploration', 0.05019241076924477), ('foundation', 0.040177953057138734), ('book', 0.030993300554730353), ('forum', 0.01970276015597752)], [('former participant', 0.157146388962416), ('litigation', 0.138257645864032), ('controversy', 0.1251180305211911), ('rapid financial success', 0.11963591301838965), ('erhard', 0.11177694769152804), ('pressman', 0.09562702200694223), ('company', 0.05066091917093187), ('course', 0.04001515712152331)], [('60 minutes', 0.13070631401979182), ('erhard', 0.1284003059530494), ('member', 0.09928666251166995), ('cbs', 0.09895470030662337), ('march 3 1991', 0.09852930504889434), ('erhard family', 0.08929108493031913), ('allegation', 0.08728374011811274), ('erhard decision', 0.08475486222914307), ('march 3 1991 60 minutes', 0.07958773123045963), ('united states', 0.07258500654318663), ('impact', 0.04895196902269279), ('work', 0.03685236149682453)]]\n",
      "\n",
      "\n",
      "[[('player', 0.16378761950206297), ('controversy', 0.16149326763856592), ('betting aspect', 0.11772045186907706), ('cricket', 0.1122375853456592), ('number', 0.08774669495346814), ('game', 0.06230891900498937)], [('numerous player', 0.17591551455297413), ('other information', 0.16845261213271845), ('match', 0.14818207782928533), ('aspect', 0.12933526237838786), ('bookmaker', 0.11762344137663218)]]\n",
      "\n",
      "\n",
      "[[('crime', 0.20404205790212704), ('rape', 0.16134335188175059), ('domestic violence', 0.15851764463792856), ('gender target crime', 0.15120971756345317), ('legal proceeding', 0.10378892922321263), ('prosecution', 0.09635186903736284)], [('sir peter von hagenbach', 0.19743657702315737), ('peter von hagenbach', 0.18243723628972283), ('1474', 0.11766855523106734), ('rape', 0.09694463798734745), ('gender base target crime', 0.0914664515384116), ('early document prosecution', 0.07974959195363059), ('troop', 0.041262201413418784)], [('sir von hagenbach', 0.18651350127142174), ('rape', 0.1728686403013238), ('von hagenbach', 0.16121999225697148), ('trial', 0.05962949837006634), ('charge', 0.053156000082374234), ('war', 0.042150224715930884)], [('other crime', 0.14905691146046507), ('world war ii', 0.13306084946564053), ('tokyo tribunal)-', 0.11451459921590819), ('particularly rape', 0.10869302780068858), ('officer', 0.09540418304217692), ('international military tribunal', 0.09138643086056052), ('gender target crime', 0.08455702836715917), ('tokyo', 0.0802500998134933), ('humanity', 0.07172060469397076), ('far east', 0.06466438993176835)], [('rape', 0.18189293947005294), ('other war crime', 0.17897897774610172), ('various rape charge', 0.1332526347488591), ('reference', 0.10517782637547204), ('tokyo tribunal', 0.0869330010382247), ('charter', 0.059561549505054434)], [('other tribunal', 0.14281815198863382), ('other form', 0.14074011419118573), ('international criminal tribunal', 0.10682172013601565), ('more attention', 0.10573837075685374), ('rape', 0.10288209273368903), ('gender target crime', 0.10019839054142603), ('gender target violence', 0.10019839054142603), ('rwanda', 0.09237275869378798), ('icty', 0.08167786519372602), ('yugoslavia', 0.08167786519372601), ('former yugoslavia', 0.06789327920386003), ('ictr', 0.06082479828667477), ('situation', 0.05099043312423434), ('prosecution', 0.04450822205178756), ('statute', 0.04154303135441055), ('establishment', 0.030855863825216535)]]\n",
      "\n",
      "\n",
      "answer:  Badr Hari\n",
      "number_sentences:  40\n",
      "number_reduced_sentences:  8\n",
      "number of questions:  6\n",
      "number of questions with answer neither yes nor no:  6\n",
      "common_phrases_num_le2:  4\n",
      "extended:  3\n",
      "answer_in_reduced_context:  4\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2]\n",
      "ratio of reduced context:  0.2402849694166096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a7d0db955429909bec76924\n",
      "question:  The Dutch-Belgian television series that \"House of Anubis\" was based on first aired in what year?\n",
      "question_phrases_text:  ['first', 'anubis', 'house', 'dutch', 'dutch belgian television series', 'year']\n",
      "common_phrases:  ['house', 'first', 'anubis', 'dutch belgian television series', 'dutch', 'year']\n",
      "extended_phrases:  ['house', 'first', 'anubis', 'dutch belgian television series', '1 january 2011', 'show', 'dutch', 'year']\n",
      "paras_phrases\n",
      "[[('het huis anubis', 0.1975053284874585), ('mystery television series', 0.15439618468016997), ('anubis', 0.1445019169512091), ('dutch belgian television series', 0.12497903241579769), ('dutch', 0.12043341114828607), ('nickelodeon', 0.1193709141845915), ('house', 0.08494181624851174)], [('1 january 2011', 0.194313725786432), ('25 february 2011', 0.18929403433659708), ('hans bourlon', 0.1634524664994083), ('gert verhulst', 0.1609166966215812), ('1 january', 0.14987752892516887), ('25 february', 0.14215034244106972), ('nickelodeon', 0.11579602256000668), ('united states', 0.09230523492218351), ('united kingdom', 0.08566719031232382), ('series', 0.03079119126166932)], [('first', 0.19870928097494106), ('first series', 0.15858260011822153), ('first telenovela format series', 0.15108015323711893), ('united states', 0.11033463354579456), ('network', 0.08551043419462574), ('series', 0.08263187264184704)], [('1 january 2011', 0.26698130156975136), ('17 june 2013', 0.23749891556054822), ('1 january', 0.23639070780118254), ('17 june', 0.22433361038783023), ('show', 0.05262893154998362)]]\n",
      "\n",
      "\n",
      "[[('sesame street', 0.17472499631826854), ('philippine', 0.15839956968238122), ('pctv', 0.1572411708272131), ('philippine child television series', 0.1353932129293623), ('batibot', 0.10218756436896848)], [('1984', 0.25095481772180467), ('rpn', 0.21735766565082118), ('sesame', 0.16354006955611122)], [('sesame workshop', 0.19747965133171003), ('children television workshop', 0.14619978786210971), ('partnership', 0.07537783614444091)], [('sesame', 0.4714045207910317)], [('filipino', 0.168902199240097), ('batibot', 0.16466460729831606), ('1985', 0.154549627517732)], [('at least four television network', 0.30285854962988557), ('at least four', 0.2781744056611172), ('1998', 0.14132388055459083)], [('tv5', 0.17468678456075815), ('2010–2013', 0.1451613010005062), ('show', 0.11378234211574563)], [('series', 0.19355137532446443), ('2015', 0.15161648648983567), ('mobile app', 0.10581566703763971)]]\n",
      "\n",
      "\n",
      "[[('british german fantasy teen drama television series', 0.15691912957133086), ('german', 0.13791702512791798), ('british', 0.1312536416458898), ('young adult audience', 0.11775876513451432), ('wolfblood', 0.08751487262926172)], [('debbie moon', 0.2041241452319315), ('cbbc', 0.17518020447278193), ('co - production', 0.15220342285409058), ('zdf zdfe', 0.10621264833210367)], [('wolfblood', 0.16822201903901537), ('specie', 0.10688892575422933), ('television series', 0.09537292016194446), ('life', 0.088394210508695)], [('will', 0.1823759166841547), ('sense', 0.14874042537887605), ('human', 0.14729562775285182), ('creature', 0.1145755864754246), ('wolf', 0.1145755864754246)], [('full moon', 0.17451935592028778), ('new moon', 0.1582820350173096), ('moon', 0.13226992292847684), ('dark', 0.08050692701936064), ('transformation', 0.059389480178149635)], [('daily', 0.15303550261416346), ('daily life', 0.11860015456707293), ('television series', 0.08534950594533834), ('challenge', 0.08448796461392717), ('secret', 0.06660475714509877)], [('new character', 0.21898738264583412), ('overall television series', 0.16891707829033792), ('concept', 0.1688577649051327), ('interesting storyline', 0.10771471290464026), ('series', 0.08412570498041336)], [('five complete serie', 0.33511356453722757), ('five', 0.21726008945965164), ('date', 0.18200064648685815)], [('10 september 2012', 0.20889728155304244), ('22 october 2012', 0.20414891056697795), ('10 september', 0.17133264797673567), ('22 october', 0.16448854629680665), ('1 first', 0.16420050254235485), ('13 episode', 0.1419454537403047), ('13', 0.10926966123627799), ('series', 0.06284206579214287)], [('9 september 2013', 0.20455242765831072), ('21 october 2013', 0.19891467254632922), ('9 september', 0.16315392082251362), ('2 first', 0.157414884630099), ('21 october', 0.15476949934208864), ('13 episode', 0.14167366456922711), ('13', 0.11755271655232918), ('series', 0.06028041148908509)], [('15 september 2014', 0.20455242765831072), ('27 october 2014', 0.19891467254632922), ('15 september', 0.16315392082251362), ('3 first', 0.157414884630099), ('27 october', 0.15476949934208864), ('13 episode', 0.14167366456922711), ('13', 0.11755271655232918), ('series', 0.06028041148908509)], [('8 march 2016', 0.20316382197571412), ('13 april 2016', 0.19152147835039288), ('8 march', 0.16615898839111273), ('4 first', 0.15866848213615314), ('12 episode', 0.15233397041927266), ('13 april', 0.14907706487085765), ('12', 0.12663017647683097), ('time', 0.06485129365206302), ('series', 0.060706206724878385)], [('27 february 2017', 0.194595357385617), ('1 may 2017', 0.18950737408829388), ('6 june 2016', 0.17595413129601323), ('27 february', 0.1547167620645627), ('6 june', 0.15348499754018816), ('1 may', 0.14712943772591774), ('10 episode', 0.12981084111543134), ('10', 0.10792034565163978), ('fifth', 0.1003621667691729), ('fifth season', 0.056900000209461926)]]\n",
      "\n",
      "\n",
      "[[('house', 0.15090746902213498), ('episode list', 0.11487941030299827), ('anubis', 0.11160672241966105), ('nickelodeon', 0.11072327580417192), ('mystery comedy drama television series', 0.10620290825726003), ('article', 0.059188402686710266)]]\n",
      "\n",
      "\n",
      "[[('majisuka gakuen', 0.30368238303033623), ('マジすか学園', 0.28547632672935286)], [('tv tokyo', 0.1849494756328479), ('majisuka academy', 0.17677669529663687), ('first', 0.14497141308669226), ('japanese television drama series', 0.14467426527963576), ('akb48', 0.12076683938448125), ('japanese', 0.11683358756068792)], [('majisuka gakuen 2', 0.20267800613611298), ('majisuka gakuen', 0.1822037591786818), ('july', 0.12641492189484982), ('second', 0.11729072133646985), ('july 13 2012', 0.11299555387881453), ('3rd season', 0.08823874192336749), ('following year', 0.08823874192336749)], [('ntv', 0.162198154295855), ('2015', 0.1586971793005528), ('january', 0.1575224637504962), ('january 19 2015', 0.14804531864947562), ('4th season', 0.11327215030533619), ('series', 0.08582385831152799)], [('full season', 0.1263487458152286), ('various scene', 0.10660035817780522), ('many problem', 0.10660035817780522), ('only first two episode', 0.10531897102998339), ('first', 0.10020675233883898), ('august 24', 0.09290928529713527), ('two', 0.08487668979347501), ('violence', 0.08206099398622183), ('hulu', 0.07858378907299697), ('august', 0.07712423289895526), ('5th season', 0.07687233494031866), ('ntv', 0.07339677082854736), ('usa', 0.07261138255279498), ('tv', 0.0675253081313818), ('first time', 0.06741255271982173), ('internet', 0.0649983756437838), ('japan', 0.05701627855231526), ('streaming site', 0.0560363130291734), ('same year', 0.05408177022800707), ('usa japan', 0.050047950906094416)], [('majisuka gakuen', 0.17065806909465894), ('kisarazu rantōhen', 0.15732919388188818), ('木更津乱闘編', 0.10145652765751997), ('マジすか学園0 木更津乱闘編', 0.09285079585170145), ('4th 5th season', 0.08578624488876092), ('special spin off', 0.06897699057546841), ('series', 0.06514269081206264)], [('brawl', 0.14704034255721), ('first', 0.1432596516266204), ('hkt48', 0.12543517113369684), ('kishidan', 0.12072075364573405), ('kisarazu', 0.10682598491262033), ('rock group', 0.10329335529436627), ('main cast', 0.08870558656304879), ('majisuka academy', 0.06900655593423542), ('story', 0.05665303375398424), ('collaboration', 0.04854696964254099)], [('25:05 jst', 0.2233724415403746), ('november', 0.17195218567050563), ('25:05', 0.17195218567050563), ('ntv', 0.1705462109986461), ('november 28 2015', 0.16076700775087155), ('hour', 0.024615501138743005)]]\n",
      "\n",
      "\n",
      "[[('graduation day', 0.1404878717372541), ('buffy', 0.12429349694308624), ('third', 0.1054107338623619), ('wb television network third season', 0.10349400057386128), ('buffy vampire slayer', 0.10330704529588731), ('drama television series', 0.10050720811377498), ('twenty second', 0.09401240345531181), ('season finale', 0.08178059617295831), ('wb television network', 0.07878933413939243), ('vampire slayer', 0.07851989928560153), ('twenty first twenty second episode', 0.07837911754355045), ('twenty first', 0.0562463451976348)], [('series creator joss whedon', 0.32159239866199585), ('joss whedon', 0.24532998867716999)], [('first', 0.1902174004671611), ('part', 0.15419629086955927), ('may', 0.14032677810422395), ('july', 0.14032677810422395), ('may 18 1999', 0.13246118251872196), ('july 13 1999', 0.13246118251872196)], [('columbine high school', 0.1758898752076759), ('one month', 0.15411062321275976), ('columbine high school shooting', 0.13256018669298889), ('may', 0.12338206860191608), ('may 25 1999', 0.10961992948311014), ('second', 0.08837148504246117), ('second part', 0.05893548218159646), ('episode content', 0.056312910147109214), ('occurrence', 0.05382285199739342)]]\n",
      "\n",
      "\n",
      "[[('steve moncuse', 0.14869288115206034), ('fish police', 0.14297190839296994), ('comic book series', 0.1400858679907019), ('animate television series', 0.1394694215709475), ('hanna barbera', 0.09662824296878422)], [('six episode', 0.230002765799072), ('one season', 0.18750167730584355), ('six', 0.17679117994568444), ('cbs', 0.16747741356873946), ('1992', 0.15853896814140106), ('first', 0.14234700932576067)], [('three episode', 0.20651515173087598), ('three', 0.14819766843156185), ('television rating', 0.10205061146643225), ('february', 0.09854913588930886), ('year', 0.08144016464725318), ('february year', 0.07314948039917252), ('show', 0.07074796365761762)], [('european syndication', 0.16804657498613979), ('three', 0.14679659317112437), ('european', 0.14024078471213278), ('remain three episode', 0.09988352057196347), ('entire series', 0.09917586077082137), ('united states', 0.08613983319741572)], [('most other animate hanna barbara', 0.17563598355198243), ('decidedly more mature tone', 0.16008442506543014), ('hanna barbara', 0.11369094791430975), ('show', 0.03470581840938109)], [('case', 0.20202745328735852), ('mild profanity', 0.1985684772048182), ('innuendo', 0.19519122568554292), ('episode', 0.09068234528079994)]]\n",
      "\n",
      "\n",
      "[[('nathalia norah ramos cohen', 0.19647568950356856), ('u.s. citizenship', 0.1569761026380836), ('u.s.', 0.12084026015258116), ('spanish', 0.10962019062539644), ('australian', 0.10962019062539644), ('july 3 1992', 0.10853683940986508), ('spanish australian actress', 0.08240469671411611)], [('nina martin', 0.14470424608623003), ('2011 nickelodeon television series', 0.12297492799330119), ('2011', 0.11743909905977609), ('yasmin', 0.11157796840305537), ('2007', 0.11104790620381329), ('house', 0.11058412071158842), ('nickelodeon', 0.10355333490782911), ('2013 film', 0.09699339496625817), ('2007 film', 0.0954278287433426), ('ramos', 0.08685209839727301), ('anubis', 0.072244212041125), ('house anubis', 0.07160724289964851), ('portrayal', 0.06008098625744931), ('jill 2013 film damned', 0.04663333299869969), ('damned', 0.0322957330323736)]]\n",
      "\n",
      "\n",
      "[[('het huis anubis', 0.18532042544215543), ('studio 100', 0.15947919157426138), ('anubis', 0.1427382729980985), ('studio', 0.1298778293724758), ('nickelodeon', 0.12100130125399879), ('netherlands', 0.1191380699333366), ('belgian', 0.09631488050876708), ('belgian dutch child television drama', 0.09180327958575733), ('flanders', 0.09008954777500418), ('house anubis', 0.0673572803534773), ('house', 0.03411533305377601)], [('september 2006', 0.20040624870830595), ('september', 0.1549915891397674), ('december', 0.1532543283763301), ('december 4 2009', 0.13651946706639267), ('first', 0.13017732346576574), ('last episode', 0.10814547896201114)], [('first two season', 0.14681114340138016), ('benelux', 0.12262676218990305), ('huge success', 0.12197421377431103), ('show low budget', 0.1178508776161769), ('show', 0.06829552319596525)]]\n",
      "\n",
      "\n",
      "[[('het huis anubis', 0.18755813105786664), ('belgian broadcaster studio', 0.1653863374575119), ('das haus anubis', 0.15952403657056904), ('studio 100', 0.14212612511863404), ('belgian', 0.1195757686199055), ('first', 0.10059883981444617), ('nickelodeon', 0.09853454069590956), ('television program', 0.0793548349706708), ('first remake', 0.07719521319601319), ('belgium', 0.07698850048925124), ('netherlands', 0.05254849968271546)], [('house', 0.21014015771349737), ('anubis', 0.19220053218426814), ('english', 0.16657377325868078), ('2011', 0.14428929812575658), ('english remake', 0.0944384526403137)], [('first german daily soap opera', 0.13776384949529955), ('old child', 0.12323004794579658), ('daily', 0.1217271461724433), ('nickelodeon', 0.12009174709889071), ('german', 0.11037047652817686), ('house', 0.10900348526284812), ('seven', 0.10317522107482005), ('seven figure production budget', 0.09851449167683389), ('first', 0.09772772403810484), ('one', 0.08994324651926475)], [('music channel viva', 0.17576014975264445), ('29 september 2009', 0.15402414949634458), ('4 may', 0.14521535083508824), ('may 2012', 0.13704820952269653), ('season 1', 0.1260456813845546), ('29 september', 0.1258669865669292), ('daily', 0.10924305373646742), ('nick', 0.10606212579825071), ('child channel', 0.09748339004448345), ('season', 0.08848248079045787), ('viva', 0.08759626023235752), ('weekend', 0.08251413993019248), ('afternoon', 0.0583303505840608), ('show', 0.048921692169563796)]]\n",
      "\n",
      "\n",
      "answer:  2006\n",
      "number_sentences:  53\n",
      "number_reduced_sentences:  21\n",
      "number of questions:  7\n",
      "number of questions with answer neither yes nor no:  7\n",
      "common_phrases_num_le2:  5\n",
      "extended:  4\n",
      "answer_in_reduced_context:  5\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965]\n",
      "ratio of reduced context:  0.2625623187991425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a89372855429951533612e6\n",
      "question:  What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "question_phrases_text:  ['liqui moly bathurst 12 hour', '12 hour', '2013 liqui moly bathurst', '2013', 'track', 'length']\n",
      "common_phrases:  ['2013', '12 hour', 'liqui moly bathurst 12 hour', '2013 liqui moly bathurst']\n",
      "extended_phrases:  ['12 hour', 'liqui moly bathurst 12 hour', '2013', '2013 liqui moly bathurst', 'length', 'track']\n",
      "paras_phrases\n",
      "[[('new south wales', 0.2038490274040512), ('mount panorama circuit', 0.18830893418900577), ('bathurst', 0.14661428745225033), ('motor racing track', 0.13244495410295906), ('australia', 0.11246190214576796)], [('bathurst 1000', 0.15127272905488887), ('mount panorama', 0.1428154090208319), ('bathurst', 0.13121304755052976), ('12 hour', 0.12928039050364698), ('bathurst 12 hour event', 0.11875923940326001), ('bathurst 1000 motor race', 0.11875923940326), ('wahluu', 0.10445778816307846), ('dual official name', 0.10319882831121277), ('october', 0.0755582705351159), ('february', 0.0755582705351159), ('hill', 0.052522345203539975), ('home', 0.04467737320986841)], [('normal speed restriction', 0.16186982670443473), ('6.213 km', 0.1268349749500351), ('many residence', 0.12391645880032506), ('6.213 km long track', 0.08627403786965576), ('racing event', 0.07989931154642889), ('street circuit', 0.07190011067157658), ('public road', 0.06886264927749114), ('circuit', 0.053937241869255914)]]\n",
      "\n",
      "\n",
      "[[('2016 intercontinental gt challenge', 0.22480404546281), ('intercontinental gt challenge', 0.20892286925115605), ('first season', 0.11543549427924298)], [('liqui moly bathurst 12 hour', 0.19998194910945657), ('liqui moly bathurst', 0.16212707797518677), ('three round', 0.13051709970689285), ('7 february', 0.12434668574742361), ('sepang 12 hour', 0.12293057203361876), ('10 december', 0.12018131568977791), ('three', 0.10047211019949844), ('6 hour', 0.0919869669793654), ('americas', 0.08446559757312691), ('season', 0.0669283005084552), ('cancellation', 0.039570761946411716)]]\n",
      "\n",
      "\n",
      "[[('12 hour', 0.1819866289997907), ('bathurst', 0.14041094946777422), ('bathurst 12 hour', 0.1314368543447419), ('gt', 0.12096922073471933), ('sponsorship reason', 0.10794532417115595), ('liqui moly bathurst', 0.10737549723801838), ('gt production car', 0.10294332617818688), ('february', 0.09912302377646094), ('mount panorama circuit', 0.08989839466131036), ('australia', 0.08864644618423104), ('endurance race', 0.06929086632026839), ('february year', 0.06768454801457804)], [('eastern creek raceway', 0.19612401458286804), ('series production car', 0.1887067684847208), ('1991', 0.14072212813461002), ('sydney eastern creek raceway', 0.14051773053621341), ('1995', 0.13350537671143636), ('sydney', 0.1252406408314035), ('series', 0.12240152459013466), ('race', 0.041154613414835686)], [('other gt car', 0.22105203958271372), ('production car', 0.19213734258902476), ('gt', 0.1438341975125101), ('gt3', 0.14319843929950873), ('2007', 0.12411678033424386), ('2011', 0.10681863081854834), ('new class', 0.0970349424485792), ('race', 0.03863686070188132)], [('unprecedented domestic international exposure', 0.22444361794113027), ('event', 0.07080806549152095)], [('eastern creek raceway', 0.19983717628978703), ('mount panorama', 0.17947140800048358), ('sixteen race', 0.16904610087964603), ('fifteen', 0.15712940173414688), ('place', 0.13884606122972232), ('sixteen', 0.1184554832782019)]]\n",
      "\n",
      "\n",
      "[[('intercontinental gt challenge', 0.28150811122160807), ('2018 intercontinental gt challenge', 0.19407113687010874), ('third season', 0.1044286615515285), ('2018', 0.07822611170636892)], [('four round', 0.1501262761980032), ('21 october', 0.13083845580777412), ('4 february', 0.13082759012359307), ('four', 0.12127211053377288), ('california 8 hour', 0.1066587100478405), ('liqui moly bathurst', 0.10218347896207257), ('season', 0.03723436907239936)]]\n",
      "\n",
      "\n",
      "[[('liqui moly bathurst 12 hour', 0.18147428559210954), ('gt4 car', 0.17272491347386076), ('group 3e series production cars', 0.16959225690185145), ('gt3 car', 0.16775411639311055), ('liqui moly bathurst', 0.16398258596092385), ('group 3e', 0.14264613409021568), ('12 hour', 0.13753716333412958), ('gt tour car class', 0.1210742067564756), ('gt4', 0.09889729907865615), ('gt', 0.09580419713580914), ('2016', 0.09162398108944089), ('endurance race', 0.06725842507147606), ('variety', 0.04614863564863265)], [('new south wales', 0.1739326538159214), ('7 february 2016', 0.16653671867449812), ('bathurst', 0.16051996488370918), ('7 february', 0.15481878281007874), ('australia', 0.1340383772309537), ('bathurst 12 hour', 0.11881008794414442), ('mount panorama circuit', 0.11611196006950146), ('fourteenth', 0.08671365477566624), ('fourteenth running', 0.07734273609557583), ('event', 0.01748643278588075)], [('2016 intercontinental gt challenge series', 0.20266467632498725), ('opening round', 0.12288845352266826)]]\n",
      "\n",
      "\n",
      "[[('intercontinental gt challenge', 0.30728332624304583), ('2017 intercontinental gt challenge', 0.20941668017454695), ('2017', 0.14950115741858588), ('second season', 0.10592836986896641)], [('four round', 0.15768575294327636), ('5 february', 0.13681566465931697), ('10 december', 0.12880011149188328), ('sepang 12 hour', 0.12340899299839662), ('four', 0.12138654921222589), ('liqui moly bathurst', 0.10805706007861579), ('season', 0.041229954418086356)], [('defend driver champion', 0.1498437520580755), ('defend manufacturer champion', 0.1498437520580755), ('audi', 0.1485582049379086), ('laurens vanthoor', 0.1136076689925821)]]\n",
      "\n",
      "\n",
      "[[('24 hour car', 0.19077491045321146), ('gt4 car', 0.1736464738454816), ('liqui moly bathurst 12 hour', 0.17362480378400785), ('gt3 car', 0.1695794285450707), ('group 3e series production cars', 0.16359706554154912), ('dubai 24 hour', 0.1548926058293327), ('12 hour', 0.1415572896435222), ('group 3e', 0.13018298062847686), ('gt tour car class', 0.11929015937135647), ('2013 liqui moly bathurst', 0.10427627045874274), ('dubai', 0.1005978201132798), ('gt4', 0.09159810306476793), ('gt', 0.08962653210650198), ('2013', 0.0842499484471729), ('endurance race', 0.06205078389165282), ('variety', 0.043288499735523345)], [('new south wales', 0.1739326538159214), ('10 february 2013', 0.16653671867449812), ('bathurst', 0.16051996488370918), ('10 february', 0.15481878281007874), ('australia', 0.1340383772309537), ('bathurst 12 hour', 0.11881008794414442), ('mount panorama circuit', 0.11611196006950146), ('eleventh', 0.08671365477566624), ('eleventh running', 0.07734273609557583), ('event', 0.01748643278588075)], [('australian gt championship', 0.22491914476205818), ('2013 australian gt championship', 0.16953155655621635), ('opening round', 0.11859979310896165), ('2013', 0.09236173992236524), ('race', 0.05080742196860357)], [('first hour', 0.11883428719989142), ('only hour', 0.11295915753501704), ('australian gt championship', 0.11154009141484689), ('car', 0.08847938260148511), ('endurance race', 0.07865026212523665)]]\n",
      "\n",
      "\n",
      "[[('liqui moly bathurst 12 hour', 0.18147428559210954), ('gt4 car', 0.17272491347386076), ('group 3e series production cars', 0.16959225690185145), ('gt3 car', 0.16775411639311055), ('group 3e', 0.14264613409021568), ('12 hour', 0.13753716333412958), ('gt tour car class', 0.1210742067564756), ('2015 liqui moly bathurst', 0.11432107270461281), ('gt4', 0.09889729907865615), ('gt', 0.09580419713580914), ('2015', 0.09162398108944089), ('endurance race', 0.06725842507147606), ('variety', 0.04614863564863265)], [('new south wales', 0.1739326538159214), ('8 february 2015', 0.16653671867449812), ('bathurst', 0.16051996488370918), ('8 february', 0.15481878281007874), ('australia', 0.1340383772309537), ('bathurst 12 hour', 0.11881008794414442), ('mount panorama circuit', 0.11611196006950146), ('thirteenth', 0.08671365477566624), ('thirteenth running', 0.07734273609557583), ('event', 0.01748643278588075)]]\n",
      "\n",
      "\n",
      "[[('liqui moly bathurst', 0.15579257679734765), ('2017 liqui moly bathurst 12 hour endurance race', 0.14392818218576442), ('car class', 0.13979170365943086), ('new south wales', 0.1297654278174075), ('february 2017', 0.12650957494343643), ('bathurst', 0.12566739312771968), ('5 february', 0.11503861194891205), ('2017', 0.11012814096828767), ('australia', 0.10442940883871556), ('hour', 0.09920826520891601), ('gt3 gt4 car', 0.09798115740101057), ('gt3', 0.0971970676912013), ('gt', 0.09396697499189838), ('gt4', 0.08680483954831693), ('mount panorama circuit', 0.08133844430063825)], [('2017 intercontinental gt challenge series', 0.1552955988629032), ('bathurst 12 hour', 0.12923018730491925), ('opening round', 0.09400308169408152), ('15th', 0.09362076352294686)], [('australian', 0.1798365458255769), ('australian tourist trophy', 0.1598115985958532), ('first', 0.13131667154316862), ('first time', 0.11878750999117745), ('winner', 0.08891366495259663), ('race', 0.08479417801134528)]]\n",
      "\n",
      "\n",
      "[[('liqui moly bathurst 12 hour', 0.18147428559210954), ('gt4 car', 0.17272491347386076), ('group 3e series production cars', 0.16959225690185145), ('gt3 car', 0.16775411639311055), ('group 3e', 0.14264613409021568), ('12 hour', 0.13753716333412958), ('gt tour car class', 0.1210742067564756), ('2014 liqui moly bathurst', 0.11432107270461281), ('gt4', 0.09889729907865615), ('gt', 0.09580419713580914), ('2014', 0.09162398108944089), ('endurance race', 0.06725842507147606), ('variety', 0.04614863564863265)], [('new south wales', 0.1739326538159214), ('9 february 2014', 0.16653671867449812), ('bathurst', 0.16051996488370918), ('9 february', 0.15481878281007874), ('australia', 0.1340383772309537), ('bathurst 12 hour', 0.11881008794414442), ('mount panorama circuit', 0.11611196006950146), ('twelfth', 0.08671365477566624), ('twelfth running', 0.07734273609557583), ('event', 0.01748643278588075)]]\n",
      "\n",
      "\n",
      "answer:  6.213 km long\n",
      "number_sentences:  29\n",
      "number_reduced_sentences:  8\n",
      "number of questions:  8\n",
      "number of questions with answer neither yes nor no:  8\n",
      "common_phrases_num_le2:  6\n",
      "extended:  4\n",
      "answer_in_reduced_context:  5\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724]\n",
      "ratio of reduced context:  0.26422478756993933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5abd90545542996e802b47d7\n",
      "question:  Fast Cars, Danger, Fire and Knives includes guest appearances from which hip hop record executive?\n",
      "question_phrases_text:  ['guest appearance', 'fast cars', 'knives', 'hip hop record executive', 'danger', 'fire']\n",
      "common_phrases:  ['fire', 'danger', 'fast cars', 'knives', 'guest appearance']\n",
      "extended_phrases:  ['fast cars', 'fire', 'knives', 'danger', 'guest appearance', 'american', 'hip hop record executive']\n",
      "paras_phrases\n",
      "[[('american hip hop artist sims', 0.2329094234440149), ('minneapolis indie hip hop collective doomtree', 0.22960394658570776), ('american', 0.12915743702000426), ('first', 0.11996920815291386), ('sims', 0.11352578364461564), ('paris', 0.11323019514857402), ('minneapolis', 0.11320559594050417), ('first studio album', 0.110800262199582), ('doomtree', 0.099684020292873), ('lights', 0.08758469279549337), ('lights paris', 0.07760273497161976), ('member', 0.053911836827566444)], [('guest appearance', 0.16251926629872065), ('doomtree records', 0.1608198748300871), ('toki wright', 0.15642129501297167), ('crescent moon', 0.15338504769021943), ('p.o.s', 0.1389904806241396), ('july 28 2005', 0.11786002826957616), ('other', 0.0937473751623481)], [('false hopes four', 0.17692384864016464), ('five song', 0.1607955603753567), ('june 2015', 0.14515170222780646), ('vinyl', 0.13226479716425732), ('five', 0.13108590968007822), ('four', 0.12946541041995452), ('sim', 0.11889546116245056), ('june', 0.11173783247274195), ('four remixe', 0.09938746923467819), ('album', 0.038118703264983726)]]\n",
      "\n",
      "\n",
      "[[('el producto', 0.13904687569202062), ('record producer', 0.13755551121387494), ('record executive', 0.12276724025787675), ('american hip hop recording artist', 0.12255370532880892), ('jaime meline', 0.1199935487136336), ('american', 0.08998200947644819), ('el p', 0.08695092849920877), ('stage name', 0.07710316751822521), ('march 2 1975', 0.07435155492629272)], [('alternative hip hop', 0.13956729287382072), ('several notable rapper', 0.1391702407927794), ('company flow', 0.13243539659015044), ('aesop rock', 0.12787043108615403), ('mr. lif', 0.1191072217588624), ('lif', 0.09430693909448973), ('cage', 0.08751073241597025), ('more two decade', 0.0846870051921368), ('major driving force', 0.08335194533127852), ('other', 0.06735859004541303), ('el p', 0.06693943197853713), ('member', 0.05532246021842237)]]\n",
      "\n",
      "\n",
      "[[('american hip hop duo', 0.19134399105494768), ('duck down music inc', 0.1729197037562259), ('american', 0.12575097381887404), ('december', 0.10766706967730595), ('december 3 2013', 0.10064824909700207), ('debut ep', 0.08062134255517643), ('smif n wessun', 0.071962793728534)], [('junior reid', 0.15760804911658766), ('guest appearance', 0.15685973468493786), ('beatnick', 0.13110735740635537), ('reid', 0.11340143098396674), ('reggae hip hop', 0.10849974938411702), ('jr.', 0.0955390505245613), ('k salaam', 0.08467883572421811), ('6-song ep', 0.08464501107610094), ('beatnick k salaam', 0.08342724317719499), ('blend', 0.05669514316661321)], [('dj full factor', 0.28284271247461906), ('jahdan blakkamoore', 0.257638781372262), ('kelly', 0.18011439437577453)], [('dancehall icon junior reid', 0.2306974015274815), ('solid ground', 0.17490102152219378), ('one', 0.1283540253278503), ('one single solid ground', 0.11310489757164566), ('ep', 0.03870312940986705)]]\n",
      "\n",
      "\n",
      "[[('step brothers', 0.16469085849830767), ('lord steppington', 0.13084856617280005), ('california base hip hop duo step brothers rapper producer', 0.12798345247205092), ('california', 0.1252608867213146), ('steppington', 0.11303981605726317), ('debut studio album', 0.11137982474463282), ('evidence', 0.08914139315912703), ('alchemist', 0.06229044620300798), ('alchemist evidence', 0.05911231467520493)], [('rhymesayers entertainment', 0.2073761929644596), ('january', 0.188454133387496), ('january 21 2014', 0.18559880624489639), ('album', 0.048013495585856235)], [('actor scott caan', 0.13165087735116307), ('action bronson', 0.12974770092816096), ('roc marciano', 0.12658792784500297), ('domo genesis', 0.12639892274155268), ('alchemist', 0.12321513212634447), ('guest appearance', 0.11962059071687225), ('scott caan', 0.11118905112779175), ('alchemist old group', 0.09698224128787979), ('blu', 0.09680475655291867), ('fashawn', 0.0895496964154779), ('alchemist evidence', 0.07777191065969714), ('evidence', 0.07348218028155015), ('rakaa', 0.06885704582290829), ('style p', 0.041700726415879116), ('whooliganz', 0.04154761731851947), ('record', 0.030202306974081862)]]\n",
      "\n",
      "\n",
      "[[('west coast hip hop crew tha alkaholiks', 0.1712220842460004), ('rapper tash', 0.158112926022922), ('tha alkaholiks', 0.15019134873993586), ('control freek', 0.1399412823523771), ('second', 0.13192946217942586), ('second solo effort', 0.12526832266857943), ('tash', 0.11985732346324458), ('west coast', 0.09522233110297751)], [('ten year', 0.1820178210081955), ('rap life', 0.16947152122875542), ('tash first well receive solo album rap life', 0.165644655331198), ('tash', 0.14107673696802356), ('first', 0.12413996315145094), ('album', 0.06879569879585785)], [('amalgam digital', 0.30368238303033623), ('2009', 0.2854763267293529)], [('guest appearance', 0.13948832923386434), ('guest spot', 0.13853751673043888), ('goodie mob', 0.13075339141003983), ('cypress hill', 0.1267824678497099), ('tha alkaholiks', 0.1241943201513045), ('tash', 0.10132416045620925), ('addition', 0.10086349394376333), ('del funky homosapien', 0.09187244899354893), ('tash group', 0.07331209208448347), ('other', 0.06957097169248178)]]\n",
      "\n",
      "\n",
      "[[('new york city', 0.19208567253626507), ('south bronx', 0.17550475885596364), ('hip hop', 0.10231289325630372), ('subculture art movement', 0.08859462701104304), ('late 1970', 0.08198495973594903)], [('hip hop music', 0.20631245811152202), ('hip hop culture', 0.19467308770447705), ('hip hop', 0.16014757324265372), ('only four element', 0.14659829879982195), ('nine distinct element', 0.14514350942194285), ('only four', 0.1143650440167069), ('expressive realm', 0.0997159398719265), ('beatboxing', 0.0901692633315735), ('nine', 0.08040674237123539), ('breaking', 0.06848783378600201), ('people', 0.06414000991100918), ('expression', 0.04324325283157908)], [('hip hop culture', 0.14694844490000666), ('hip hop', 0.14347678826040014), ('record player', 0.0949759557593417), ('dj mixer', 0.08957790999923972), ('music', 0.08236363243012595), ('zulu nation', 0.07940273455712014), ('b', 0.07442205904206402), ('orality', 0.07066340170640385), ('mcing', 0.07006537905797042), ('bambaataa', 0.059191336091272174), ('aural sound music creation', 0.05606367432011544), ('year early', 0.0521640530957301), ('afrika bambaataa', 0.04088151802839978), ('graffiti', 0.0408612723697248), ('pillar', 0.03761700891739288), ('term', 0.03050928655707757)], [('visual art', 0.1889822365046136)], [('hip hop culture', 0.21414122978191785), ('hip hop fashion', 0.2103779093041129), ('hip hop language', 0.20987192152774847), ('hip hop subculture art movement', 0.1524305167778201), ('style', 0.12901420424109017), ('street entrepreneurship', 0.12397444695172437), ('historical knowledge', 0.11236841403184872), ('percussive vocal style', 0.09871850312445238), ('beatboxing', 0.08384174642577552), ('four', 0.0760802189148664), ('movement', 0.060866812735363894), ('other element', 0.06004902074694235), ('other', 0.05891011073554145)]]\n",
      "\n",
      "\n",
      "[[('american hip hop artist aesop rock', 0.2439103220267142), ('aesop rock', 0.166823176080204), ('fast cars', 0.16515240364861328), ('danger', 0.15164763895947983), ('american', 0.138582694874893), ('fire', 0.1234814557805696), ('knives', 0.11836074429379091), ('ep', 0.06867487135977253)], [('one track', 0.15336657185298486), ('three track', 0.15318651145321635), ('definitive jux', 0.14005839015940394), ('aesop rock', 0.11901301901533289), ('february', 0.11764981344567711), ('rob sonic', 0.11521473782215605), ('blockhead', 0.10560060418674119), ('definitive jux label', 0.10475543917948507), ('february 22 2005', 0.10137466909306078), ('four', 0.095148582429846), ('one', 0.09427501828322611), ('three', 0.09392741419107715), ('record', 0.04443917335621907)], [('definitive jux', 0.1636138810455131), ('camu tao', 0.15284226727716613), ('aesop rock', 0.1473704947972173), ('guest appearance', 0.14644665207928526), ('s.a. smash definitive jux label head', 0.14485286739173758), ('metro', 0.1219725758012273), ('el p.', 0.08765314158255662), ('vocal', 0.04311549821131705)], [('dj big wiz', 0.32154695007993855), ('scratch', 0.05780267999665161)]]\n",
      "\n",
      "\n",
      "[[('american hip hop recording artist ab soul', 0.18878686486806368), ('american', 0.1516468867426213), ('longterm mentality', 0.14824236847115818), ('debut studio album', 0.12737003048090184), ('ab soul', 0.09244927839366046)], [('top dawg entertainment', 0.16940949125304713), ('digital retailer', 0.1508487249602442), ('april', 0.1184240618292823), ('tde', 0.11513657639111069), ('april 5 2011', 0.11058144081531021), ('ab soul debut retail release', 0.10386200740014194), ('ab soul', 0.0625100106651488)], [('american hip hop record producer', 0.1376047463632744), ('alexis carrington', 0.10945954338262776), ('guest appearance', 0.10893751019483436), ('schoolboy q', 0.10352544793277357), ('jhené aiko', 0.10252826906613695), ('kendrick lamar', 0.0991902417274888), ('tae beast', 0.09821447019293475), ('alori joh', 0.097874892991851), ('tommy black', 0.09449759098328925), ('pat brown', 0.09409762709743016), ('kid', 0.0891970444358639), ('punch', 0.08342006102112026), ('context', 0.0793292820249619), ('bj', 0.07846406047585444), ('american', 0.0772161270208525), ('javonté', 0.07719937959211376), ('ayiro', 0.07460831959480459), ('aayhasis', 0.06753612668631881), ('sounwave', 0.06645751068685114), ('murs', 0.06583297200392868), ('chicago kid', 0.0642272961648493), ('ayiro sounwave aayhasis context', 0.049241242697666145), ('production', 0.030895330602623457), ('album', 0.02713436445185597)], [('music critic', 0.21561066531426237), ('album', 0.10006966366500977), ('release', 0.06462658444218514)]]\n",
      "\n",
      "\n",
      "[[('hip hop', 0.23822753934014196), ('abstract hip hop', 0.2381555887899074), ('traditional hip hop music', 0.23744938433132093), ('experimental hip hop', 0.23064068522373457), ('structural element', 0.15403434398952762), ('genre', 0.04314965201383969)], [('big dada', 0.16478611638741367), ('definitive jux', 0.16337329460394964), ('ninja tune', 0.14538304620810472), ('notable experimental hip hop record label', 0.1303247796205807), ('anticon', 0.12724140642616913)], [('most experimental hip hop', 0.19380073030935868), ('acoustic element', 0.16271381461875822), ('turntablism', 0.12334829109018308), ('artist', 0.06547296020363812), ('music', 0.05942928104362373)]]\n",
      "\n",
      "\n",
      "[[('new vocalist', 0.1812575638093659), ('alyson avenue', 0.17903352682446924), ('swedish aor rock band alyson avenue', 0.17429161226894713), ('arabella vitanc', 0.15292143669923577), ('swedish', 0.1398088369426756), ('third', 0.1324722009912783), ('third album', 0.0987266718021946), ('change', 0.08681230397868679)], [('alyson avenue', 0.24610254038562432), ('avenue', 0.22402483352150293), ('third', 0.19616688323587012), ('change', 0.1728832125187542), ('third album', 0.14156183819217283), ('allies', 0.1152981464855811)], [('rob marcello', 0.10030190947441714), ('mike andersson', 0.09846366499624007), ('chris laney', 0.09611979868613496), ('guest appearance', 0.09311302528834794), ('tommy stråhle', 0.09238303803842363), ('anette olzon', 0.09199730294275393), ('crazy lixx', 0.09178844954629262), ('street talk', 0.09028696858461109), ('brian robertson', 0.08292912687594277), ('cloudscape', 0.08254637575538663), ('fredrik bergh', 0.0825117448840088), ('michael bormann', 0.08138327423306144), ('planet alliance', 0.0804529631897131), ('ex alyson avenue', 0.07962968839207071), ('h.e.a.t.', 0.0773203032756943), ('bloodbound', 0.07417325512357446), ('ex nightwish', 0.07046592063734651), ('biss', 0.05763960846116632), ('marcello vestry', 0.05729126357114323), ('band member', 0.056738435520154805), ('record', 0.02209704715199343)]]\n",
      "\n",
      "\n",
      "answer:  Jaime Meline\n",
      "number_sentences:  35\n",
      "number_reduced_sentences:  12\n",
      "number of questions:  9\n",
      "number of questions with answer neither yes nor no:  9\n",
      "common_phrases_num_le2:  7\n",
      "extended:  5\n",
      "answer_in_reduced_context:  6\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286]\n",
      "ratio of reduced context:  0.2729617159351842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5aba66c855429939ce03dcdb\n",
      "question:  Gunmen from Laredo starred which narrator of \"Frontier\"?\n",
      "question_phrases_text:  ['laredo', 'gunman', 'frontier']\n",
      "common_phrases:  ['laredo', 'frontier', 'gunman']\n",
      "extended_phrases:  ['laredo', 'frontier', 'gunman', 'robert knapp', 'early sunday']\n",
      "paras_phrases\n",
      "[[('louis stevens', 0.15101253433246847), ('december 25 1896', 0.12815486567808204), ('september', 0.12718095347533298), ('september 29 1963', 0.11340362890112128), ('silent sound film era', 0.10956786311797262), ('american', 0.09503146729414369), ('american screenwriter', 0.08515947829079606), ('december', 0.0755906805250667)], [('christmas day 1896', 0.16113422642327047), ('christmas day', 0.14596002291101146), ('jane grogan', 0.13693063937629152), ('1920', 0.107577631336306), ('riga', 0.10282183260644384), ('latvia', 0.09990750417418437), ('stevens', 0.09802667935021726), ('film industry', 0.09761939080859483), ('silent film', 0.09370987592360307), ('folly', 0.07343935373071703), ('world', 0.049661090912883066), ('world folly', 0.04770804336731626)], [('several film short', 0.2033416739543845), ('two television series', 0.18375990374495108), ('two', 0.14125303902335973), ('40', 0.12872947760077388), ('30-year', 0.11759761963000973), ('40 screenplay', 0.09718104970088322), ('30-year career', 0.06667158349589428)], [('bela lugosi', 0.15723100739455623), ('1931', 0.11016572682127697), ('more notable film', 0.10942376670766624), ('dracula', 0.10402125093654115), ('1931 version', 0.08372715479904214), ('price hollywood', 0.07491419372932764), ('script', 0.05863859516136878)], [('william holden', 0.12820032522900446), ('william bendix', 0.12313697562606876), ('robert ryan', 0.11311617943337487), ('macdonald carey', 0.10944838922482165), ('julie adams', 0.109386837071908), ('joseph kane', 0.10304490333207558), ('roy rogers', 0.10023848517395254), ('horizons west', 0.09391364036023718), ('rock hudson', 0.09107280920443811), ('audie murphy', 0.09015620187327339), ('1940', 0.08606483515423782), ('colorado', 0.0782447379126085), ('street', 0.0755932910893788), ('laredo', 0.07501748225719856), ('1952', 0.07474884820841585), ('1949', 0.07184281026519154), ('1940 western', 0.06451617082903204), ('1951', 0.06418986162542284), ('cimarron kid', 0.05168799553927269), ('street laredo', 0.04269445320225073), ('story', 0.03915733466744713), ('1951 cimarron kid', 0.038552284636783694), ('1932', 0.03171009961029961), ('1932 screenplay', 0.017794259948338772)], [('additional dialogue', 0.18151171985206102), ('flaming frontier', 0.17933013235850656), ('stevens', 0.13074409009212268), ('1959', 0.12935542938759725), ('1958', 0.11474898542605799), ('1959 film', 0.10087194786694484), ('desert desperadoes', 0.09406696609560423), ('stevens final screenplay', 0.09264084824819419), ('work', 0.0668233531638914)], [('several television episode', 0.2173003869974427), ('hawkeye', 0.1540934006780692), ('stevens', 0.12007333416281862), ('mohicans', 0.1132917187338838), ('two', 0.11329171873388379), ('cheyenne', 0.08753916861206648), ('1957', 0.052378280087892415)]]\n",
      "\n",
      "\n",
      "[[('john fitzgerald byers', 0.13685657167502813), ('melvin frohike', 0.12320205138771101), ('fictional character', 0.1202774473340106), ('recur role', 0.11327406193777947), ('american', 0.09591664257302243), ('american television series', 0.08574881762820658), ('x - file', 0.08357669702848326), ('lone gunmen', 0.06765897447654368), ('short live spin off', 0.06559451951784849), ('richard ringo langly', 0.06176659724121673), ('trio', 0.04942613391341567)], [('lee harvey oswald', 0.19767859042904762), ('john f. kennedy', 0.18110262034938107), ('warren commission conclusion', 0.09311553976846772), ('warren commission', 0.07010060884401857), ('assassination', 0.06765376980284643), ('name', 0.036088725976306114)]]\n",
      "\n",
      "\n",
      "[[('hermandad de pistoleros latinos', 0.2079970712429192), ('pistoleros latinos', 0.1958088760379722), ('chino avitia', 0.1588400416294763), ('latinos', 0.15073374305365508), ('texas', 0.12127225705449943), ('hpl', 0.11643263836216625), ('latino', 0.11105831843944161), ('latino prison gang', 0.10913666603700244), ('cuetes', 0.09230847363413015), ('early 1980s', 0.07662386097292706)], [('latin gunmen', 0.22306241791559314), ('brotherhood', 0.20744080786462998), ('english', 0.1414890468293717), ('brotherhood latin gunmen', 0.10712287628946145), ('gang name', 0.10165699236265369), ('english translation', 0.09479894897035138)], [('texas', 0.24351738932622338), ('many community', 0.23834599430180603), ('texas prison', 0.14701795869148904), ('laredo', 0.12650315652353636), ('street', 0.08085254059793469)], [('nuevo laredo', 0.2309103753773006), ('mexico', 0.1734788380902356), ('large contingent', 0.14943228855722235), ('hpl', 0.13832417530918695)], [('1,000 member', 0.267092929620611), ('1,000', 0.23378309949153975), ('gang', 0.06654984588933559)], [('several mexican drug trafficking organization', 0.20442125663392227), ('close tie', 0.15297511208424375), ('large quantity', 0.13665168914957915), ('mexican', 0.12171746890297204), ('cocaine', 0.11072794679710968), ('distribution', 0.10417742513918654), ('mexico', 0.10187464911031226), ('marijuana', 0.0986746309870496), ('united states', 0.08798317166108993), ('trafficking', 0.07767413240305547), ('member', 0.05278798842579472)]]\n",
      "\n",
      "\n",
      "[[('william smith', 0.13903315461654198), ('piranha', 0.1339298494040307), ('ahna capri', 0.12064824128591028), ('peter brown', 0.11868766556741112), ('venezuela', 0.11108864550808625), ('1972', 0.09047433722825579), ('1972 adventure film', 0.0885515492125609), ('laredo western tv series', 0.07102737584168102), ('caribe', 0.06368761430589415)]]\n",
      "\n",
      "\n",
      "[[('robert knapp', 0.16037617901739193), ('maureen hingert', 0.15417979478505306), ('wallace macdonald', 0.1345296406601256), ('1959 american western film', 0.13366770357553068), ('walter coy', 0.12766187581293909), ('1959', 0.1256342446561361), ('american', 0.12032297313745155), ('laredo', 0.10454603496144826), ('gunman', 0.08127658242335412)]]\n",
      "\n",
      "\n",
      "[[('sharadindu bandyopadhyay', 0.17080535895790258), ('ajit bandyopadhyay', 0.1698988131882253), ('byomkesh bakshi', 0.1604098805742616), ('sheemanto heera', 0.158113883008419), ('bengali', 0.13001247049194475), ('sleuth byomkesh bakshi', 0.11560643634042922), ('frontier diamond', 0.09331389496316869), ('detective novella', 0.08481172341278102)], [('byomkesh', 0.14839336479110177), ('ajit bandyopadhyay', 0.13935218673822325), ('fiction', 0.12841244208275915), ('narrator', 0.1281878977577956), ('first', 0.12199011568409998), ('first person narrative', 0.1083037473216964), ('third such work', 0.10636859291406975), ('associate', 0.10504345579078317), ('byomkesh friend', 0.09760062117271784), ('third', 0.09559072909787045), ('1934', 0.07928041387491117)]]\n",
      "\n",
      "\n",
      "[[('frontier texas', 0.4330127018922193), ('texas', 0.3333333333333333)], [('west texas', 0.20197337656532044), ('14000 sqft museum', 0.19960089096884753), ('taylor county', 0.18945966365076772), ('downtown abilene', 0.17804020755784275), ('abilene', 0.1366104137273635), ('american west', 0.1271029899623759), ('seat', 0.07245075622157832)], [('ten texas historical commission', 0.2279476480978782), ('texas historical commission', 0.22089622043256607), ('texas forts trail', 0.12745120514824115), ('one', 0.12643076405472545), ('visitor information center', 0.11695795021794983), ('region', 0.10960165204868429), ('museum', 0.03611003034911782)], [('625 north first street', 0.19367100079998167), ('north first street', 0.18127224352213006), ('pacific railway', 0.1452544809679322), ('6.4 acre', 0.13720493379156956), ('settler', 0.12313967864653283), ('625', 0.11989645807860279), ('2004', 0.11207234260428986), ('texas', 0.11022310620865053), ('lifestyle', 0.10840196052399305), ('texas pacific railway track', 0.09232097498911179), ('old west', 0.07787512243086075), ('museum', 0.06303813413403878)], [('display attack', 0.18517280756315163), ('buffalo', 0.14537689569496365), ('wolf', 0.14385381435077174), ('indians', 0.1419689710120733), ('card game shootout', 0.12536090916956447), ('prairie thunderstorm', 0.1043281061914602), ('exhibit', 0.06340032007421853)], [('buffalo hunter', 0.17226276451822065), ('comanche warrior', 0.16472994686415374), ('comanche', 0.13428703344919482), ('depiction', 0.13385111444204212), ('adventure', 0.12588886221235934), ('explorer', 0.12368212697759187), ('pioneer', 0.11103975006788916), ('1780 1880', 0.08811429620103409), ('theatre', 0.06181020172557621), ('century adventure', 0.05739346302535683), ('visitor', 0.0530324975560502)], [('buck taylor', 0.24885652727059754), ('fort worth', 0.2016090861410878), ('actor artist buck taylor', 0.19496703304255864), ('theater', 0.08527041234059429), ('narrator', 0.04738153748156415)]]\n",
      "\n",
      "\n",
      "[[('walter darwin coy', 0.1518912095951773), ('television actor', 0.13999189076645047), ('great falls', 0.13999189076645047), ('radio', 0.12766724248717964), ('january 31 1909', 0.10504823390271271), ('american', 0.10454781946165344), ('december 11 1974', 0.09420272935465858), ('montana', 0.09081652817308566), ('american stage', 0.08015178213107402), ('film', 0.07927815923563783)], [('early sunday', 0.16724139705227015), ('evening', 0.15031674489036095), ('nbc western anthology series', 0.14699470850971835), ('nbc', 0.14057189305985396), ('frontier', 0.08258043571458118), ('1955–1956 season', 0.08206951454389383)]]\n",
      "\n",
      "\n",
      "[[('new york city', 0.17126945476968614), ('artistic director', 0.1535203206384962), ('live theater', 0.1509085856726766), ('performing arts', 0.13873342629080596), ('fellowship', 0.132977611525772), ('max mclean', 0.1286839199537425), ('new york city base producer', 0.11156076321362265), ('christian', 0.10935601602383788), ('fellowship performing arts', 0.10891993894938763), ('christian worldview', 0.07472747095318703), ('founder', 0.06526220049693776)], [('fantasy writer c.s. lewis', 0.17870120809164927), ('c.s. lewis', 0.13706140912765954), ('author', 0.12255473930562916), ('oxford', 0.11674770777132515), ('cambridge', 0.11147159028092087), ('mclean', 0.10881569661860176), ('oxford cambridge scholar', 0.1061790086584883), ('screwtape letters', 0.08518354199999197), ('book', 0.055985234696455013), ('play', 0.04525754996143937)], [('late 2013', 0.18112668890906344), ('lewis', 0.14907119849998596), ('national tour', 0.12366711823553773), ('great divorce', 0.10015869457481039), ('stage adaptation', 0.08451542547285167)], [('martin luther', 0.14593901338869392), ('c.s. lewis onstage most reluctant convert', 0.11272683427647917), ('most reluctant convert', 0.1045775167260988), ('trial', 0.09546040332069883), ('mclean', 0.08971274852155993)], [('mclean', 0.17290157147431207), ('bible', 0.17290157147431207), ('narrator', 0.1222330204886807), ('listener bible', 0.11656891119752026)]]\n",
      "\n",
      "\n",
      "[[('john fitzgerald byers', 0.14927543567679788), ('bruce harwood', 0.11799630774674533), ('one', 0.10058823053268764), ('x - file', 0.093822829288397), ('canadian character actor', 0.09217181034694334), ('april 29 1963', 0.09215122259681072), ('canadian', 0.09004388183715974), ('television series', 0.07190299812771662), ('lone gunmen', 0.06973886121621362), ('role', 0.050080588603979244)], [('thirteen episode', 0.1769029098171505), ('byers', 0.1404712345646898), ('harwood', 0.13824360528446752), ('thirteen', 0.1361799234711466), ('x - file', 0.11689180643561892), ('2001', 0.11342191065908887), ('lone gunmen', 0.08962306629750157), ('spin series', 0.05734209761417455), ('addition', 0.04853568381162902)], [('other role', 0.13617107639253354), ('byers', 0.10658539509021356), ('avery', 0.09620211361221748), ('willis', 0.09616750321713942), ('government scientist turn conspiracy theorist dr. avery strong', 0.08452346380070883), ('phoenix foundation', 0.07916971532683316), ('macgyver', 0.07837229898940737), ('outer limit', 0.07535776838808994), ('strong similarity', 0.07323294014608486), ('technician', 0.05236884132161124)], [('vancouver summer shakespeare festival', 0.19946914482054304), ('vancouver', 0.19531374263287818), ('shakespeare', 0.1914000205492019), ('summer', 0.16686040656879533), ('found member', 0.1076700023904791), ('bard beach', 0.08362858976989489), ('beach', 0.06012709744628258)], [('earth star voyager', 0.2725385399779458), ('1988', 0.1920336947662991), ('1988 movie', 0.14478825089858438)]]\n",
      "\n",
      "\n",
      "answer:  Walter Darwin Coy\n",
      "number_sentences:  38\n",
      "number_reduced_sentences:  4\n",
      "number of questions:  10\n",
      "number of questions with answer neither yes nor no:  10\n",
      "common_phrases_num_le2:  8\n",
      "extended:  6\n",
      "answer_in_reduced_context:  6\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286, 0.10526315789473684]\n",
      "ratio of reduced context:  0.2561918601311394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5a7722d655429966f1a36c99\n",
      "question:  Where did the form of music played by Die Rhöner Säuwäntzt originate?\n",
      "question_phrases_text:  ['die rhöner säuwäntzt', 'die rhöner', 'music', 'form']\n",
      "common_phrases:  ['music', 'form', 'die rhöner säuwäntzt']\n",
      "extended_phrases:  ['music', 'form', 'sundanese', 'die rhöner säuwäntzt', 'die rhöner']\n",
      "paras_phrases\n",
      "[[('sundanese oral narrative performance', 0.2285780699027698), ('song', 0.1439838587716319), ('pantun sunda', 0.1418159839898978), ('sundanese', 0.1382129410364195), ('zither', 0.13074409009212268), ('music', 0.11009475113187008), ('kind', 0.06933752452815364), ('type', 0.06896626706070483)], [('other kingdom', 0.1296722685112414), ('beautiful princess', 0.1071016778172231), ('rosidi 1984a:143', 0.09590298752591533), ('evening', 0.0935848767738864), ('experience', 0.08712536055517531), ('power', 0.07928587983515782), ('order', 0.07673651922651734), ('rosidi', 0.07382615421890204), ('kingdom', 0.06205562084522624), ('single performer', 0.05961692712217257), ('evening length performance', 0.05885982286943273), ('dream', 0.046534367961881457), ('story', 0.044854085648589614), ('goal', 0.04437779392729585), ('protagonist', 0.04326997043493367), ('hero initiation', 0.040324610708853285), ('realization', 0.03740421497282527), ('wife', 0.0354985849665816), ('pantun', 0.024160830061866645)], [('mythical element', 0.21511786504928698), ('historical event', 0.2082259085963343), ('description', 0.1477069619614974), ('story', 0.09527459379936966)], [('many case', 0.21036117706819918), ('pantun', 0.13790872408444751), ('bard', 0.07799182688479127)], [('divine figure', 0.12575385124118071), ('bad influence', 0.10837976932414886), ('sacred character', 0.07228063223242011), ('introductory part', 0.07053896517848703), ('invocatory song', 0.06604522640472467), ('story', 0.05754759807967834), ('performance', 0.05697029081098077), ('offering', 0.05378517185909756), ('help', 0.05190114222103917), ('beginning', 0.05112589891671327), ('recitation', 0.050520726684869295), ('content', 0.04969956661418228)], [('most pantun', 0.2051443091569966), ('dominant form', 0.1267602908109173), ('pantun', 0.09383440552354123), ('octosyllabic verse', 0.08975130627335565), ('linguistic form', 0.08438753786715728)], [('eringa', 0.15339658307461485), ('form', 0.14667741171487947), ('sundanese', 0.14600574181302373), ('hermansoemantri', 0.14213381090374028), ('1949', 0.11415294778394383), ('sundanese pantun', 0.11219334008357848), ('detailed description', 0.10365605050307705), ('nature', 0.07897215503030595)]]\n",
      "\n",
      "\n",
      "[[('traditional music', 0.24632799963100072), ('bubu music', 0.2198030925703351), ('sierra leone', 0.20495600210775688), ('temne', 0.16716933449860133), ('temne people', 0.129498658485535)], [('witchcraft ceremony', 0.17238405391583983), ('popular religious processional style', 0.15108263472731792), ('ramadan', 0.10246989785013377), ('music', 0.04286929005971833)], [('metal pipe -often repurpose auto part', 0.22202585304273148), ('bamboo cane flute', 0.18519416667768743), ('folk form', 0.08926922109065673), ('music', 0.06650068136939873)]]\n",
      "\n",
      "\n",
      "[[('turkish classical music', 0.19488362174609622), ('turkish', 0.15128935735135207), ('peşrev', 0.11281089071741346), ('arabic', 0.10541940900679778), ('instrumental form', 0.09367753608375136), ('pishrev', 0.05590708423303869), ('pişrev', 0.026401250392828608), ('piʃˈɾev', 0.026401250392828608), ('peshrev', 0.026401250392828608)], [('first', 0.17166471221389196), ('music', 0.1654928825721238), ('first piece', 0.1292629035489799), ('group performance', 0.1252514897426051), ('name', 0.05822366970594913)], [('ritual music', 0.15216564911388858), ('mevlevi', 0.14291260276065598), ('final peşrev', 0.1392309226045201), ('son peşrev', 0.10341642448775872), ('son semai', 0.09603026759679435), ('mevlevi order', 0.09118712929333332), ('penultimate piece', 0.09035079029052512), ('mevlevi ayini', 0.07406395579987742), ('name', 0.05548797695056664)], [('long rhythm cycle', 0.17299149973071112), ('instrumental music', 0.14058352324812598), ('many measure', 0.13640515422737914), ('other major form', 0.10882824016213592), ('simple usul', 0.07984717679350296), ('saz semai', 0.06778589051367992)]]\n",
      "\n",
      "\n",
      "[[('jazz blue folk american folk influence', 0.11362075199848205), ('american', 0.1134778182579231), ('manufactured homemade improvised instrument', 0.09634065610125457), ('music genre', 0.09622103280230523), ('skiffle', 0.08714480726272586), ('combination', 0.06416697706034466)], [('ken colyer', 0.13143618713583827), ('lonnie donegan', 0.11834002333497488), ('chas mcdevitt', 0.10810952535911743), ('artist', 0.09231377266870666), ('vipers skiffle group', 0.08722489974053074), ('uk', 0.08615039501064284), ('united states', 0.07301712150139193), ('first half', 0.07082420911518497), ('20th century', 0.06847701535473237), ('first half 20th century', 0.06199076771962659), ('term', 0.05269003706081395), ('1950', 0.04562043702706545)], [('later eminent jazz', 0.1332469979747815), ('blue boom', 0.12936970476631507), ('british invasion', 0.12454568974396843), ('folk', 0.11876917339857265), ('second british folk revival', 0.1126734927811335), ('british', 0.10836887097250825), ('blue', 0.1082642585719622), ('us', 0.09744522464852068), ('us popular music scene', 0.09563607270783014), ('second', 0.09344667146599657), ('rock musician', 0.09300391381046627), ('critical step stone', 0.08552064185291779), ('pop', 0.08398137220959287), ('skiffle', 0.07628166792871494), ('major part', 0.07403723486830756), ('career', 0.046486766499889455)]]\n",
      "\n",
      "\n",
      "[[('kachi kachi', 0.21259028778464423), ('cachi cachi music', 0.19369352736011894), ('puerto ricans', 0.15750273805179765), ('music', 0.1564631351508176), ('cachi cachi', 0.15267562668143156), ('hawaii', 0.1359831650326326), ('katchi', 0.09090387713147363), ('katchi katchi', 0.06969162812031895), ('term', 0.04625560665705192)], [('dance music', 0.3029458871795072), ('hawaii', 0.18200064648685815), ('variation', 0.07005208149458232)], [('cachi cachi', 0.3124455859231893), ('fast improvised solo', 0.168852981393307), ('guitar', 0.03904344047215152)], [('puerto rican', 0.1653100622214005), ('puerto rican jibaro style', 0.131097087621665), (\"hawai'i\", 0.11018851466198683), ('cachi cachi', 0.10500129096461286), ('derivative', 0.10429167998052796), ('musical form', 0.08875881125854222), ('quarto sic', 0.06023020182702337), ('day', 0.05684308348558115), ('influence', 0.03443391083187089)], [('peasant', 0.2561306370643219), ('jibaro', 0.21332652874908856), ('spanish', 0.21332652874908856)]]\n",
      "\n",
      "\n",
      "[[('background music', 0.2168516959595161), ('music', 0.20504253119632276), ('various style', 0.19035394120246701), ('soundscape', 0.14584165540278138)], [('main focus', 0.13322157057798878), ('audience', 0.10330586154585199)], [('background music', 0.19166399765501804), ('low volume', 0.10772705286241381), ('main focus', 0.102917454441668), ('audience', 0.09182853128145209), ('music', 0.07931947070406406)], [('background music', 0.23411081756411134), ('music', 0.2123281286481642), ('various social gathering', 0.18134368194562148), ('certain retail venue', 0.17219789599124394), ('traditional example', 0.08267206147511763)], [('various electronic medium', 0.1819273611576323), ('internet video', 0.17131029994153701), ('video game', 0.1710123464890947), ('video blog', 0.16344697986277293), ('background music', 0.15529205080140268), ('television', 0.11685928650839224), ('film', 0.11537875320970549)]]\n",
      "\n",
      "\n",
      "[[('folk music', 0.1824289794544686), ('thai กันตรึม', 0.16984155512168936), ('thailand', 0.13140395684253647), ('kantrum', 0.13074409009212268), ('thai', 0.13074409009212268), ('isan', 0.128015739960666), ('khmer', 0.12352837711835923), ('cambodia', 0.10425526801366014), ('border', 0.07413397419782196), ('type', 0.062163519566885504)], [('fast traditional dance music', 0.19444444444444445)], [('percussion', 0.16882659432669903), ('fiddle', 0.1675197948321785), ('singer', 0.1446830386844786), ('cho kantrum', 0.12490040858618864), ('pure form', 0.1136757397493443), ('sound', 0.0742573059426472)], [('electric instrumentation', 0.22655454495331562), ('more modern form', 0.11649256604666527), ('mid-1980', 0.05459866002220472)]]\n",
      "\n",
      "\n",
      "[[('14 metal string', 0.13906126145524061), ('5 course', 0.13422545551082707), ('very small guitar shape fret stringed instrument', 0.10790094925474036), ('14', 0.10027266589532466), ('bolivia', 0.0983008979589052), ('pair triple course', 0.0956516114474471), ('peru', 0.09428090415820634), ('5', 0.07885178768285904), ('border area', 0.06451036619083642), ('10 12', 0.0632475520977701), ('chillador', 0.0628970577563248), ('cousin', 0.047107261109490026), ('charango', 0.03630626164140105)], [('music', 0.23847723674964416), ('chillador', 0.17509915506588727), ('charango', 0.14442385473776032), ('sort', 0.05558876760683288)], [('charango', 0.15835392624767755), ('armadillo', 0.12508181269783356), ('chillador', 0.12508181269783353), ('just little guitar', 0.12501490072485824), ('armadillo shell', 0.0962271728826021), ('charango soundbox', 0.0954013034944338), ('main difference', 0.07351874724868752)]]\n",
      "\n",
      "\n",
      "[[('die rhöner säuwäntzt', 0.23735537728330258), ('hessen', 0.16852010164362877), ('germany', 0.12559113449755333), ('eichenzell lütter', 0.12354752781152767), ('skiffle bluesband', 0.08770599708834374)], [('other hessian dialect variety', 0.1768614057506179), ('rhön mountains dialect', 0.16982786846741604), ('christoph leipold', 0.16308212738974462), ('christoph günther', 0.1629438309111545), ('martin caba', 0.14063671844873007), ('rhön mountains', 0.13688016832012376), ('hessian', 0.10343302811845996), ('lyric', 0.09490027503674911), ('skiffle blue', 0.08127312271366871), ('line up', 0.04307664544775216)], [('pork belly', 0.20404942350912572), ('säuwäntzt', 0.1474345793605663), ('untidy unruly child', 0.13817661352563318), ('youth', 0.12024148151104294), ('expression', 0.0368967504095597)]]\n",
      "\n",
      "\n",
      "[[('japanese experimental punk band', 0.21162174858761942), ('11 october 1968', 0.1779082534169099), ('japanese', 0.1413936426911379), ('minoru kojima', 0.14066465355299496), ('mad capsule markets', 0.10744057990764908), ('original guitarist', 0.0809127806392195)], [('different boøwy member', 0.20544108534289812), ('scene', 0.17194374769577936), ('shin murohime', 0.16306413548264312), ('boøwy', 0.14750101990140502), ('character', 0.1324978842274296), ('name', 0.07966843755067184), ('conglomeration', 0.07448376676118877)], [('music', 0.15368154563462583), ('vocalist hiroshi kyono', 0.15275104731571876), ('hiroshi kyono', 0.12616656197292883), ('berrie', 0.11636581026764514), ('loud punk music', 0.11511790773759062), ('television', 0.11453246347978648), ('mad capsule markets', 0.09930392641267238), ('1985', 0.09623155249792209), ('radio', 0.07282840265541667), ('time', 0.051507283239151214), ('attempt', 0.04105037524577275)], [('ai ishigaki', 0.16534176754086355), ('minoru', 0.13841732568001133), ('humanity', 0.13727245200323915), ('mad noël coward humanity', 0.11496565373939922), ('support guitarist', 0.10585997616898127), ('mad', 0.07600944734070843), ('band', 0.07399113207346723), ('release', 0.048560652595696925)], [('1994', 0.14649230196006974), ('cry', 0.13925045135756836), ('minoru', 0.1362808688052285), ('1991', 0.1362808688052285), ('bloody imitation society', 0.13027524974491156), ('member', 0.07945832314008576)], [('more band', 0.14804680624139166), ('cistm konfliqt', 0.13693063937629152), ('010', 0.1092576150363135), ('minoru', 0.10208741120681498), ('short time', 0.0786261360517242), ('good day', 0.07408596940097259), ('cistm konfliqt tour', 0.06123724356957946), ('year', 0.04576438381671637), ('album', 0.04353782287435799)]]\n",
      "\n",
      "\n",
      "answer:  United States\n",
      "number_sentences:  43\n",
      "number_reduced_sentences:  12\n",
      "number of questions:  11\n",
      "number of questions with answer neither yes nor no:  11\n",
      "common_phrases_num_le2:  9\n",
      "extended:  7\n",
      "answer_in_reduced_context:  6\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286, 0.10526315789473684, 0.27906976744186046]\n",
      "ratio of reduced context:  0.25827166988665956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5ade025e5542997dc790711e\n",
      "question:  In which American football game was Malcolm Smith named Most Valuable player?\n",
      "question_phrases_text:  ['malcolm smith', 'american football game', 'american']\n",
      "common_phrases:  ['malcolm smith', 'american', 'american football game']\n",
      "extended_phrases:  ['malcolm smith', 'american', 'australian national antarctic research expeditions', 'american football game']\n",
      "paras_phrases\n",
      "[[('about 1 nautical mile', 0.1792130412236046), ('winston lagoon', 0.13693063937629152), ('indian ocean', 0.13569676256102026), ('heard island', 0.13179772001641765), ('cape lockyer', 0.12609508766215255), ('northeast', 0.11505619899584453), ('southern indian ocean', 0.09638567489899566), ('southeast coast', 0.08929378239554121), ('1.9 km', 0.07440879971378936), ('lagoon', 0.046229125805878075)], [('american', 0.1857172788876598), ('1860', 0.16765982331580734), ('american sealer chart', 0.16668981053162554), ('1860 period', 0.11400060696311762), ('feature', 0.05998444019306309)], [('australian national antarctic research expeditions', 0.1874826822169612), ('malcolm smith', 0.14891655288800526), ('first', 0.10853118254581152), ('raaf', 0.10637142607477501), ('first reconnaissance flight', 0.10321880869667155), ('anare', 0.09936705933018276), ('pilot', 0.08757910135814202), ('1948', 0.07831399178571247), ('air', 0.05948445231756022), ('island', 0.054365043276315604)], [('lake winston', 0.25620777144784995), ('smith', 0.1781741612749496), ('lieutenant smith', 0.13659755535250212), ('wife', 0.07106565701340121)], [('australian antarctic names medals committee', 0.13667712163365653), ('generic term', 0.1335656679105232), ('anca', 0.11146807817599198), ('australian', 0.10736543293903418), ('aircraft accident', 0.09308213110571557), ('only change', 0.08488181486979188), ('view', 0.0808734119497492), ('death', 0.05570202290911306), ('proposal', 0.0494269451688484)], [('heard island', 0.18392621079991506), ('mcdonald islands', 0.1823916480409451), ('major topographical feature', 0.1214490783612657), ('map', 0.07202277827856605)]]\n",
      "\n",
      "\n",
      "[[('malcolm xavier smith', 0.16917008584140283), ('san francisco', 0.15170715936927628), ('san francisco 49er', 0.11272203871372878), ('american', 0.10859590895538158), ('american football linebacker', 0.10856956696179322), ('national football league', 0.10856956696179322), ('july 5 1989', 0.10791155990996511), ('nfl', 0.04543108504242547)], [('college football', 0.30337792881618225), ('smith', 0.20407496432019762), ('usc', 0.17276216969160274)], [('seventh', 0.16755090532504324), ('2011 nfl draft', 0.16099756410939559), ('seattle seahawks', 0.13427932451158178), ('seventh round', 0.1268203027316527)], [('super bowl', 0.1935260325958296), ('denver broncos', 0.09852536311211262), ('smith', 0.09622862195077606)]]\n",
      "\n",
      "\n",
      "[[('national football conference', 0.19025848728492148), ('super bowl xlviii', 0.14341745528366362), ('national football conference nfc champion seattle seahawks', 0.12571362700002675), ('denver broncos', 0.12333147498196384), ('seattle seahawks', 0.11949455748509599), ('national football league', 0.11416436060988479), ('american football conference', 0.11295476137262361), ('american', 0.10397575105983943), ('nfc', 0.09529922323730335), ('afc', 0.09485534166393134), ('american football game', 0.09086795968736133), ('nfl', 0.08517808014910325), ('nfl champion', 0.0643905900991986), ('2013 season', 0.059788032686201205)], [('super bowl history', 0.18181888977550426), ('super bowl xxvii', 0.17864334571500984), ('super bowl', 0.17314516855154224), ('third large point differential', 0.13274457579873467), ('third', 0.11368475899691904), ('broncos', 0.10896945564823099), ('victory', 0.10550897715240688), ('43–8', 0.10543866487555209), ('35', 0.0948044069575969), ('large margin', 0.09268846143325794), ('seahawks', 0.09210506515207298), ('1993', 0.08006768988304219), ('underdog', 0.04838842887210579)], [('40', 0.1481837391108243), ('win team', 0.1276217954481409), ('first', 0.12402974884862429), ('40 point', 0.11616531860498469), ('first time', 0.10432075871132157), ('opponent', 0.08016776674265484), ('10', 0.06057099001555317)], [('super bowl', 0.23372827155467082), ('fifth super bowl loss', 0.17665451344930666), ('first super bowl victory', 0.17467371887529803), ('fifth', 0.1466708870558912), ('first', 0.1447666652494321), ('broncos', 0.12739920439545802), ('seahawks', 0.10991954684423708), ('team', 0.05649990965565532)], [('super bowl', 0.15432298090419871), ('east rutherford', 0.14123672343545746), ('february 2', 0.13831180743433194), ('first', 0.12592384338357293), ('new jersey', 0.12184845853414819), ('first super bowl', 0.1136435239273397), ('metlife stadium', 0.11229180292219414), ('february', 0.11128970834180599), ('meadowlands sports complex', 0.09665860224987025), ('february 2 2014', 0.09634003157204142), ('cold weather city', 0.06413815283334005), ('game', 0.022849651135383016)]]\n",
      "\n",
      "\n",
      "[[('nba summer league', 0.23795788208532304), ('nba', 0.19590690487659027), ('2013', 0.18234777605405356), ('2013 nba summer league', 0.17880163909163038), ('2013 nba draft', 0.15718568191498736)], [('newly draft player', 0.22456715641286365), ('professional basketball', 0.16558721995853978), ('feel', 0.07915876776538235), ('chance', 0.07762491685087501), ('skill', 0.07626307942180842)], [('30', 0.1781741612749496), ('nba', 0.1781741612749496), ('30 nba team', 0.12624819542352972), ('d league select', 0.12624819542352972)], [('summer leagues', 0.2099449070681655), ('only team', 0.14719395830869472), ('miami heat', 0.12390295294416283)], [('july 7–12', 0.2607547868797778), ('las vegas', 0.2042518405966182), ('orlando', 0.18809189960153022)], [('oklahoma city thunder', 0.1331441939014073), ('orlando summer league', 0.12353700534843565), ('most valuable player orlando summer league', 0.11447513716528639), ('jeremy lamb', 0.09025468342586819)], [('jonas valančiūnas', 0.154954687555045), ('las vegas summer league', 0.1421383218393119), ('toronto raptors', 0.10925487816232417)], [('las vegas summer league championship game', 0.1564125165794834), ('ian clark', 0.13632287338539628), ('most valuable player las vegas summer league championship game', 0.12612556268292704), ('golden state warriors', 0.11795322395319846)]]\n",
      "\n",
      "\n",
      "[[('stephen spence clark', 0.14835422360055125), ('former professional american football player', 0.12388944306896449), ('defensive tackle]and offensive guard', 0.11643256648763287), ('five season', 0.11178725404234015), ('american', 0.10532174752338369), ('august 2 1960', 0.09463337213752927), ('miami dolphins', 0.04747795383448982)], [('two state championship team', 0.20424513378916334), ('most valuable player', 0.15022840710828908), ('two year', 0.14356110549462897), ('two', 0.14293534018688198), ('parade magazine', 0.1305582419667734), ('high school', 0.11618680330139934), ('five team', 0.08003543064858434), ('25 1', 0.07272693237165354), ('state', 0.06912326162670296), ('five', 0.06349728964780407), ('utah', 0.06262479261816943), ('american', 0.03501159942667063)], [('defensive most valuable player', 0.1793656261263124), ('first team', 0.1525943291019388), ('utah', 0.10705113194566565), ('western athletic conference', 0.10022204907587232), ('two', 0.09762707897592254), ('university utah', 0.053911837974397116), ('university', 0.04316528106950994)], [('mvp', 0.15006159623872126), ('east west shrine game', 0.13452283438807464), ('senior bowl', 0.10628801219501913)], [('pre - season', 0.13662309725473454), ('don shula', 0.1340355561727942), ('coach shula', 0.13400348013047275), ('shula', 0.12199628600623846), ('long snap', 0.10011024818957803), ('pre - season game', 0.09809929380176136), ('nfl', 0.08456332033975789), ('second year', 0.06529477340150029), ('offensive defensive line', 0.06457273870023002), ('miami dolphins', 0.06356862391467659), ('senior bowl', 0.05934369849133695), ('guy', 0.042808741967093694), ('way', 0.04201024374697582), ('position', 0.040498304976155856)], [('american football)|the fridge', 0.1429441811543696), ('monday night football', 0.14119870925356146), ('right guard', 0.13111339233459296), ('william perry', 0.11642608173737905), ('american', 0.11096845054505396), ('dolphin', 0.09669935214505672), ('undefeated dolphin record', 0.09060004246025764), ('dolphins', 0.08950896903799267), ('starting position', 0.07737904532977337), ('chicago bears', 0.07524556236187976)], [('two super bowl team', 0.23300303976139988), ('super bowl', 0.1783739031534151), ('two', 0.16294199033316725), ('start right guard', 0.1311463207590692), ('nfl', 0.08831585010135225), ('miami dolphins', 0.0837432765577747)], [('9th', 0.12904686089047693), ('top 100 great player', 0.1283965556301804), ('steve', 0.1147628304721391), ('100', 0.11209105045804159), ('utah', 0.11178298956216456), ('all time', 0.0782522715860261), ('university utah', 0.06401151677165078), ('university', 0.06046683720429826), ('history', 0.051099268970972174)]]\n",
      "\n",
      "\n",
      "[[('illinois fight illini', 0.19470065619969704), ('1959 illinois fight illini football team', 0.18728654073769474), ('1959 big ten conference football season', 0.17469362212648432), ('1959', 0.14970055652058978), ('american football team', 0.1415391467189698), ('illinois', 0.14123201315169476), ('american', 0.10396684917480198), ('university illinois', 0.06786710483681468), ('university', 0.04950205980885498)], [('head coach ray eliot', 0.19318480882913003), ('big ten conference', 0.1644634094463249), ('ray eliot', 0.14910664634311072), ('third place', 0.14432803785997894), ('illini', 0.10973626924992944), ('third', 0.10039088347045368), ('5–3–1 record', 0.09168355733374738), ('18th year', 0.0772884300721602), ('tie', 0.06283892003285482)], [('guard bill burrell', 0.16760850781396258), ('bill burrell', 0.1508926679171771), ('chicago tribune silver football trophy', 0.1309758207511226), ('chicago tribune silver football', 0.12021645568571267), ('big ten most valuable player', 0.10916916601180415), ('team most valuable player', 0.10223391270569344), ('season', 0.048945906596728046)]]\n",
      "\n",
      "\n",
      "[[('east division', 0.13867508324336747), ('west division', 0.13647317671190015), ('grey cup', 0.12347939198282004), ('edmonton eskimos', 0.12160930389210436), ('east division champion ottawa redblacks', 0.12051848269375913), ('ottawa redblacks', 0.11433180007771943), ('west division champion', 0.10339005564419369), ('canadian', 0.0998937935421729), ('november 29 2015', 0.09523946170290606), ('november', 0.09298207287743485), ('cfl', 0.09082764241536113), ('canadian football game', 0.08810295497597245), ('103rd grey cup', 0.08658473111216862), ('canadian football league', 0.08644777574729026), ('2015 season', 0.07135765214879382), ('canadian football league cfl championship', 0.0686786946791639)], [('investors group field', 0.2892897242022457), ('winnipeg', 0.193864838366809), ('manitoba', 0.12413899767723546), ('game', 0.047781122483921475)], [('cfl history', 0.1933866000111662), ('shaw communications', 0.1724081609500765), ('cfl', 0.14750080562691642), ('first', 0.12290831792770418), ('present sponsor', 0.11487941030299827), ('grey cup', 0.10467168150981536), ('first time', 0.10408261718268402), ('game', 0.059188402686710266)], [('grey cup', 0.17640586887875664), ('franchise history', 0.17317067184883764), ('14th grey cup championship', 0.14950926703428635), ('14th', 0.13558028205456268), ('first', 0.13289535366137584), ('26–20', 0.1250022174507819), ('eskimos', 0.10747155600365367), ('2005', 0.08699388750294434), ('contest', 0.0760925271034526)], [('most valuable canadian', 0.1701951118528999), ('most valuable player', 0.1701951118528999), ('shamawd chambers', 0.1660082984985689), ('mike reilly', 0.15811388300841897), ('most valuable player shamawd chambers', 0.14174349205253636), ('dick suderman trophy', 0.11939521790603383), ('canadian', 0.09833942267826963)]]\n",
      "\n",
      "\n",
      "[[('cardiff rfc', 0.17594824281897248), ('vale rfc', 0.16737085356581108), ('ebbw vale rfc', 0.16713717538096126), ('newport rfc', 0.16633309744450397), ('newbridge rfc', 0.16521119873321735), ('merthyr rfc', 0.16521119873321735), ('6 june 1973', 0.12822064270895764), ('richard malcolm smith', 0.12494341478528603), ('cardiff blues', 0.10995063503696739), ('worcester warriors', 0.10763342928824733), ('sale shark', 0.10734146617608177), ('bristol rugby', 0.10392348951302016), ('former rugby union player', 0.09527891057779787), ('half', 0.08842643121848394), ('ebbw', 0.07481835864527994), ('scrum half', 0.0644761952261134)], [('one wales cap', 0.21511205730681537), ('robert howley', 0.19555088906347162), ('wales', 0.17806973853208607), ('rupert moon', 0.16804654726154794), ('one', 0.13510226655074226), ('22', 0.11915921437755972)], [('territory', 0.12686212243973494), ('opposition', 0.06507213711989665), ('pressure', 0.06263834786221709)], [('excellent game management', 0.22535440629856085), ('very skilful technical intelligent rugby player', 0.13479113637824164)]]\n",
      "\n",
      "\n",
      "[[('kevin wayne durant', 0.16024087650494048), ('american professional basketball player', 0.12119220733789861), ('american', 0.1092260859348822), ('national basketball association', 0.10810083433584011), ('september 29 1988', 0.10221572483683271), ('golden state warriors', 0.10137536757836212), ('nba', 0.097107335746346)], [('four nba scoring title', 0.17712267631526935), ('bill russell nba finals most valuable player award', 0.1748571145479368), ('nba', 0.17159339841498872), ('nba most valuable player award', 0.1696136227558691), ('two olympic gold medal', 0.14682159118266772), ('nba all star game most valuable player award', 0.14313086087108845), ('nba championship', 0.10192282084834252), ('two', 0.09854643309455975), ('four', 0.09012674309145292), ('year', 0.03642798291442019)], [('eight nba all star team', 0.20238877821653659), ('seven all nba team', 0.1925716133141047), ('eight', 0.14427507188595867), ('seven', 0.1363138324949285), ('durant', 0.11147024922077281)]]\n",
      "\n",
      "\n",
      "[[('super bowl mvp', 0.1976476230967086), ('super bowl most valuable player award', 0.15739514459764642), ('nfl', 0.11907393457960008), ('super bowl', 0.11379740197471662), ('most valuable player', 0.09806128312957853), ('annually', 0.09537474484451815), ('national football league nfl championship game', 0.07845938908674976), ('national football league', 0.07458401333865546)], [('16 football writer', 0.22560229922361208), ('broadcaster', 0.1498458166922388), ('16', 0.1462988311781698), ('fan vote', 0.11063682150919486), ('game', 0.07322703497884223), ('panel', 0.06500270793346438), ('winner', 0.04357436371395183)], [('80 percent', 0.11550342826963056), ('20 percent', 0.10970787456719379), ('other 20 percent', 0.10085022463072804), ('vote tally', 0.08903404786139038), ('viewer ballot', 0.08760374321000121), ('medium panel ballot', 0.0861084983862936)], [('super bowl xxxv', 0.2126739646928773), ('super bowl', 0.2082134763067192), ('cellular phone', 0.14696923691891625), ('first super bowl', 0.13165357883097428), ('fan voting', 0.127541303233307), ('first', 0.08821000506284433), ('2001', 0.0749557545867933), ('game viewing audience', 0.06708670455935767), ('internet', 0.049361613363499736)]]\n",
      "\n",
      "\n",
      "answer:  Super Bowl XLVIII\n",
      "number_sentences:  50\n",
      "number_reduced_sentences:  9\n",
      "number of questions:  12\n",
      "number of questions with answer neither yes nor no:  12\n",
      "common_phrases_num_le2:  10\n",
      "extended:  8\n",
      "answer_in_reduced_context:  7\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286, 0.10526315789473684, 0.27906976744186046, 0.18]\n",
      "ratio of reduced context:  0.25174903072943794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5ab381b155429969a97a816b\n",
      "question:  What U.S Highway gives access to Zilpo Road, and is also known as Midland Trail?\n",
      "question_phrases_text:  ['midland trail', 'u.s highway', 'access', 'zilpo road']\n",
      "common_phrases:  ['zilpo road', 'midland trail', 'access']\n",
      "extended_phrases:  ['zilpo road', 'concept 400,000 public art spherical metal sculpture', 'access', 'united states', 'u.s. route 60', 'midland trail', 'u.s highway']\n",
      "paras_phrases\n",
      "[[('eastern kentucky', 0.19623488815378476), ('united states', 0.1607435214248364), ('national forest scenic byway', 0.1557590379951653), ('kentucky', 0.15168111137810164), ('zilpo road', 0.14844156656747975), ('forested hill', 0.10131858431646742)], [('u.s. highway 60', 0.2000916137464687), ('u.s. highway', 0.1863680087824762), ('nine mile', 0.17288412123977773), ('morehead', 0.1311061731084968), ('kentucky', 0.11747931353068797), ('nine mile byway', 0.09626327383799783)], [('cave run lake', 0.18652768825721086), ('daniel boone national forest', 0.1410818225016629), ('zilpo recreation area', 0.10979572720897444), ('western shore', 0.0916069317849067), ('byway', 0.03376931126119255)], [('fsr 918', 0.16984155512168936), ('two lane pave road', 0.1452221971155201), ('fsr', 0.13074409009212268), ('two', 0.12268280151899594), ('motor vehicle', 0.09297606434938477), ('year', 0.05463055286143998)]]\n",
      "\n",
      "\n",
      "[[('concept 400,000 public art spherical metal sculpture', 0.16434373660599072), ('belfast', 0.1538883677218112), ('wolfgang buttress', 0.1538269350024657), ('400,000', 0.14587602555208257), ('rise', 0.0918841537830113)], [('early 2011', 0.12189982836636863), ('37.5 m high 30 m', 0.12091535481736394), ('average flow', 0.11714630868526438), ('westlink', 0.11081844579852942), ('broadway', 0.09674683649130614), ('m1', 0.090519258495481), ('more 80,000', 0.07658787553241744), ('westlink m1 motorway', 0.07367583358285894), ('2009', 0.06521423828034396), ('city', 0.05300599368410167), ('centre', 0.048308162550530526), ('junction', 0.036760999378032004), ('day', 0.019307082106913554)], [('access', 0.15539334122079784), ('falls road area', 0.1466099348131481), ('falls road', 0.1245506095543482), ('broadway', 0.12121433229081371), ('falls', 0.0951728884418552), ('junction', 0.08240976399634592), ('balls', 0.0692668963403916)]]\n",
      "\n",
      "\n",
      "[[('boyd county', 0.15329053623782207), ('three mile', 0.13895221610385922), ('peterman hill', 0.12412760906833589), ('catlettsburg', 0.11220082449730928), ('west', 0.0970190943076631), ('kentucky', 0.09236533637077096), ('cannonsburg road', 0.08565246933324416), ('unincorporated community', 0.0846840185685761), ('high ridge', 0.08462525394582608), ('5 km', 0.08273650019308772), ('catlettsburg cannonsburg pike', 0.08254098426404835)], [('later u.s.', 0.1746353386582897), ('midland trail', 0.16883009305883448), ('u.s. 60', 0.16576357577413478), ('county maintenance', 0.13867016430096327), ('1964', 0.13169499360903072), ('road', 0.038867230448088326)], [('state route', 0.30618621784789724), ('3294', 0.23570226039551584)]]\n",
      "\n",
      "\n",
      "[[('113', 0.2726732497244431), ('arkansas highway', 0.2409087260017159), ('ar', 0.22592251643645503), ('arkansas', 0.16908134009167564), ('hwy', 0.1674691857511467)], [('central arkansas', 0.20070481892744557), ('north south state highway', 0.14709100706928785), ('113', 0.0682788741998919)], [('arkansas highway 10', 0.252127161045494), ('29.48 mi', 0.23987211159406718), ('arkansas highway', 0.2306036532806035), ('morrilton', 0.13463199435388132), ('route', 0.059387915824493105)], [('access', 0.19389260636610334), ('morrilton', 0.15750307439630723), ('rural area', 0.14427857149394444)], [('conway counties', 0.267092929620611), ('pulaski', 0.23378309949153975), ('conway', 0.23378309949153975), ('perry', 0.23048479379322753)], [('business route', 0.30368238303033623), ('spur', 0.15139668487391394)]]\n",
      "\n",
      "\n",
      "[[('266', 0.20215165368054627), ('state route', 0.19432940221002254), ('u.s.', 0.18111190400951688), ('sr', 0.1596514502907299), ('california', 0.15084440255310463), ('u.s. state', 0.1388497813370388), ('state highway', 0.12777531299998796)], [('fish lake valley', 0.24696994158557764), ('part', 0.20134585321838563), ('california', 0.16474191409951972), ('nevada', 0.12511307870850313), ('route', 0.059173915152672674)], [('two nevada state route', 0.24464546251939479), ('nevada', 0.16723789686607485), ('nv', 0.16385633219616164), ('two', 0.1416499836847458), ('nevada portion', 0.11209863788271442), ('266', 0.11081138037821442), ('valley', 0.06806014857410486), ('route', 0.06364374501649002)], [('sr', 0.2204198886329344), ('california', 0.17124909456554643), ('california road network', 0.1515212853640852), ('266', 0.1443306581241658), ('168', 0.10937644408024755), ('only connection', 0.08177709581024346), ('rest', 0.07660651364726749)], [('separate numerical designation', 0.20174073267676312), ('modern sr', 0.1996376845846865), ('266', 0.15345252634976736), ('1986', 0.13547083251730424), ('southern northern half', 0.10488156673098607)], [('modern sr', 0.15660239922855), ('part', 0.13391360757721413), ('168', 0.13051020573638825), ('auto trail era', 0.1255486572193435), ('midland trail', 0.08317885189788843), ('southern portion', 0.07541976936670437), ('highway', 0.058639656573304624)]]\n",
      "\n",
      "\n",
      "[[('rowan county', 0.15588604345337195), ('interstate 64', 0.1447989092684725), ('us 60', 0.1410725195230269), ('midland trail', 0.1361899706986805), ('interstate', 0.11161071216932264), ('us', 0.10785261931374181), ('historic midland trail', 0.10088614496581064), ('home rule class city', 0.09763445369412933), ('kentucky', 0.09414343008533195), ('united states', 0.08518354199999197), ('morehead', 0.07509794347222042)], [('seat', 0.1767766952966369), ('county', 0.1767766952966369)], [('2010', 0.2260232622951707), ('6,845', 0.20252424201908717), ('2010 u.s. census', 0.1880900557386389), ('u.s.', 0.18664129319733963), ('time', 0.10264611749993356), ('population', 0.05835721285899458)]]\n",
      "\n",
      "\n",
      "[[('puente romano de salamanca', 0.2066336206183335), ('puente mayor del tormes', 0.20204292813750163), ('puente', 0.15961591177370135), ('salamanca', 0.1551969691918056), ('roman bridge', 0.15243989291088034), ('roman', 0.117348284276446), ('león', 0.10529360118690156), ('castile', 0.09499997341507754), ('tormes river', 0.09224800830760017), ('spanish', 0.08197354784018959), ('spain', 0.08041081734475236), ('bank', 0.046776476608384736), ('city', 0.04629330505758837)], [('first', 0.13774546907626667), ('city coat', 0.12571930478090684), ('city', 0.10330010349423711), ('first quartering', 0.09741118324643847), ('arm', 0.09641911869909636), ('stone bull verraco', 0.09264084824819419), ('bridge', 0.07059499905045492), ('symbol', 0.06596078912182089), ('importance', 0.03867182496358254)], [('puente prinçipal', 0.20199658805562695), ('main bridge', 0.17887836281723582), ('puente', 0.17099103267810226), ('access', 0.13956875477336728), ('southern part', 0.11064429714632014), ('puente mayor', 0.1088263388250504), ('city', 0.057862541879442064)], [('several restoration', 0.22306241791559314), ('21st century', 0.13746534338912172), ('result', 0.11001210145192168), ('bridge', 0.05445915951621421)], [('san policarpo', 0.1909169859893511), ('year 1626', 0.15187557503778945), ('january 26 night', 0.1372727945630831), ('year', 0.13128297186633264), ('flood san policarpo', 0.09723136698325781), ('disaster', 0.08740900055397527), ('flood', 0.061140036532173155)], [('bien de interés cultural', 0.22503157858879283), ('artistic historic monument', 0.20952994252963342), ('june', 0.14282987292912036), ('june 3 1931', 0.12395609068629684), ('1998', 0.10945689894152977)], [('20th century', 0.15811388300841897), ('many year', 0.14611227618122682), ('heavy traffic', 0.14611227618122682), ('access', 0.14528811492143964), ('single point', 0.10140360348248405), ('beginning 20th century', 0.08624393618641034), ('status', 0.06644026665175072), ('beginning', 0.06454972243679027), ('city', 0.04803188813580986)], [('road traffic', 0.19736817881025398), ('third', 0.1497751622934603), ('pedestrian walking use', 0.13060388418013005), ('third bridge', 0.11246238634436728), ('unique way', 0.10823653259161677), ('construction', 0.05137914409226899)]]\n",
      "\n",
      "\n",
      "[[('hawks nest state park', 0.22431143283904703), ('gauley mountain', 0.17363863873939706), ('west virginia', 0.17363863873939706), ('ansted', 0.1510404864958722), ('usa', 0.11264397703608553), ('hawk nest', 0.10388357348970284), ('site', 0.0655049190778681), ('peak', 0.05973849001652835)], [('178 m', 0.21650635094610965), ('585', 0.16530348187683505), ('new river', 0.12777531299998798), ('point', 0.10705405433819953), ('cliff', 0.048246179783729505)], [('many early traveler', 0.15664909160561136), ('kanawha turnpike', 0.14412801982108758), ('west virginia', 0.13863099872650797), ('james river', 0.08699279398251891), ('road', 0.07604890330980507), ('river', 0.05762731576681747), ('extension', 0.056920408281046164), ('view', 0.05431794595283594), ('canal', 0.04296120525017182)], [('u.s. route 60', 0.22566257809907297), ('u.s. route', 0.20141744669687492), ('modern time', 0.15039061555816136), ('same general route', 0.12418462767348566), ('midland trail', 0.11558348428575728)], [('free access', 0.1965262477823922), ('tourist', 0.1853501060393179), ('state park', 0.12161316063909917), ('ample parking', 0.10156255085213398), ('overlook', 0.07308830009169236), ('view', 0.05335423135515999)]]\n",
      "\n",
      "\n",
      "[[('sand island state recreation area', 0.1745213599822123), ('nimitz highway', 0.13694474093117978), ('hawaii route', 0.13685730927210055), ('route 64', 0.1206195948338723), ('downtown honolulu', 0.10588292390895934), ('route', 0.07848597740720048), ('three mile', 0.07706164919837837), ('honolulu', 0.07481446003638534), ('5 km', 0.07347203496666625), ('three mile 5 km road', 0.057333193229937046), ('entrance', 0.03874670034676898)], [('sand island parkway', 0.24932445139385748), ('street name', 0.1303228642767255), ('route', 0.05841149144320102)], [('sand island state recreation area', 0.2045432095209415), ('u.s. coast guard honolulu branch', 0.14368862650662875), ('access', 0.12239575004659198), ('kapalama channel', 0.0755306931131643), ('route', 0.03577159325304243)]]\n",
      "\n",
      "\n",
      "[[('fayette county', 0.18811785236947556), ('west virginia', 0.15240214399437632), ('glen ferris', 0.144297413236294), ('cdp', 0.1143591617628554), ('kanawha river', 0.10008047539549286), ('census designate place', 0.09808158702519694), ('western bank', 0.08298318309733295)], [('approximately one mile', 0.25855263418017216), ('gauley bridge', 0.19187697206171772), ('town', 0.09119510733766067)], [('u.s. route 60', 0.20483608042652374), ('glen ferris', 0.17691807326712408), ('u.s. route', 0.17608706530176912), ('midland trail', 0.0855050352138187), ('sole highway', 0.07250740516964606), ('area', 0.06596838499117263)], [('104 housing unit', 0.24824765342323196), ('104', 0.16098205699878185), ('203', 0.147223912407967), ('87', 0.13475136553491612), ('2010', 0.12232472151790463), ('2010 census', 0.11056816207931947), ('community', 0.08775072505220155), ('population', 0.08245740356281878)], [('half', 0.23378309949153975), ('roughly mile', 0.1779704171702564), ('length', 0.17290157147431207), ('village', 0.06654984588933559)], [('one apostolic', 0.2508672284292285), ('one methodist', 0.22687241675656142), ('two church', 0.21673590150377975), ('one', 0.21002512965077885), ('home', 0.18662882171184203), ('two', 0.15637045451495374), ('methodist', 0.12997008262993925), ('glen ferris', 0.10874218555117467)], [('us route 60', 0.22372568072722696), ('norfolk southern', 0.21479943352672792), ('us route', 0.19801997206841493), ('village', 0.05266825134181397), ('railway', 0.04563018617274084)]]\n",
      "\n",
      "\n",
      "answer:  US 60\n",
      "number_sentences:  48\n",
      "number_reduced_sentences:  12\n",
      "number of questions:  13\n",
      "number of questions with answer neither yes nor no:  13\n",
      "common_phrases_num_le2:  11\n",
      "extended:  9\n",
      "answer_in_reduced_context:  8\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286, 0.10526315789473684, 0.27906976744186046, 0.18, 0.25]\n",
      "ratio of reduced context:  0.2516144899040965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id:  5ae0d91e55429924de1b7198\n",
      "question:  The 1988 American comedy film, The Great Outdoors, starred a four-time Academy Award nominee, who received a star on the Hollywood Walk of Fame in what year?\n",
      "question_phrases_text:  ['academy award', 'fame', '1988 american comedy film', '1988', 'american', 'four', 'four time academy award nominee', 'hollywood walk', 'hollywood walk fame', 'great outdoors', 'star', 'year']\n",
      "common_phrases:  ['academy award', '1988 american comedy film', 'fame', '1988', 'american', 'great outdoors', 'hollywood walk fame', 'hollywood walk', 'four', 'four time academy award nominee', 'star']\n",
      "extended_phrases:  ['academy award', '1988 american comedy film', 'american', 'fame', '1988', 'great outdoors', 'hollywood walk fame', 'hollywood walk', 'kevin norwood bacon', 'four', 'four time academy award nominee', 'star', 'year']\n",
      "paras_phrases\n",
      "[[('visual arts entertainment', 0.13699140018818887), ('los angeles', 0.13412616850226364), ('shane stanley', 0.11355335326794826), ('founder', 0.1045831034131072), ('multi - emmy award win filmmaker', 0.09949803890852427), ('june 15 1971', 0.09283143478690437), ('film television production company', 0.07992180790542083)], [('bret michaels music video', 0.16694904092859744), ('the rock', 0.1473379194903239), ('bret michaels', 0.13713679653258198), ('gridiron gang', 0.1342636129446875), ('rock', 0.12432104804785785), ('sony pictures', 0.12096432686305812), ('dwayne', 0.10175622548688236), ('johnson sony pictures', 0.08968964897301396), ('the rock johnson', 0.0774513258857919), ('hit show', 0.07164655979555774), ('love', 0.06086628520858967), ('rock love', 0.05549193135771125)], [('emmy award', 0.14280362040087533), ('four', 0.13457493887492591), ('nineteen', 0.10667143474373256), ('desperate passage series', 0.10616218711834938), ('second', 0.1056276334900514), ('sixteen', 0.10255161662533654), ('first', 0.09607420267302393), ('four time nominee', 0.08423655757103982), ('stanley', 0.08356515506271853), ('production', 0.06224077082887402), ('work', 0.05627032549733429)], [('academy award nominee gary busey', 0.20045237067006075), ('academy award', 0.1618418640831334), ('gary busey', 0.14462176136783625), ('sore eye', 0.13877463214299415), ('directorial debut', 0.09897866122710297), ('own screenplay', 0.0872195125332951), ('sight sore eye', 0.0781042938261484), ('sight', 0.06190633625908847), ('stanley', 0.05137492421610408)], [('film festival honor', 0.17355959764561957), ('prestigious award', 0.14732184815337768), ('international family film festival', 0.13256495541674515), ('good drama', 0.13024995837051054), ('cannes film festival', 0.12135059681307013), ('good drama international family film festival', 0.11746442511365461), ('dozen', 0.11192827843857829), ('2005', 0.11111382532919786), ('2006', 0.0814698949693095), ('film', 0.07593261654422823)]]\n",
      "\n",
      "\n",
      "[[('charles clarence robert orville cummings', 0.12691837413673737), ('dramatic film', 0.12572085061132973), ('comedy film', 0.12109392039077649), ('bob cummings', 0.10575303268131245), ('miss jones', 0.10459647679542135), ('murder', 0.08809997532058308), ('two', 0.0761681889342255), ('dial m murder', 0.07296305940239121), ('december', 0.07104514279100241), ('alfred hitchcock thriller', 0.06973032354719716), ('saboteur', 0.06887533099323237), ('american film television actor', 0.06810132562016862), ('june 9 1910', 0.06745010918216687), ('1943', 0.06384713998678737), ('december 2 1990', 0.06346599247748119), (\"princess o'rourke\", 0.058879060356497134), ('alfred hitchcock', 0.05707385899802894), ('1941', 0.05470623727245106), ('1954', 0.05470623727245106), ('american', 0.054458337805688026), ('1942', 0.05300729007698949), ('role', 0.034531869880011605), ('devil', 0.02776841146448684)], [('five primetime emmy award nomination', 0.2527335307123498), ('emmy award', 0.21718175656992406), ('primetime emmy award', 0.15765297842200537), ('best actor', 0.14789028003127636), ('five', 0.13063913242736871), ('primetime emmy award best actor single performance', 0.13038183493826122), ('1955', 0.114775154673383), ('cummings', 0.10582641394939507), ('single performance', 0.09522644286633064)], [('two star', 0.16106465932559139), ('fame', 0.13494195318309912), ('february', 0.11635842587879774), ('february 8 1960', 0.11627925838220057), ('two', 0.11261490701387368), ('motion picture television industry', 0.10562035120679829), ('hollywood walk', 0.09496039103097588), ('hollywood walk fame', 0.09045794390899752), ('contribution', 0.05945939382086725)], [('6816 hollywood boulevard', 0.21956628225683175), ('1718 vine street', 0.21296079511537103), ('television star', 0.1295295223380791), ('motion picture star', 0.11209274632630642)]]\n",
      "\n",
      "\n",
      "[[('lloyd vernet', 0.1523908702768513), ('beau bridges iii', 0.13688712798582198), ('director', 0.13608276348795434), ('american', 0.13608276348795434), ('lloyd vernet beau bridges iii', 0.12485983654004058), ('december 9 1941', 0.124491206984593), ('american actor', 0.1043281061914602)], [('one time grammy award winner', 0.18990907404220844), ('grammy award', 0.18293968591371634), ('golden globe', 0.18123591090954277), ('two time golden globe', 0.1793677533820979), ('one', 0.14815773002661642), ('two', 0.1477891208239342), ('emmy', 0.1334722884048236), ('three time emmy', 0.11745665340466777), ('three', 0.11307911141424411)], [('screen actors guild award', 0.2881807269930254), ('two time screen actors guild award nominee', 0.1873427256045405), ('two', 0.162392963043344)], [('7065 hollywood boulevard', 0.21368092415333917), ('hollywood boulevard', 0.20053788668727293), ('fame', 0.14094933864307588), ('7065', 0.12551205381239067), ('april', 0.122683141646035), ('april 7 2003', 0.1207785884094898), ('hollywood walk', 0.11028418556000319), ('hollywood walk fame', 0.10124760034848546), ('bridge', 0.09543498734617817), ('television industry', 0.08685544105913073), ('contribution', 0.06319405424413821), ('star', 0.06144534184069039)], [('fellow actor jeff bridges', 0.28738851260874937), ('actor lloyd bridges', 0.27930270952722197), ('lloyd bridges', 0.2371802712678422), ('jeff bridges', 0.22547465745984419), ('eld brother', 0.2046207378647836), ('son', 0.06429825335964137)]]\n",
      "\n",
      "\n",
      "[[('annette carol bening', 0.22661473493537404), ('american', 0.15713484026367722), ('may 29 1958', 0.14455480958013733), ('american actress', 0.12046772038736682)], [('lady macbeth', 0.1598524826672551), ('colorado shakespeare festival company', 0.1410728779732469), ('1984', 0.125098551621406), ('colorado shakespeare festival', 0.12282212317773653), ('1980', 0.11890249925320591), ('stage', 0.1123690293378833), ('american conservatory theatre', 0.11052128568921425), ('career', 0.06459795785064906)], [('best feature actress', 0.2140572768662127), ('tony award', 0.19225432127044179), ('coastal disturbances', 0.16532181141287466), ('1987', 0.14427761924962657), ('1987 tony award', 0.13759498052190985), ('broadway', 0.13313257131606965), ('broadway debut', 0.10408845064785668), ('play', 0.06713382060142963)], [('american beauty', 0.16164573909694202), ('academy award', 0.15925454133480504), ('julia', 0.11785113019775792), ('1990', 0.11785113019775792), ('2004', 0.11785113019775792), ('four time academy award nominee', 0.10878565864408424), ('1999', 0.10343381512719582), ('four', 0.09657686022051251), ('kids all right', 0.0893463611504729), ('kids', 0.06198888743511804), ('grifters', 0.045360921162651446)], [('fame', 0.18664129319733963), ('hollywood walk', 0.15890373282106462), ('2006', 0.15161648648983567), ('hollywood walk fame', 0.14215921437285148), ('star', 0.10264611749993356)]]\n",
      "\n",
      "\n",
      "[[('bear ferrah leni fawcett', 0.21302367207940637), ('ferrah leni fawcett', 0.19940716401492226), ('farrah fawcett', 0.17213032301824827), ('model', 0.14741934122123349), ('february', 0.12269116105235534), ('american', 0.1207207914711041), ('june', 0.11900678511679365), ('february 2 1947', 0.11318940802813726), ('june 25 2009', 0.10630487171524901), ('american actress', 0.0925508214949596), ('artist', 0.09154112794988492)], [('private investigator jill munroe', 0.13444768074693084), ('emmy award', 0.11475545246948118), ('globe award', 0.1137290946230835), ('six time golden globe award nominee', 0.11071877462561183), ('jill munroe', 0.10772893084841845), ('international fame', 0.10316430879134308), ('iconic red swimsuit poster', 0.0908037199482446), ('fawcett', 0.07396217065137747), ('six', 0.07043530963418704), ('four time emmy award nominee', 0.06776171862132017), ('charlie angels', 0.06568934872117412), ('history', 0.06438923606633294), ('television series', 0.06274051912244594), ('good sell pin poster', 0.05745818088428347), ('four', 0.05541582541792587), ('first season', 0.05451166359222646)], [('26', 0.17524759099031262), ('tv guide', 0.16212550397481268), ('50 great tv star', 0.1570258323835693), ('50', 0.1468842164130772), ('1996', 0.056888012398857435), ('time', 0.021896206181428738)]]\n",
      "\n",
      "\n",
      "[[('fame', 0.15584414711694294), ('hollywood walk', 0.13153242296807136), ('star actual location', 0.12598482368500588), ('hollywood walk fame', 0.11797014496717394), ('list', 0.08891504849935936)], [('various reason star', 0.23100742001673458), ('multiple occasion', 0.15214149302767954), ('award ceremony', 0.11263671837032635), ('star name', 0.08514682446378413), ('actual award ceremony', 0.07953131813083184), ('list', 0.03816841419212887)], [('fame website', 0.19817418660079922), ('hollywood walk', 0.13246111528008372), ('hollywood chamber', 0.12709481833363465), ('commerce', 0.12456467690137499), ('hollywood walk fame', 0.11988354847787619), ('hollywood chamber commerce', 0.10860708309550729), ('list', 0.08826932128648522)], [('surname', 0.21332652874908856), ('star', 0.08210941919904981)]]\n",
      "\n",
      "\n",
      "[[('kevin norwood bacon', 0.21498584908474117), ('musician', 0.14907119849998596), ('american', 0.14907119849998596), ('july 8 1958', 0.13713688337932442), ('american actor', 0.11428571428571428)], [('controversial historical conspiracy legal thriller', 0.12082185808711783), ('mystic river', 0.11883956659768584), ('musical drama film', 0.11403304299949804), ('legal drama', 0.10020371583161218), ('jfk', 0.09101942038096744), ('apollo', 0.09029614929559274), ('footloose', 0.09010930821266647), ('mystery drama', 0.08772084597937467), ('few good men', 0.08729402790773429), ('historical docudrama', 0.08027787675887083), ('1992', 0.06472733137734442), ('1995', 0.06238325895047598), ('2003', 0.06120578833917116), ('1991', 0.06024386566982744), ('1984', 0.05985470609439981), ('notable film', 0.05642709698868774)], [('former child abuser', 0.16378802217507116), ('dark role', 0.1399919260549876), ('1996', 0.09742792064522873), ('critically acclaimed performance', 0.09477340365292847), ('sadistic guard', 0.07431751776256396), ('woodsman', 0.05590169943749474), ('sleeper', 0.055137896326002266), ('bacon', 0.04816272009105328)], [('television', 0.18320942714312022), ('fox', 0.16327344405835942), ('fox drama series', 0.14721367574879674), ('follow', 0.07909911272854749)], [('emmy award', 0.1807476137990835), ('take chance', 0.14098445467883458), ('primetime emmy award nomination', 0.13129568337860087), ('screen actors guild award', 0.12885921666776282), ('golden globe award', 0.12081992016983528), ('chance', 0.10868017500205629), ('bacon', 0.10363195074140666), ('hbo original film', 0.10226342772068844), ('hbo', 0.09164848946440982), ('2009', 0.09024370581090241)], [('academy award', 0.20413512228331504), ('one', 0.14590699371125954), ('academy award nomination', 0.1398044925646595), ('good actor', 0.1165069637535197), ('guardian', 0.11600240425636389)], [('fame', 0.1533925170354953), ('bacon', 0.14909997915343004), ('motion picture industry', 0.13331716753319467), ('2003', 0.12501030112520084), ('hollywood walk', 0.10704576880458502), ('hollywood walk fame', 0.10228990992005664), ('star', 0.07883075073191032), ('contribution', 0.06884090011890735)]]\n",
      "\n",
      "\n",
      "[[('larry richard williams', 0.1755350846952279), ('stock', 0.15295987677547965), ('trader', 0.13613213961763115), ('politician', 0.11930462285525134), ('october 6 1942', 0.1119717160050878), ('american', 0.11185396861519634), ('commodity', 0.11155656770999314), ('montana', 0.09477721863053652), ('american author', 0.08575305510058528), ('state', 0.0668847640652246)], [('tony award', 0.21212814897204468), ('academy award', 0.20767676026580348), ('one time tony award nominee actress michelle williams', 0.20767103723384056), ('four time academy award', 0.16744702779527365), ('michelle williams', 0.16287149036252496), ('one', 0.132716484133799), ('four', 0.13179857592425878), ('father', 0.04729226893994203)]]\n",
      "\n",
      "\n",
      "[[('howard deutch', 0.16311189581581548), ('john hughes', 0.15659156794142548), ('1988 american comedy film', 0.15284514924532985), ('1988', 0.14366026669468868), ('american', 0.13756180372098564), ('great outdoors', 0.0820895478840533)], [('stephanie faracy', 0.20223149421869674), ('john candy', 0.19915287788985986), ('dan aykroyd', 0.1905134336246), ('annette bening', 0.18607301457705983), ('film debut', 0.0926073869179522)]]\n",
      "\n",
      "\n",
      "[[('voice actor', 0.18869479399117417), ('john arthur lithgow', 0.18120602746658443), ('musician', 0.1346743707223467), ('comedian', 0.1346743707223467), ('october 19 1945', 0.11830932270617033), ('singer', 0.11251137608679392), ('american', 0.11206578353439967), ('american actor', 0.1113617972790639), ('author', 0.0861383257045499)], [('two academy awards', 0.23059808911182575), ('two tony awards', 0.23041593622878273), ('two golden globe awards', 0.22506543673003232), ('four grammy awards', 0.2234590936223013), ('four drama desk awards', 0.22039036919194105), ('academy awards', 0.2152584639097386), ('emmy awards', 0.21446827623686376), ('three screen actors guild awards', 0.21172491411634461), ('six emmy awards', 0.21147669749267758), ('golden globe awards', 0.2114679124469245), ('grammy awards', 0.2114327799328829), ('drama desk awards', 0.2101621742012601), ('two', 0.13761484768797583), ('four', 0.12794696395874997), ('three', 0.0971759439984417), ('six', 0.0871773906630273), ('american comedy award', 0.08041587370841931)], [('fame', 0.1804467468574445), ('american theater hall', 0.14958321642669695), ('american theater hall fame', 0.13613982440041902), ('lithgow', 0.11555693043323635), ('hollywood walk', 0.11441270720744824), ('hollywood walk fame', 0.11359497704250975), ('star', 0.07671321511219399)]]\n",
      "\n",
      "\n",
      "answer:  2006\n",
      "number_sentences:  40\n",
      "number_reduced_sentences:  23\n",
      "number of questions:  14\n",
      "number of questions with answer neither yes nor no:  14\n",
      "common_phrases_num_le2:  12\n",
      "extended:  10\n",
      "answer_in_reduced_context:  9\n",
      "reduced_context_ratios:  [0.3235294117647059, 0.08695652173913043, 0.0392156862745098, 0.22950819672131148, 0.5625, 0.2, 0.39622641509433965, 0.27586206896551724, 0.34285714285714286, 0.10526315789473684, 0.27906976744186046, 0.18, 0.25, 0.575]\n",
      "ratio of reduced context:  0.2747134549109468\n"
     ]
    }
   ],
   "source": [
    "# debug: check whether convert_hotpot_to_squad_format() works\n",
    "import os\n",
    "os.chdir('/xdisk/msurdeanu/fanluo/hotpotQA/')\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/hotpot_train_v1.1.json | ../jq-linux64 -c '.[2:16]' > small.json\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/hotpot_train_v1.1.json | ../jq-linux64 -c '.[380:400]' > small_dev.json\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/hotpot_train_v1.1.json | ../jq-linux64 -c '.[31:50]' > sample.json\n",
    "\n",
    "import json\n",
    "with open(\"/xdisk/msurdeanu/fanluo/hotpotQA/small.json\", \"r\", encoding='utf-8') as f:  \n",
    "    convert_hotpot_to_squad_format(json.load(f))\n",
    "#     json_dict = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "#     print(json.dumps(json_dict[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### longfomer's fine-tuning\n",
    "\n",
    "\n",
    "- For answer span extraction we use BERT’s QA model with addition of a question type (yes/no/span) classification head over the first special token ([CLS]).\n",
    "\n",
    "- For evidence extraction we apply 2 layer feedforward networks on top of the representations corresponding to sentence and paragraph tokens to get the corresponding evidence prediction scores and use binary cross entropy loss to train the model.\n",
    "\n",
    "- We combine span, question classification, sentence, and paragraphs losses and train the model in a multitask way using linear combination of losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Section2: This is modified from longfomer's fine-tuning with triviaqa.py from https://github.com/allenai/longformer/blob/master/scripts/triviaqa.py\n",
    "# !conda install transformers --yes\n",
    "# !conda install cudatoolkit=10.0 --yes\n",
    "# !python -m pip install git+https://github.com/allenai/longformer.git\n",
    "####requirements.txt:torch>=1.2.0, transformers>=3.0.2, tensorboardX, pytorch-lightning==0.6.0, test-tube==0.7.5\n",
    "# !conda install -c conda-forge regex --force-reinstall --yes\n",
    "# !conda install pytorch-lightning -c conda-forge\n",
    "# !pip install jdc \n",
    "# !pip install test-tube \n",
    "# !conda install ipywidgets --yes\n",
    "# !conda update --force conda --yes  \n",
    "# !jupyter nbextension enable --py widgetsnbextension \n",
    "# !conda install jupyter --yes\n",
    "\n",
    "# need to run this every time start this notebook, to add python3.7/site-packages to sys.pat, in order to import ipywidgets, which is used when RobertaTokenizer.from_pretrained('roberta-base') \n",
    "import sys\n",
    "sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.overrides.data_parallel import LightningDistributedDataParallel\n",
    "from pytorch_lightning.logging import TestTubeLogger    # sometimes pytorch_lightning.loggers works instead\n",
    "\n",
    "\n",
    "from longformer.longformer import Longformer\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "import jdc\n",
    "from more_itertools import locate\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/pytorch_lightning/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(pl.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqaDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_, \\_\\_getitem\\_\\_ and \\_\\_len\\_\\_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hotpotqaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Largely based on\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
    "    and\n",
    "    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride,\n",
    "                 max_num_answers, ignore_seq_with_no_answers, max_question_len):\n",
    "        assert os.path.isfile(file_path)\n",
    "        self.file_path = file_path\n",
    "        with open(self.file_path, \"r\", encoding='utf-8') as f:\n",
    "            print(f'reading file: {self.file_path}')\n",
    "            self.data_json = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "#             print(self.data_json[0])\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_doc_len = max_doc_len\n",
    "        self.doc_stride = doc_stride\n",
    "        self.max_num_answers = max_num_answers\n",
    "        self.ignore_seq_with_no_answers = ignore_seq_with_no_answers\n",
    "        self.max_question_len = max_question_len\n",
    "\n",
    "        print(tokenizer.all_special_tokens)\n",
    "        print(tokenizer.all_special_ids)\n",
    "    \n",
    "        # A mapping from qid to an int, which can be synched across gpus using `torch.distributed`\n",
    "        if 'train' not in self.file_path:  # only for the evaluation set \n",
    "            self.val_qid_string_to_int_map =  \\\n",
    "                {\n",
    "                    entry[\"paragraphs\"][0]['qas'][0]['id']: index\n",
    "                    for index, entry in enumerate(self.data_json)\n",
    "                }\n",
    "        else:\n",
    "            self.val_qid_string_to_int_map = None\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_json)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data_json[idx]\n",
    "        tensors_list = self.one_example_to_tensors(entry, idx)\n",
    "        assert len(tensors_list) == 1\n",
    "        return tensors_list[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### one_example_to_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     106,
     122,
     147,
     162
    ]
   },
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    def one_example_to_tensors(self, example, idx):\n",
    "        def is_whitespace(c):\n",
    "            if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "                return True\n",
    "            return False\n",
    "        tensors_list = []\n",
    "        for paragraph in example[\"paragraphs\"]:  # example[\"paragraphs\"] only contains one paragraph in hotpotqa\n",
    "            paragraph_text = paragraph[\"context\"]\n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            for c in paragraph_text:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        doc_tokens.append(c) # add a new token\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c  # append the character to the last token\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question_text = qa[\"question\"]\n",
    "#                 print(\"question text: \", question_text)  \n",
    "                sp_sent = qa[\"is_sup_fact\"]\n",
    "                sp_para = qa[\"is_supporting_para\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                \n",
    "                p_list = list(locate(doc_tokens , lambda x: x == \"<p>\")) \n",
    "                assert(len(p_list) == len(sp_para))\n",
    "                s_list = list(locate(doc_tokens , lambda x: x == \"<s>\"))\n",
    "#                 \n",
    "#                 if(len(s_list) + len(p_list) != len(sp_sent)):\n",
    "#                     print(\"len(s_list):\", len(s_list))\n",
    "#                     print(\"len(p_list):\", len(p_list))\n",
    "#                     print(\"len(sp_sent):\", len(sp_sent))\n",
    "#                     print(\"sp_sent\", sp_sent)\n",
    "#                     print(\"paragraph_text\", paragraph_text)\n",
    "#                     print(\"doc_tokens\", doc_tokens)\n",
    "                assert(len(s_list) + len(p_list) == len(sp_sent) )\n",
    "                \n",
    "                # keep all answers in the document, not just the first matched answer. It also added the list of textual answers to make evaluation easy.\n",
    "                answer_spans = []\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    orig_answer_text = answer[\"text\"]\n",
    "#                     print(\"orig_answer_text: \", orig_answer_text)\n",
    "                    answer_start = answer[\"answer_start\"]\n",
    "                    answer_end = answer[\"answer_end\"]  \n",
    "                    if(answer_start >= 0 and answer_end > 0):\n",
    "                        try:\n",
    "                            start_word_position = char_to_word_offset[answer_start]\n",
    "                            end_word_position = char_to_word_offset[answer_end-1]\n",
    "#                             print(\"answer by start_word_position and end_word_position: \", doc_tokens[start_word_position: end_word_position+1])\n",
    "                        except:\n",
    "                            print(f'error: Reading example {idx} failed')\n",
    "                            start_word_position = -3\n",
    "                            end_word_position = -3\n",
    "                            \n",
    "                    else:\n",
    "                        start_word_position = answer[\"answer_start\"]\n",
    "                        end_word_position = answer[\"answer_end\"]\n",
    "                    answer_spans.append({'start': start_word_position, 'end': end_word_position})\n",
    "\n",
    "                    \n",
    "                # ===== Given an example, convert it into tensors  =============\n",
    "                query_tokens = self.tokenizer.tokenize(question_text)\n",
    "                query_tokens = query_tokens[:self.max_question_len]\n",
    "                tok_to_orig_index = []\n",
    "                orig_to_tok_index = []\n",
    "                all_doc_tokens = []\n",
    "                \n",
    "                # each original token in the context is tokenized to multiple sub_tokens\n",
    "                for (i, token) in enumerate(doc_tokens):\n",
    "                    orig_to_tok_index.append(len(all_doc_tokens))\n",
    "                    # hack: the line below should have been `self.tokenizer.tokenize(token')`\n",
    "                    # but roberta tokenizer uses a different subword if the token is the beginning of the string\n",
    "                    # or in the middle. So for all tokens other than the first, simulate that it is not the first\n",
    "                    # token by prepending a period before tokenizing, then dropping the period afterwards\n",
    "                    sub_tokens = self.tokenizer.tokenize(f'. {token}')[1:] if i > 0 else self.tokenizer.tokenize(token)\n",
    "                    for sub_token in sub_tokens:\n",
    "                        tok_to_orig_index.append(i)\n",
    "                        all_doc_tokens.append(sub_token)\n",
    "                \n",
    "                # all sub tokens, truncate up to limit\n",
    "                all_doc_tokens = all_doc_tokens[:self.max_doc_len-3]\n",
    "\n",
    "                # The -3 accounts for [CLS], [q], [/q]  \n",
    "                max_tokens_per_doc_slice = self.max_seq_len - len(query_tokens) - 3\n",
    "                assert max_tokens_per_doc_slice > 0\n",
    "                if self.doc_stride < 0:                           # default\n",
    "                    # negative doc_stride indicates no sliding window, but using first slice\n",
    "                    self.doc_stride = -100 * len(all_doc_tokens)  # large -negtive value for the next loop to execute once\n",
    "                \n",
    "                # inputs to the model\n",
    "                input_ids_list = []\n",
    "                input_mask_list = []\n",
    "                segment_ids_list = []\n",
    "                start_positions_list = []\n",
    "                end_positions_list = []\n",
    "                q_type_list = []\n",
    "                sp_sent_list =  [1 if ss else 0 for ss in sp_sent]\n",
    "                sp_para_list = [1 if sp else 0 for sp in sp_para]\n",
    "                \n",
    "                for slice_start in range(0, len(all_doc_tokens), max_tokens_per_doc_slice - self.doc_stride):    # execute once by default\n",
    "                    slice_end = min(slice_start + max_tokens_per_doc_slice, len(all_doc_tokens))\n",
    "\n",
    "                    doc_slice_tokens = all_doc_tokens[slice_start:slice_end]\n",
    "                    tokens = [\"<cls>\"] + [\"<q>\"] + query_tokens + [\"</q>\"] + doc_slice_tokens   \n",
    "#                     print(\"tokens: \", tokens)\n",
    "                    segment_ids = [0] * (len(query_tokens) + 3) + [1] *  len(doc_slice_tokens) \n",
    "                    assert len(segment_ids) == len(tokens)\n",
    "\n",
    "                    input_ids = self.tokenizer.convert_tokens_to_ids(tokens)   \n",
    "                    input_mask = [1] * len(input_ids)\n",
    "\n",
    "                    if self.doc_stride >= 0:  # no need to pad if document is not strided\n",
    "                        # Zero-pad up to the sequence length.\n",
    "                        padding_len = self.max_seq_len - len(input_ids)\n",
    "                        input_ids.extend([self.tokenizer.pad_token_id] * padding_len)\n",
    "                        input_mask.extend([0] * padding_len)\n",
    "                        segment_ids.extend([0] * padding_len)\n",
    "\n",
    "                        assert len(input_ids) == self.max_seq_len\n",
    "                        assert len(input_mask) == self.max_seq_len\n",
    "                        assert len(segment_ids) == self.max_seq_len\n",
    "\n",
    "                    # ===== answer positions tensors  ============\n",
    "                    doc_offset = len(query_tokens) + 3 - slice_start  # where context starts\n",
    "                    start_positions = []\n",
    "                    end_positions = []\n",
    "                    q_type = None\n",
    "                    assert(len(answer_spans) > 0)\n",
    "                    for answer_span in answer_spans:\n",
    "                        start_position = answer_span['start']   # reletive to context\n",
    "                        end_position = answer_span['end']\n",
    "                        if(start_position >= 0):\n",
    "                            tok_start_position_in_doc = orig_to_tok_index[start_position]  # sub_tokens postion reletive to context\n",
    "                            not_end_of_doc = int(end_position + 1 < len(orig_to_tok_index))\n",
    "                            tok_end_position_in_doc = orig_to_tok_index[end_position + not_end_of_doc] - not_end_of_doc\n",
    "                            if tok_start_position_in_doc < slice_start or tok_end_position_in_doc > slice_end:\n",
    "                                assert(\"this answer is outside the current slice\")   # only has one slice with the large negative doc_stride\n",
    "                                continue                                \n",
    "                            start_positions.append(tok_start_position_in_doc + doc_offset)   # sub_tokens postion reletive to begining of all the tokens, including query sub tokens  \n",
    "                            end_positions.append(tok_end_position_in_doc + doc_offset)\n",
    "#                             print(\"answer by start_positions and end_positions: \", tokens[tok_start_position_in_doc + doc_offset: tok_end_position_in_doc + doc_offset+1])\n",
    "                            if(q_type != None and q_type != 0):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 0\n",
    "                \n",
    "                        elif(start_position == -1):\n",
    "                            if(q_type != None and q_type != 1):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 1\n",
    "                            start_positions.append(-1)  # -1 is the IGNORE_INDEX, will be ignored\n",
    "                            end_positions.append(-1)     \n",
    "                        elif(start_position == -2):\n",
    "                            if(q_type != None and q_type != 2):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 2\n",
    "                            start_positions.append(-1)\n",
    "                            end_positions.append(-1)     \n",
    "                        else:\n",
    "                            assert(\"unknown start_positions\")\n",
    "                            continue\n",
    "                    assert len(start_positions) == len(end_positions)\n",
    "                    \n",
    "                    \n",
    "                    if self.ignore_seq_with_no_answers and len(start_positions) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # answers from start_positions and end_positions if > self.max_num_answers\n",
    "                    start_positions = start_positions[:self.max_num_answers]\n",
    "                    end_positions = end_positions[:self.max_num_answers]\n",
    "\n",
    "                    # -1 padding up to self.max_num_answers\n",
    "                    padding_len = self.max_num_answers - len(start_positions)\n",
    "                    start_positions.extend([-1] * padding_len)\n",
    "                    end_positions.extend([-1] * padding_len)\n",
    "\n",
    "                    # replace duplicate start/end positions with `-1` because duplicates can result into -ve loss values\n",
    "                    found_start_positions = set()\n",
    "                    found_end_positions = set()\n",
    "                    for i, (start_position, end_position) in enumerate(zip(start_positions, end_positions)):\n",
    "                        if start_position in found_start_positions:\n",
    "                            start_positions[i] = -1\n",
    "                        if end_position in found_end_positions:\n",
    "                            end_positions[i] = -1\n",
    "                        found_start_positions.add(start_position)\n",
    "                        found_end_positions.add(end_position)\n",
    "\n",
    "                    input_ids_list.append(input_ids)\n",
    "                    input_mask_list.append(input_mask)\n",
    "                    segment_ids_list.append(segment_ids)\n",
    "                    start_positions_list.append(start_positions)\n",
    "                    end_positions_list.append(end_positions)\n",
    "                    q_type_list.append(q_type)\n",
    "                if (input_ids_list is None):\n",
    "                    print(\"input_ids_list is None\")\n",
    "                if (input_mask_list is None):\n",
    "                    print(\"input_mask_list is None\")\n",
    "                if (segment_ids_list is None):\n",
    "                    print(\"segment_ids_list is None\")\n",
    "                if (start_positions_list is None):\n",
    "                    print(\"start_positions_list is None\")\n",
    "                if (end_positions_list is None):\n",
    "                    print(\"end_positions_list is None\")\n",
    "                if (q_type_list is None):\n",
    "                    print(\"q_type_list is None\")\n",
    "                if (sp_sent_list is None):\n",
    "                    print(\"sp_sent_list is None\")\n",
    "                if (sp_para_list is None):\n",
    "                    print(\"sp_para_list is None\")\n",
    "                if (qa['id'] is None):\n",
    "                    print(\"qa['id'] is None\")\n",
    "                tensors_list.append((torch.tensor(input_ids_list), torch.tensor(input_mask_list), torch.tensor(segment_ids_list),\n",
    "                                     torch.tensor(start_positions_list), torch.tensor(end_positions_list), torch.tensor(q_type_list),\n",
    "                                      torch.tensor([sp_sent_list]),  torch.tensor([sp_para_list]),\n",
    "                                     qa['id']))    \n",
    "#                 tensors_list.append((doc_tokens))\n",
    "        return tensors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### collate_one_doc_and_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    @staticmethod\n",
    "    def collate_one_doc_and_lists(batch):\n",
    "        num_metadata_fields = 1  # qids  \n",
    "        fields = [x for x in zip(*batch)]\n",
    "        stacked_fields = [torch.stack(field) for field in fields[:-num_metadata_fields]]  # don't stack metadata fields\n",
    "        stacked_fields.extend(fields[-num_metadata_fields:])  # add them as lists not torch tensors\n",
    "\n",
    "        # always use batch_size=1 where each batch is one document\n",
    "        # will use grad_accum to increase effective batch size\n",
    "        assert len(batch) == 1\n",
    "        fields_with_batch_size_one = [f[0] for f in stacked_fields]\n",
    "        return fields_with_batch_size_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'collate_one_doc_and_lists',\n",
       " 'one_example_to_tensors']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__class__', type),\n",
       " ('__delattr__', <slot wrapper '__delattr__' of 'object' objects>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__doc__': '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    ',\n",
       "                '__init__': <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>,\n",
       "                '__len__': <function __main__.hotpotqaDataset.__len__(self)>,\n",
       "                '__getitem__': <function __main__.hotpotqaDataset.__getitem__(self, idx)>,\n",
       "                'one_example_to_tensors': <function __main__.one_example_to_tensors(self, example, idx)>,\n",
       "                'collate_one_doc_and_lists': <staticmethod at 0x7f8d9c59ce10>})),\n",
       " ('__dir__', <method '__dir__' of 'object' objects>),\n",
       " ('__doc__',\n",
       "  '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    '),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__init_subclass__', <function hotpotqaDataset.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <slot wrapper '__repr__' of 'object' objects>),\n",
       " ('__setattr__', <slot wrapper '__setattr__' of 'object' objects>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqaDataset.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'Dataset' objects>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers\n",
    "getmembers(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import isfunction\n",
    "functions_list = [o for o in getmembers(hotpotqaDataset) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqaDataset, torch.utils.data.dataset.Dataset, object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqaDataset)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'example', 'idx'], varargs=None, varkw=None, defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getfullargspec(hotpotqaDataset.one_example_to_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class hotpotqaDataset in module __main__:\n",
      "\n",
      "class hotpotqaDataset(torch.utils.data.dataset.Dataset)\n",
      " |  Largely based on\n",
      " |  https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
      " |  and\n",
      " |  https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      hotpotqaDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  one_example_to_tensors(self, example, idx)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  collate_one_doc_and_lists(batch)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_,  forward, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class hotpotqa(pl.LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super(hotpotqa, self).__init__()\n",
    "        self.args = args\n",
    "        self.hparams = args\n",
    "\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        num_new_tokens = self.tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<cls>\", \"<p>\", \"<q>\", \"</q>\"]})\n",
    "#         print(self.tokenizer.all_special_tokens)\n",
    "        self.tokenizer.model_max_length = self.args.max_seq_len\n",
    "        self.model = self.load_model()\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.num_labels = 2\n",
    "        self.qa_outputs = torch.nn.Linear(self.model.config.hidden_size, self.num_labels)\n",
    "        \n",
    "        self.dense_type = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_type = torch.nn.Linear(self.model.config.hidden_size, 3)   #  question type (yes/no/span) classification \n",
    "        self.dense_sp_sent = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_sp_sent = torch.nn.Linear(self.model.config.hidden_size, 1)    \n",
    "        self.dense_sp_para = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_sp_para = torch.nn.Linear(self.model.config.hidden_size, 1) \n",
    "        self.train_dataloader_object = self.val_dataloader_object  = None  # = self.test_dataloader_object = None\n",
    "    \n",
    "    def load_model(self):\n",
    "#         model = Longformer.from_pretrained(self.args.model_path)\n",
    "        model = Longformer.from_pretrained('longformer-base-4096')\n",
    "        for layer in model.encoder.layer:\n",
    "            layer.attention.self.attention_mode = self.args.attention_mode\n",
    "            self.args.attention_window = layer.attention.self.attention_window\n",
    "\n",
    "        print(\"Loaded model with config:\")\n",
    "        print(model.config)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        model.train()\n",
    "        return model\n",
    "\n",
    "#%%add_to hotpotqa    # does not seems to work for the @pl.data_loader decorator, missing which causes error \"validation_step() takes 3 positional arguments but 4 were given\"    \n",
    "###################################################### dataloaders ########################################################### \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        if self.train_dataloader_object is not None:\n",
    "            return self.train_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.train_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=self.args.ignore_seq_with_no_answers)\n",
    " \n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,   # set shuffle=False, otherwise it will sample a different subset of data every epoch with train_percent_check\n",
    "                        num_workers=self.args.num_workers,  \n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "        self.train_dataloader_object = dl\n",
    "        return self.train_dataloader_object\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        if self.val_dataloader_object is not None:\n",
    "            return self.val_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=False)  # evaluation data should keep all examples \n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,\n",
    "                        num_workers=self.args.num_workers, \n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "        self.val_dataloader_object = dl\n",
    "        return self.val_dataloader_object\n",
    "\n",
    "    # @pl.data_loader\n",
    "    # def test_dataloader(self):\n",
    "    #     if self.test_dataloader_object is not None:\n",
    "    #         return self.test_dataloader_object\n",
    "    #     dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "    #                               max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "    #                               doc_stride=self.args.doc_stride,\n",
    "    #                               max_num_answers=self.args.max_num_answers,\n",
    "    #                               max_question_len=self.args.max_question_len,\n",
    "    #                               ignore_seq_with_no_answers=False)  # evaluation data should keep all examples\n",
    "\n",
    "    #     dl = DataLoader(dataset, batch_size=1, shuffle=False,\n",
    "    #                     num_workers=self.args.num_workers, sampler=None,\n",
    "    #                     collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "    #     self.test_dataloader_object = dl\n",
    "    #     return self.test_dataloader_object\n",
    "\n",
    "#%%add_to hotpotqa  \n",
    "    def forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para):\n",
    "#         print(\"input_ids: \" + str(input_ids)) \n",
    "#         print(\"attention_mask: \" + str(attention_mask)) \n",
    "#         print(\"segment_ids: \" + str(segment_ids)) \n",
    "#         print(\"start_positions: \" + str(start_positions)) \n",
    "#         print(\"end_positions: \" + str(end_positions)) \n",
    "        print(\"q_type: \" + str(q_type))\n",
    "#         print(\"sp_sent: \" + str(sp_sent)) \n",
    "#         print(\"sp_para: \" + str(sp_para)) \n",
    "        print(\"size of input_ids: \" + str(input_ids.size())) \n",
    "        print(\"size of attention_mask: \" + str(attention_mask.size()))\n",
    "        print(\"size of segment_ids: \" + str(segment_ids.size()))\n",
    "        print(\"size of start_positions: \" + str(start_positions.size()))\n",
    "        print(\"size of end_positions:\" + str(end_positions.size()))\n",
    "        print(\"size of q_type:\" + str(q_type.size()))\n",
    "        print(\"size of sp_sent: \" + str(sp_sent.size()))\n",
    "        print(\"size of sp_para: \" + str(sp_para.size())) \n",
    "#         if(input_ids.size(0) > 1):\n",
    "#             assert(\"multi rows per document\")\n",
    "        # Each batch is one document, and each row of the batch is a chunck of the document.    ????\n",
    "        # Make sure all rows have the same question length.\n",
    "        \n",
    "#         size of input_ids: torch.Size([1, 1495])\n",
    "#         size of attention_mask: torch.Size([1, 1495])\n",
    "#         size of segment_ids: torch.Size([1, 1495])\n",
    "#         size of start_positions: torch.Size([1, 64])   # multiple occurences of the same answer string, -1 padding up to self.max_num_answers\n",
    "#         size of end_positions: torch.Size([1, 64])\n",
    "#         size of q_type: torch.Size([1, 1])\n",
    "#         size of sp_sent: torch.Size([1, 40])           # number of sentences in context\n",
    "#         size of sp_para: torch.Size([1, 10])\n",
    "#         print(\"input tokens: \", self.tokenizer.convert_ids_to_tokens(input_ids[0].tolist()) )\n",
    "#         print(\"sp_para: \" + str(sp_para)) \n",
    "#         print(\"sp_sent: \" + str(sp_sent)) \n",
    "#         print(\"sp_sent_index: \" + str(torch.where(sp_sent.squeeze())[0].tolist()))\n",
    "        # sp_para: tensor([[0, 0, 0, 1, 0, 0, 0, 0, 1, 0]], device='cuda:0')\n",
    "        # sp_sent: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
    "        #          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]], device='cuda:0')\n",
    "        # sp_sent_index: [14, 17, 18, 35, 36]\n",
    "\n",
    "        # local attention everywhere\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "        \n",
    "        # global attention for the cls and all question tokens\n",
    "        question_end_index = self._get_special_index(input_ids, [\"</q>\"])\n",
    "#         if(question_end_index.size(0) == 1):\n",
    "#             attention_mask[:,:question_end_index.item()] = 2  \n",
    "#         else:\n",
    "        attention_mask[:,:question_end_index[0].item()] = 2  # from <cls> until </q>\n",
    "#             print(\"more than 1 <q> in: \", self.tokenizer.convert_ids_to_tokens(input_ids[0].tolist()) )\n",
    "        \n",
    "        # global attention for the sentence and paragraph special tokens  \n",
    "        sent_indexes = self._get_special_index(input_ids, [\"<p>\", \"<s>\"])\n",
    "        attention_mask[:, sent_indexes] = 2\n",
    "#         p_index = self._get_special_index(input_ids, [\"<p>\"])\n",
    "#         print(\"size of p_index: \" + str(p_index.size()))\n",
    "#         attention_mask[:, p_index] = 2 \n",
    "#         s_index = self._get_special_index(input_ids, [\"<s>\"])\n",
    "#         print(\"size of s_index: \" + str(s_index.size()))\n",
    "#         attention_mask[:, s_index] = 2\n",
    "        \n",
    "#         print(\"p_index:\", p_index) \n",
    "#         print(\"attention_mask: \", attention_mask)\n",
    "        \n",
    "\n",
    "        # sliding_chunks implemenation of selfattention requires that seqlen is multiple of window size\n",
    "        input_ids, attention_mask = pad_to_window_size(\n",
    "            input_ids, attention_mask, self.args.attention_window, self.tokenizer.pad_token_id)\n",
    "\n",
    "        sequence_output = self.model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask)[0]\n",
    "        print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "\n",
    "        # The pretrained hotpotqa model wasn't trained with padding, so remove padding tokens\n",
    "        # before computing loss and decoding.\n",
    "        padding_len = input_ids[0].eq(self.tokenizer.pad_token_id).sum()\n",
    "        if padding_len > 0:\n",
    "            sequence_output = sequence_output[:, :-padding_len]\n",
    "        print(\"size of sequence_output after removing padding: \" + str(sequence_output.size()))\n",
    "              \n",
    "        \n",
    "        ###################################### layers on top of sequence_output ##################################\n",
    "        \n",
    "\n",
    "        ### 1. answer start and end positions classification ###   \n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "#         print(\"size of logits: \" + str(logits.size())) \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "#         print(\"size of start_logits: \" + str(start_logits.size())) \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "#         print(\"size of start_logits after squeeze: \" + str(start_logits.size())) \n",
    "        end_logits = end_logits.squeeze(-1)\n",
    " \n",
    "        ### 2. type classification, similar as class LongformerClassificationHead(nn.Module) https://huggingface.co/transformers/_modules/transformers/modeling_longformer.html#LongformerForSequenceClassification.forward ### \n",
    "#         print(\"size of sequence_output[:,0]: \" + str(sequence_output[:,0].size()))\n",
    "        type_logits = self.linear_type(sequence_output[:,0])\n",
    "        print(\"size of type_logits: \" + str(type_logits.size()))\n",
    "        \n",
    "        ### 3. supporting paragraph classification ### \n",
    "        p_index = self._get_special_index(input_ids, [\"<p>\"])\n",
    "        print(\"size of p_index: \" + str(p_index.size()))\n",
    "        sp_para_output = sequence_output[:,p_index,:]\n",
    "        print(\"size of sp_para_output: \" + str(sp_para_output.size()))      \n",
    "        sp_para_output_t = self.linear_sp_para(sp_para_output)\n",
    "#         print(\"size of sp_para_output_t: \" + str(sp_para_output_t.size()))  \n",
    "\n",
    "         # linear_sp_sent generates a single score for each sentence, instead of 2 scores for yes and no. \t\n",
    "        # Argument the score with additional score=0. The same way did in the HOTPOTqa paper\n",
    "        sp_para_output_aux = torch.zeros(sp_para_output_t.shape, dtype=torch.float, device=sp_para_output_t.device) \n",
    "        predict_support_para = torch.cat([sp_para_output_aux, sp_para_output_t], dim=-1).contiguous() \n",
    " \n",
    "        ### 4. supporting fact classification ###     \n",
    "        # the first sentence in a paragraph is leading by <p>, other sentences are leading by <s>\n",
    "        \n",
    "#         sent_indexes = torch.sort(torch.cat((s_index, p_index)))[0] # torch.sort returns a 'torch.return_types.sort' object has 2 items: values, indices\n",
    "#         print(\"size of sent_indexes: \" + str(sent_indexes.size()))\n",
    "        print(\"sent_indexes: \", sent_indexes)\n",
    "        sp_sent_output = sequence_output[:,sent_indexes,:]\n",
    "#         print(\"size of sp_sent_output: \" + str(sp_sent_output.size()))      \n",
    "        sp_sent_output_t = self.linear_sp_sent(sp_sent_output)\n",
    "#         print(\"size of sp_sent_output_t: \" + str(sp_sent_output_t.size()))       \n",
    "        sp_sent_output_aux = torch.zeros(sp_sent_output_t.shape, dtype=torch.float, device=sp_sent_output_t.device) \n",
    "        predict_support_sent = torch.cat([sp_sent_output_aux, sp_sent_output_t], dim=-1).contiguous() \n",
    "        \n",
    "        outputs = (start_logits, end_logits, type_logits, sp_para_output_t, sp_sent_output_t)  \n",
    "        #outputs = (torch.sigmoid(start_logits), torch.sigmoid(end_logits), torch.sigmoid(type_logits), torch.sigmoid(sp_para_output_t), torch.sigmoid(sp_sent_output_t))  \n",
    "        answer_loss, type_loss, sp_para_loss, sp_sent_loss  = self.loss_computation(start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)\n",
    "#         print(\"answer_loss: \" + str(answer_loss))\n",
    "#         print(\"type_loss: \" + str(type_loss))\n",
    "#         print(\"sp_para_loss: \" + str(sp_para_loss))\n",
    "#         print(\"sp_sent_loss: \" + str(sp_sent_loss))\n",
    "        outputs = (answer_loss, type_loss, sp_para_loss, sp_sent_loss,) + outputs    \n",
    "        return outputs\n",
    "    \n",
    "    def loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent):\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "\n",
    "            if not self.args.regular_softmax_loss:\n",
    "                # loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\n",
    "                # NOTE: this returns sum of losses, not mean, so loss won't be normalized across different batch sizes\n",
    "                # but batch size is always 1, so this is not a problem\n",
    "                start_loss = self.or_softmax_cross_entropy_loss_one_doc(start_logits, start_positions, ignore_index=-1)\n",
    "#                 print(\"start_positions: \" + str(start_positions)) \n",
    "#                 print(\"start_loss: \" + str(start_loss)) \n",
    "                end_loss = self.or_softmax_cross_entropy_loss_one_doc(end_logits, end_positions, ignore_index=-1)\n",
    "#                 print(\"end_positions: \" + str(end_positions)) \n",
    "#                 print(\"end_loss: \" + str(end_loss)) \n",
    "\n",
    "#                 binary_loss = torch.nn.BCELoss()\n",
    "# #                 print(\"sp_para_output_t.squeeze().type(): \", sp_para_output_t.squeeze().type())\n",
    "# #                 print(\"sp_para.to(dtype=torch.half, device=sp_para.device).type(): \", sp_para.to(dtype=torch.half, device=sp_para.device).type())\n",
    "#                 sp_para_loss = binary_loss(sp_para_output_t.squeeze(), sp_para.squeeze().to(dtype=torch.half, device=sp_para.device))\n",
    "#                 sp_sent_loss = binary_loss(sp_sent_output_t.squeeze(), sp_sent.squeeze().to(dtype=torch.half, device=sp_sent.device))\n",
    "                \n",
    "#                 sp_para_loss = torch.tensor([0.0], device = predict_support_para.device )\n",
    "# #                 print(\"predict_support_para.squeeze(): \", predict_support_para.squeeze())\n",
    "# #                 print(\"sp_para.squeeze(): \", sp_para.squeeze())\n",
    "#                 for para_predict, para_gold in zip(predict_support_para.squeeze(), sp_para.squeeze()):\n",
    "# #                     print(\"para_predict.unsqueeze(0): \", para_predict.unsqueeze(0))\n",
    "# #                     print(\" para_gold.unsqueeze(0): \",  para_gold.unsqueeze(0))\n",
    "\n",
    "                # only one example per batch\n",
    "    \n",
    "#                 print(\"size of sp_para_output_t: \" + str(sp_para_output_t.size()))      \n",
    "#                 print(\"size of sp_sent_output_t: \" + str(sp_sent_output_t.size()))  \n",
    "\n",
    "            else: \n",
    "                start_positions = start_positions[:, 0:1]   # only use the top1 start_position considering only one appearance of the answer string\n",
    "                end_positions = end_positions[:, 0:1]\n",
    "                start_loss = crossentropy(start_logits, start_positions[:, 0])\n",
    "                end_loss = crossentropy(end_logits, end_positions[:, 0])\n",
    "                \n",
    "\n",
    "            crossentropy = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "            type_loss_or_softmax_cross_entropy = self.or_softmax_cross_entropy_loss_one_doc(type_logits, q_type.unsqueeze(0), ignore_index=-1)\n",
    "            type_loss = crossentropy(type_logits, q_type) \n",
    "            print(\"type_loss_or_softmax_cross_entropy: \", type_loss_or_softmax_cross_entropy)\n",
    "            print(\"type_loss: \", type_loss) \n",
    "            \n",
    "            crossentropy_average = torch.nn.CrossEntropyLoss(reduction = 'mean', ignore_index=-1)     \n",
    "# #         print(\"predict_support_para.view(-1, 2).size()\", predict_support_para.view(-1, 2).size())\n",
    "# #         print(\"sp_para.view(-1).size()\", sp_para.view(-1).size()) \n",
    "            sp_para_loss = crossentropy_average(predict_support_para.view(-1, 2), sp_para.view(-1))\n",
    "            sp_sent_loss = crossentropy_average(predict_support_sent.view(-1, 2), sp_sent.view(-1))      \n",
    "                \n",
    "            answer_loss = (start_loss + end_loss) / 2 \n",
    "        return answer_loss, type_loss, sp_para_loss, sp_sent_loss  \n",
    "\n",
    "\n",
    "#     %%add_to hotpotqa    \n",
    "    def _get_special_index(self, input_ids, special_tokens):\n",
    "        assert(input_ids.size(0)==1) \n",
    "        mask = input_ids != input_ids # initilaize \n",
    "        for special_token in special_tokens:\n",
    "            mask = torch.logical_or(mask, input_ids.eq(self.tokenizer.convert_tokens_to_ids(special_token))) \n",
    "#             print(\"mask: \", mask)\n",
    "        token_indices = torch.nonzero(mask)    \n",
    "         \n",
    "        ### FOR DEBUG ###\n",
    "        # input_ids = torch.tensor([[0.6, 0.0, 0.6, 0.0]]) \n",
    "        # token_indices =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "        return token_indices[:,1]    \n",
    "\n",
    "    def or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1):\n",
    "        \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "#         assert logits.ndim == 2\n",
    "#         assert target.ndim == 2\n",
    "#         assert logits.size(0) == target.size(0) \n",
    "        \n",
    "        # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "        # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "        # target are indexes of tokens, padded with ignore_index=-1\n",
    "        # logits are scores (one for each label) for each token\n",
    "#         print(\"or_softmax_cross_entropy_loss_one_doc\" ) \n",
    "#         print(\"logits: \" + str(logits)) \n",
    "#         print(\"size of logits: \" + str(logits.size()))                    # torch.Size([1, 746]), 746 is number of all tokens \n",
    "#         print(\"size of target: \" + str(target.size()))                    # torch.Size([1, 64]),  -1 padded\n",
    "#         print(\"target: \" + str(target)) \n",
    "\n",
    "        # compute a target mask\n",
    "        target_mask = target == ignore_index\n",
    "        # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "        masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "#         print(\"masked_target: \" + str(masked_target))     \n",
    "        # gather logits\n",
    "        gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    "#         print(\"size of gathered_logits: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"gathered_logits: \" + str(gathered_logits)) \n",
    "        # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "        gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    "#         print(\"gathered_logits after -inf: \" + str(gathered_logits))      # tensor([[0.4382,   -inf,   -inf,   -inf,   -inf,...]])\n",
    "        \n",
    "        # each batch is one example\n",
    "        gathered_logits = gathered_logits.view(1, -1)\n",
    "        logits = logits.view(1, -1)\n",
    "#         print(\"size of gathered_logits after view: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"size of logits after view: \" + str(logits.size()))                    # torch.Size([1, 746])　　\n",
    "\n",
    "        # numerator = log(sum(exp(gathered logits)))\n",
    "        log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_score: \" + str(log_score)) \n",
    "        # denominator = log(sum(exp(logits)))\n",
    "        log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_norm: \" + str(log_norm)) \n",
    "        \n",
    "        # compute the loss\n",
    "        loss = -(log_score - log_norm)\n",
    "#         print(\"loss: \" + str(loss))\n",
    "        \n",
    "        # some of the examples might have a loss of `inf` when `target` is all `ignore_index`: when computing start_loss and end_loss for question with the gold answer of yes/no \n",
    "        # when `target` is all `ignore_index`, loss is 0 \n",
    "        loss = loss[~torch.isinf(loss)].sum()\n",
    "#         loss = torch.tanh(loss)\n",
    "#         print(\"final loss: \" + str(loss)) \n",
    "        return loss \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# input_ids = torch.tensor([[-1, 5, -1, 2]])\n",
    "# input_ids.size(0)\n",
    "# token_indices =  torch.nonzero(input_ids == torch.tensor(-1))[:,1]\n",
    "# # token_indices\n",
    "# # token_indices.item()\n",
    "# # indices =  torch.LongTensor([[2],[0,2]])\n",
    "\n",
    "# # torch.gather(input_ids, 1, token_indices.unsqueeze(0))\n",
    "# # p_index = token_indices.view(input_ids.size(0), -1)[:,1::2]   \n",
    "# # attention_mask = torch.ones(input_ids.shape, dtype=torch.long) \n",
    "# # attention_mask[:,token_indices] = 2\n",
    "# # attention_mask\n",
    "# p_index = torch.tensor([1, 3, 4])\n",
    "# s_index = torch.tensor([1,3,6])\n",
    "# torch.sort(torch.cat((s_index, p_index)))[0]\n",
    "# attention_mask.view(-1)[ p_index.view(-1), :].view(attention_mask.size(0), -1)\n",
    "# # for pi in p_index[0]:\n",
    "# #     attention_mask[:, pi] = 2\n",
    "# # attention_mask\n",
    "# # s_index = torch.tensor([[1,3]])\n",
    "# # torch.sort(torch.cat((p_index, s_index), -1), -1)\n",
    "\n",
    "# sequence_output  = torch.tensor([[[-1, 5, -1, 2],\n",
    "#                                  [-2, 27, 2, 9],\n",
    "#                                  [3, 6, 1, 65],\n",
    "#                                  [52, 36, 13, 2],\n",
    "#                                  [73, 26, 1, 7]\n",
    "#                                 ]])\n",
    "\n",
    "# sp_para_output_t   = torch.tensor([[[-1],\n",
    "#                                  [-2 ],\n",
    "#                                  [3],\n",
    "#                                  [52],\n",
    "#                                  [73]\n",
    "#                                 ]])\n",
    "# torch.zeros(sp_para_output_t.shape, dtype=torch.float) \n",
    "\n",
    "# print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "# # print(\"size of p_index.unsqueeze(0).unsqueeze(-1): \" + str(p_index.unsqueeze(0).size()))\n",
    "# sequence_output[:,p_index,:]\n",
    "# b = torch.tensor([0, 1, 2, 3])\n",
    "# p_index.unsqueeze(-1) * b\n",
    "\n",
    "# input_ids = torch.tensor([[0.2, 0.0, 0.6, 0.6], [0.2, 0.6, 0.0, 0.0]]) \n",
    "# # input_ids.tolist()\n",
    "# p_index =  torch.nonzero(input_ids == torch.tensor(0.2))\n",
    "# print(p_index)\n",
    "# s_index =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "# print(s_index)\n",
    "\n",
    "# sp_sent = torch.tensor([[0, 1, 1, 0]])\n",
    "# torch.nonzero(sp_sent, as_tuple=True)[1]\n",
    "# cat_index = torch.tensor([])\n",
    "# cat_index = torch.cat((cat_index, ids[0][1]))\n",
    "# print(ids)\n",
    "# print(cat_index)\n",
    "# p_index[p_index[:,0] == 0]\n",
    "\n",
    "# cat_index[cat_index[:,0].argsort()]\n",
    "\n",
    "# sorted(torch.cat((p_index, s_index)), key = lambda x: x[0])\n",
    "# torch.sort(torch.cat((p_index, s_index)), 0)[0]\n",
    "# for cor in token_indices:\n",
    "#     attention_mask[cor[0].item()][cor[1].item()] = 2\n",
    "# attention_mask \n",
    "# input_ids = torch.tensor([[-1, 5, -6, 2]])\n",
    "# print(input_ids.size())\n",
    "# input_ids.topk(k=2, dim=-1).indices\n",
    "\n",
    "# predict_type = torch.tensor([[-0.0925, -0.0999, -0.1671]])\n",
    "# p_type = torch.argmax(predict_type, dim=1).item()\n",
    "# p_type_score = torch.max(predict_type, dim=1)[0].item()\n",
    "# print(\"predict_type: \", predict_type)\n",
    "# print(\"p_type: \", p_type)\n",
    "# print(\"p_type_score: \", p_type_score)\n",
    "    \n",
    "# a = torch.tensor([[0.9213,  1.0887, -0.8858, -1.7683]])\n",
    "# a.view(-1).size() \n",
    "# print(torch.sigmoid(a))\n",
    "# a = torch.tensor([ 9.213,  1.0887, -0.8858, 7683])\n",
    "# print(torch.sigmoid(a))\n",
    "\n",
    "# a = torch.tensor([[[1],[2],[4],[-1],[-1]]])\n",
    "# a= a.squeeze(-1)\n",
    "# a.size() \n",
    "# a[:, torch.where(a!=-1)[1]]\n",
    "# m = torch.nn.Sigmoid()\n",
    "# print(\"m: \", m)\n",
    "# loss = torch.nn.BCELoss()\n",
    "# # input = torch.randn(3, requires_grad=True)\n",
    "# # print(\"input: \", input)\n",
    "# # target = torch.empty(3).random_(2)\n",
    "# # print(\"target: \", target)\n",
    "# # output = loss(m(input), target)\n",
    "# # print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([1.0293, -0.1585,  1.1408], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# print(\"Sigmoid(input): \", m(input))\n",
    "# target = torch.tensor([0., 1., 0.])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([[1.0293, -0.1585,  1.1408]], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# target = torch.tensor([[0., 1., 0.]])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# 1.1761 * 3\n",
    "# soft_input = torch.nn.Softmax(dim=-1)\n",
    "# log_soft_input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss() \n",
    "# loss(log_soft_input, target)\n",
    "# input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss()\n",
    "# loss(input,target)\n",
    "\n",
    "# loss =torch.nn.CrossEntropyLoss()\n",
    "# loss(input,target) \n",
    "\n",
    "# sp_sent_logits =torch.tensor([[[0.0988],\n",
    "#          [0.0319],\n",
    "#          [0.0314]]])\n",
    "# sp_sent_logits.squeeze()\n",
    "\n",
    "# input_ids = torch.tensor([[0.6, 0.0, 0.6, 0.0]]) \n",
    "# token_indices =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "# token_indices[:,1][0].item()\n",
    "\n",
    "# def or_softmax_cross_entropy_loss_one_doc(logits, target, ignore_index=-1, dim=-1):\n",
    "#     \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "#     assert logits.ndim == 2\n",
    "#     assert target.ndim == 2\n",
    "#     assert logits.size(0) == target.size(0) \n",
    "\n",
    "#     # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "#     # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "#     # target are indexes of tokens, padded with ignore_index=-1\n",
    "#     # logits are scores (one for each label) for each token\n",
    "# #         print(\"or_softmax_cross_entropy_loss_one_doc\" ) \n",
    "# #         print(\"size of logits: \" + str(logits.size()))                    # torch.Size([1, 746]), 746 is number of all tokens \n",
    "# #         print(\"size of target: \" + str(target.size()))                    # torch.Size([1, 64]),  -1 padded\n",
    "#     print(\"target: \" + str(target)) \n",
    "\n",
    "#     # compute a target mask\n",
    "#     target_mask = target == ignore_index\n",
    "#     # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "#     masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "#     print(\"masked_target: \" + str(masked_target))     \n",
    "#     # gather logits\n",
    "#     gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    "# #         print(\"size of gathered_logits: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#     print(\"gathered_logits: \" + str(gathered_logits)) \n",
    "#     # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "#     gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    "#     print(\"gathered_logits after -inf: \" + str(gathered_logits))      # tensor([[0.4382,   -inf,   -inf,   -inf,   -inf,...]])\n",
    "\n",
    "#     # each batch is one example\n",
    "#     gathered_logits = gathered_logits.view(1, -1)\n",
    "#     logits = logits.view(1, -1)\n",
    "# #         print(\"size of gathered_logits after view: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "# #         print(\"size of logits after view: \" + str(logits.size()))                    # torch.Size([1, 746])　　\n",
    "\n",
    "#     # numerator = log(sum(exp(gathered logits)))\n",
    "#     log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    "#     print(\"log_score: \" + str(log_score)) \n",
    "#     # denominator = log(sum(exp(logits)))\n",
    "#     log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "#     print(\"log_norm: \" + str(log_norm)) \n",
    "\n",
    "#     # compute the loss\n",
    "#     loss = -(log_score - log_norm)\n",
    "#     print(\"loss: \" + str(loss))\n",
    "\n",
    "\n",
    "#     # some of the examples might have a loss of `inf` when `target` is all `ignore_index`: when computing start_loss and end_loss for question with the gold answer of yes/no \n",
    "#     # replace -inf with 0\n",
    "#     loss = loss[~torch.isinf(loss)].sum()\n",
    "#     print(\"final loss: \" + str(loss)) \n",
    "#     return loss \n",
    "\n",
    "# # input = torch.tensor([[ 0,  0.0780],\n",
    "# #         [0, 0.9253 ],\n",
    "# #         [0, 0.0987]])\n",
    "# # target = torch.tensor([0,1,0])\n",
    "# # target.size(0) < 1\n",
    "# # input = torch.tensor([[ 1.1879,  1.0780,  0.5312],\n",
    "# #         [-0.3499, -1.9253, -1.5725],\n",
    "# #         [-0.6578, -0.0987,  1.1570]])\n",
    "# # target=torch.tensor([0,1,2])\n",
    "# # predict_support_para.view(-1, 2), sp_para.view(-1)\n",
    "# # input = torch.tensor([[ 1.1879,  1.0780,  0.5312]])\n",
    "# # target=torch.tensor([0])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([1])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([2])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([-1])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# a = torch.tensor([6.4062])    \n",
    "# b = torch.tensor([2.23])\n",
    "# torch.cat((a,b))\n",
    " \n",
    "# for a in list_tensor\n",
    "# from functools import reduce\n",
    "# reduce(lambda x,y: torch.cat((x,y)), list_tensor[:-1])\n",
    "\n",
    "# torch.tanh(a)\n",
    "# # if(torch.isinf(a)):\n",
    "# #     print(\"is inf\")\n",
    "# 5 * 1e-2\n",
    "\n",
    "\n",
    "# import torch\n",
    "# special_tokens = [1,2]\n",
    "# input_ids = torch.tensor([[ 1, 0, 2, 1, 0, 2]])\n",
    "\n",
    "# mask = input_ids != input_ids # initilaize \n",
    "# for special_token in special_tokens:\n",
    "#     mask = torch.logical_or(mask, input_ids.eq(special_token)) \n",
    "#     print(\"mask: \", mask)\n",
    "# torch.nonzero(mask)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug: check loaded dataset by DataLoader\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# num_new_tokens = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<p>\", \"<q>\", \"</q>\"]})\n",
    "# # # print(tokenizer.all_special_tokens)    \n",
    "# # # print(tokenizer.all_special_ids)     \n",
    "# # # tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "# # # tokenizer.sep_token\n",
    "\n",
    "# # # all_doc_tokens = []\n",
    "# # # orig_to_tok_index = []\n",
    "# # # tok_to_orig_index = []\n",
    "# # # for (i, token) in enumerate([\"<s>\", \"da\", \"tell\", \"<p>\", \"say\"]):\n",
    "# # #     orig_to_tok_index.append(len(all_doc_tokens))\n",
    "# # #     sub_tokens = tokenizer.tokenize(f'. {token}')[1:] if i > 0 else tokenizer.tokenize(token)\n",
    "# # #     for sub_token in sub_tokens:\n",
    "# # #         tok_to_orig_index.append(i)\n",
    "# # #         all_doc_tokens.append(sub_token)\n",
    "# # # all_doc_tokens\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# dataset = hotpotqaDataset(file_path= args.train_dataset, tokenizer=tokenizer,\n",
    "#                           max_seq_len= args.max_seq_len, max_doc_len= args.max_doc_len,\n",
    "#                           doc_stride= args.doc_stride,\n",
    "#                           max_num_answers= args.max_num_answers,\n",
    "#                           max_question_len= args.max_question_len,\n",
    "#                           ignore_seq_with_no_answers= args.ignore_seq_with_no_answers)\n",
    "# print(len(dataset))\n",
    "\n",
    "# # # dl = DataLoader(dataset, batch_size=1, shuffle=None,\n",
    "# # #                     num_workers=args.num_workers, sampler=None,\n",
    "# # #                     collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "# example = dataset[3]  \n",
    "# [input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids] = example\n",
    " \n",
    "\n",
    "# print(input_ids[0][:20].tolist())\n",
    "# print(input_mask) \n",
    "# print(segment_ids) \n",
    "# print(subword_starts) \n",
    "# print(subword_ends)\n",
    "# print(q_type)\n",
    "# print(sp_sent) \n",
    "# print(sp_para) \n",
    "# print(qids)\n",
    "# print(tokenizer.convert_ids_to_tokens(input_ids[0][667:669+1].tolist()))\n",
    "# 0.0033 * 90447 \n",
    "# 28*4\n",
    "# torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### configure_ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%add_to hotpotqa\n",
    " # A hook to overwrite to define your own DDP(DistributedDataParallel) implementation init. \n",
    " # The only requirement is that: \n",
    " # 1. On a validation batch the call goes to model.validation_step.\n",
    " # 2. On a training batch the call goes to model.training_step.\n",
    " # 3. On a testing batch, the call goes to model.test_step\n",
    " def configure_ddp(self, model, device_ids):\n",
    "    model = LightningDistributedDataParallel(\n",
    "        model,\n",
    "        device_ids=device_ids,\n",
    "        find_unused_parameters=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **configure_optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def configure_optimizers(self):\n",
    "    # Set up optimizers and (optionally) learning rate schedulers\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < self.args.warmup:\n",
    "            return float(current_step) / float(max(1, self.args.warmup))\n",
    "        return max(0.0, float(self.args.steps - current_step) / float(max(1, self.args.steps - self.args.warmup)))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=self.args.lr)\n",
    "\n",
    "    self.scheduler = LambdaLR(optimizer, lr_lambda, last_epoch=-1)  # scheduler is not saved in the checkpoint, but global_step is, which is enough to restart\n",
    "    self.scheduler.step(self.global_step)\n",
    "\n",
    "    return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optimizer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# A hook to do a lot of non-standard training tricks such as learning-rate warm-up\n",
    "def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None):\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    self.scheduler.step(self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **training_step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# A hook\n",
    "def on_epoch_start(self):\n",
    "    print(\"Start epoch \", self.current_epoch)\n",
    "    \n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def training_step(self, batch, batch_idx):\n",
    "    # do the forward pass and calculate the loss for a batch \n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch \n",
    "    print(\"size of input_ids: \" + str(input_ids.size())) \n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss  = output[:4]\n",
    "    print(\"answer_loss: \", answer_loss)\n",
    "    print(\"type_loss: \", type_loss)\n",
    "    print(\"sp_para_loss: \", sp_para_loss)\n",
    "    print(\"sp_sent_loss: \", sp_sent_loss)\n",
    "    \n",
    "#     loss  = answer_loss +  type_loss + sp_para_loss + sp_sent_loss\n",
    "    loss = answer_loss + type_loss + sp_para_loss + sp_sent_loss\n",
    "#     print(\"weighted loss: \", loss)\n",
    "#     print(\"self.trainer.optimizers[0].param_groups[0]['lr']: \", self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "    lr = loss.new_zeros(1) + self.trainer.optimizers[0].param_groups[0]['lr']  # loss.new_zeros(1) is tensor([0.]), converting 'lr' to tensor' by adding it. \n",
    "    if(q_type == 1 or q_type == 2 ):\n",
    "        print(\"answer_loss of q_type == 1 or q_type == 2: \", answer_loss)\n",
    "    print(\"lr: \", lr)    # lr will increading over time\n",
    "    tensorboard_logs = {'train_answer_loss': answer_loss, 'train_type_loss': type_loss, 'train_sp_para_loss': sp_para_loss, 'train_sp_sent_loss': sp_sent_loss, \n",
    "                        'lr': lr,\n",
    "                        'input_size': torch.tensor(input_ids.numel()).type_as(loss) ,\n",
    "                        'mem': torch.tensor(torch.cuda.memory_allocated(input_ids.device) / 1024 ** 3).type_as(loss) }\n",
    "    \n",
    "    if(self.current_epoch == self.args.epochs-1):\n",
    "        print(\"training_step \", batch_idx)\n",
    "                            \n",
    "    return {'loss': loss, 'log': tensorboard_logs}  # It is necessary that the output dictionary contains the loss key. This is the minimum requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%add_to hotpotqa\n",
    "# # the function is called after every epoch is completed\n",
    "# def training_end(self, outputs):\n",
    "#     print(\"self.current_epoch: \", self.current_epoch)\n",
    "\n",
    " \n",
    "\n",
    "#     # calculating average loss  \n",
    "#     avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#     if self.trainer.use_ddp:\n",
    "#         torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "#         avg_loss /= self.trainer.world_size \n",
    "        \n",
    "#     epoch_dictionary={\n",
    "#         'loss': avg_loss # required \n",
    "#     }\n",
    "\n",
    "#     return epoch_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# When the validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, model goes back to training mode and gradients are enabled.\n",
    "def validation_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch\n",
    "    print(\"validation_step\")\n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output = output \n",
    "    loss = answer_loss +  type_loss + sp_para_loss + sp_sent_loss\n",
    "    print(\"answer_loss: \" + str(answer_loss))\n",
    "\n",
    "    answers_pred, sp_sent_pred, sp_para_pred = self.decode(input_ids, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output)\n",
    "    print(\"answers_pred: \" + str(answers_pred))\n",
    "    \n",
    "    # answers_pred only contains the top one predicted answer['text', 'score']\n",
    "#     answers_pred = sorted(answers_pred, key=lambda x: x['score'], reverse=True)[0:1] # each batch is one document\n",
    "#     print(\"answers_pred after sorted: \" + str(answers_pred))\n",
    "    if(len(answers_pred) != 1):\n",
    "        print(\"len(answers_pred) != 1\")\n",
    "        assert(len(answers_pred) == 1)\n",
    "    answers_pred = answers_pred[0]\n",
    "\n",
    "    answer_score = answers_pred['score']  # (start_logit + end_logit + p_type_score) / 3\n",
    "    print(\"pred answer_score: \" + str(answer_score))\n",
    "    \n",
    "    print(\"pred answer_text: \" + str(answers_pred['text'])) \n",
    "\n",
    "    if(q_type == 1):\n",
    "        answer_gold = 'yes'\n",
    "    elif(q_type == 2):\n",
    "        answer_gold = 'no' \n",
    "    else:\n",
    "        # even though there can be multiple gold start_postion (subword_start) and end_position(subword_end), the corresponing answer string are same\n",
    "        answer_gold_token_ids = input_ids[0, subword_starts[0][0]: subword_ends[0][0] + 1]\n",
    "        print(\"answer_gold_token_ids: \" + str(answer_gold_token_ids))\n",
    "        answer_gold_tokens = self.tokenizer.convert_ids_to_tokens(answer_gold_token_ids.tolist())\n",
    "        print(\"answer_gold_tokens: \" + str(answer_gold_tokens))\n",
    "        answer_gold = self.tokenizer.convert_tokens_to_string(answer_gold_tokens)\n",
    "    print(\"answer_gold: \" + str(answer_gold))\n",
    " \n",
    "    f1, prec, recall = self.f1_score(answers_pred['text'], answer_gold)\n",
    "    em = self.exact_match_score(answers_pred['text'], answer_gold) \n",
    "    f1 = torch.tensor(f1).type_as(loss)\n",
    "    prec = torch.tensor(prec).type_as(loss)\n",
    "    recall = torch.tensor(recall).type_as(loss)\n",
    "    em = torch.tensor(em).type_as(loss)\n",
    "    print(\"f1: \" + str(f1))\n",
    "    print(\"prec: \" + str(prec))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"em: \" + str(em)) \n",
    "\n",
    "    if(len(sp_sent_pred) > 0):\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = self.sp_metrics(sp_sent_pred, torch.where(sp_sent.squeeze())[0].tolist())\n",
    "        sp_sent_em = torch.tensor(sp_sent_em).type_as(loss)\n",
    "        sp_sent_precision = torch.tensor(sp_sent_precision).type_as(loss)\n",
    "        sp_sent_recall = torch.tensor(sp_sent_recall).type_as(loss)\n",
    "        sp_sent_f1 = torch.tensor(sp_sent_f1).type_as(loss)\n",
    "        \n",
    "        #         print(\"sp_sent_em: \" + str(sp_sent_em))\n",
    "#         print(\"sp_sent_precision: \" + str(sp_sent_precision))\n",
    "#         print(\"sp_sent_recall: \" + str(sp_sent_recall))    \n",
    "#         print(\"sp_sent_f1: \" + str(sp_sent_f1))    \n",
    "        \n",
    "        joint_prec = prec * sp_sent_precision\n",
    "        joint_recall = recall * sp_sent_recall\n",
    "        if joint_prec + joint_recall > 0:\n",
    "            joint_f1 = 2 * joint_prec * joint_recall / (joint_prec + joint_recall)\n",
    "        else:\n",
    "            joint_f1 = torch.tensor(0.0).type_as(loss)\n",
    "        joint_em = em * sp_sent_em \n",
    "\n",
    "    else:\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss)\n",
    "        joint_em, joint_f1, joint_prec, joint_recall =  torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss)\n",
    "         \n",
    "    print(\"return\") \n",
    "#     return {'qids': [qids], 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss,\n",
    "#             'answer_score': [answer_score], 'f1': [f1], 'prec':[prec], 'recall':[recall], 'em': [em],\n",
    "#             'sp_em': [sp_sent_em], 'sp_f1': [sp_sent_f1], 'sp_prec': [sp_sent_precision], 'sp_recall': [sp_sent_recall],\n",
    "#             'joint_em': [joint_em], 'joint_f1': [joint_f1], 'joint_prec': [joint_prec], 'joint_recall': [joint_recall]}\n",
    "    return { 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss,\n",
    "                'answer_score': answer_score, 'f1': f1, 'prec':prec, 'recall':recall, 'em': em,\n",
    "                'sp_em': sp_sent_em, 'sp_f1': sp_sent_f1, 'sp_prec': sp_sent_precision, 'sp_recall': sp_sent_recall,\n",
    "                'joint_em': joint_em, 'joint_f1': joint_f1, 'joint_prec': joint_prec, 'joint_recall': joint_recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits):\n",
    "    print(\"decode\")\n",
    "    \n",
    "    question_end_index = self._get_special_index(input_ids, [\"</q>\"])\n",
    "#     print(\"question_end_index: \", question_end_index)\n",
    "    \n",
    "    # one example per batch\n",
    "    start_logits = start_logits.squeeze()\n",
    "    end_logits = end_logits.squeeze()\n",
    "#     print(\"start_logits: \", start_logits)\n",
    "#     print(\"end_logits: \", end_logits)\n",
    "    start_logits_indices = start_logits.topk(k=self.args.n_best_size, dim=-1).indices\n",
    "#     print(\"start_logits_indices: \", start_logits_indices)\n",
    "    end_logits_indices = end_logits.topk(k=self.args.n_best_size, dim=-1).indices \n",
    "    if(len(start_logits_indices.size()) > 1):\n",
    "        print(\"len(start_logits_indices.size()): \", len(start_logits_indices.size()))\n",
    "        assert(\"len(start_logits_indices.size()) > 1\")\n",
    "    p_type = torch.argmax(type_logits, dim=1).item()\n",
    "    p_type_score = torch.max(type_logits, dim=1)[0] \n",
    "#     print(\"type_logits: \", type_logits)\n",
    "#     print(\"p_type: \", p_type)\n",
    "#     print(\"p_type_score: \", p_type_score)\n",
    "    \n",
    "    answers = []\n",
    "    if p_type == 0:\n",
    "        potential_answers = []\n",
    "        for start_logit_index in start_logits_indices: \n",
    "            for end_logit_index in end_logits_indices: \n",
    "                if start_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if end_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if start_logit_index > end_logit_index:\n",
    "                    continue\n",
    "                answer_len = end_logit_index - start_logit_index + 1\n",
    "                if answer_len > self.args.max_answer_length:\n",
    "                    continue\n",
    "                potential_answers.append({'start': start_logit_index, 'end': end_logit_index,\n",
    "                                          'start_logit': start_logits[start_logit_index],  # single logit score for start position at start_logit_index\n",
    "                                          'end_logit': end_logits[end_logit_index]})    \n",
    "        sorted_answers = sorted(potential_answers, key=lambda x: (x['start_logit'] + x['end_logit']), reverse=True) \n",
    "#         print(\"sorted_answers: \" + str(sorted_answers))\n",
    "        if len(sorted_answers) == 0:\n",
    "            answers.append({'text': 'NoAnswerFound', 'score': -1000000})\n",
    "        else:\n",
    "            answer = sorted_answers[0]\n",
    "            answer_token_ids = input_ids[0, answer['start']: answer['end'] + 1]\n",
    "            answer_tokens = self.tokenizer.convert_ids_to_tokens(answer_token_ids.tolist())\n",
    "            text = self.tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "#             score = (answer['start_logit'] + answer['end_logit'] + p_type_score) / 3\n",
    "            score = (torch.sigmoid(answer['start_logit']) + torch.sigmoid(answer['end_logit']) + torch.sigmoid(p_type_score)) / 3\n",
    "            answers.append({'text': text, 'score': score})\n",
    "            print(\"answers: \" + str(answers))\n",
    "    elif p_type == 1: \n",
    "        answers.append({'text': 'yes', 'score': p_type_score})\n",
    "    elif p_type == 2:\n",
    "        answers.append({'text': 'no', 'score': p_type_score})\n",
    "    else:\n",
    "        assert False \n",
    "\n",
    "    p_index = self._get_special_index(input_ids, [\"<p>\"])\n",
    "# #     print(\"p_index: \" + str(p_index))\n",
    "#     s_index = self._get_special_index(input_ids, [\"<s>\"])\n",
    "# #     print(\"s_index: \" + str(s_index))\n",
    "#     sent_indexes = torch.sort(torch.cat((s_index, p_index)))[0]\n",
    "    sent_indexes = self._get_special_index(input_ids, [\"<p>\", \"<s>\"])\n",
    "    \n",
    "    s_to_p_map = []\n",
    "    for s in sent_indexes:\n",
    "        s_to_p = torch.where(torch.le(p_index, s))[0][-1]     # last p_index smaller or equal to s\n",
    "        s_to_p_map.append(s_to_p.item()) \n",
    "#     print(\"s_to_p_map: \" + str(s_to_p_map))\n",
    "    \n",
    "#     print(\"sp_para_logits\", sp_para_logits)\n",
    "#     print(\"sp_sent_logits\", sp_sent_logits)\n",
    "\n",
    "#     print(\"sp_para_logits.squeeze().size(0): \", sp_para_logits.squeeze().size(0))\n",
    "#     print(\"sp_sent_logits.squeeze().size(0): \", sp_sent_logits.squeeze().size(0))\n",
    "    sp_para_top2 = sp_para_logits.squeeze().topk(k=2).indices\n",
    "    if(sp_sent_logits.squeeze().size(0) > 12):\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=12).indices\n",
    "    else:\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=sp_sent_logits.squeeze().size(0)).indices\n",
    "#     print(\"sp_para_top2\", sp_para_top2)\n",
    "#     print(\"sp_sent_top12\", sp_sent_top12)\n",
    "    \n",
    "    sp_sent_pred = set()\n",
    "    sp_para_pred = set()\n",
    "    for sp_sent in sp_sent_top12:\n",
    "        sp_sent_to_para = s_to_p_map[sp_sent.item()]\n",
    "        if sp_sent_to_para in sp_para_top2:\n",
    "            sp_sent_pred.add(sp_sent.item())\n",
    "            sp_para_pred.add(sp_sent_to_para) \n",
    "#     print(\"sp_sent_pred: \" + str(sp_sent_pred))\n",
    "#     print(\"sp_para_pred: \" + str(sp_para_pred))\n",
    "    return (answers, sp_sent_pred, sp_para_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def normalize_answer(self, s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(self, prediction, ground_truth):\n",
    "    normalized_prediction = self.normalize_answer(prediction)\n",
    "    normalized_ground_truth = self.normalize_answer(ground_truth)\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "    \n",
    "    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def exact_match_score(self, prediction, ground_truth):\n",
    "    return int(self.normalize_answer(prediction) == self.normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def sp_metrics(self, prediction, gold):\n",
    "    print(\"prediction: \", prediction)\n",
    "    print(\"gold: \", gold)\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for e in prediction:\n",
    "        if e in gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "#             print(\"e: \", e)\n",
    "#             print(\"gold: \", gold)\n",
    "#             print(\"e not in gold!!!\")\n",
    "    for e in gold:\n",
    "        if e not in prediction:\n",
    "            fn += 1\n",
    "#             print(\"e: \", e)\n",
    "#             print(\"prediction: \", prediction)\n",
    "#             print(\"e not in prediction!!!\")\n",
    "    prec = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    print(\"sp prec: \", prec)\n",
    "    print(\"sp recall: \", recall)\n",
    "    print(\"sp f1: \", f1)\n",
    "    print(\"sp em: \", em)\n",
    "    return em, prec, recall, f1 \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# If a validation_step is not defined, this won't be called. Called at the end of the validation loop with the outputs of validation_step.\n",
    "def validation_end(self, outputs):\n",
    "    print(\"validation_end\")\n",
    "    avg_loss = torch.stack([x['vloss'] for x in outputs]).mean()  \n",
    "    avg_answer_loss = torch.stack([x['answer_loss'] for x in outputs]).mean()  \n",
    "    avg_type_loss = torch.stack([x['type_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_para_loss = torch.stack([x['sp_para_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_sent_loss = torch.stack([x['sp_sent_loss'] for x in outputs]).mean()  \n",
    "        \n",
    "#     string_qids = [item for sublist in outputs for item in sublist['qids']]\n",
    "#     int_qids = [self.val_dataloader_object.dataset.val_qid_string_to_int_map[qid] for qid in string_qids]\n",
    "    answer_scores = [x['answer_score'] for x in outputs]  # [item for sublist in outputs for item in sublist['answer_score']] #torch.stack([x['answer_score'] for x in outputs]).mean() # \n",
    "    f1_scores = [x['f1'] for x in outputs] # [item for sublist in outputs for item in sublist['f1']] #torch.stack([x['f1'] for x in outputs]).mean()  #\n",
    "    em_scores = [x['em'] for x in outputs] # [item for sublist in outputs for item in sublist['em']] #torch.stack([x['em'] for x in outputs]).mean()  #\n",
    "    prec_scores =  [x['prec'] for x in outputs] #[item for sublist in outputs for item in sublist['prec']] #torch.stack([x['prec'] for x in outputs]).mean()  #\n",
    "    recall_scores = [x['recall'] for x in outputs] #[item for sublist in outputs for item in sublist['recall']]  #torch.stack([x['recall'] for x in outputs]).mean()  #\n",
    "    \n",
    "    sp_sent_f1_scores = [x['sp_f1'] for x in outputs] #[item for sublist in outputs for item in sublist['sp_f1']] #torch.stack([x['sp_f1'] for x in outputs]).mean() #\n",
    "    sp_sent_em_scores = [x['sp_em'] for x in outputs] # [item for sublist in outputs for item in sublist['sp_em']] #torch.stack([x['sp_em'] for x in outputs]).mean() #\n",
    "    sp_sent_prec_scores = [x['sp_prec'] for x in outputs]  #[item for sublist in outputs for item in sublist['sp_prec']] #torch.stack([x['sp_prec'] for x in outputs]).mean() #\n",
    "    sp_sent_recall_scores = [x['sp_recall'] for x in outputs] # [item for sublist in outputs for item in sublist['sp_recall']]  #torch.stack([x['sp_recall'] for x in outputs]).mean() #\n",
    "     \n",
    "    joint_f1_scores = [x['joint_f1'] for x in outputs]   #[item for sublist in outputs for item in sublist['joint_f1']] #torch.stack([x['joint_f1'] for x in outputs]).mean() #\n",
    "    joint_em_scores = [x['joint_em'] for x in outputs]   # [item for sublist in outputs for item in sublist['joint_em']] #torch.stack([x['joint_em'] for x in outputs]).mean() #\n",
    "    joint_prec_scores = [x['joint_prec'] for x in outputs]   #[item for sublist in outputs for item in sublist['joint_prec']] #torch.stack([x['joint_prec'] for x in outputs]).mean() #\n",
    "    joint_recall_scores = [x['joint_recall'] for x in outputs]   #[item for sublist in outputs for item in sublist['joint_recall']] #torch.stack([x['joint_recall'] for x in outputs]).mean() #     \n",
    "\n",
    "    print(f'before sync --> sizes:  {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "    if self.trainer.use_ddp:\n",
    "        torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_answer_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_answer_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_type_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_type_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_para_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_para_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_sent_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_sent_loss /= self.trainer.world_size \n",
    "\n",
    "#         int_qids = self.sync_list_across_gpus(int_qids, avg_loss.device, torch.int)\n",
    "        answer_scores = self.sync_list_across_gpus(answer_scores, avg_loss.device, torch.float)\n",
    "        f1_scores = self.sync_list_across_gpus(f1_scores, avg_loss.device, torch.float)\n",
    "        em_scores = self.sync_list_across_gpus(em_scores, avg_loss.device, torch.float)\n",
    "        prec_scores = self.sync_list_across_gpus(prec_scores, avg_loss.device, torch.float)\n",
    "        recall_scores = self.sync_list_across_gpus(recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        sp_sent_f1_scores = self.sync_list_across_gpus(sp_sent_f1_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_em_scores = self.sync_list_across_gpus(sp_sent_em_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_prec_scores = self.sync_list_across_gpus(sp_sent_prec_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_recall_scores = self.sync_list_across_gpus(sp_sent_recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        joint_f1_scores = self.sync_list_across_gpus(joint_f1_scores, avg_loss.device, torch.float)\n",
    "        joint_em_scores = self.sync_list_across_gpus(joint_em_scores, avg_loss.device, torch.float)\n",
    "        joint_prec_scores = self.sync_list_across_gpus(joint_prec_scores, avg_loss.device, torch.float)\n",
    "        joint_recall_scores = self.sync_list_across_gpus(joint_recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        \n",
    "    print(f'after sync --> sizes: {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "    print(\"answer_scores: \", answer_scores)\n",
    "    print(\"f1_scores: \", f1_scores)\n",
    "    print(\"em_scores: \", em_scores)\n",
    "    \n",
    "    print(\"avg_loss: \", avg_loss, end = '\\t') \n",
    "    print(\"avg_answer_loss: \", avg_answer_loss, end = '\\t') \n",
    "    print(\"avg_type_loss: \", avg_type_loss, end = '\\t') \n",
    "    print(\"avg_sp_para_loss: \", avg_sp_para_loss, end = '\\t') \n",
    "    print(\"avg_sp_sent_loss: \", avg_sp_sent_loss, end = '\\t')  \n",
    "        \n",
    "    avg_val_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    print(\"len(f1_scores): \", len(f1_scores))\n",
    "    print(\"avg_val_f1: \", avg_val_f1)\n",
    "    avg_val_em = sum(em_scores) / len(em_scores)\n",
    "#     print(\"len(em_scores): \", len(em_scores))\n",
    "    print(\"avg_val_em: \", avg_val_em)\n",
    "    avg_val_prec = sum(prec_scores) / len(prec_scores)\n",
    "#     print(\"len(prec_scores): \", len(prec_scores))\n",
    "    print(\"avg_val_prec: \", avg_val_prec)\n",
    "    avg_val_recall = sum(recall_scores) / len(recall_scores) \n",
    "#     print(\"len(recall_scores): \", len(recall_scores))\n",
    "    print(\"avg_val_recall: \", avg_val_recall)\n",
    "    \n",
    "    avg_val_sp_sent_f1 = sum(sp_sent_f1_scores) / len(sp_sent_f1_scores)\n",
    "    print(\"avg_val_sp_sent_f1: \", avg_val_sp_sent_f1)\n",
    "    avg_val_sp_sent_em = sum(sp_sent_em_scores) / len(sp_sent_em_scores)\n",
    "    print(\"avg_val_sp_sent_em: \", avg_val_sp_sent_em)\n",
    "    avg_val_sp_sent_prec = sum(sp_sent_prec_scores) / len(sp_sent_prec_scores)\n",
    "    print(\"avg_val_sp_sent_prec: \", avg_val_sp_sent_prec)\n",
    "    avg_val_sp_sent_recall = sum(sp_sent_recall_scores) / len(sp_sent_recall_scores) \n",
    "    print(\"avg_val_sp_sent_recall: \", avg_val_sp_sent_recall)\n",
    "        \n",
    "    avg_val_joint_f1 = sum(joint_f1_scores) / len(joint_f1_scores)\n",
    "    print(\"avg_val_joint_f1: \", avg_val_joint_f1)\n",
    "    avg_val_joint_em = sum(joint_em_scores) / len(joint_em_scores)\n",
    "    print(\"avg_val_joint_em: \", avg_val_joint_em)\n",
    "    avg_val_joint_prec = sum(joint_prec_scores) / len(joint_prec_scores)\n",
    "    print(\"avg_val_joint_prec: \", avg_val_joint_prec)\n",
    "    avg_val_joint_recall = sum(joint_recall_scores) / len(joint_recall_scores) \n",
    "    print(\"avg_val_joint_recall: \", avg_val_joint_recall)\n",
    "     \n",
    "    \n",
    "    \n",
    "#     print(\"avg_loss: \", avg_loss)\n",
    "    \n",
    "    logs = {'avg_val_loss': avg_loss, 'avg_val_answer_loss': avg_answer_loss, 'avg_val_type_loss': avg_type_loss, 'avg_val_sp_para_loss': avg_sp_para_loss, 'avg_val_sp_sent_loss': avg_sp_sent_loss, \n",
    "            'avg_val_f1': avg_val_f1, 'avg_val_em': avg_val_em,  'avg_val_prec': avg_val_prec, 'avg_val_recall': avg_val_recall,\n",
    "            'avg_val_sp_sent_f1': avg_val_sp_sent_f1, 'avg_val_sp_sent_em': avg_val_sp_sent_em,  'avg_val_sp_sent_prec': avg_val_sp_sent_prec, 'avg_val_sp_sent_recall': avg_val_sp_sent_recall,\n",
    "            'avg_val_joint_f1': avg_val_joint_f1, 'avg_val_joint_em': avg_val_joint_em,  'avg_val_joint_prec': avg_val_joint_prec, 'avg_val_joint_recall': avg_val_joint_recall\n",
    "           }\n",
    "\n",
    "    return {'avg_val_loss': avg_loss, 'log': logs}\n",
    "\n",
    "#     answer_scores =  torch.stack([x['answer_score'] for x in outputs]).mean() # \n",
    "#     f1_scores =  torch.stack([x['f1'] for x in outputs]).mean()  #\n",
    "#     em_scores =  torch.stack([x['em'] for x in outputs]).mean()  #\n",
    "#     prec_scores =  torch.stack([x['prec'] for x in outputs]).mean()  #\n",
    "#     recall_scores =  torch.stack([x['recall'] for x in outputs]).mean()  #\n",
    "    \n",
    "#     sp_sent_f1_scores =  torch.stack([x['sp_f1'] for x in outputs]).mean() #\n",
    "#     sp_sent_em_scores =  torch.stack([x['sp_em'] for x in outputs]).mean() #\n",
    "#     sp_sent_prec_scores =  torch.stack([x['sp_prec'] for x in outputs]).mean() #\n",
    "#     sp_sent_recall_scores =  torch.stack([x['sp_recall'] for x in outputs]).mean() #\n",
    "     \n",
    "#     joint_f1_scores =  torch.stack([x['joint_f1'] for x in outputs]).mean() #\n",
    "#     joint_em_scores =  torch.stack([x['joint_em'] for x in outputs]).mean() #\n",
    "#     joint_prec_scores =  torch.stack([x['joint_prec'] for x in outputs]).mean() #\n",
    "#     joint_recall_scores = torch.stack([x['joint_recall'] for x in outputs]).mean() #     \n",
    "\n",
    "#     return {'avg_val_loss': avg_loss}\n",
    "\n",
    "def sync_list_across_gpus(self, l, device, dtype):\n",
    "    l_tensor = torch.tensor(l, device=device, dtype=dtype)\n",
    "    gather_l_tensor = [torch.ones_like(l_tensor) for _ in range(self.trainer.world_size)]\n",
    "    torch.distributed.all_gather(gather_l_tensor, l_tensor)\n",
    "    return torch.cat(gather_l_tensor).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch\n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    loss, start_logits, end_logits = output[:3]\n",
    "    answers = self.decode(input_ids, start_logits, end_logits)\n",
    "\n",
    "    # each batch is one document\n",
    "    answers = sorted(answers, key=lambda x: x['score'], reverse=True)[0:1]\n",
    "    qids = [qids]\n",
    "    assert len(answers) == len(qids)\n",
    "    return {'qids': qids, 'answers': answers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_end(self, outputs):\n",
    "    qids = [item for sublist in outputs for item in sublist['qids']]\n",
    "    answers = [item for sublist in outputs for item in sublist['answers']]\n",
    "\n",
    "    qa_with_duplicates = defaultdict(list)\n",
    "    for qid, answer in zip(qids, answers):\n",
    "        qa_with_duplicates[qid].append({'answer_score': answer['score'], 'answer_text': answer['text'], })\n",
    "\n",
    "    qid_to_answer_text = {}\n",
    "    for qid, answer_metrics in qa_with_duplicates.items():\n",
    "        top_answer = sorted(answer_metrics, key=lambda x: x['answer_score'], reverse=True)[0]\n",
    "        qid_to_answer_text[qid] = top_answer['answer_text']\n",
    "\n",
    "    with open('predictions.json', 'w') as f:\n",
    "        json.dump(qid_to_answer_text, f)\n",
    "\n",
    "    return {'count': len(qid_to_answer_text)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add_model_specific_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "@staticmethod\n",
    "def add_model_specific_args(parser, root_dir):\n",
    "    parser.add_argument(\"--save_dir\", type=str, default='jupyter-hotpotqa')\n",
    "    parser.add_argument(\"--save_prefix\", type=str, required=True)\n",
    "    parser.add_argument(\"--train_dataset\", type=str, required=False, help=\"Path to the training squad-format\")\n",
    "    parser.add_argument(\"--dev_dataset\", type=str, required=True, help=\"Path to the dev squad-format\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2, help=\"Batch size\")\n",
    "    parser.add_argument(\"--gpus\", type=str, default='0',\n",
    "                        help=\"Comma separated list of gpus. Default is gpu 0. To use CPU, use --gpus \"\" \")\n",
    "    parser.add_argument(\"--warmup\", type=int, default=1000, help=\"Number of warmup steps\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.00005, help=\"Maximum learning rate\")\n",
    "    parser.add_argument(\"--val_every\", type=float, default=1.0, help=\"How often within one training epoch to check the validation set.\")\n",
    "    parser.add_argument(\"--val_percent_check\", default=1.00, type=float, help='Percent of validation data used')\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=4, help=\"Number of data loader workers\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=1234, help=\"Seed\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=6, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=4096,\n",
    "                        help=\"Maximum length of seq passed to the transformer model\")\n",
    "    parser.add_argument(\"--max_doc_len\", type=int, default=4096,\n",
    "                        help=\"Maximum number of wordpieces of the input document\")\n",
    "    parser.add_argument(\"--max_num_answers\", type=int, default=64,\n",
    "                        help=\"Maximum number of answer spans per document (64 => 94%)\")\n",
    "    parser.add_argument(\"--max_question_len\", type=int, default=55,\n",
    "                        help=\"Maximum length of the question\")\n",
    "    parser.add_argument(\"--doc_stride\", type=int, default=-1,\n",
    "                        help=\"Overlap between document chunks. Use -1 to only use the first chunk\")\n",
    "    parser.add_argument(\"--ignore_seq_with_no_answers\", action='store_true',\n",
    "                        help=\"each example should have at least one answer. Default is False\")\n",
    "    parser.add_argument(\"--disable_checkpointing\", action='store_true', help=\"No logging or checkpointing\")\n",
    "    parser.add_argument(\"--n_best_size\", type=int, default=20,\n",
    "                        help=\"Number of answer candidates. Used at decoding time\")\n",
    "    parser.add_argument(\"--max_answer_length\", type=int, default=30,\n",
    "                        help=\"maximum num of wordpieces/answer. Used at decoding time\")\n",
    "    parser.add_argument(\"--regular_softmax_loss\", action='store_true', help=\"IF true, use regular softmax. Default is using ORed softmax loss\")\n",
    "    parser.add_argument(\"--test\", action='store_true', help=\"Test only, no training\")\n",
    "    parser.add_argument(\"--model_path\", type=str,\n",
    "                        help=\"Path to the checkpoint directory\")\n",
    "    parser.add_argument(\"--no_progress_bar\", action='store_true', help=\"no progress bar. Good for printing\")\n",
    "    parser.add_argument(\"--attention_mode\", type=str, choices=['tvm', 'sliding_chunks'],\n",
    "                        default='sliding_chunks', help='Which implementation of selfattention to use')\n",
    "    parser.add_argument(\"--fp32\", action='store_true', help=\"default is fp16. Use --fp32 to switch to fp32\")\n",
    "    parser.add_argument('--train_percent', type=float, default=1.0)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_apply',\n",
       " '_call_impl',\n",
       " '_forward_unimplemented',\n",
       " '_get_name',\n",
       " '_get_special_index',\n",
       " '_load_from_state_dict',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " 'add_model_specific_args',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'configure_apex',\n",
       " 'configure_ddp',\n",
       " 'configure_optimizers',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'decode',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'exact_match_score',\n",
       " 'extra_repr',\n",
       " 'f1_score',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'grad_norm',\n",
       " 'half',\n",
       " 'init_ddp_connection',\n",
       " 'load_from_checkpoint',\n",
       " 'load_from_metrics',\n",
       " 'load_model',\n",
       " 'load_state_dict',\n",
       " 'loss_computation',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'normalize_answer',\n",
       " 'on_after_backward',\n",
       " 'on_batch_end',\n",
       " 'on_batch_start',\n",
       " 'on_before_zero_grad',\n",
       " 'on_epoch_end',\n",
       " 'on_epoch_start',\n",
       " 'on_hpc_load',\n",
       " 'on_hpc_save',\n",
       " 'on_load_checkpoint',\n",
       " 'on_post_performance_check',\n",
       " 'on_pre_performance_check',\n",
       " 'on_sanity_check_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_train_end',\n",
       " 'on_train_start',\n",
       " 'optimizer_step',\n",
       " 'or_softmax_cross_entropy_loss_one_doc',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'sp_metrics',\n",
       " 'state_dict',\n",
       " 'summarize',\n",
       " 'sync_list_across_gpus',\n",
       " 'tbptt_split_batch',\n",
       " 'test_dataloader',\n",
       " 'test_end',\n",
       " 'test_step',\n",
       " 'tng_dataloader',\n",
       " 'to',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'training_end',\n",
       " 'training_step',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'val_dataloader',\n",
       " 'validation_end',\n",
       " 'validation_step',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T_destination', ~T_destination),\n",
       " ('__abstractmethods__', frozenset({'configure_optimizers', 'training_step'})),\n",
       " ('__annotations__',\n",
       "  {'dump_patches': bool,\n",
       "   '_version': int,\n",
       "   'training': bool,\n",
       "   'forward': typing.Callable[..., typing.Any],\n",
       "   '__call__': typing.Callable[..., typing.Any]}),\n",
       " ('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__class__', abc.ABCMeta),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__init__': <function __main__.hotpotqa.__init__(self, args)>,\n",
       "                'load_model': <function __main__.hotpotqa.load_model(self)>,\n",
       "                'train_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>,\n",
       "                'val_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>,\n",
       "                'forward': <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>,\n",
       "                'loss_computation': <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>,\n",
       "                '_get_special_index': <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>,\n",
       "                'or_softmax_cross_entropy_loss_one_doc': <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>,\n",
       "                '__doc__': None,\n",
       "                '__abstractmethods__': frozenset({'configure_optimizers',\n",
       "                           'training_step'}),\n",
       "                '_abc_registry': <_weakrefset.WeakSet at 0x7f8d9c4f9e48>,\n",
       "                '_abc_cache': <_weakrefset.WeakSet at 0x7f8d9c4f9eb8>,\n",
       "                '_abc_negative_cache': <_weakrefset.WeakSet at 0x7f8d9c4f9f28>,\n",
       "                '_abc_negative_cache_version': 230,\n",
       "                'configure_ddp': <function __main__.configure_ddp(self, model, device_ids)>,\n",
       "                'configure_optimizers': <function __main__.configure_optimizers(self)>,\n",
       "                'optimizer_step': <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>,\n",
       "                'on_epoch_start': <function __main__.on_epoch_start(self)>,\n",
       "                'training_step': <function __main__.training_step(self, batch, batch_idx)>,\n",
       "                'validation_step': <function __main__.validation_step(self, batch, batch_nb)>,\n",
       "                'decode': <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>,\n",
       "                'normalize_answer': <function __main__.normalize_answer(self, s)>,\n",
       "                'f1_score': <function __main__.f1_score(self, prediction, ground_truth)>,\n",
       "                'exact_match_score': <function __main__.exact_match_score(self, prediction, ground_truth)>,\n",
       "                'sp_metrics': <function __main__.sp_metrics(self, prediction, gold)>,\n",
       "                'validation_end': <function __main__.validation_end(self, outputs)>,\n",
       "                'sync_list_across_gpus': <function __main__.sync_list_across_gpus(self, l, device, dtype)>,\n",
       "                'test_step': <function __main__.test_step(self, batch, batch_nb)>,\n",
       "                'test_end': <function __main__.test_end(self, outputs)>,\n",
       "                'add_model_specific_args': <staticmethod at 0x7f8d9c4f79e8>})),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__doc__', None),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__init_subclass__', <function hotpotqa.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqa.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'ABC' objects>),\n",
       " ('_abc_cache', <_weakrefset.WeakSet at 0x7f8d9c4f9eb8>),\n",
       " ('_abc_negative_cache', <_weakrefset.WeakSet at 0x7f8d9c4f9f28>),\n",
       " ('_abc_negative_cache_version', 230),\n",
       " ('_abc_registry', <_weakrefset.WeakSet at 0x7f8d9c4f9e48>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('_version', 1),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, use_amp, loss, optimizer)>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp, model, optimizers, amp_level)>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu', <function torch.nn.modules.module.Module.cpu(self:~T) -> ~T>),\n",
       " ('cuda',\n",
       "  <function torch.nn.modules.module.Module.cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('double', <function torch.nn.modules.module.Module.double(self:~T) -> ~T>),\n",
       " ('dump_patches', False),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float', <function torch.nn.modules.module.Module.float(self:~T) -> ~T>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self)>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type)>),\n",
       " ('half', <function torch.nn.modules.module.Module.half(self:~T) -> ~T>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, proc_rank, world_size)>),\n",
       " ('load_from_checkpoint',\n",
       "  <bound method LightningModule.load_from_checkpoint of <class '__main__.hotpotqa'>>),\n",
       " ('load_from_metrics',\n",
       "  <bound method LightningModule.load_from_metrics of <class '__main__.hotpotqa'>>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('normalize_answer', <function __main__.normalize_answer(self, s)>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self)>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self)>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch)>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer)>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self)>),\n",
       " ('on_epoch_start', <function __main__.on_epoch_start(self)>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint)>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint)>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint)>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self)>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self)>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint)>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self)>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self)>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode)>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch, split_size)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('to', <function torch.nn.modules.module.Module.to(self, *args, **kwargs)>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_idx)>),\n",
       " ('type',\n",
       "  <function torch.nn.modules.module.Module.type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self)>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "getmembers(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, use_amp, loss, optimizer)>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp, model, optimizers, amp_level)>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu', <function torch.nn.modules.module.Module.cpu(self:~T) -> ~T>),\n",
       " ('cuda',\n",
       "  <function torch.nn.modules.module.Module.cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('double', <function torch.nn.modules.module.Module.double(self:~T) -> ~T>),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float', <function torch.nn.modules.module.Module.float(self:~T) -> ~T>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self)>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type)>),\n",
       " ('half', <function torch.nn.modules.module.Module.half(self:~T) -> ~T>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, proc_rank, world_size)>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('normalize_answer', <function __main__.normalize_answer(self, s)>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self)>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self)>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch)>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer)>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self)>),\n",
       " ('on_epoch_start', <function __main__.on_epoch_start(self)>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint)>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint)>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint)>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self)>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self)>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint)>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self)>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self)>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode)>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch, split_size)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('to', <function torch.nn.modules.module.Module.to(self, *args, **kwargs)>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_idx)>),\n",
       " ('type',\n",
       "  <function torch.nn.modules.module.Module.type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self)>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions_list = [o for o in getmembers(hotpotqa) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqa,\n",
       " pytorch_lightning.core.lightning.LightningModule,\n",
       " abc.ABC,\n",
       " pytorch_lightning.core.grads.GradInformation,\n",
       " pytorch_lightning.core.saving.ModelIO,\n",
       " pytorch_lightning.core.hooks.ModelHooks,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqa)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function configure_optimizers in module __main__:\n",
      "\n",
      "configure_optimizers(self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqa.configure_optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# code, line_no = inspect.getsourcelines(hotpotqa.training_step)\n",
    "# print(''.join(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/u32/fanluo/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/u32/fanluo/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:transformers.tokenization_utils_base:Assigning ['<cls>', '<p>', '<q>', '</q>'] to the additional_special_tokens key of the tokenizer\n",
      "INFO:transformers.tokenization_utils:Adding <cls> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding <p> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding <q> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding </q> to the vocabulary\n",
      "INFO:transformers.configuration_utils:loading configuration file longformer-base-4096/config.json\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"attention_dilation\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"attention_mode\": \"tvm\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"autoregressive\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file longformer-base-4096/pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing Longformer.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of Longformer were initialized from the model checkpoint at longformer-base-4096.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use Longformer for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with config:\n",
      "RobertaConfig {\n",
      "  \"attention_dilation\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"attention_mode\": \"tvm\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"autoregressive\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hotpotqa(\n",
       "  (model): Longformer(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50269, 768)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dense_type): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_type): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dense_sp_sent): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_sp_sent): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dense_sp_para): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_sp_para): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    hotpotqa.__abstractmethods__=set()   # without this, got an error \"Can't instantiate abstract class hotpotqa with abstract methods\" if these two abstract methods are not implemented in the same cell where class hotpotqa defined \n",
    "    model = hotpotqa(args)\n",
    "    model.to('cuda')    # this is necessary to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger = TestTubeLogger( # The TestTubeLogger adds a nicer folder structure to manage experiments and snapshots all hyperparameters you pass to a LightningModule.\n",
    "        save_dir=args.save_dir,\n",
    "        name=args.save_prefix,\n",
    "        version=0  # always use version=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:224: UserWarning: Checkpoint directory jupyter-hotpotqa/hotpotqa-longformer/checkpoints exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  f\"Checkpoint directory {filepath} exists and is not empty with save_top_k != 0.\"\n"
     ]
    }
   ],
   "source": [
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(args.save_dir, args.save_prefix, \"checkpoints\"),\n",
    "        save_top_k=5,\n",
    "        verbose=True,\n",
    "        monitor='avg_val_f1',\n",
    "        mode='max',\n",
    "        prefix=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_size:  16.0\n",
      "num_devices:  1\n",
      ">>>>>>> #train_set_size: 90447.0, #steps: 271341.0,  #warmup steps: 1000, #epochs: 6, batch_size: 2 <<<<<<<\n"
     ]
    }
   ],
   "source": [
    "    train_set_size = 16 * args.train_percent # 90447 * args.train_percent   # hardcode dataset size. Needed to compute number of steps for the lr scheduler\n",
    "    print(\"train_set_size: \", train_set_size) \n",
    "    \n",
    "    args.gpus = [int(x) for x in args.gpus.split(',')] if args.gpus is not \"\" else None\n",
    "    num_devices = len(args.gpus) #1 or len(args.gpus)\n",
    "    print(\"num_devices: \", num_devices)\n",
    "    \n",
    "    train_set_size = 90447 * args.train_percent    # hardcode dataset size. Needed to compute number of steps for the lr scheduler\n",
    "    args.steps = args.epochs * train_set_size / (args.batch_size * num_devices)\n",
    "\n",
    "    print(f'>>>>>>> #train_set_size: {train_set_size}, #steps: {args.steps},  #warmup steps: {args.warmup}, #epochs: {args.epochs}, batch_size: {args.batch_size * num_devices} <<<<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To install apex ### \n",
    "#     !git clone https://github.com/NVIDIA/apex\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/apex/\")\n",
    "#     !module load cuda101/neuralnet/7/7.6.4  \n",
    "#     !module load cuda10.1/toolkit/10.1.243 \n",
    "#     !conda install -c conda-forge cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf201901 cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf202003 cudatoolkit-dev --yes\n",
    "#     !which nvcc\n",
    "#     !python -m pip install -v --no-cache-dir ./\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:using 16bit precision\n"
     ]
    }
   ],
   "source": [
    "    trainer = pl.Trainer(gpus=args.gpus, distributed_backend='ddp', # if args.gpus and (len(args.gpus) > 1) else None,\n",
    "                         track_grad_norm=-1, max_epochs=args.epochs, early_stop_callback=None,\n",
    "                         accumulate_grad_batches=args.batch_size,\n",
    "                         train_percent_check = args.train_percent,\n",
    "#                          val_check_interval=args.val_every,\n",
    "                         val_percent_check=args.val_percent_check,\n",
    "                         test_percent_check=args.val_percent_check,\n",
    "                         logger=logger if not args.disable_checkpointing else False,\n",
    "                         checkpoint_callback=checkpoint_callback if not args.disable_checkpointing else False,\n",
    "                         show_progress_bar=args.no_progress_bar,\n",
    "                         use_amp=not args.fp32, amp_level='O1',\n",
    "                         check_val_every_n_epoch=1\n",
    "                         )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "INFO:root:set slurm handle signals\n",
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: \n",
      "            You're using multiple gpus and multiple nodes without using a DistributedSampler\n",
      "            to assign a subset of your data to each process. To silence this warning, pass a\n",
      "            DistributedSampler to your DataLoader.\n",
      "\n",
      "            ie: this:\n",
      "            dataset = myDataset()\n",
      "            dataloader = Dataloader(dataset)\n",
      "\n",
      "            becomes:\n",
      "            dataset = myDataset()\n",
      "            dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
      "            dataloader = Dataloader(dataset, sampler=dist_sampler)\n",
      "\n",
      "            If you want each process to load the full dataset, ignore this warning.\n",
      "            \n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: small.json\n",
      "['<mask>', '</s>', '<s>', '<p>', '<pad>', '<unk>', '</q>', '</s>', '<cls>', '<q>', '<s>']\n",
      "[50264, 2, 0, 50266, 1, 3, 50268, 2, 50265, 50267, 0]\n",
      "reading file: small_dev.json\n",
      "['<mask>', '</s>', '<s>', '<p>', '<pad>', '<unk>', '</q>', '</s>', '<cls>', '<q>', '<s>']\n",
      "[50264, 2, 0, 50266, 1, 3, 50268, 2, 50265, 50267, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:145: UserWarning: \n",
      "                    Your val_dataloader(s) don't use DistributedSampler.\n",
      "\n",
      "                    You're using multiple gpus and multiple nodes without using a\n",
      "                    DistributedSampler to assign a subset of your data to each process.\n",
      "                    To silence this warning, pass a DistributedSampler to your DataLoader.\n",
      "\n",
      "                    ie: this:\n",
      "                    dataset = myDataset()\n",
      "                    dataloader = Dataloader(dataset)\n",
      "\n",
      "                    becomes:\n",
      "                    dataset = myDataset()\n",
      "                    dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
      "                    dataloader = Dataloader(dataset, sampler=dist_sampler)\n",
      "\n",
      "                    If you want each process to load the full dataset, ignore this warning.\n",
      "                    \n",
      "  warnings.warn(msg)\n",
      "INFO:root:\n",
      "                                       Name               Type Params\n",
      "0                                     model         Longformer  148 M\n",
      "1                          model.embeddings  RobertaEmbeddings   41 M\n",
      "2          model.embeddings.word_embeddings          Embedding   38 M\n",
      "3      model.embeddings.position_embeddings          Embedding    3 M\n",
      "4    model.embeddings.token_type_embeddings          Embedding  768  \n",
      "..                                      ...                ...    ...\n",
      "242                             linear_type             Linear    2 K\n",
      "243                           dense_sp_sent             Linear  590 K\n",
      "244                          linear_sp_sent             Linear  769  \n",
      "245                           dense_sp_para             Linear  590 K\n",
      "246                          linear_sp_para             Linear  769  \n",
      "\n",
      "[247 rows x 3 columns]\n",
      "INFO:root:model and trainer restored from checkpoint: jupyter-hotpotqa/hotpotqa-longformer/checkpoints/_ckpt_epoch_4.ckpt\n",
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/ipykernel_launcher.py:294: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1660])\n",
      "size of attention_mask: torch.Size([1, 1660])\n",
      "size of segment_ids: torch.Size([1, 1660])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 57])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1660, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  24,   50,   81,  118,  130,  161,  201,  237,  269,  297,  356,  389,\n",
      "         415,  462,  480,  500,  520,  540,  562,  591,  620,  662,  678,  706,\n",
      "         754,  773,  782,  813,  839,  854,  883,  923,  955,  991, 1027, 1069,\n",
      "        1083, 1109, 1126, 1154, 1194, 1253, 1287, 1316, 1325, 1360, 1374, 1406,\n",
      "        1436, 1462, 1476, 1497, 1524, 1569, 1586, 1615, 1632], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1543, device='cuda:0')\n",
      "type_loss:  tensor(1.1545, device='cuda:0')\n",
      "answer_loss: tensor(6.7012, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1526], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1526], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([2063], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠFox']\n",
      "answer_gold:  Fox\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {8, 10, 11, 12, 25, 26, 28, 31}\n",
      "gold:  [19, 39]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1011])\n",
      "size of attention_mask: torch.Size([1, 1011])\n",
      "size of segment_ids: torch.Size([1, 1011])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1011, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 52,  78, 111, 127, 144, 167, 192, 213, 234, 261, 276, 293, 321, 345,\n",
      "        369, 394, 428, 453, 480, 505, 521, 558, 572, 604, 620, 670, 697, 718,\n",
      "        736, 747, 766, 779, 783, 808, 834, 861, 885, 900, 928, 963, 980],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2227, device='cuda:0')\n",
      "type_loss:  tensor(1.2220, device='cuda:0')\n",
      "answer_loss: tensor(4.1562, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2817], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2817], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  36, 3789,  322], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ(', '2017', ').']\n",
      "answer_gold:  (2017).\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {0}\n",
      "gold:  [10, 33]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1187])\n",
      "size of attention_mask: torch.Size([1, 1187])\n",
      "size of segment_ids: torch.Size([1, 1187])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1187, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  31,   53,   72,   85,  110,  144,  174,  201,  230,  261,  272,  289,\n",
      "         344,  374,  401,  428,  443,  466,  503,  537,  558,  581,  631,  664,\n",
      "         678,  709,  764,  791,  816,  839,  879,  924,  941,  967,  983, 1008,\n",
      "        1047, 1066, 1111, 1131, 1163], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2500, device='cuda:0')\n",
      "type_loss:  tensor(1.2498, device='cuda:0')\n",
      "answer_loss: tensor(5.4551, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2118], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2118], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([5077,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNevada', '.']\n",
      "answer_gold:  Nevada.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {11, 12, 13}\n",
      "gold:  [10, 11, 13]\n",
      "sp prec:  0.6666666666666666\n",
      "sp recall:  0.6666666666666666\n",
      "sp f1:  0.6666666666666666\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 933])\n",
      "size of attention_mask: torch.Size([1, 933])\n",
      "size of segment_ids: torch.Size([1, 933])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 37])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 933, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 21,  54,  68,  97, 157, 176, 190, 216, 263, 282, 315, 362, 398, 417,\n",
      "        441, 456, 474, 488, 510, 523, 543, 554, 578, 599, 616, 645, 675, 696,\n",
      "        709, 745, 757, 772, 805, 829, 849, 871, 913], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2715, device='cuda:0')\n",
      "type_loss:  tensor(1.2714, device='cuda:0')\n",
      "answer_loss: tensor(6.7871, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2783], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2783], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([6467,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠHawaii', '.']\n",
      "answer_gold:  Hawaii.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {32, 33, 10, 11}\n",
      "gold:  [8, 25]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 851])\n",
      "size of attention_mask: torch.Size([1, 851])\n",
      "size of segment_ids: torch.Size([1, 851])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 35])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 851, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 13,  34,  61,  75,  97, 116, 151, 185, 214, 237, 258, 295, 316, 353,\n",
      "        374, 385, 414, 433, 455, 501, 522, 550, 572, 590, 618, 645, 657, 683,\n",
      "        706, 720, 747, 761, 775, 797, 826], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2734, device='cuda:0')\n",
      "type_loss:  tensor(1.2739, device='cuda:0')\n",
      "answer_loss: tensor(6.0332, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1793], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1793], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  229, 13750,  5986], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠK', 'elli', 'ĠWard']\n",
      "answer_gold:  Kelli Ward\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {11, 12, 13}\n",
      "gold:  [16, 23]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_end\n",
      "before sync --> sizes:  5, 5, 5\n",
      "after sync --> sizes: 5, 5, 5\n",
      "answer_scores:  [0.152587890625, 0.28173828125, 0.2117919921875, 0.2783203125, 0.1793212890625]\n",
      "f1_scores:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "em_scores:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "avg_loss:  tensor(8.3086, device='cuda:0')\tavg_answer_loss:  tensor(5.8266, device='cuda:0')\tavg_type_loss:  tensor(1.2343, device='cuda:0')\tavg_sp_para_loss:  tensor(0.6861, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.5616, device='cuda:0')\tlen(f1_scores):  5\n",
      "avg_val_f1:  0.0\n",
      "avg_val_em:  0.0\n",
      "avg_val_prec:  0.0\n",
      "avg_val_recall:  0.0\n",
      "avg_val_sp_sent_f1:  0.13333333730697633\n",
      "avg_val_sp_sent_em:  0.0\n",
      "avg_val_sp_sent_prec:  0.13333333730697633\n",
      "avg_val_sp_sent_recall:  0.13333333730697633\n",
      "avg_val_joint_f1:  0.0\n",
      "avg_val_joint_em:  0.0\n",
      "avg_val_joint_prec:  0.0\n",
      "avg_val_joint_recall:  0.0\n",
      "Start epoch  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1118])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1118])\n",
      "size of attention_mask: torch.Size([1, 1118])\n",
      "size of segment_ids: torch.Size([1, 1118])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 46])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1118, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  16,   36,   84,   95,  123,  167,  182,  192,  212,  264,  298,  327,\n",
      "         351,  387,  401,  410,  417,  475,  483,  507,  526,  571,  585,  615,\n",
      "         638,  666,  693,  732,  750,  770,  798,  829,  848,  868,  887,  896,\n",
      "         911,  927,  950,  965,  993, 1015, 1035, 1046, 1077, 1092],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2607, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.1152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([1.9500e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1079])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1079])\n",
      "size of attention_mask: torch.Size([1, 1079])\n",
      "size of segment_ids: torch.Size([1, 1079])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 39])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1079, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  22,   50,   76,   91,  111,  119,  144,  171,  190,  231,  289,  322,\n",
      "         336,  349,  381,  398,  430,  457,  521,  552,  576,  594,  621,  644,\n",
      "         664,  681,  715,  742,  759,  801,  855,  887,  921,  931,  964,  979,\n",
      "         998, 1011, 1043], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2197, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([1.9500e-06], device='cuda:0')\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "size of input_ids: torch.Size([1, 2078])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 2078])\n",
      "size of attention_mask: torch.Size([1, 2078])\n",
      "size of segment_ids: torch.Size([1, 2078])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 68])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 2078, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  34,   52,   67,  103,  123,  156,  172,  209,  248,  284,  313,  344,\n",
      "         357,  391,  424,  459,  483,  518,  549,  583,  606,  624,  642,  675,\n",
      "         689,  733,  743,  766,  813,  834,  855,  870,  893,  903, 1028, 1059,\n",
      "        1087, 1103, 1115, 1157, 1179, 1210, 1242, 1288, 1316, 1350, 1364, 1396,\n",
      "        1419, 1456, 1486, 1514, 1541, 1591, 1612, 1656, 1694, 1723, 1746, 1785,\n",
      "        1810, 1842, 1905, 1952, 1979, 2017, 2037, 2059], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1680, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.6426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([1.9500e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 746])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 746])\n",
      "size of attention_mask: torch.Size([1, 746])\n",
      "size of segment_ids: torch.Size([1, 746])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 23])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 746, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 12,  54,  79, 107, 127, 153, 169, 212, 244, 283, 299, 326, 348, 382,\n",
      "        430, 452, 490, 546, 571, 604, 634, 663, 721], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2441, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([1.9500e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1314])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1314])\n",
      "size of attention_mask: torch.Size([1, 1314])\n",
      "size of segment_ids: torch.Size([1, 1314])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 51])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1314, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  23,   49,   71,   93,  125,  142,  189,  200,  212,  295,  308,  344,\n",
      "         364,  376,  402,  437,  452,  465,  481,  511,  528,  545,  563,  581,\n",
      "         625,  641,  664,  676,  709,  754,  775,  794,  833,  856,  890,  899,\n",
      "         918,  930,  947,  970, 1000, 1028, 1049, 1093, 1116, 1129, 1146, 1182,\n",
      "        1199, 1232, 1269], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.4619, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(4.9922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.0000e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1872])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1872])\n",
      "size of attention_mask: torch.Size([1, 1872])\n",
      "size of segment_ids: torch.Size([1, 1872])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 61])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1872, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  20,   60,   92,  124,  163,  210,  273,  304,  377,  409,  461,  493,\n",
      "         533,  553,  579,  618,  628,  663,  684,  712,  732,  769,  785,  823,\n",
      "         834,  881,  923,  944,  982,  994, 1019, 1030, 1044, 1066, 1097, 1110,\n",
      "        1166, 1197, 1238, 1277, 1301, 1337, 1352, 1397, 1447, 1482, 1493, 1509,\n",
      "        1526, 1554, 1589, 1611, 1637, 1664, 1684, 1715, 1754, 1778, 1795, 1829,\n",
      "        1858], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2305, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.7072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.0000e-06], device='cuda:0')\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "size of input_ids: torch.Size([1, 878])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 878])\n",
      "size of attention_mask: torch.Size([1, 878])\n",
      "size of segment_ids: torch.Size([1, 878])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 32])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 878, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 20,  49,  85, 114, 149, 169, 187, 197, 232, 251, 311, 324, 353, 390,\n",
      "        414, 434, 454, 481, 517, 552, 569, 595, 604, 626, 651, 677, 697, 720,\n",
      "        739, 808, 821, 841], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2559, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(5.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.0500e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1494])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1494])\n",
      "size of attention_mask: torch.Size([1, 1494])\n",
      "size of segment_ids: torch.Size([1, 1494])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1494, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  47,   86,  110,  139,  182,  208,  229,  247,  302,  349,  366,  393,\n",
      "         424,  466,  498,  522,  550,  588,  614,  666,  708,  767,  804,  828,\n",
      "         886,  915,  948,  967,  982, 1027, 1090, 1120, 1165, 1187, 1222, 1246,\n",
      "        1280, 1325, 1388, 1420], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6545, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.0500e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1459])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1459])\n",
      "size of attention_mask: torch.Size([1, 1459])\n",
      "size of segment_ids: torch.Size([1, 1459])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1459, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  26,   59,  100,  132,  145,  169,  185,  212,  218,  237,  253,  269,\n",
      "         282,  303,  327,  345,  367,  397,  418,  437,  448,  470,  493,  516,\n",
      "         540,  567,  597,  618,  643,  673,  697,  772,  837,  883,  908,  951,\n",
      "         965,  991, 1029, 1057, 1074, 1099, 1122, 1142, 1157, 1188, 1234, 1275,\n",
      "        1295, 1320, 1360, 1374, 1411], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2119, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.1000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 994])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 994])\n",
      "size of attention_mask: torch.Size([1, 994])\n",
      "size of segment_ids: torch.Size([1, 994])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 29])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 994, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 24,  46,  96, 143, 162, 208, 259, 287, 316, 331, 354, 374, 408, 451,\n",
      "        493, 509, 529, 564, 585, 633, 675, 691, 731, 774, 816, 866, 891, 910,\n",
      "        953], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2324, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.1000e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1376])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1376])\n",
      "size of attention_mask: torch.Size([1, 1376])\n",
      "size of segment_ids: torch.Size([1, 1376])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 35])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1376, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  22,   50,   85,  114,  158,  207,  244,  285,  302,  322,  353,  370,\n",
      "         430,  459,  479,  492,  553,  582,  645,  790,  796,  858,  882,  931,\n",
      "         968,  978,  999, 1034, 1114, 1129, 1161, 1185, 1217, 1243, 1260],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.4336, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.1500e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1316])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1316])\n",
      "size of attention_mask: torch.Size([1, 1316])\n",
      "size of segment_ids: torch.Size([1, 1316])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 38])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1316, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  17,   45,   85,  113,  152,  240,  277,  310,  375,  402,  450,  469,\n",
      "         493,  513,  529,  562,  616,  652,  704,  755,  760,  788,  814,  850,\n",
      "         878,  912,  928,  967,  998, 1031, 1072, 1095, 1135, 1149, 1193, 1228,\n",
      "        1284, 1303], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1807, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.1500e-06], device='cuda:0')\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "size of input_ids: torch.Size([1, 1548])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1548])\n",
      "size of attention_mask: torch.Size([1, 1548])\n",
      "size of segment_ids: torch.Size([1, 1548])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 43])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1548, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   62,  148,  164,  187,  250,  282,  322,  340,  366,  395,  457,\n",
      "         483,  534,  568,  600,  665,  718,  771,  786,  806,  852,  863,  885,\n",
      "         913,  940,  962,  991, 1038, 1049, 1073, 1090, 1150, 1172, 1207, 1246,\n",
      "        1293, 1322, 1350, 1383, 1439, 1474, 1498], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.0840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.2000e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1597])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1597])\n",
      "size of attention_mask: torch.Size([1, 1597])\n",
      "size of segment_ids: torch.Size([1, 1597])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 50])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  17,   60,   78,  123,  138,  175,  196,  227,  236,  255,  277,  327,\n",
      "         370,  393,  421,  474,  497,  524,  540,  557,  577,  599,  629,  653,\n",
      "         694,  747,  783,  804,  865,  909,  937,  968,  998, 1036, 1072, 1126,\n",
      "        1141, 1169, 1197, 1223, 1280, 1309, 1334, 1353, 1384, 1443, 1463, 1503,\n",
      "        1532, 1562], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.7520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.2000e-06], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1285])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1285])\n",
      "size of attention_mask: torch.Size([1, 1285])\n",
      "size of segment_ids: torch.Size([1, 1285])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 48])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1285, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   51,   77,  107,  135,  158,  225,  251,  306,  334,  343,  355,\n",
      "         372,  390,  406,  422,  431,  454,  474,  498,  520,  540,  569,  606,\n",
      "         616,  636,  698,  736,  772,  792,  821,  846,  881,  903,  933,  954,\n",
      "        1002, 1025, 1045, 1087, 1102, 1131, 1165, 1182, 1210, 1236, 1250, 1268],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.2500e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1345])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1345])\n",
      "size of attention_mask: torch.Size([1, 1345])\n",
      "size of segment_ids: torch.Size([1, 1345])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1345, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  37,   79,  117,  158,  189,  229,  331,  359,  388,  410,  435,  458,\n",
      "         474,  505,  523,  542,  574,  604,  651,  666,  703,  777,  803,  823,\n",
      "         860,  885,  895,  915,  984, 1030, 1055, 1093, 1114, 1137, 1167, 1189,\n",
      "        1215, 1240, 1271, 1319], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1670, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.2500e-06], device='cuda:0')\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1660])\n",
      "size of attention_mask: torch.Size([1, 1660])\n",
      "size of segment_ids: torch.Size([1, 1660])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 57])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1660, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  24,   50,   81,  118,  130,  161,  201,  237,  269,  297,  356,  389,\n",
      "         415,  462,  480,  500,  520,  540,  562,  591,  620,  662,  678,  706,\n",
      "         754,  773,  782,  813,  839,  854,  883,  923,  955,  991, 1027, 1069,\n",
      "        1083, 1109, 1126, 1154, 1194, 1253, 1287, 1316, 1325, 1360, 1374, 1406,\n",
      "        1436, 1462, 1476, 1497, 1524, 1569, 1586, 1615, 1632], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0859, device='cuda:0')\n",
      "type_loss:  tensor(1.0861, device='cuda:0')\n",
      "answer_loss: tensor(6.6914, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1025], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1025], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([2063], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠFox']\n",
      "answer_gold:  Fox\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {8, 9, 11, 12, 25, 26, 28, 31}\n",
      "gold:  [19, 39]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1011])\n",
      "size of attention_mask: torch.Size([1, 1011])\n",
      "size of segment_ids: torch.Size([1, 1011])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1011, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 52,  78, 111, 127, 144, 167, 192, 213, 234, 261, 276, 293, 321, 345,\n",
      "        369, 394, 428, 453, 480, 505, 521, 558, 572, 604, 620, 670, 697, 718,\n",
      "        736, 747, 766, 779, 783, 808, 834, 861, 885, 900, 928, 963, 980],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1729, device='cuda:0')\n",
      "type_loss:  tensor(1.1720, device='cuda:0')\n",
      "answer_loss: tensor(4.1504, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2542], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2542], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  36, 3789,  322], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ(', '2017', ').']\n",
      "answer_gold:  (2017).\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {10}\n",
      "gold:  [10, 33]\n",
      "sp prec:  1.0\n",
      "sp recall:  0.5\n",
      "sp f1:  0.6666666666666666\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1187])\n",
      "size of attention_mask: torch.Size([1, 1187])\n",
      "size of segment_ids: torch.Size([1, 1187])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1187, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  31,   53,   72,   85,  110,  144,  174,  201,  230,  261,  272,  289,\n",
      "         344,  374,  401,  428,  443,  466,  503,  537,  558,  581,  631,  664,\n",
      "         678,  709,  764,  791,  816,  839,  879,  924,  941,  967,  983, 1008,\n",
      "        1047, 1066, 1111, 1131, 1163], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2070, device='cuda:0')\n",
      "type_loss:  tensor(1.2071, device='cuda:0')\n",
      "answer_loss: tensor(5.4492, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1841], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1841], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([5077,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNevada', '.']\n",
      "answer_gold:  Nevada.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {11, 12, 13}\n",
      "gold:  [10, 11, 13]\n",
      "sp prec:  0.6666666666666666\n",
      "sp recall:  0.6666666666666666\n",
      "sp f1:  0.6666666666666666\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 933])\n",
      "size of attention_mask: torch.Size([1, 933])\n",
      "size of segment_ids: torch.Size([1, 933])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 37])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 933, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 21,  54,  68,  97, 157, 176, 190, 216, 263, 282, 315, 362, 398, 417,\n",
      "        441, 456, 474, 488, 510, 523, 543, 554, 578, 599, 616, 645, 675, 696,\n",
      "        709, 745, 757, 772, 805, 829, 849, 871, 913], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2324, device='cuda:0')\n",
      "type_loss:  tensor(1.2323, device='cuda:0')\n",
      "answer_loss: tensor(6.7754, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2729], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2729], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([6467,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠHawaii', '.']\n",
      "answer_gold:  Hawaii.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {32, 33, 10, 11}\n",
      "gold:  [8, 25]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 851])\n",
      "size of attention_mask: torch.Size([1, 851])\n",
      "size of segment_ids: torch.Size([1, 851])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 35])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 851, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 13,  34,  61,  75,  97, 116, 151, 185, 214, 237, 258, 295, 316, 353,\n",
      "        374, 385, 414, 433, 455, 501, 522, 550, 572, 590, 618, 645, 657, 683,\n",
      "        706, 720, 747, 761, 775, 797, 826], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2275, device='cuda:0')\n",
      "type_loss:  tensor(1.2280, device='cuda:0')\n",
      "answer_loss: tensor(6.0254, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1539], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1539], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  229, 13750,  5986], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠK', 'elli', 'ĠWard']\n",
      "answer_gold:  Kelli Ward\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {11, 12, 13}\n",
      "gold:  [16, 23]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1320])\n",
      "size of attention_mask: torch.Size([1, 1320])\n",
      "size of segment_ids: torch.Size([1, 1320])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 37])\n",
      "size of sp_para: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1320, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  29,   60,  100,  151,  168,  237,  329,  376,  438,  475,  516,  546,\n",
      "         578,  601,  639,  662,  692,  741,  765,  782,  817,  839,  895,  935,\n",
      "         953,  971,  992, 1032, 1068, 1098, 1127, 1160, 1192, 1208, 1238, 1264,\n",
      "        1287], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2344, device='cuda:0')\n",
      "type_loss:  tensor(1.2348, device='cuda:0')\n",
      "answer_loss: tensor(7.3691, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.3208], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.3208], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([   20,  7602,   298, 12363], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠThe', 'ĠWolf', 'h', 'ounds']\n",
      "answer_gold:  The Wolfhounds\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {36}\n",
      "gold:  [16, 33, 35]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1662])\n",
      "size of attention_mask: torch.Size([1, 1662])\n",
      "size of segment_ids: torch.Size([1, 1662])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1662, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  15,   45,   81,  126,  144,  171,  212,  231,  306,  334,  370,  416,\n",
      "         459,  504,  551,  586,  623,  649,  666,  704,  725,  767,  776,  805,\n",
      "         844,  886,  920,  940,  955,  978, 1003, 1046, 1074, 1114, 1159, 1204,\n",
      "        1226, 1274, 1295, 1342, 1365, 1378, 1398, 1426, 1460, 1463, 1503, 1529,\n",
      "        1545, 1582, 1602, 1617, 1635], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2715, device='cuda:0')\n",
      "type_loss:  tensor(1.2714, device='cuda:0')\n",
      "answer_loss: tensor(7.4766, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1200], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1200], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([545,  12, 180,  12, 279], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ16', '-', 'year', '-', 'old']\n",
      "answer_gold:  16-year-old\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {10, 11, 22, 23, 25, 26}\n",
      "gold:  [0, 18]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1649])\n",
      "size of attention_mask: torch.Size([1, 1649])\n",
      "size of segment_ids: torch.Size([1, 1649])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1649, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,  148,  197,  240,  268,  323,  341,  352,  366,  401,  428,  458,\n",
      "         476,  495,  523,  548,  584,  642,  661,  670,  701,  755,  794,  828,\n",
      "         884,  931,  960,  973, 1003, 1026, 1042, 1082, 1104, 1127, 1163, 1182,\n",
      "        1205, 1232, 1259, 1278, 1297, 1325, 1347, 1365, 1418, 1489, 1509, 1528,\n",
      "        1548, 1570, 1596, 1610, 1624], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2188, device='cuda:0')\n",
      "type_loss:  tensor(1.2188, device='cuda:0')\n",
      "answer_loss: tensor(6.2227, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1564], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1564], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([ 623, 1771, 3082], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠWorld', 'ĠWar', 'ĠII']\n",
      "answer_gold:  World War II\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {25, 26, 27}\n",
      "gold:  [19, 50]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 2018])\n",
      "size of attention_mask: torch.Size([1, 2018])\n",
      "size of segment_ids: torch.Size([1, 2018])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 58])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 2018, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   40,   74,  103,  184,  196,  262,  275,  295,  332,  354,  392,\n",
      "         433,  460,  470,  498,  525,  619,  654,  682,  705,  753,  801,  831,\n",
      "         856,  870,  884,  912,  936,  979,  993, 1032, 1078, 1131, 1176, 1179,\n",
      "        1225, 1279, 1333, 1360, 1375, 1398, 1416, 1446, 1482, 1513, 1547, 1572,\n",
      "        1608, 1632, 1646, 1673, 1717, 1743, 1781, 1879, 1912, 1994],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2803, device='cuda:0')\n",
      "type_loss:  tensor(1.2802, device='cuda:0')\n",
      "answer_loss: tensor(7.6582, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1946], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1946], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([6540, 7431,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠTodd', 'ĠPhillips', '.']\n",
      "answer_gold:  Todd Phillips.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {22, 23, 26, 27, 28}\n",
      "gold:  [18, 55, 56]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1310])\n",
      "size of attention_mask: torch.Size([1, 1310])\n",
      "size of segment_ids: torch.Size([1, 1310])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1310, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  34,   60,   91,  127,  199,  211,  222,  240,  263,  316,  347,  381,\n",
      "         398,  453,  471,  479,  516,  579,  615,  651,  685,  711,  750,  785,\n",
      "         804,  837,  871,  932,  979,  997, 1027, 1048, 1069, 1092, 1115, 1155,\n",
      "        1207, 1251, 1277, 1301], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1855, device='cuda:0')\n",
      "type_loss:  tensor(1.1860, device='cuda:0')\n",
      "answer_loss: tensor(6.5723, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1715], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1715], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([9347, 6226,    6], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠCarol', 'ĠLawrence', ',']\n",
      "answer_gold:  Carol Lawrence,\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {6}\n",
      "gold:  [8, 9]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([2], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1400])\n",
      "size of attention_mask: torch.Size([1, 1400])\n",
      "size of segment_ids: torch.Size([1, 1400])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1400, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  21,  109,  128,  158,  182,  219,  243,  290,  322,  363,  389,  445,\n",
      "         480,  514,  553,  563,  572,  602,  612,  628,  661,  672,  691,  703,\n",
      "         745,  780,  833,  868,  967, 1072, 1116, 1132, 1152, 1198, 1219, 1251,\n",
      "        1297, 1325, 1349, 1368, 1380], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(0.8350, device='cuda:0')\n",
      "type_loss:  tensor(0.8351, device='cuda:0')\n",
      "answer_loss: tensor(0., device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1089], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1089], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold: no\n",
      "f1: tensor(1., device='cuda:0')\n",
      "prec: tensor(1., device='cuda:0')\n",
      "recall: tensor(1., device='cuda:0')\n",
      "em: tensor(1., device='cuda:0')\n",
      "prediction:  {36, 38, 40, 24, 25, 26}\n",
      "gold:  [27, 28]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([2], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 943])\n",
      "size of attention_mask: torch.Size([1, 943])\n",
      "size of segment_ids: torch.Size([1, 943])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 27])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 943, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 17,  37,  70,  92, 115, 148, 168, 248, 261, 330, 367, 385, 430, 460,\n",
      "        495, 556, 594, 607, 634, 672, 687, 723, 746, 807, 832, 877, 898],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(0.8022, device='cuda:0')\n",
      "type_loss:  tensor(0.8025, device='cuda:0')\n",
      "answer_loss: tensor(0., device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1713], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1713], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold: no\n",
      "f1: tensor(1., device='cuda:0')\n",
      "prec: tensor(1., device='cuda:0')\n",
      "recall: tensor(1., device='cuda:0')\n",
      "em: tensor(1., device='cuda:0')\n",
      "prediction:  {8, 9, 10, 19, 20, 21, 22, 23, 24}\n",
      "gold:  [5, 25]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1849])\n",
      "size of attention_mask: torch.Size([1, 1849])\n",
      "size of segment_ids: torch.Size([1, 1849])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 51])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1849, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  18,   60,   75,  117,  171,  192,  206,  225,  285,  319,  338,  393,\n",
      "         495,  521,  538,  568,  601,  622,  644,  652,  689,  722,  747,  805,\n",
      "         836,  870,  901,  941,  970, 1013, 1047, 1085, 1103, 1203, 1238, 1256,\n",
      "        1280, 1355, 1395, 1442, 1467, 1553, 1567, 1596, 1625, 1661, 1671, 1696,\n",
      "        1736, 1806, 1824], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.3203, device='cuda:0')\n",
      "type_loss:  tensor(1.3201, device='cuda:0')\n",
      "answer_loss: tensor(5.2676, device='cuda:0')\n",
      "decode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Epoch 00004: avg_val_f1 reached 0.15385 (best 0.15385), saving model to jupyter-hotpotqa/hotpotqa-longformer/checkpoints/_ckpt_epoch_4_v0.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_pred: [{'text': 'no', 'score': tensor([0.1996], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1996], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([188, 469, 412], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNew', 'ĠYork', 'ĠCity']\n",
      "answer_gold:  New York City\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {49, 50}\n",
      "gold:  [4, 12]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_end\n",
      "before sync --> sizes:  13, 13, 13\n",
      "after sync --> sizes: 13, 13, 13\n",
      "answer_scores:  [0.1025390625, 0.254150390625, 0.18408203125, 0.27294921875, 0.1539306640625, 0.32080078125, 0.1199951171875, 0.1563720703125, 0.194580078125, 0.1715087890625, 0.10888671875, 0.1712646484375, 0.1995849609375]\n",
      "f1_scores:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "em_scores:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "avg_loss:  tensor(7.7167, device='cuda:0')\tavg_answer_loss:  tensor(5.3583, device='cuda:0')\tavg_type_loss:  tensor(1.1595, device='cuda:0')\tavg_sp_para_loss:  tensor(0.6557, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.5431, device='cuda:0')\tlen(f1_scores):  13\n",
      "avg_val_f1:  0.15384615384615385\n",
      "avg_val_em:  0.15384615384615385\n",
      "avg_val_prec:  0.15384615384615385\n",
      "avg_val_recall:  0.15384615384615385\n",
      "avg_val_sp_sent_f1:  0.10256410562075101\n",
      "avg_val_sp_sent_em:  0.0\n",
      "avg_val_sp_sent_prec:  0.12820512973345244\n",
      "avg_val_sp_sent_recall:  0.08974359127191398\n",
      "avg_val_joint_f1:  0.0\n",
      "avg_val_joint_em:  0.0\n",
      "avg_val_joint_prec:  0.0\n",
      "avg_val_joint_recall:  0.0\n",
      "Start epoch  5\n",
      "size of input_ids: torch.Size([1, 1118])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1118])\n",
      "size of attention_mask: torch.Size([1, 1118])\n",
      "size of segment_ids: torch.Size([1, 1118])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 46])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1118, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  16,   36,   84,   95,  123,  167,  182,  192,  212,  264,  298,  327,\n",
      "         351,  387,  401,  410,  417,  475,  483,  507,  526,  571,  585,  615,\n",
      "         638,  666,  693,  732,  750,  770,  798,  829,  848,  868,  887,  896,\n",
      "         911,  927,  950,  965,  993, 1015, 1035, 1046, 1077, 1092],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.3000e-06], device='cuda:0')\n",
      "training_step  0\n",
      "size of input_ids: torch.Size([1, 1079])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1079])\n",
      "size of attention_mask: torch.Size([1, 1079])\n",
      "size of segment_ids: torch.Size([1, 1079])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 39])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1079, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  22,   50,   76,   91,  111,  119,  144,  171,  190,  231,  289,  322,\n",
      "         336,  349,  381,  398,  430,  457,  521,  552,  576,  594,  621,  644,\n",
      "         664,  681,  715,  742,  759,  801,  855,  887,  921,  931,  964,  979,\n",
      "         998, 1011, 1043], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.3000e-06], device='cuda:0')\n",
      "training_step  1\n",
      "size of input_ids: torch.Size([1, 2078])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 2078])\n",
      "size of attention_mask: torch.Size([1, 2078])\n",
      "size of segment_ids: torch.Size([1, 2078])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 68])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 2078, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  34,   52,   67,  103,  123,  156,  172,  209,  248,  284,  313,  344,\n",
      "         357,  391,  424,  459,  483,  518,  549,  583,  606,  624,  642,  675,\n",
      "         689,  733,  743,  766,  813,  834,  855,  870,  893,  903, 1028, 1059,\n",
      "        1087, 1103, 1115, 1157, 1179, 1210, 1242, 1288, 1316, 1350, 1364, 1396,\n",
      "        1419, 1456, 1486, 1514, 1541, 1591, 1612, 1656, 1694, 1723, 1746, 1785,\n",
      "        1810, 1842, 1905, 1952, 1979, 2017, 2037, 2059], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1807, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.6250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.5971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.3500e-06], device='cuda:0')\n",
      "training_step  2\n",
      "size of input_ids: torch.Size([1, 746])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 746])\n",
      "size of attention_mask: torch.Size([1, 746])\n",
      "size of segment_ids: torch.Size([1, 746])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 23])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 746, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 12,  54,  79, 107, 127, 153, 169, 212, 244, 283, 299, 326, 348, 382,\n",
      "        430, 452, 490, 546, 571, 604, 634, 663, 721], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.4941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.3500e-06], device='cuda:0')\n",
      "training_step  3\n",
      "size of input_ids: torch.Size([1, 1314])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1314])\n",
      "size of attention_mask: torch.Size([1, 1314])\n",
      "size of segment_ids: torch.Size([1, 1314])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 51])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1314, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  23,   49,   71,   93,  125,  142,  189,  200,  212,  295,  308,  344,\n",
      "         364,  376,  402,  437,  452,  465,  481,  511,  528,  545,  563,  581,\n",
      "         625,  641,  664,  676,  709,  754,  775,  794,  833,  856,  890,  899,\n",
      "         918,  930,  947,  970, 1000, 1028, 1049, 1093, 1116, 1129, 1146, 1182,\n",
      "        1199, 1232, 1269], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1973, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(5.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.4000e-06], device='cuda:0')\n",
      "training_step  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1872])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1872])\n",
      "size of attention_mask: torch.Size([1, 1872])\n",
      "size of segment_ids: torch.Size([1, 1872])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 61])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1872, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  20,   60,   92,  124,  163,  210,  273,  304,  377,  409,  461,  493,\n",
      "         533,  553,  579,  618,  628,  663,  684,  712,  732,  769,  785,  823,\n",
      "         834,  881,  923,  944,  982,  994, 1019, 1030, 1044, 1066, 1097, 1110,\n",
      "        1166, 1197, 1238, 1277, 1301, 1337, 1352, 1397, 1447, 1482, 1493, 1509,\n",
      "        1526, 1554, 1589, 1611, 1637, 1664, 1684, 1715, 1754, 1778, 1795, 1829,\n",
      "        1858], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1885, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.4000e-06], device='cuda:0')\n",
      "training_step  5\n",
      "size of input_ids: torch.Size([1, 878])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 878])\n",
      "size of attention_mask: torch.Size([1, 878])\n",
      "size of segment_ids: torch.Size([1, 878])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 32])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 878, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 20,  49,  85, 114, 149, 169, 187, 197, 232, 251, 311, 324, 353, 390,\n",
      "        414, 434, 454, 481, 517, 552, 569, 595, 604, 626, 651, 677, 697, 720,\n",
      "        739, 808, 821, 841], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1680, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(5.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.4500e-06], device='cuda:0')\n",
      "training_step  6\n",
      "size of input_ids: torch.Size([1, 1494])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1494])\n",
      "size of attention_mask: torch.Size([1, 1494])\n",
      "size of segment_ids: torch.Size([1, 1494])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1494, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  47,   86,  110,  139,  182,  208,  229,  247,  302,  349,  366,  393,\n",
      "         424,  466,  498,  522,  550,  588,  614,  666,  708,  767,  804,  828,\n",
      "         886,  915,  948,  967,  982, 1027, 1090, 1120, 1165, 1187, 1222, 1246,\n",
      "        1280, 1325, 1388, 1420], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.0891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.0891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.4500e-06], device='cuda:0')\n",
      "training_step  7\n",
      "size of input_ids: torch.Size([1, 1459])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1459])\n",
      "size of attention_mask: torch.Size([1, 1459])\n",
      "size of segment_ids: torch.Size([1, 1459])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1459, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  26,   59,  100,  132,  145,  169,  185,  212,  218,  237,  253,  269,\n",
      "         282,  303,  327,  345,  367,  397,  418,  437,  448,  470,  493,  516,\n",
      "         540,  567,  597,  618,  643,  673,  697,  772,  837,  883,  908,  951,\n",
      "         965,  991, 1029, 1057, 1074, 1099, 1122, 1142, 1157, 1188, 1234, 1275,\n",
      "        1295, 1320, 1360, 1374, 1411], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1396, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.5000e-06], device='cuda:0')\n",
      "training_step  8\n",
      "size of input_ids: torch.Size([1, 994])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 994])\n",
      "size of attention_mask: torch.Size([1, 994])\n",
      "size of segment_ids: torch.Size([1, 994])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 29])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 994, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 24,  46,  96, 143, 162, 208, 259, 287, 316, 331, 354, 374, 408, 451,\n",
      "        493, 509, 529, 564, 585, 633, 675, 691, 731, 774, 816, 866, 891, 910,\n",
      "        953], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1084, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.5000e-06], device='cuda:0')\n",
      "training_step  9\n",
      "size of input_ids: torch.Size([1, 1376])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1376])\n",
      "size of attention_mask: torch.Size([1, 1376])\n",
      "size of segment_ids: torch.Size([1, 1376])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 35])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1376, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  22,   50,   85,  114,  158,  207,  244,  285,  302,  322,  353,  370,\n",
      "         430,  459,  479,  492,  553,  582,  645,  790,  796,  858,  882,  931,\n",
      "         968,  978,  999, 1034, 1114, 1129, 1161, 1185, 1217, 1243, 1260],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.5500e-06], device='cuda:0')\n",
      "training_step  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1316])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1316])\n",
      "size of attention_mask: torch.Size([1, 1316])\n",
      "size of segment_ids: torch.Size([1, 1316])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 38])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1316, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  17,   45,   85,  113,  152,  240,  277,  310,  375,  402,  450,  469,\n",
      "         493,  513,  529,  562,  616,  652,  704,  755,  760,  788,  814,  850,\n",
      "         878,  912,  928,  967,  998, 1031, 1072, 1095, 1135, 1149, 1193, 1228,\n",
      "        1284, 1303], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2852, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.2854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.5500e-06], device='cuda:0')\n",
      "training_step  11\n",
      "size of input_ids: torch.Size([1, 1548])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1548])\n",
      "size of attention_mask: torch.Size([1, 1548])\n",
      "size of segment_ids: torch.Size([1, 1548])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 43])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1548, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   62,  148,  164,  187,  250,  282,  322,  340,  366,  395,  457,\n",
      "         483,  534,  568,  600,  665,  718,  771,  786,  806,  852,  863,  885,\n",
      "         913,  940,  962,  991, 1038, 1049, 1073, 1090, 1150, 1172, 1207, 1246,\n",
      "        1293, 1322, 1350, 1383, 1439, 1474, 1498], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1436, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.5856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.6000e-06], device='cuda:0')\n",
      "training_step  12\n",
      "size of input_ids: torch.Size([1, 1597])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1597])\n",
      "size of attention_mask: torch.Size([1, 1597])\n",
      "size of segment_ids: torch.Size([1, 1597])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 50])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  17,   60,   78,  123,  138,  175,  196,  227,  236,  255,  277,  327,\n",
      "         370,  393,  421,  474,  497,  524,  540,  557,  577,  599,  629,  653,\n",
      "         694,  747,  783,  804,  865,  909,  937,  968,  998, 1036, 1072, 1126,\n",
      "        1141, 1169, 1197, 1223, 1280, 1309, 1334, 1353, 1384, 1443, 1463, 1503,\n",
      "        1532, 1562], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0664, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.0666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.5801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.0666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.6000e-06], device='cuda:0')\n",
      "training_step  13\n",
      "size of input_ids: torch.Size([1, 1285])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1285])\n",
      "size of attention_mask: torch.Size([1, 1285])\n",
      "size of segment_ids: torch.Size([1, 1285])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 48])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1285, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   51,   77,  107,  135,  158,  225,  251,  306,  334,  343,  355,\n",
      "         372,  390,  406,  422,  431,  454,  474,  498,  520,  540,  569,  606,\n",
      "         616,  636,  698,  736,  772,  792,  821,  846,  881,  903,  933,  954,\n",
      "        1002, 1025, 1045, 1087, 1102, 1131, 1165, 1182, 1210, 1236, 1250, 1268],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1270, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(7.0723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.6500e-06], device='cuda:0')\n",
      "training_step  14\n",
      "size of input_ids: torch.Size([1, 1345])\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1345])\n",
      "size of attention_mask: torch.Size([1, 1345])\n",
      "size of segment_ids: torch.Size([1, 1345])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1345, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  37,   79,  117,  158,  189,  229,  331,  359,  388,  410,  435,  458,\n",
      "         474,  505,  523,  542,  574,  604,  651,  666,  703,  777,  803,  823,\n",
      "         860,  885,  895,  915,  984, 1030, 1055, 1093, 1114, 1137, 1167, 1189,\n",
      "        1215, 1240, 1271, 1319], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "type_loss:  tensor(1.1094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "answer_loss:  tensor(6.6074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "type_loss:  tensor(1.1094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_para_loss:  tensor(0.6511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "sp_sent_loss:  tensor(0.5376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "lr:  tensor([2.6500e-06], device='cuda:0')\n",
      "training_step  15\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1660])\n",
      "size of attention_mask: torch.Size([1, 1660])\n",
      "size of segment_ids: torch.Size([1, 1660])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 57])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1660, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  24,   50,   81,  118,  130,  161,  201,  237,  269,  297,  356,  389,\n",
      "         415,  462,  480,  500,  520,  540,  562,  591,  620,  662,  678,  706,\n",
      "         754,  773,  782,  813,  839,  854,  883,  923,  955,  991, 1027, 1069,\n",
      "        1083, 1109, 1126, 1154, 1194, 1253, 1287, 1316, 1325, 1360, 1374, 1406,\n",
      "        1436, 1462, 1476, 1497, 1524, 1569, 1586, 1615, 1632], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(0.9546, device='cuda:0')\n",
      "type_loss:  tensor(0.9548, device='cuda:0')\n",
      "answer_loss: tensor(6.6680, device='cuda:0')\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers: [{'text': ' This is a list of episodes for the Canadian crime series \"Republic of Doyle\".', 'score': tensor([0.6260], device='cuda:0', dtype=torch.float16)}]\n",
      "answers_pred: [{'text': ' This is a list of episodes for the Canadian crime series \"Republic of Doyle\".', 'score': tensor([0.6260], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.6260], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text:  This is a list of episodes for the Canadian crime series \"Republic of Doyle\".\n",
      "answer_gold_token_ids: tensor([2063], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠFox']\n",
      "answer_gold:  Fox\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {26, 28, 30, 31}\n",
      "gold:  [19, 39]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1011])\n",
      "size of attention_mask: torch.Size([1, 1011])\n",
      "size of segment_ids: torch.Size([1, 1011])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1011, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 52,  78, 111, 127, 144, 167, 192, 213, 234, 261, 276, 293, 321, 345,\n",
      "        369, 394, 428, 453, 480, 505, 521, 558, 572, 604, 620, 670, 697, 718,\n",
      "        736, 747, 766, 779, 783, 808, 834, 861, 885, 900, 928, 963, 980],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0771, device='cuda:0')\n",
      "type_loss:  tensor(1.0767, device='cuda:0')\n",
      "answer_loss: tensor(4.1445, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1992], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1992], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  36, 3789,  322], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ(', '2017', ').']\n",
      "answer_gold:  (2017).\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {10, 11, 5}\n",
      "gold:  [10, 33]\n",
      "sp prec:  0.3333333333333333\n",
      "sp recall:  0.5\n",
      "sp f1:  0.4\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1187])\n",
      "size of attention_mask: torch.Size([1, 1187])\n",
      "size of segment_ids: torch.Size([1, 1187])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1187, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  31,   53,   72,   85,  110,  144,  174,  201,  230,  261,  272,  289,\n",
      "         344,  374,  401,  428,  443,  466,  503,  537,  558,  581,  631,  664,\n",
      "         678,  709,  764,  791,  816,  839,  879,  924,  941,  967,  983, 1008,\n",
      "        1047, 1066, 1111, 1131, 1163], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1094, device='cuda:0')\n",
      "type_loss:  tensor(1.1098, device='cuda:0')\n",
      "answer_loss: tensor(5.4375, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1149], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1149], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([5077,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNevada', '.']\n",
      "answer_gold:  Nevada.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 933])\n",
      "size of attention_mask: torch.Size([1, 933])\n",
      "size of segment_ids: torch.Size([1, 933])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 37])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 933, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 21,  54,  68,  97, 157, 176, 190, 216, 263, 282, 315, 362, 398, 417,\n",
      "        441, 456, 474, 488, 510, 523, 543, 554, 578, 599, 616, 645, 675, 696,\n",
      "        709, 745, 757, 772, 805, 829, 849, 871, 913], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1338, device='cuda:0')\n",
      "type_loss:  tensor(1.1337, device='cuda:0')\n",
      "answer_loss: tensor(6.7266, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.2246], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2246], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([6467,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠHawaii', '.']\n",
      "answer_gold:  Hawaii.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {32, 33, 34, 36}\n",
      "gold:  [8, 25]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 851])\n",
      "size of attention_mask: torch.Size([1, 851])\n",
      "size of segment_ids: torch.Size([1, 851])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 35])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 851, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 13,  34,  61,  75,  97, 116, 151, 185, 214, 237, 258, 295, 316, 353,\n",
      "        374, 385, 414, 433, 455, 501, 522, 550, 572, 590, 618, 645, 657, 683,\n",
      "        706, 720, 747, 761, 775, 797, 826], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1211, device='cuda:0')\n",
      "type_loss:  tensor(1.1211, device='cuda:0')\n",
      "answer_loss: tensor(6.0039, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.0858], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.0858], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([  229, 13750,  5986], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠK', 'elli', 'ĠWard']\n",
      "answer_gold:  Kelli Ward\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {11, 12, 13}\n",
      "gold:  [16, 23]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1320])\n",
      "size of attention_mask: torch.Size([1, 1320])\n",
      "size of segment_ids: torch.Size([1, 1320])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 37])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1320, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  29,   60,  100,  151,  168,  237,  329,  376,  438,  475,  516,  546,\n",
      "         578,  601,  639,  662,  692,  741,  765,  782,  817,  839,  895,  935,\n",
      "         953,  971,  992, 1032, 1068, 1098, 1127, 1160, 1192, 1208, 1238, 1264,\n",
      "        1287], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0840, device='cuda:0')\n",
      "type_loss:  tensor(1.0846, device='cuda:0')\n",
      "answer_loss: tensor(7.3828, device='cuda:0')\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_pred: [{'text': 'no', 'score': tensor([0.2269], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.2269], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([   20,  7602,   298, 12363], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠThe', 'ĠWolf', 'h', 'ounds']\n",
      "answer_gold:  The Wolfhounds\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {4, 5, 7}\n",
      "gold:  [16, 33, 35]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1662])\n",
      "size of attention_mask: torch.Size([1, 1662])\n",
      "size of segment_ids: torch.Size([1, 1662])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1662, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  15,   45,   81,  126,  144,  171,  212,  231,  306,  334,  370,  416,\n",
      "         459,  504,  551,  586,  623,  649,  666,  704,  725,  767,  776,  805,\n",
      "         844,  886,  920,  940,  955,  978, 1003, 1046, 1074, 1114, 1159, 1204,\n",
      "        1226, 1274, 1295, 1342, 1365, 1378, 1398, 1426, 1460, 1463, 1503, 1529,\n",
      "        1545, 1582, 1602, 1617, 1635], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0947, device='cuda:0')\n",
      "type_loss:  tensor(1.0947, device='cuda:0')\n",
      "answer_loss: tensor(7.4629, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([-0.0041], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([-0.0041], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([545,  12, 180,  12, 279], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ16', '-', 'year', '-', 'old']\n",
      "answer_gold:  16-year-old\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {19, 22, 23, 25, 26}\n",
      "gold:  [0, 18]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1649])\n",
      "size of attention_mask: torch.Size([1, 1649])\n",
      "size of segment_ids: torch.Size([1, 1649])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 53])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1649, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,  148,  197,  240,  268,  323,  341,  352,  366,  401,  428,  458,\n",
      "         476,  495,  523,  548,  584,  642,  661,  670,  701,  755,  794,  828,\n",
      "         884,  931,  960,  973, 1003, 1026, 1042, 1082, 1104, 1127, 1163, 1182,\n",
      "        1205, 1232, 1259, 1278, 1297, 1325, 1347, 1365, 1418, 1489, 1509, 1528,\n",
      "        1548, 1570, 1596, 1610, 1624], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0938, device='cuda:0')\n",
      "type_loss:  tensor(1.0937, device='cuda:0')\n",
      "answer_loss: tensor(6.2051, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.1031], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1031], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([ 623, 1771, 3082], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠWorld', 'ĠWar', 'ĠII']\n",
      "answer_gold:  World War II\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {25, 26, 27}\n",
      "gold:  [19, 50]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 2018])\n",
      "size of attention_mask: torch.Size([1, 2018])\n",
      "size of segment_ids: torch.Size([1, 2018])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 58])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 2018, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  25,   40,   74,  103,  184,  196,  262,  275,  295,  332,  354,  392,\n",
      "         433,  460,  470,  498,  525,  619,  654,  682,  705,  753,  801,  831,\n",
      "         856,  870,  884,  912,  936,  979,  993, 1032, 1078, 1131, 1176, 1179,\n",
      "        1225, 1279, 1333, 1360, 1375, 1398, 1416, 1446, 1482, 1513, 1547, 1572,\n",
      "        1608, 1632, 1646, 1673, 1717, 1743, 1781, 1879, 1912, 1994],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.1309, device='cuda:0')\n",
      "type_loss:  tensor(1.1313, device='cuda:0')\n",
      "answer_loss: tensor(7.6465, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.0963], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.0963], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([6540, 7431,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠTodd', 'ĠPhillips', '.']\n",
      "answer_gold:  Todd Phillips.\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {26, 27, 28, 22}\n",
      "gold:  [18, 55, 56]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1310])\n",
      "size of attention_mask: torch.Size([1, 1310])\n",
      "size of segment_ids: torch.Size([1, 1310])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 40])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1310, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  34,   60,   91,  127,  199,  211,  222,  240,  263,  316,  347,  381,\n",
      "         398,  453,  471,  479,  516,  579,  615,  651,  685,  711,  750,  785,\n",
      "         804,  837,  871,  932,  979,  997, 1027, 1048, 1069, 1092, 1115, 1155,\n",
      "        1207, 1251, 1277, 1301], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.0840, device='cuda:0')\n",
      "type_loss:  tensor(1.0836, device='cuda:0')\n",
      "answer_loss: tensor(6.5547, device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.0969], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.0969], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([9347, 6226,    6], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠCarol', 'ĠLawrence', ',']\n",
      "answer_gold:  Carol Lawrence,\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {8, 6}\n",
      "gold:  [8, 9]\n",
      "sp prec:  0.5\n",
      "sp recall:  0.5\n",
      "sp f1:  0.5\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([2], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1400])\n",
      "size of attention_mask: torch.Size([1, 1400])\n",
      "size of segment_ids: torch.Size([1, 1400])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 41])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1400, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  21,  109,  128,  158,  182,  219,  243,  290,  322,  363,  389,  445,\n",
      "         480,  514,  553,  563,  572,  602,  612,  628,  661,  672,  691,  703,\n",
      "         745,  780,  833,  868,  967, 1072, 1116, 1132, 1152, 1198, 1219, 1251,\n",
      "        1297, 1325, 1349, 1368, 1380], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(0.8652, device='cuda:0')\n",
      "type_loss:  tensor(0.8654, device='cuda:0')\n",
      "answer_loss: tensor(0., device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.0481], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.0481], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold: no\n",
      "f1: tensor(1., device='cuda:0')\n",
      "prec: tensor(1., device='cuda:0')\n",
      "recall: tensor(1., device='cuda:0')\n",
      "em: tensor(1., device='cuda:0')\n",
      "prediction:  {24, 25, 26}\n",
      "gold:  [27, 28]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([2], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 943])\n",
      "size of attention_mask: torch.Size([1, 943])\n",
      "size of segment_ids: torch.Size([1, 943])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 27])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 943, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([ 17,  37,  70,  92, 115, 148, 168, 248, 261, 330, 367, 385, 430, 460,\n",
      "        495, 556, 594, 607, 634, 672, 687, 723, 746, 807, 832, 877, 898],\n",
      "       device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(0.8550, device='cuda:0')\n",
      "type_loss:  tensor(0.8550, device='cuda:0')\n",
      "answer_loss: tensor(0., device='cuda:0')\n",
      "decode\n",
      "answers_pred: [{'text': 'no', 'score': tensor([0.0957], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.0957], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold: no\n",
      "f1: tensor(1., device='cuda:0')\n",
      "prec: tensor(1., device='cuda:0')\n",
      "recall: tensor(1., device='cuda:0')\n",
      "em: tensor(1., device='cuda:0')\n",
      "prediction:  {8, 9, 10, 20, 21, 22, 23, 24}\n",
      "gold:  [5, 25]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_step\n",
      "q_type: tensor([0], device='cuda:0')\n",
      "size of input_ids: torch.Size([1, 1849])\n",
      "size of attention_mask: torch.Size([1, 1849])\n",
      "size of segment_ids: torch.Size([1, 1849])\n",
      "size of start_positions: torch.Size([1, 64])\n",
      "size of end_positions:torch.Size([1, 64])\n",
      "size of q_type:torch.Size([1])\n",
      "size of sp_sent: torch.Size([1, 51])\n",
      "size of sp_para: torch.Size([1, 10])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "size of sequence_output after removing padding: torch.Size([1, 1849, 768])\n",
      "size of type_logits: torch.Size([1, 3])\n",
      "size of p_index: torch.Size([10])\n",
      "size of sp_para_output: torch.Size([1, 10, 768])\n",
      "sent_indexes:  tensor([  18,   60,   75,  117,  171,  192,  206,  225,  285,  319,  338,  393,\n",
      "         495,  521,  538,  568,  601,  622,  644,  652,  689,  722,  747,  805,\n",
      "         836,  870,  901,  941,  970, 1013, 1047, 1085, 1103, 1203, 1238, 1256,\n",
      "        1280, 1355, 1395, 1442, 1467, 1553, 1567, 1596, 1625, 1661, 1671, 1696,\n",
      "        1736, 1806, 1824], device='cuda:0')\n",
      "type_loss_or_softmax_cross_entropy:  tensor(1.2041, device='cuda:0')\n",
      "type_loss:  tensor(1.2043, device='cuda:0')\n",
      "answer_loss: tensor(5.2539, device='cuda:0')\n",
      "decode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Epoch 00005: avg_val_f1 reached 0.15385 (best 0.15385), saving model to jupyter-hotpotqa/hotpotqa-longformer/checkpoints/_ckpt_epoch_5.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_pred: [{'text': 'no', 'score': tensor([0.1313], device='cuda:0', dtype=torch.float16)}]\n",
      "pred answer_score: tensor([0.1313], device='cuda:0', dtype=torch.float16)\n",
      "pred answer_text: no\n",
      "answer_gold_token_ids: tensor([188, 469, 412], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNew', 'ĠYork', 'ĠCity']\n",
      "answer_gold:  New York City\n",
      "f1: tensor(0., device='cuda:0')\n",
      "prec: tensor(0., device='cuda:0')\n",
      "recall: tensor(0., device='cuda:0')\n",
      "em: tensor(0., device='cuda:0')\n",
      "prediction:  {49, 50}\n",
      "gold:  [4, 12]\n",
      "sp prec:  0.0\n",
      "sp recall:  0.0\n",
      "sp f1:  0.0\n",
      "sp em:  0.0\n",
      "return\n",
      "validation_end\n",
      "before sync --> sizes:  13, 13, 13\n",
      "after sync --> sizes: 13, 13, 13\n",
      "answer_scores:  [0.6259765625, 0.19921875, 0.11492919921875, 0.224609375, 0.08575439453125, 0.2269287109375, -0.004085540771484375, 0.1031494140625, 0.0963134765625, 0.096923828125, 0.048126220703125, 0.095703125, 0.13134765625]\n",
      "f1_scores:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "em_scores:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "avg_loss:  tensor(7.4932, device='cuda:0')\tavg_answer_loss:  tensor(5.3451, device='cuda:0')\tavg_type_loss:  tensor(1.0622, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5896, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.4963, device='cuda:0')\tlen(f1_scores):  13\n",
      "avg_val_f1:  0.15384615384615385\n",
      "avg_val_em:  0.15384615384615385\n",
      "avg_val_prec:  0.15384615384615385\n",
      "avg_val_recall:  0.15384615384615385\n",
      "avg_val_sp_sent_f1:  0.0692307696892665\n",
      "avg_val_sp_sent_em:  0.0\n",
      "avg_val_sp_sent_prec:  0.06410256486672622\n",
      "avg_val_sp_sent_recall:  0.07692307692307693\n",
      "avg_val_joint_f1:  0.0\n",
      "avg_val_joint_em:  0.0\n",
      "avg_val_joint_prec:  0.0\n",
      "avg_val_joint_recall:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     if not args.test:\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('save_dir', 'jupyter-hotpotqa')\n",
      "('save_prefix', 'hotpotqa-longformer')\n",
      "('train_dataset', 'small.json')\n",
      "('dev_dataset', 'small_dev.json')\n",
      "('batch_size', 2)\n",
      "('gpus', '0')\n",
      "('warmup', 1000)\n",
      "('lr', 5e-05)\n",
      "('val_every', 1.0)\n",
      "('val_percent_check', 1.0)\n",
      "('num_workers', 1)\n",
      "('seed', 1234)\n",
      "('epochs', 6)\n",
      "('max_seq_len', 4096)\n",
      "('max_doc_len', 4096)\n",
      "('max_num_answers', 64)\n",
      "('max_question_len', 55)\n",
      "('doc_stride', -1)\n",
      "('ignore_seq_with_no_answers', False)\n",
      "('disable_checkpointing', False)\n",
      "('n_best_size', 20)\n",
      "('max_answer_length', 30)\n",
      "('regular_softmax_loss', False)\n",
      "('test', True)\n",
      "('model_path', '/Users/fan/Downloads/longformer-base-4096')\n",
      "('no_progress_bar', False)\n",
      "('attention_mode', 'sliding_chunks')\n",
      "('fp32', False)\n",
      "('train_percent', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# debug: check args\n",
    "import shlex\n",
    "argString ='--train_dataset small.json --dev_dataset small_dev.json  \\\n",
    "    --gpus 0 --num_workers 1 \\\n",
    "    --max_seq_len 4096 --doc_stride -1  \\\n",
    "    --save_prefix hotpotqa-longformer  --model_path /Users/fan/Downloads/longformer-base-4096 --test '\n",
    "# hotpot_dev_distractor_v1.json\n",
    "\n",
    "import argparse \n",
    "if __name__ == \"__main__\":\n",
    "    main_arg_parser = argparse.ArgumentParser(description=\"hotpotqa\")\n",
    "    parser = hotpotqa.add_model_specific_args(main_arg_parser, os.getcwd())\n",
    "    args = parser.parse_args(shlex.split(argString)) \n",
    "    for arg in vars(args):\n",
    "        print((arg, getattr(args, arg)))\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotpotqa",
   "language": "python",
   "name": "hotpotqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "593px",
    "left": "1926px",
    "right": "20px",
    "top": "158px",
    "width": "612px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
