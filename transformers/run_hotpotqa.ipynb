{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase the cell width \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; } </style>\"))   \n",
    "\n",
    "# need to run this every time start this notebook, to add python3.7/site-packages to sys.pat, in order to import ipywidgets, which is used when RobertaTokenizer.from_pretrained('roberta-base') \n",
    "import sys\n",
    "# sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.7/site-packages')\n",
    "sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert hotpotqa to squard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Longformer: use the following input format with special tokens:  “[CLS] [q] question [/q] [p] sent1,1 [s] sent1,2 [s] ... [p] sent2,1 [s] sent2,2 [s] ...” \n",
    "where [s] and [p] are special tokens representing sentences and paragraphs. The special tokens were added to the RoBERTa vocabulary and randomly initialized before task finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to convert hotpotqa to squard format modified from  https://github.com/chiayewken/bert-qa/blob/master/run_hotpot.py\n",
    "\n",
    "import tqdm \n",
    "from datetime import datetime \n",
    "import pytz \n",
    "timeZ_Az = pytz.timezone('US/Mountain') \n",
    "import transformers \n",
    "\n",
    "QUESTION_START = '[question]'\n",
    "QUESTION_END = '[/question]' \n",
    "TITLE_START = '<t>'  # indicating the start of the title of a paragraph (also used for loss over paragraphs)\n",
    "TITLE_END = '</t>'   # indicating the end of the title of a paragraph\n",
    "SENT_MARKER_END = '[/sent]'  # indicating the end of the title of a sentence (used for loss over sentences)\n",
    "PAR = '[/par]'  # used for indicating end of the regular context and beginning of `yes/no/null` answers\n",
    "EXTRA_ANSWERS = \" yes no null\"\n",
    "\n",
    " \n",
    "def create_example_dict(context, answer, id, question, is_sup_fact, is_supporting_para):\n",
    "    return {\n",
    "        \"context\": context,\n",
    "        \"qas\": [                        # each context corresponds to only one qa in hotpotqa\n",
    "            {\n",
    "                \"answer\": answer,\n",
    "                \"id\": id,\n",
    "                \"question\": question,\n",
    "                \"is_sup_fact\": is_sup_fact,\n",
    "                \"is_supporting_para\": is_supporting_para\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "def create_para_dict(example_dicts):\n",
    "    if type(example_dicts) == dict:\n",
    "        example_dicts = [example_dicts]   # each paragraph corresponds to only one [context, qas] in hotpotqa\n",
    "    return {\"paragraphs\": example_dicts}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install tqdm \n",
    "# !python -m pip install git+https://github.com/allenai/longformer.git \n",
    "# !python -m pip install pytorch-lightning==0.6.0\n",
    "# !python -m pip install jdc  \n",
    "# !wget https://ai2-s2-research.s3-us-west-2.amazonaws.com/longformer/longformer-base-4096.tar.gz\n",
    "# !tar -xf longformer-base-4096.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def convert_hotpot_to_squad_format(json_dict, gold_paras_only=False):\n",
    "    \n",
    "    \"\"\"function to convert hotpotqa to squard format.\n",
    "\n",
    "\n",
    "    Note: A context corresponds to several qas in SQuard. In hotpotqa, one question corresponds to several paragraphs as context. \n",
    "          \"paragraphs\" means different: each paragraph in SQuard contains a context and a list of qas; while 10 paragraphs in hotpotqa concatenated into a context for one question.\n",
    "\n",
    "    Args:\n",
    "        json_dict: The original data load from hotpotqa file.\n",
    "        gold_paras_only: when is true, only use the 2 paragraphs that contain the gold supporting facts; if false, use all the 10 paragraphs\n",
    " \n",
    "\n",
    "    Returns:\n",
    "        new_dict: The converted dict of hotpotqa dataset, use it as a dict would load from SQuAD json file\n",
    "                  usage: input_data = new_dict[\"data\"]   https://github.com/google-research/bert/blob/eedf5716ce1268e56f0a50264a88cafad334ac61/run_squad.py#L230\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "    new_dict = {\"data\": []} \n",
    "    for example in json_dict: \n",
    "\n",
    "        support_para = set(\n",
    "            para_title for para_title, _ in example[\"supporting_facts\"]\n",
    "        )\n",
    "        sp_set = set(list(map(tuple, example['supporting_facts'])))\n",
    "        \n",
    "        raw_contexts = example[\"context\"]\n",
    "        if gold_paras_only: \n",
    "            raw_contexts = [lst for lst in raw_contexts if lst[0] in support_para]\n",
    "            \n",
    "        is_supporting_para = []  # a boolean list with 10 True/False elements, one for each paragraph\n",
    "        is_sup_fact = []         # a boolean list with True/False elements, one for each context sentence\n",
    "        for para_title, para_lines in raw_contexts:\n",
    "            is_supporting_para.append(para_title in support_para)   \n",
    "            for sent_id, sent in enumerate(para_lines):\n",
    "                is_sup_fact.append( (para_title, sent_id) in sp_set )    \n",
    "        \n",
    "        for lst in raw_contexts:\n",
    "            lst[0] = normalize_answer(lst[0])\n",
    "            lst[1] = [normalize_answer(sent) for sent in lst[1]]\n",
    "        \n",
    "        contexts = [TITLE_START + ' ' + lst[0]  + ' ' + TITLE_END + ' ' + (' ' + SENT_MARKER_END +' ').join(lst[1]) + ' ' + SENT_MARKER_END for lst in raw_contexts]    \n",
    "        # extra space is fine, which would be ignored latter. most sentences has already have heading space, there are several no heading space; call the normalize_answer() which is same as the one used during evaluation\n",
    "   \n",
    "        context = \" \".join(contexts)\n",
    "#         print(context)\n",
    "        \n",
    "#         exit(0)\n",
    "\n",
    "        \n",
    "        answer = normalize_answer(example[\"answer\"]) \n",
    "#         print(\"answer: \", answer)\n",
    "        if(len(answer) > 0):   # answer can be '' after normalize\n",
    "            new_dict[\"data\"].append(\n",
    "                create_para_dict(\n",
    "                    create_example_dict(\n",
    "                        context=context,\n",
    "                        answer=answer,\n",
    "                        id = example[\"_id\"],\n",
    "                        question=normalize_answer(example[\"question\"]),\n",
    "                        is_sup_fact = is_sup_fact,\n",
    "                        is_supporting_para = is_supporting_para \n",
    "                    )\n",
    "                )\n",
    "            ) \n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"context\": \"<t> dr seuss how grinch stole christmas </t> dr seuss how grinch stole christmas [/sent] is video game based on dr seuss book with same name but mostly based on film [/sent] game was released on november 8 2007 [/sent] <t> lorax film </t> lorax also known as dr seuss lorax is 2012 american 3d computeranimated musical fantasy\\u2013comedy film produced by illumination entertainment and based on dr seusss childrens book of same name [/sent] film was released by universal pictures on march 2 2012 on 108th birthday of dr seuss [/sent] second film adaptation of book following 1972 animated television special film builds on book by expanding story of ted previously unnamed boy who visits onceler [/sent] cast includes danny devito as lorax ed helms as onceler and zac efron as ted [/sent] new characters introduced in film are audrey voiced by taylor swift aloysius ohare rob riggle mrs wiggins teds mother jenny slate and grammy norma betty white [/sent] <t> horton hears who tv special </t> horton hears who [/sent] is 1970 television special based on dr seuss book of same name horton hears who [/sent]  [/sent] it was produced and directed by chuck jones \\u2013 who previously produced seuss special how grinch stole christmas [/sent] \\u2013 for mgm television and first broadcast march 19 1970 on cbs [/sent] special contains songs with lyrics by seuss and music by eugene poddany who previously wrote songs for seuss book cat in hat song book [/sent] <t> dr seuss memorial </t> dr seuss national memorial sculpture garden is sculpture garden in springfield massachusetts that honors theodor seuss geisel better known to world as dr seuss [/sent] located at quadrangle dr seuss national memorial sculpture garden honors author and illustrator who was born in springfield in 1904 [/sent] monument was designed by lark grey dimondcates authors stepdaughter and created by sculptor and artist ron henson [/sent] <t> dr seuss bibliography </t> theodor seuss geisel better known as dr seuss published over 60 childrens books over course of his long career [/sent] though most were published under his wellknown pseudonym dr seuss he also authored over dozen books as theo [/sent] lesieg and one as rosetta stone [/sent] as one of most popular childrens authors of all time geisels books have topped many bestseller lists sold over 222 million copies and been translated into more than 15 languages [/sent] in 2000 when publishers weekly compiled their list of bestselling childrens books of all time 16 of top 100 hardcover books were written by geisel including green eggs and ham at number 4 cat in hat at number 9 and one fish two fish red fish blue fish at number 13 and dr seusss abc [/sent] in years following his death in 1991 several additional books based on his sketches and notes were published including hooray for diffendoofer day [/sent] and daisyhead mayzie [/sent] although they were all published under name dr seuss only my many colored days originally written in 1973 was entirely by geisel [/sent] <t> how grinch stole christmas 2018 film </t> dr seuss how grinch stole christmas promoted theatrically as dr seuss grinch is upcoming american 3d computeranimated christmas musical comedy film produced by illumination entertainment [/sent] it is based on 1957 dr seuss story of same name [/sent] film will be released on november 9 2018 by universal pictures [/sent] <t> do you know what im going to do next saturday </t> do you know what im going to do next saturday [/sent] is 1963 childrens book published by beginner books and written by helen palmer geisel first wife of theodor seuss geisel dr seuss [/sent] unlike most of beginner books do you know what im going to do next saturday [/sent] did not follow format of text with inline drawings being illustrated with blackandwhite photographs by lynn fayman featuring boy named rawli davis [/sent] it is sometimes misattributed to dr seuss himself [/sent] books cover features photograph of young boy sitting at breakfast table with huge pile of pancakes [/sent] <t> wubbulous world of dr seuss </t> wubbulous world of dr seuss is liveactionpuppet television series based on characters created by dr seuss produced by jim henson company [/sent] it aired from october 13 1996 to december 28 1998 on nickelodeon [/sent] it is notable for its use of live puppets with digitally animated backgrounds and in its first season for refashioning characters and themes from original dr seuss books into new stories that often retained much of flavor of dr seuss own works [/sent] <t> cat in hat film </t> dr seuss cat in hat is 2003 american family comedy film directed by bo welch [/sent] it is based on 1957 dr seuss book of same name [/sent] film stars mike myers in title role of cat in hat and dakota fanning as sally [/sent] sallys brother who is unnamed in book and 1971 tv special conrad is portrayed by spencer breslin [/sent] film is second featurelength dr seuss adaptation after 2000 holiday film how grinch stole christmas [/sent] <t> kyle balda </t> kyle balda is american animator and film director best known for codirecting animated films lorax 2012 with chris renaud and minions 2015 with pierre coffin [/sent] he has also worked as animator on several films including jumanji toy story 2 and despicable me [/sent] he has worked for pixar for years and now he is working for illumination entertainment [/sent]\",\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answer\": \"lorax\",\n",
      "          \"id\": \"5ab990925542996be2020553\",\n",
      "          \"question\": \"what film did kyle balda work on that was based on dr seuss book\",\n",
      "          \"is_sup_fact\": [\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false\n",
      "          ],\n",
      "          \"is_supporting_para\": [\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# debug: check whether convert_hotpot_to_squad_format() works\n",
    "import os\n",
    "os.chdir('/xdisk/msurdeanu/fanluo/hotpotQA/Data')\n",
    "# !cat /xdisk/msurdeanu/fanluo/hotpotQA/Data/hotpot_train_v1.1.json | ../../helper/jq-linux64 -c '.[76200:76280]' > small.json\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/Data/hotpot_train_v1.1.json | ../../helper/jq-linux64 -c '.[37:50]' > small_dev.json\n",
    "# !cat /xdisk/msurdeanu/fanluo/hotpotQA/Data/hotpot_train_v1.1.json | ../../helper/jq-linux64 -c '.[31:50]' > sample.json\n",
    "\n",
    "import json\n",
    "with open(\"small.json\", \"r\", encoding='utf-8') as f:  \n",
    "    json_dict = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "    print(json.dumps(json_dict[3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### longfomer's fine-tuning\n",
    "\n",
    "\n",
    "- For answer span extraction we use BERT’s QA model with addition of a question type (yes/no/span) classification head over the first special token ([CLS]).\n",
    "\n",
    "- For evidence extraction we apply 2 layer feedforward networks on top of the representations corresponding to sentence and paragraph tokens to get the corresponding evidence prediction scores and use binary cross entropy loss to train the model.\n",
    "\n",
    "- We combine span, question classification, sentence, and paragraphs losses and train the model in a multitask way using linear combination of losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Section2: This is modified from longfomer's fine-tuning with triviaqa.py from https://github.com/allenai/longformer/blob/master/scripts/triviaqa.py\n",
    "\n",
    "# !conda install transformers --yes\n",
    "# !conda install cudatoolkit=10.0 --yes\n",
    "# !python -m pip install git+https://github.com/allenai/longformer.git\n",
    "####requirements.txt:torch>=1.2.0, transformers>=3.0.2, tensorboardX, pytorch-lightning==0.6.0, test-tube==0.7.5\n",
    "# !conda install -c conda-forge regex --force-reinstall --yes\n",
    "# !conda install pytorch-lightning -c conda-forge\n",
    "#!python -m pip install jdc \n",
    "# !pip install test-tube \n",
    "#!python -m pip install ipywidgets \n",
    "# !conda update --force conda --yes  \n",
    "# !jupyter nbextension enable --py widgetsnbextension \n",
    "# !conda install jupyter --yes\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.overrides.data_parallel import LightningDistributedDataParallel\n",
    "from pytorch_lightning.logging import TestTubeLogger    # sometimes pytorch_lightning.loggers works instead\n",
    "\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "from transformers import RobertaTokenizer\n",
    "import jdc\n",
    "from more_itertools import locate\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.8/site-packages/pytorch_lightning/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(pl.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqaDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_, \\_\\_getitem\\_\\_ and \\_\\_len\\_\\_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hotpotqaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Largely based on\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
    "    and\n",
    "    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride,\n",
    "                 max_num_answers, ignore_seq_with_no_answers, max_question_len):\n",
    "        assert os.path.isfile(file_path)\n",
    "        self.file_path = file_path\n",
    "        if(\"reduced_context\" not in self.file_path):\n",
    "            with open(self.file_path, \"r\", encoding='utf-8') as f:\n",
    "                print(f'reading file: {self.file_path}')\n",
    "                self.data_json = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "                \n",
    "        else:\n",
    "            with open(self.file_path, \"r\", encoding='utf-8') as f:\n",
    "                print(f'reading file: {self.file_path}')\n",
    "                self.data_json = json.load(f)['data']            \n",
    "                print(self.data_json[0])\n",
    "            \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_doc_len = max_doc_len\n",
    "        self.doc_stride = doc_stride\n",
    "        self.max_num_answers = max_num_answers\n",
    "        self.ignore_seq_with_no_answers = ignore_seq_with_no_answers\n",
    "        self.max_question_len = max_question_len\n",
    "\n",
    "\n",
    "#         print(tokenizer.all_special_tokens) \n",
    "    \n",
    "        # A mapping from qid to an int, which can be synched across gpus using `torch.distributed`\n",
    "        if 'train' not in self.file_path:  # only for the evaluation set \n",
    "            self.val_qid_string_to_int_map =                  {\n",
    "                    entry[\"paragraphs\"][0]['qas'][0]['id']: index\n",
    "                    for index, entry in enumerate(self.data_json)\n",
    "                }\n",
    "        else:\n",
    "            self.val_qid_string_to_int_map = None\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_json)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data_json[idx]\n",
    "        tensors_list = self.one_example_to_tensors(entry, idx)\n",
    "        if(len(tensors_list) != 1):\n",
    "            print(\"tensors_list: \", tensors_list)\n",
    "        assert len(tensors_list) == 1\n",
    "        return tensors_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### one_example_to_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     106,
     122,
     147,
     162
    ]
   },
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    def one_example_to_tensors(self, example, idx):\n",
    "        def is_whitespace(c):\n",
    "            if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        def map_answer_positions(char_to_word_offset, orig_to_tok_index, answer_start, answer_end, slice_start, slice_end, doc_offset):\n",
    "            \n",
    "            # char offset to word offset\n",
    "            start_word_position = char_to_word_offset[answer_start]\n",
    "            end_word_position = char_to_word_offset[answer_end-1] \n",
    "\n",
    "#             print(\"start_word_position: \", start_word_position)\n",
    "#             print(\"end_word_position: \", end_word_position)\n",
    "            # sub_tokens postion reletive to context\n",
    "            tok_start_position_in_doc = orig_to_tok_index[start_word_position]  \n",
    "            not_end_of_doc = int(end_word_position + 1 < len(orig_to_tok_index))\n",
    "            tok_end_position_in_doc = orig_to_tok_index[end_word_position + not_end_of_doc] - not_end_of_doc\n",
    "            \n",
    "            if tok_start_position_in_doc < slice_start or tok_end_position_in_doc > slice_end:\n",
    "                return (-1, -1) # this answer is outside the current slice                     \n",
    "            \n",
    "            # sub_tokens postion reletive to begining of all the tokens, including query sub tokens  \n",
    "            start_position = tok_start_position_in_doc + doc_offset  \n",
    "            end_position = tok_end_position_in_doc + doc_offset\n",
    "            \n",
    "            return (start_position, end_position)\n",
    "        \n",
    "        tensors_list = []\n",
    "        for paragraph in example[\"paragraphs\"]:  # example[\"paragraphs\"] only contains one paragraph in hotpotqa\n",
    "            context = paragraph[\"context\"]\n",
    "            \n",
    "#             print(\"self.tokenizer.sep_token: \", self.tokenizer.sep_token)\n",
    "#             print(\"self.tokenizer.sep_token == '</s>': \", self.tokenizer.sep_token == '</s>')\n",
    "            \n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            for c in context:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        doc_tokens.append(c) # add a new token\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c  # append the character to the last token\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "            \n",
    "#             print(\"len(char_to_word_offset): \", len(char_to_word_offset))\n",
    "#             print(\"char_to_word_offset: \", char_to_word_offset)\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question_text = qa[\"question\"]\n",
    "#                 print(\"question text: \", question_text)  \n",
    "                sp_sent = qa[\"is_sup_fact\"]\n",
    "                sp_para = qa[\"is_supporting_para\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None \n",
    "\n",
    "#                     print(\"len(sp_sent):\", len(sp_sent))\n",
    "#                     print(\"sp_sent\", sp_sent) \n",
    "#                     print(\"doc_tokens\", doc_tokens)\n",
    " \n",
    "                # keep all answers in the document, not just the first matched answer. It also added the list of textual answers to make evaluation easy.\n",
    "                \n",
    "                   \n",
    "                # ===== Given an example, convert it into tensors  =============\n",
    "                 \n",
    "                query_tokens = self.tokenizer.tokenize(question_text)\n",
    "                query_tokens = query_tokens[:self.max_question_len]\n",
    "                tok_to_orig_index = []\n",
    "                orig_to_tok_index = []\n",
    "                all_doc_tokens = []\n",
    "                \n",
    "                # each original token in the context is tokenized to multiple sub_tokens\n",
    "                for (i, token) in enumerate(doc_tokens):\n",
    "                    orig_to_tok_index.append(len(all_doc_tokens))\n",
    "                    # hack: the line below should have been `self.tokenizer.tokenize(token')`\n",
    "                    # but roberta tokenizer uses a different subword if the token is the beginning of the string\n",
    "                    # or in the middle. So for all tokens other than the first, simulate that it is not the first\n",
    "                    # token by prepending a period before tokenizing, then dropping the period afterwards\n",
    "                    sub_tokens = self.tokenizer.tokenize(f'. {token}')[1:] if i > 0 else self.tokenizer.tokenize(token)\n",
    "                    for sub_token in sub_tokens:\n",
    "                        tok_to_orig_index.append(i)\n",
    "                        all_doc_tokens.append(sub_token)\n",
    "                \n",
    "                # all sub tokens, truncate up to limit\n",
    "                all_doc_tokens = all_doc_tokens[:self.max_doc_len-8] \n",
    "\n",
    "                # The -8 accounts for CLS, QUESTION_START, QUESTION_END， [/par]， yes， no， null， </s>   \n",
    "                max_tokens_per_doc_slice = self.max_seq_len - len(query_tokens) - 8\n",
    "                if(max_tokens_per_doc_slice <= 0):\n",
    "                    print(\"(max_tokens_per_doc_slice <= 0)\")\n",
    "                assert max_tokens_per_doc_slice > 0\n",
    "                if self.doc_stride < 0:                           # default\n",
    "                    # negative doc_stride indicates no sliding window, but using first slice\n",
    "                    self.doc_stride = -100 * len(all_doc_tokens)  # large -negtive value for the next loop to execute once\n",
    "                \n",
    "                # inputs to the model\n",
    "                input_ids_list = []\n",
    "                input_mask_list = []\n",
    "                segment_ids_list = []\n",
    "                start_positions_list = []\n",
    "                end_positions_list = []\n",
    "                q_type_list = []\n",
    "                sp_sent_list =  [1 if ss else 0 for ss in sp_sent]\n",
    "                sp_para_list = [1 if sp else 0 for sp in sp_para]\n",
    "                \n",
    "#                 print(\"before for\")\n",
    "                for slice_start in range(0, len(all_doc_tokens), max_tokens_per_doc_slice - self.doc_stride):    # execute once by default\n",
    "                    slice_end = min(slice_start + max_tokens_per_doc_slice, len(all_doc_tokens))\n",
    "\n",
    "                    doc_slice_tokens = all_doc_tokens[slice_start:slice_end]\n",
    "                    tokens = [self.tokenizer.cls_token] + [QUESTION_START] + query_tokens + [QUESTION_END] + doc_slice_tokens + [PAR] + self.tokenizer.tokenize(\"yes\") + self.tokenizer.tokenize(\"no\") + self.tokenizer.tokenize(\"null\") +  [self.tokenizer.eos_token]   \n",
    "                    segment_ids = [0] * (len(query_tokens) + 3) + [1] * (len(doc_slice_tokens) + 5) \n",
    "#                     if(len(segment_ids) != len(tokens)):\n",
    "#                         print(\"len(segment_ids): \", len(segment_ids))\n",
    "#                         print(\"len(tokens): \", len(tokens))\n",
    "                    assert len(segment_ids) == len(tokens)\n",
    "\n",
    "                    input_ids = self.tokenizer.convert_tokens_to_ids(tokens)   \n",
    "                    input_mask = [1] * len(input_ids)\n",
    "\n",
    "                    doc_offset = len(query_tokens) + 3 - slice_start  # where context starts\n",
    "                    \n",
    "                    # ===== answer positions tensors  ============\n",
    "                    start_positions = []\n",
    "                    end_positions = []\n",
    " \n",
    "                    answer = qa[\"answer\"] \n",
    "                    print(\"answer: \", answer)\n",
    "                    if answer == 'yes':\n",
    "                        q_type = 1\n",
    "                        start_positions.append(len(tokens)-4)   \n",
    "                        end_positions.append(len(tokens)-4) \n",
    "                    elif answer == 'no':\n",
    "                        q_type = 2\n",
    "                        start_positions.append(len(tokens)-3)   \n",
    "                        end_positions.append(len(tokens)-3)  \n",
    "                    else:\n",
    "                        # keep all the occurences of answer in the context \n",
    "#                         for m in re.finditer(\"\\s?\".join(answer.split()), context):   # \"\\s?\".join(answer.split()) in order to match even with extra space in answer or context\n",
    "                        for m in re.finditer(normalize_answer(answer), context, re.IGNORECASE):\n",
    "                            answer_start, answer_end = m.span() \n",
    "                            start_position, end_position = map_answer_positions(char_to_word_offset, orig_to_tok_index, answer_start, answer_end, slice_start, slice_end, doc_offset)\n",
    "                            if(start_position != -1):\n",
    "                                start_positions.append(start_position)   \n",
    "                                end_positions.append(end_position)\n",
    "                            \n",
    "                        if(len(start_positions) > 0): \n",
    "                            q_type = 0\n",
    "                        else: # answer not found in context\n",
    "                            q_type = 3 \n",
    "                            start_positions.append(len(tokens)-2)   \n",
    "                            end_positions.append(len(tokens)-2)  \n",
    "\n",
    "\n",
    "                    # answers from start_positions and end_positions if > self.max_num_answers\n",
    "                    start_positions = start_positions[:self.max_num_answers]\n",
    "                    end_positions = end_positions[:self.max_num_answers]\n",
    "\n",
    "                    # -1 padding up to self.max_num_answers\n",
    "                    padding_len = self.max_num_answers - len(start_positions)\n",
    "                    start_positions.extend([-1] * padding_len)\n",
    "                    end_positions.extend([-1] * padding_len)\n",
    "\n",
    "                    # replace duplicate start/end positions with `-1` because duplicates can result into -ve loss values\n",
    "                    found_start_positions = set()\n",
    "                    found_end_positions = set()\n",
    "                    for i, (start_position, end_position) in enumerate(zip(start_positions, end_positions)):\n",
    "                        \n",
    "                        if start_position in found_start_positions:\n",
    "                            start_positions[i] = -1\n",
    "                        if end_position in found_end_positions:\n",
    "                            end_positions[i] = -1\n",
    "                        found_start_positions.add(start_position)\n",
    "                        found_end_positions.add(end_position)\n",
    "                        \n",
    "#                         # for debug\n",
    "#                         if(start_position != -1):\n",
    "#                             answer_token_ids = input_ids[start_position: end_position+1]\n",
    "#                             answer_tokens = self.tokenizer.convert_ids_to_tokens(answer_token_ids)\n",
    "#                             answer_text = self.tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "#                             print(\"answer_text: \", answer_text)\n",
    "                        \n",
    "                    if self.doc_stride >= 0:  # no need to pad if document is not strided\n",
    "                        # Zero-pad up to the sequence length.\n",
    "                        padding_len = self.max_seq_len - len(input_ids)\n",
    "                        input_ids.extend([self.tokenizer.pad_token_id] * padding_len)\n",
    "                        input_mask.extend([0] * padding_len)\n",
    "                        segment_ids.extend([0] * padding_len)\n",
    "                        \n",
    "                        print(\"self.doc_stride >= 0\")\n",
    "                        assert len(input_ids) == self.max_seq_len\n",
    "                        assert len(input_mask) == self.max_seq_len\n",
    "                        assert len(segment_ids) == self.max_seq_len  \n",
    "                        \n",
    "                    input_ids_list.append(input_ids)\n",
    "                    input_mask_list.append(input_mask)\n",
    "                    segment_ids_list.append(segment_ids)\n",
    "                    start_positions_list.append(start_positions)\n",
    "                    end_positions_list.append(end_positions)\n",
    "                    q_type_list.append(q_type)\n",
    "                    \n",
    "                tensors_list.append((torch.tensor(input_ids_list), torch.tensor(input_mask_list), torch.tensor(segment_ids_list),\n",
    "                                     torch.tensor(start_positions_list), torch.tensor(end_positions_list), torch.tensor(q_type_list),\n",
    "                                      torch.tensor([sp_sent_list]),  torch.tensor([sp_para_list]),\n",
    "                                     qa['id'], answer))     \n",
    "        return tensors_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### collate_one_doc_and_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    @staticmethod\n",
    "    def collate_one_doc_and_lists(batch):\n",
    "        num_metadata_fields = 2  # qid and answer  \n",
    "        fields = [x for x in zip(*batch)]\n",
    "        stacked_fields = [torch.stack(field) for field in fields[:-num_metadata_fields]]  # don't stack metadata fields\n",
    "        stacked_fields.extend(fields[-num_metadata_fields:])  # add them as lists not torch tensors\n",
    "\n",
    "        # always use batch_size=1 where each batch is one document\n",
    "        # will use grad_accum to increase effective batch size\n",
    "        assert len(batch) == 1\n",
    "        fields_with_batch_size_one = [f[0] for f in stacked_fields]\n",
    "        return fields_with_batch_size_one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'collate_one_doc_and_lists',\n",
       " 'one_example_to_tensors']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__class__', type),\n",
       " ('__delattr__', <slot wrapper '__delattr__' of 'object' objects>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__doc__': '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    ',\n",
       "                '__init__': <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>,\n",
       "                '__len__': <function __main__.hotpotqaDataset.__len__(self)>,\n",
       "                '__getitem__': <function __main__.hotpotqaDataset.__getitem__(self, idx)>,\n",
       "                'one_example_to_tensors': <function __main__.one_example_to_tensors(self, example, idx)>,\n",
       "                'collate_one_doc_and_lists': <staticmethod at 0x7f1da1964eb8>})),\n",
       " ('__dir__', <method '__dir__' of 'object' objects>),\n",
       " ('__doc__',\n",
       "  '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    '),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__init_subclass__', <function hotpotqaDataset.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <slot wrapper '__repr__' of 'object' objects>),\n",
       " ('__setattr__', <slot wrapper '__setattr__' of 'object' objects>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqaDataset.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'Dataset' objects>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers\n",
    "getmembers(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import isfunction\n",
    "functions_list = [o for o in getmembers(hotpotqaDataset) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqaDataset, torch.utils.data.dataset.Dataset, object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqaDataset)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'example', 'idx'], varargs=None, varkw=None, defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getfullargspec(hotpotqaDataset.one_example_to_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class hotpotqaDataset in module __main__:\n",
      "\n",
      "class hotpotqaDataset(torch.utils.data.dataset.Dataset)\n",
      " |  Largely based on\n",
      " |  https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
      " |  and\n",
      " |  https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      hotpotqaDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  one_example_to_tensors(self, example, idx)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  collate_one_doc_and_lists(batch)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_,  forward, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class hotpotqa(pl.LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super(hotpotqa, self).__init__()\n",
    "        self.args = args\n",
    "        self.hparams = args\n",
    " \n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        num_new_tokens = self.tokenizer.add_special_tokens({\"additional_special_tokens\": [TITLE_START, TITLE_END, SENT_MARKER_END, QUESTION_START , QUESTION_END, PAR]})\n",
    "#         print(self.tokenizer.all_special_tokens)\n",
    "        self.tokenizer.model_max_length = self.args.max_seq_len\n",
    "        self.model = self.load_model()\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.num_labels = 2\n",
    "        self.qa_outputs = torch.nn.Linear(self.model.config.hidden_size, self.num_labels)\n",
    "         \n",
    "        self.linear_type = torch.nn.Linear(self.model.config.hidden_size, 4)   #  question type (yes/no/span/null) classification \n",
    "           \n",
    "       \n",
    "        self.fnn_sp_sent = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size), \n",
    "          torch.nn.GELU(),\n",
    "          torch.nn.Linear(self.model.config.hidden_size, 1),      # score for 'yes', while 0 for 'no'\n",
    "        )\n",
    "        \n",
    "        self.fnn_sp_para = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size), \n",
    "          torch.nn.GELU(),\n",
    "          torch.nn.Linear(self.model.config.hidden_size, 1),      # score for 'yes', while 0 for 'no'\n",
    "        )\n",
    "         \n",
    "        \n",
    "        self.train_dataloader_object = self.val_dataloader_object = self.test_dataloader_object = None\n",
    "        \n",
    " \n",
    "    def load_model(self):\n",
    "        \n",
    "        config = LongformerConfig.from_pretrained(self.args.model_path) \n",
    "        # choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "        # 'n2': for regular n2 attantion\n",
    "        # 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "        # 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "        config.attention_mode = 'sliding_chunks'\n",
    "        model = Longformer.from_pretrained(self.args.model_path, config=config)\n",
    "\n",
    "        print(\"self.args.model_path: \", self.args.model_path)\n",
    "        for layer in model.encoder.layer:\n",
    "            layer.attention.self.attention_mode = self.args.attention_mode\n",
    "            self.args.attention_window = layer.attention.self.attention_window\n",
    "\n",
    "        print(\"Loaded model with config:\")\n",
    "        print(model.config)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        model.train()\n",
    "        return model\n",
    "\n",
    "#%%add_to hotpotqa    # does not seems to work for the @pl.data_loader decorator, missing which causes error \"validation_step() takes 3 positional arguments but 4 were given\"    \n",
    "###################################################### dataloaders ########################################################### \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        if self.train_dataloader_object is not None:\n",
    "            return self.train_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.train_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=self.args.ignore_seq_with_no_answers)\n",
    "        \n",
    "#         dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,   # set shuffle=False, otherwise it will sample a different subset of data every epoch with train_percent_check\n",
    "                        num_workers=self.args.num_workers,  \n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "        self.train_dataloader_object = dl  \n",
    "        return self.train_dataloader_object\n",
    "    \n",
    " \n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        if self.val_dataloader_object is not None:\n",
    "            return self.val_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=False)  # evaluation data should keep all examples \n",
    "\n",
    "        \n",
    "        \n",
    "#         dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,\n",
    "                        num_workers=self.args.num_workers, \n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "        self.val_dataloader_object = dl\n",
    "        return self.val_dataloader_object\n",
    "\n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        if self.test_dataloader_object is not None:\n",
    "            return self.test_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=False)  # evaluation data should keep all examples\n",
    "\n",
    "#         dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,\n",
    "                        num_workers=self.args.num_workers, \n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "        self.test_dataloader_object = dl\n",
    "        return self.test_dataloader_object\n",
    "\n",
    "#%%add_to hotpotqa  \n",
    "    def forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para):\n",
    " \n",
    "        if(input_ids.size(0) > 1):\n",
    "            assert(\"multi rows per document\")\n",
    "            \n",
    "        input_ids = input_ids.cuda()\n",
    "        attention_mask = attention_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        start_positions = start_positions.cuda()\n",
    "        end_positions = end_positions.cuda()\n",
    "        q_type = q_type.cuda()\n",
    "        sp_sent = sp_sent.cuda()\n",
    "        sp_para = sp_para.cuda()\n",
    "        \n",
    "        # Each batch is one document, and each row of the batch is a chunck of the document.    ????\n",
    "        # Make sure all rows have the same question length.\n",
    "        \n",
    " \n",
    "        # local attention everywhere\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "        \n",
    "        # global attention for the cls and all question tokens\n",
    "        question_end_index = self._get_special_index(input_ids, [QUESTION_END])\n",
    "#         if(question_end_index.size(0) == 1):\n",
    "#             attention_mask[:,:question_end_index.item()] = 2  \n",
    "#         else:\n",
    "        attention_mask[:,:question_end_index[0].item()+1] = 2  # from <cls> until </q>\n",
    "#             print(\"more than 1 <q> in: \", self.tokenizer.convert_ids_to_tokens(input_ids[0].tolist()) )\n",
    "        \n",
    "        # global attention for the sentence and paragraph special tokens  \n",
    "        sent_indexes = self._get_special_index(input_ids, [SENT_MARKER_END])\n",
    "        attention_mask[:, sent_indexes] = 2\n",
    "        \n",
    "        para_indexes = self._get_special_index(input_ids, [TITLE_START])\n",
    "        attention_mask[:, para_indexes] = 2       \n",
    "         \n",
    "\n",
    "        # sliding_chunks implemenation of selfattention requires that seqlen is multiple of window size\n",
    "        input_ids, attention_mask = pad_to_window_size(\n",
    "             input_ids, attention_mask, self.args.attention_window, self.tokenizer.pad_token_id)\n",
    "\n",
    "\n",
    "#         print(\"size of input_ids: \" + str(input_ids.size()))\n",
    "        sequence_output = self.model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask)[0]\n",
    "#         print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "#         print(\"sequence_output \", sequence_output)\n",
    "\n",
    "        # The pretrained hotpotqa model wasn't trained with padding, so remove padding tokens\n",
    "        # before computing loss and decoding.\n",
    "        padding_len = input_ids[0].eq(self.tokenizer.pad_token_id).sum()\n",
    "        if padding_len > 0:\n",
    "            sequence_output = sequence_output[:, :-padding_len]\n",
    "#         print(\"size of sequence_output after removing padding: \" + str(sequence_output.size()))\n",
    "              \n",
    "        \n",
    "        ###################################### layers on top of sequence_output ##################################\n",
    "        \n",
    "\n",
    "        ### 1. answer start and end positions classification ###   \n",
    "        logits = self.qa_outputs(sequence_output) \n",
    "        start_logits, end_logits = logits.split(1, dim=-1) \n",
    "        start_logits = start_logits.squeeze(-1) \n",
    "        end_logits = end_logits.squeeze(-1)\n",
    " \n",
    "        ### 2. type classification, similar as class LongformerClassificationHead(nn.Module) https://huggingface.co/transformers/_modules/transformers/modeling_longformer.html#LongformerForSequenceClassification.forward ### \n",
    "        type_logits = self.linear_type(sequence_output[:,0]) \n",
    "        \n",
    "        ### 3. supporting paragraph classification ###  \n",
    "        sp_para_output = sequence_output[:,para_indexes,:]  \n",
    "        sp_para_output_t = self.fnn_sp_para(sp_para_output) \n",
    "\n",
    "         # linear_sp_sent generates a single score for each sentence, instead of 2 scores for yes and no.   \n",
    "        # Argument the score with additional score=0. The same way did in the HOTPOTqa paper\n",
    "        sp_para_output_aux = torch.zeros(sp_para_output_t.shape, dtype=torch.float, device=sp_para_output_t.device) \n",
    "        predict_support_para = torch.cat([sp_para_output_aux, sp_para_output_t], dim=-1).contiguous() \n",
    " \n",
    "        ### 4. supporting fact classification ###     \n",
    "        # the first sentence in a paragraph is leading by <p>, other sentences are leading by <s>\n",
    " \n",
    "        sp_sent_output = sequence_output[:,sent_indexes,:]  \n",
    "        sp_sent_output_t = self.fnn_sp_sent(sp_sent_output)     \n",
    "        sp_sent_output_aux = torch.zeros(sp_sent_output_t.shape, dtype=torch.float, device=sp_sent_output_t.device) \n",
    "        predict_support_sent = torch.cat([sp_sent_output_aux, sp_sent_output_t], dim=-1).contiguous() \n",
    "        \n",
    "        outputs = (start_logits, end_logits, type_logits, sp_para_output_t, sp_sent_output_t)  \n",
    "        answer_loss, type_loss, sp_para_loss, sp_sent_loss  = self.loss_computation(start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)\n",
    " \n",
    "        outputs = (answer_loss, type_loss, sp_para_loss, sp_sent_loss,) + outputs    \n",
    "    \n",
    "    \n",
    "#         explainer = shap.GradientExplainer( (logits, sequence_output), self.qa_outputs(sequence_output))\n",
    "#         print(self.explainer)\n",
    "\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent):\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "\n",
    "            if not self.args.regular_softmax_loss:\n",
    "                # loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\n",
    "                # NOTE: this returns sum of losses, not mean, so loss won't be normalized across different batch sizes\n",
    "                # but batch size is always 1, so this is not a problem\n",
    "                start_loss = self.or_softmax_cross_entropy_loss_one_doc(start_logits, start_positions, ignore_index=-1)\n",
    " \n",
    "                end_loss = self.or_softmax_cross_entropy_loss_one_doc(end_logits, end_positions, ignore_index=-1)\n",
    "  \n",
    "\n",
    "            else: \n",
    "                start_positions = start_positions[:, 0:1]   # only use the top1 start_position considering only one appearance of the answer string\n",
    "                end_positions = end_positions[:, 0:1]\n",
    "                start_loss = crossentropy(start_logits, start_positions[:, 0])\n",
    "                end_loss = crossentropy(end_logits, end_positions[:, 0])\n",
    "                \n",
    " \n",
    "            crossentropy = torch.nn.CrossEntropyLoss()\n",
    "            type_loss = crossentropy(type_logits, q_type)  \n",
    "            \n",
    "            crossentropy_average = torch.nn.CrossEntropyLoss(reduction = 'mean', ignore_index=-1)      \n",
    "            sp_para_loss = crossentropy_average(predict_support_para.view(-1, 2), sp_para.view(-1))\n",
    "            sp_sent_loss = crossentropy_average(predict_support_sent.view(-1, 2), sp_sent.view(-1))      \n",
    " \n",
    "            answer_loss = (start_loss + end_loss) / 2 \n",
    "        return answer_loss, type_loss, sp_para_loss, sp_sent_loss  \n",
    "\n",
    "\n",
    "#     %%add_to hotpotqa    \n",
    "    def _get_special_index(self, input_ids, special_tokens):\n",
    "        assert(input_ids.size(0)==1) \n",
    "        mask = input_ids != input_ids # initilaize \n",
    "        for special_token in special_tokens:\n",
    "            mask = torch.logical_or(mask, input_ids.eq(self.tokenizer.convert_tokens_to_ids(special_token))) \n",
    " \n",
    "        token_indices = torch.nonzero(mask)    \n",
    "         \n",
    " \n",
    "        return token_indices[:,1]    \n",
    "\n",
    "    def or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1):\n",
    "        \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "        assert logits.ndim == 2\n",
    "        assert target.ndim == 2\n",
    "        assert logits.size(0) == target.size(0) \n",
    "        \n",
    "        # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "        # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "        # target are indexes of tokens, padded with ignore_index=-1\n",
    "        # logits are scores (one for each label) for each token\n",
    " \n",
    "        # compute a target mask\n",
    "        target_mask = target == ignore_index\n",
    "        # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "        masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "    \n",
    "        # gather logits\n",
    "        gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    " \n",
    "        # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "        gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    " \n",
    "        # each batch is one example\n",
    "        gathered_logits = gathered_logits.view(1, -1)\n",
    "        logits = logits.view(1, -1)\n",
    " \n",
    "        # numerator = log(sum(exp(gathered logits)))\n",
    "        log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    " \n",
    "        log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = -(log_score - log_norm) \n",
    "        \n",
    "        # some of the examples might have a loss of `inf` when `target` is all `ignore_index`: when computing start_loss and end_loss for question with the gold answer of yes/no \n",
    "        # when `target` is all `ignore_index`, loss is 0 \n",
    "        loss = loss[~torch.isinf(loss)].sum()\n",
    "#         loss = torch.tanh(loss)\n",
    "#         print(\"final loss: \" + str(loss)) \n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# input_ids = torch.tensor([[-1, 5, -1, 2]])\n",
    "# input_ids.size(0)\n",
    "# token_indices =  torch.nonzero(input_ids == torch.tensor(-1))[:,1]\n",
    "# # token_indices\n",
    "# # token_indices.item()\n",
    "# # indices =  torch.LongTensor([[2],[0,2]])\n",
    "\n",
    "# # torch.gather(input_ids, 1, token_indices.unsqueeze(0))\n",
    "# # p_index = token_indices.view(input_ids.size(0), -1)[:,1::2]   \n",
    "# # attention_mask = torch.ones(input_ids.shape, dtype=torch.long) \n",
    "# # attention_mask[:,token_indices] = 2\n",
    "# # attention_mask\n",
    "# p_index = torch.tensor([1, 3, 4])\n",
    "# s_index = torch.tensor([1,3,6])\n",
    "# torch.sort(torch.cat((s_index, p_index)))[0]\n",
    "# attention_mask.view(-1)[ p_index.view(-1), :].view(attention_mask.size(0), -1)\n",
    "# # for pi in p_index[0]:\n",
    "# #     attention_mask[:, pi] = 2\n",
    "# # attention_mask\n",
    "# # s_index = torch.tensor([[1,3]])\n",
    "# # torch.sort(torch.cat((p_index, s_index), -1), -1)\n",
    "\n",
    "# sequence_output  = torch.tensor([[[-1, 5, -1, 2],\n",
    "#                                  [-2, 27, 2, 9],\n",
    "#                                  [3, 6, 1, 65],\n",
    "#                                  [52, 36, 13, 2],\n",
    "#                                  [73, 26, 1, 7]\n",
    "#                                 ]])\n",
    "\n",
    "# sp_para_output_t   = torch.tensor([[[-1],\n",
    "#                                  [-2 ],\n",
    "#                                  [3],\n",
    "#                                  [52],\n",
    "#                                  [73]\n",
    "#                                 ]])\n",
    "# torch.zeros(sp_para_output_t.shape, dtype=torch.float) \n",
    "\n",
    "# print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "# # print(\"size of p_index.unsqueeze(0).unsqueeze(-1): \" + str(p_index.unsqueeze(0).size()))\n",
    "# sequence_output[:,p_index,:]\n",
    "# b = torch.tensor([0, 1, 2, 3])\n",
    "# p_index.unsqueeze(-1) * b\n",
    "\n",
    "# input_ids = torch.tensor([[0.2, 0.0, 0.6, 0.6], [0.2, 0.6, 0.0, 0.0]]) \n",
    "# # input_ids.tolist()\n",
    "# p_index =  torch.nonzero(input_ids == torch.tensor(0.2))\n",
    "# print(p_index)\n",
    "# s_index =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "# print(s_index)\n",
    "\n",
    "# sp_sent = torch.tensor([[0, 1, 1, 0]])\n",
    "# torch.nonzero(sp_sent, as_tuple=True)[1]\n",
    "# cat_index = torch.tensor([])\n",
    "# cat_index = torch.cat((cat_index, ids[0][1]))\n",
    "# print(ids)\n",
    "# print(cat_index)\n",
    "# p_index[p_index[:,0] == 0]\n",
    "\n",
    "# cat_index[cat_index[:,0].argsort()]\n",
    "\n",
    "# sorted(torch.cat((p_index, s_index)), key = lambda x: x[0])\n",
    "# torch.sort(torch.cat((p_index, s_index)), 0)[0]\n",
    "# for cor in token_indices:\n",
    "#     attention_mask[cor[0].item()][cor[1].item()] = 2\n",
    "# attention_mask \n",
    "# input_ids = torch.tensor([[-1, 5, -6, 2]])\n",
    "# print(input_ids.size())\n",
    "# input_ids.topk(k=2, dim=-1).indices\n",
    "\n",
    "# predict_type = torch.tensor([[-0.0925, -0.0999, -0.1671]])\n",
    "# p_type = torch.argmax(predict_type, dim=1).item()\n",
    "# p_type_score = torch.max(predict_type, dim=1)[0].item()\n",
    "# print(\"predict_type: \", predict_type)\n",
    "# print(\"p_type: \", p_type)\n",
    "# print(\"p_type_score: \", p_type_score)\n",
    "    \n",
    "# a = torch.tensor([[0.9213,  1.0887, -0.8858, -1.7683]])\n",
    "# a.view(-1).size() \n",
    "# print(torch.sigmoid(a))\n",
    "# a = torch.tensor([ 9.213,  1.0887, -0.8858, 7683])\n",
    "# print(torch.sigmoid(a))\n",
    "\n",
    "# a = torch.tensor([[[1],[2],[4],[-1],[-1]]])\n",
    "# a= a.squeeze(-1)\n",
    "# a.size() \n",
    "# a[:, torch.where(a!=-1)[1]]\n",
    "# m = torch.nn.Sigmoid()\n",
    "# print(\"m: \", m)\n",
    "# loss = torch.nn.BCELoss()\n",
    "# # input = torch.randn(3, requires_grad=True)\n",
    "# # print(\"input: \", input)\n",
    "# # target = torch.empty(3).random_(2)\n",
    "# # print(\"target: \", target)\n",
    "# # output = loss(m(input), target)\n",
    "# # print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([1.0293, -0.1585,  1.1408], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# print(\"Sigmoid(input): \", m(input))\n",
    "# target = torch.tensor([0., 1., 0.])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([[1.0293, -0.1585,  1.1408]], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# target = torch.tensor([[0., 1., 0.]])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# 1.1761 * 3\n",
    "# soft_input = torch.nn.Softmax(dim=-1)\n",
    "# log_soft_input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss() \n",
    "# loss(log_soft_input, target)\n",
    "# input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss()\n",
    "# loss(input,target)\n",
    "\n",
    "# loss =torch.nn.CrossEntropyLoss()\n",
    "# loss(input,target) \n",
    "\n",
    "# sp_sent_logits =torch.tensor([[[0.0988],\n",
    "#          [0.0319],\n",
    "#          [0.0314]]])\n",
    "# sp_sent_logits.squeeze()\n",
    "\n",
    "# input_ids = torch.tensor([[0.6, 0.0, 0.6, 0.0]]) \n",
    "# token_indices =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "# token_indices[:,1][0].item()\n",
    "\n",
    "# def or_softmax_cross_entropy_loss_one_doc(logits, target, ignore_index=-1, dim=-1):\n",
    "#     \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "#     assert logits.ndim == 2\n",
    "#     assert target.ndim == 2\n",
    "#     assert logits.size(0) == target.size(0) \n",
    "\n",
    "#     # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "#     # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "#     # target are indexes of tokens, padded with ignore_index=-1\n",
    "#     # logits are scores (one for each label) for each token\n",
    "# #         print(\"or_softmax_cross_entropy_loss_one_doc\" ) \n",
    "# #         print(\"size of logits: \" + str(logits.size()))                    # torch.Size([1, 746]), 746 is number of all tokens \n",
    "# #         print(\"size of target: \" + str(target.size()))                    # torch.Size([1, 64]),  -1 padded\n",
    "#     print(\"target: \" + str(target)) \n",
    "\n",
    "#     # compute a target mask\n",
    "#     target_mask = target == ignore_index\n",
    "#     # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "#     masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "#     print(\"masked_target: \" + str(masked_target))     \n",
    "#     # gather logits\n",
    "#     gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    "# #         print(\"size of gathered_logits: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#     print(\"gathered_logits: \" + str(gathered_logits)) \n",
    "#     # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "#     gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    "#     print(\"gathered_logits after -inf: \" + str(gathered_logits))      # tensor([[0.4382,   -inf,   -inf,   -inf,   -inf,...]])\n",
    "\n",
    "#     # each batch is one example\n",
    "#     gathered_logits = gathered_logits.view(1, -1)\n",
    "#     logits = logits.view(1, -1)\n",
    "# #         print(\"size of gathered_logits after view: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "# #         print(\"size of logits after view: \" + str(logits.size()))                    # torch.Size([1, 746])　　\n",
    "\n",
    "#     # numerator = log(sum(exp(gathered logits)))\n",
    "#     log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    "#     print(\"log_score: \" + str(log_score)) \n",
    "#     # denominator = log(sum(exp(logits)))\n",
    "#     log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "#     print(\"log_norm: \" + str(log_norm)) \n",
    "\n",
    "#     # compute the loss\n",
    "#     loss = -(log_score - log_norm)\n",
    "#     print(\"loss: \" + str(loss))\n",
    "\n",
    "\n",
    "#     # some of the examples might have a loss of `inf` when `target` is all `ignore_index`: when computing start_loss and end_loss for question with the gold answer of yes/no \n",
    "#     # replace -inf with 0\n",
    "#     loss = loss[~torch.isinf(loss)].sum()\n",
    "#     print(\"final loss: \" + str(loss)) \n",
    "#     return loss \n",
    "\n",
    "# # input = torch.tensor([[ 0,  0.0780],\n",
    "# #         [0, 0.9253 ],\n",
    "# #         [0, 0.0987]])\n",
    "# # target = torch.tensor([0,1,0])\n",
    "# # target.size(0) < 1\n",
    "# # input = torch.tensor([[ 1.1879,  1.0780,  0.5312],\n",
    "# #         [-0.3499, -1.9253, -1.5725],\n",
    "# #         [-0.6578, -0.0987,  1.1570]])\n",
    "# # target=torch.tensor([0,1,2])\n",
    "# # predict_support_para.view(-1, 2), sp_para.view(-1)\n",
    "# # input = torch.tensor([[ 1.1879,  1.0780,  0.5312]])\n",
    "# # target=torch.tensor([0])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([1])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([2])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# # target=torch.tensor([-1])\n",
    "# # or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# a = torch.tensor([6.4062])    \n",
    "# b = torch.tensor([2.23])\n",
    "# torch.cat((a,b))\n",
    " \n",
    "# for a in list_tensor\n",
    "# from functools import reduce\n",
    "# reduce(lambda x,y: torch.cat((x,y)), list_tensor[:-1])\n",
    "\n",
    "# torch.tanh(a)\n",
    "# # if(torch.isinf(a)):\n",
    "# #     print(\"is inf\")\n",
    "# 5 * 1e-2\n",
    "\n",
    "\n",
    "# import torch\n",
    "# special_tokens = [1,2]\n",
    "# input_ids = torch.tensor([[ 1, 0, 2, 1, 0, 2]])\n",
    "\n",
    "# mask = input_ids != input_ids # initilaize \n",
    "# for special_token in special_tokens:\n",
    "#     mask = torch.logical_or(mask, input_ids.eq(special_token)) \n",
    "#     print(\"mask: \", mask)\n",
    "# torch.nonzero(mask)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug: check loaded dataset by DataLoader\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# num_new_tokens = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<p>\", \"<q>\", \"</q>\"]})\n",
    "# # # # print(tokenizer.all_special_tokens)    \n",
    "# # # # print(tokenizer.all_special_ids)     \n",
    "# # # # tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "# # # # tokenizer.sep_token\n",
    "# print(tokenizer.tokenize(\"yes\"))\n",
    "# print(tokenizer.tokenize(\"no\"))\n",
    "# print(tokenizer.tokenize(\"null\"))\n",
    "# # # all_doc_tokens = []\n",
    "# # # orig_to_tok_index = []\n",
    "# # # tok_to_orig_index = []\n",
    "# # # for (i, token) in enumerate([\"<s>\", \"da\", \"tell\", \"<p>\", \"say\"]):\n",
    "# # #     orig_to_tok_index.append(len(all_doc_tokens))\n",
    "# # #     sub_tokens = tokenizer.tokenize(f'. {token}')[1:] if i > 0 else tokenizer.tokenize(token)\n",
    "# # #     for sub_token in sub_tokens:\n",
    "# # #         tok_to_orig_index.append(i)\n",
    "# # #         all_doc_tokens.append(sub_token)\n",
    "# # # all_doc_tokens\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# dataset = hotpotqaDataset(file_path= args.train_dataset, tokenizer=tokenizer,\n",
    "#                           max_seq_len= args.max_seq_len, max_doc_len= args.max_doc_len,\n",
    "#                           doc_stride= args.doc_stride,\n",
    "#                           max_num_answers= args.max_num_answers,\n",
    "#                           max_question_len= args.max_question_len,\n",
    "#                           ignore_seq_with_no_answers= args.ignore_seq_with_no_answers)\n",
    "# print(len(dataset))\n",
    "\n",
    "# # # dl = DataLoader(dataset, batch_size=1, shuffle=None,\n",
    "# # #                     num_workers=args.num_workers, sampler=None,\n",
    "# # #                     collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "# example = dataset[3]  \n",
    "# [input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids] = example\n",
    " \n",
    "\n",
    "# print(input_ids[0][:20].tolist())\n",
    "# print(input_mask) \n",
    "# print(segment_ids) \n",
    "# print(subword_starts) \n",
    "# print(subword_ends)\n",
    "# print(q_type)\n",
    "# print(sp_sent) \n",
    "# print(sp_para) \n",
    "# print(qids)\n",
    "# print(tokenizer.convert_ids_to_tokens(input_ids[0][667:669+1].tolist()))\n",
    "# 0.0033 * 90447 \n",
    "# 28*4\n",
    "# torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### configure_ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%add_to hotpotqa\n",
    " # A hook to overwrite to define your own DDP(DistributedDataParallel) implementation init. \n",
    " # The only requirement is that: \n",
    " # 1. On a validation batch the call goes to model.validation_step.\n",
    " # 2. On a training batch the call goes to model.training_step.\n",
    " # 3. On a testing batch, the call goes to model.test_step\n",
    " def configure_ddp(self, model, device_ids):\n",
    "    model = LightningDistributedDataParallel(\n",
    "        model,\n",
    "        device_ids=device_ids,\n",
    "        find_unused_parameters=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **configure_optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def configure_optimizers(self):\n",
    "    # Set up optimizers and (optionally) learning rate schedulers\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < self.args.warmup:\n",
    "            return float(current_step) / float(max(1, self.args.warmup))\n",
    "        return max(0.0, float(self.args.steps - current_step) / float(max(1, self.args.steps - self.args.warmup)))\n",
    "\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=self.args.lr)\n",
    "\n",
    "    self.scheduler = LambdaLR(optimizer, lr_lambda, last_epoch=-1)  # scheduler is not saved in the checkpoint, but global_step is, which is enough to restart\n",
    "    self.scheduler.step(self.global_step)\n",
    "    print(\"global step: \", self.global_step)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optimizer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# A hook to do a lot of non-standard training tricks such as learning-rate warm-up\n",
    "def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None,using_native_amp=None):\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    self.scheduler.step(self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **training_step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def training_step(self, batch, batch_nb):\n",
    "    # do the forward pass and calculate the loss for a batch \n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qid, answer = batch \n",
    "    # print(\"size of input_ids: \" + str(input_ids.size())) \n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    \n",
    "#     print(self.explainer(input_ids))\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss  = output[:4]\n",
    "    # print(\"answer_loss: \", answer_loss)\n",
    "    # print(\"type_loss: \", type_loss)\n",
    "    # print(\"sp_para_loss: \", sp_para_loss)\n",
    "    # print(\"sp_sent_loss: \", sp_sent_loss)\n",
    "\n",
    "#     loss  = answer_loss +  type_loss + sp_para_loss + sp_sent_loss\n",
    "    loss = answer_loss + 5*type_loss + 10*sp_para_loss + 10*sp_sent_loss\n",
    "#     print(\"weighted loss: \", loss)\n",
    "#     print(\"self.trainer.optimizers[0].param_groups[0]['lr']: \", self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "    lr = loss.new_zeros(1) + self.trainer.optimizers[0].param_groups[0]['lr']  # loss.new_zeros(1) is tensor([0.]), converting 'lr' to tensor' by adding it.  \n",
    "\n",
    "    tensorboard_logs = {'loss': loss, 'train_answer_loss': answer_loss, 'train_type_loss': type_loss, \n",
    "                        'train_sp_para_loss': sp_para_loss, 'train_sp_sent_loss': sp_sent_loss, \n",
    "                        'lr': lr,\n",
    "                        'mem': torch.tensor(torch.cuda.memory_allocated(input_ids.device) / 1024 ** 3).type_as(loss) }\n",
    "    return tensorboard_logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%add_to hotpotqa\n",
    "    # # the function is called for each batch after every epoch is completed\n",
    "    # def training_end(self, output): \n",
    "    #     # print(\"training_end at epoch: \", self.current_epoch)\n",
    "    # #     print(\"len(outputs): \",len(outputs))\n",
    "    # #     print(\"output: \",output)\n",
    "    \n",
    "    #     # one batch only has one example\n",
    "    #     avg_loss = output['loss']    \n",
    "    #     avg_answer_loss = output['train_answer_loss']  \n",
    "    #     avg_type_loss = output['train_type_loss']    \n",
    "    #     avg_sp_para_loss = output['train_sp_para_loss']   \n",
    "    #     avg_sp_sent_loss = output['train_sp_sent_loss'] \n",
    "    #     avg_lr = output['lr']      \n",
    "         \n",
    "     \n",
    "    #     if self.trainer.use_ddp:\n",
    "    #         torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_loss /= self.trainer.world_size \n",
    "    #         torch.distributed.all_reduce(avg_answer_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_answer_loss /= self.trainer.world_size \n",
    "    #         torch.distributed.all_reduce(avg_type_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_type_loss /= self.trainer.world_size \n",
    "    #         torch.distributed.all_reduce(avg_sp_para_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_sp_para_loss /= self.trainer.world_size \n",
    "    #         torch.distributed.all_reduce(avg_sp_sent_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_sp_sent_loss /= self.trainer.world_size \n",
    "    #         torch.distributed.all_reduce(avg_lr, op=torch.distributed.ReduceOp.SUM)\n",
    "    #         avg_lr /= self.trainer.world_size \n",
    "            \n",
    "     \n",
    "    #     tensorboard_logs = { #'avg_train_loss': avg_loss, \n",
    "    #             'avg_train_answer_loss': avg_answer_loss, 'avg_train_type_loss': avg_type_loss, 'avg_train_sp_para_loss': avg_sp_para_loss, 'avg_train_sp_sent_loss': avg_sp_sent_loss, 'lr': avg_lr\n",
    "    #           }\n",
    "    \n",
    "    #     return {'loss': avg_loss, 'log': tensorboard_logs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# When the validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, model goes back to training mode and gradients are enabled.\n",
    "def validation_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qid, answer = batch\n",
    "\n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output = output \n",
    "    loss = answer_loss + 5*type_loss + 10*sp_para_loss + 10*sp_sent_loss\n",
    "\n",
    "    answers_pred, sp_sent_pred, sp_para_pred = self.decode(input_ids, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output)\n",
    "\n",
    "\n",
    "    if(len(answers_pred) != 1):\n",
    "        print(\"len(answers_pred) != 1\")\n",
    "        assert(len(answers_pred) == 1)\n",
    "\n",
    "    pre_answer_score = answers_pred[0]['score']  # (start_logit + end_logit + p_type_score) / 3\n",
    "    pre_answer = normalize_answer(answers_pred[0]['text'])\n",
    "#         print(\"pred answer_score: \" + str(pre_answer_score))\n",
    "#         print(\"pred answer_text: \" + str(pre_answer)) \n",
    "\n",
    "    gold_answer = normalize_answer(answer)\n",
    "    f1, prec, recall = self.f1_score(pre_answer, gold_answer)\n",
    "    em = self.exact_match_score(pre_answer, gold_answer) \n",
    "    f1 = torch.tensor(f1).type_as(loss)\n",
    "    prec = torch.tensor(prec).type_as(loss)\n",
    "    recall = torch.tensor(recall).type_as(loss)\n",
    "    em = torch.tensor(em).type_as(loss)\n",
    "#         print(\"f1: \" + str(f1))\n",
    "#         print(\"prec: \" + str(prec))\n",
    "#         print(\"recall: \" + str(recall))\n",
    "#         print(\"em: \" + str(em))  \n",
    "\n",
    "    if(len(sp_sent_pred) > 0):\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = self.sp_metrics(sp_sent_pred, torch.where(sp_sent.squeeze())[0].tolist())\n",
    "        sp_sent_em = torch.tensor(sp_sent_em).type_as(loss)\n",
    "        sp_sent_precision = torch.tensor(sp_sent_precision).type_as(loss)\n",
    "        sp_sent_recall = torch.tensor(sp_sent_recall).type_as(loss)\n",
    "        sp_sent_f1 = torch.tensor(sp_sent_f1).type_as(loss)\n",
    "\n",
    "#         print(\"sp_sent_em: \" + str(sp_sent_em))\n",
    "#         print(\"sp_sent_precision: \" + str(sp_sent_precision))\n",
    "#         print(\"sp_sent_recall: \" + str(sp_sent_recall))    \n",
    "#         print(\"sp_sent_f1: \" + str(sp_sent_f1))    \n",
    "\n",
    "        joint_prec = prec * sp_sent_precision\n",
    "        joint_recall = recall * sp_sent_recall\n",
    "        if joint_prec + joint_recall > 0:\n",
    "            joint_f1 = 2 * joint_prec * joint_recall / (joint_prec + joint_recall)\n",
    "        else:\n",
    "            joint_f1 = torch.tensor(0.0).type_as(loss)\n",
    "        joint_em = em * sp_sent_em \n",
    "\n",
    "    else:\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss)\n",
    "        joint_em, joint_f1, joint_prec, joint_recall =  torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss), torch.tensor(0.0).type_as(loss)\n",
    "\n",
    "\n",
    "    return { 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss,\n",
    "               'answer_score': pre_answer_score, 'f1': f1, 'prec':prec, 'recall':recall, 'em': em,\n",
    "               'sp_em': sp_sent_em, 'sp_f1': sp_sent_f1, 'sp_prec': sp_sent_precision, 'sp_recall': sp_sent_recall,\n",
    "               'joint_em': joint_em, 'joint_f1': joint_f1, 'joint_prec': joint_prec, 'joint_recall': joint_recall}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits):\n",
    "#         print(\"decode\")\n",
    "\n",
    "    question_end_index = self._get_special_index(input_ids, [QUESTION_END])\n",
    "#     print(\"question_end_index: \", question_end_index)\n",
    "\n",
    "    # one example per batch\n",
    "    start_logits = start_logits.squeeze()\n",
    "    end_logits = end_logits.squeeze()\n",
    "#     print(\"start_logits: \", start_logits)\n",
    "#     print(\"end_logits: \", end_logits)\n",
    "    start_logits_indices = start_logits.topk(k=self.args.n_best_size, dim=-1).indices\n",
    "#     print(\"start_logits_indices: \", start_logits_indices)\n",
    "    end_logits_indices = end_logits.topk(k=self.args.n_best_size, dim=-1).indices \n",
    "    if(len(start_logits_indices.size()) > 1):\n",
    "        print(\"len(start_logits_indices.size()): \", len(start_logits_indices.size()))\n",
    "        assert(\"len(start_logits_indices.size()) > 1\")\n",
    "    p_type = torch.argmax(type_logits, dim=1).item()\n",
    "    p_type_score = torch.max(type_logits, dim=1)[0] \n",
    "#     print(\"type_logits: \", type_logits)\n",
    "#         print(\"p_type: \", p_type)\n",
    "#         print(\"p_type_score: \", p_type_score)\n",
    "\n",
    "    answers = []\n",
    "    if p_type == 0:\n",
    "        potential_answers = []\n",
    "        for start_logit_index in start_logits_indices: \n",
    "            for end_logit_index in end_logits_indices: \n",
    "                if start_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if end_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if start_logit_index > end_logit_index:\n",
    "                    continue\n",
    "                answer_len = end_logit_index - start_logit_index + 1\n",
    "                if answer_len > self.args.max_answer_length:\n",
    "                    continue\n",
    "                potential_answers.append({'start': start_logit_index, 'end': end_logit_index,\n",
    "                                          'start_logit': start_logits[start_logit_index],  # single logit score for start position at start_logit_index\n",
    "                                          'end_logit': end_logits[end_logit_index]})    \n",
    "        sorted_answers = sorted(potential_answers, key=lambda x: (x['start_logit'] + x['end_logit']), reverse=True) \n",
    "#             print(\"sorted_answers: \" + str(sorted_answers))\n",
    "\n",
    "        if len(sorted_answers) == 0:\n",
    "            answers.append({'text': 'NoAnswerFound', 'score': -1000000})\n",
    "        else:\n",
    "            answer = sorted_answers[0]\n",
    "            answer_token_ids = input_ids[0, answer['start']: answer['end'] + 1]\n",
    "\n",
    "            answer_tokens = self.tokenizer.convert_ids_to_tokens(answer_token_ids.tolist())\n",
    "            # remove [/sent], <t> and </t>\n",
    "            for special_token in [SENT_MARKER_END, TITLE_START, TITLE_END]:\n",
    "                try:\n",
    "                    answer_tokens.remove(special_token)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            text = self.tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "#             score = (answer['start_logit'] + answer['end_logit'] + p_type_score) / 3\n",
    "            score = (torch.sigmoid(answer['start_logit']) + torch.sigmoid(answer['end_logit']) + torch.sigmoid(p_type_score)) / 3\n",
    "            answers.append({'text': text, 'score': score})\n",
    "#             print(\"answers: \" + str(answers))\n",
    "    elif p_type == 1: \n",
    "        answers.append({'text': 'yes', 'score': p_type_score})\n",
    "    elif p_type == 2:\n",
    "        answers.append({'text': 'no', 'score': p_type_score})\n",
    "    elif p_type == 3:\n",
    "        answers.append({'text': 'null', 'score': p_type_score})\n",
    "    else:\n",
    "        assert False \n",
    "\n",
    "\n",
    "    sent_indexes = self._get_special_index(input_ids, [SENT_MARKER_END])\n",
    "    para_indexes = self._get_special_index(input_ids, [TITLE_START])\n",
    "\n",
    "    s_to_p_map = []\n",
    "    for s in sent_indexes:\n",
    "        s_to_p = torch.where(torch.le(para_indexes, s))[0][-1]     # last para_index smaller or equal to s\n",
    "        s_to_p_map.append(s_to_p.item()) \n",
    "#         print(\"s_to_p_map: \" + str(s_to_p_map))\n",
    "\n",
    "#         print(\"sp_para_logits\", sp_para_logits)\n",
    "#         print(\"sp_sent_logits\", sp_sent_logits)\n",
    "\n",
    "    sp_para_top2 = sp_para_logits.squeeze().topk(k=2).indices\n",
    "    if(sp_sent_logits.squeeze().size(0) > 12):\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=12).indices\n",
    "    else:\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=sp_sent_logits.squeeze().size(0)).indices\n",
    "#         print(\"sp_para_top2\", sp_para_top2)\n",
    "#         print(\"sp_sent_top12\", sp_sent_top12)\n",
    "\n",
    "    sp_sent_pred = set()\n",
    "    sp_para_pred = set(sp_para_top2.tolist())\n",
    "    for sp_sent in sp_sent_top12:\n",
    "        sp_sent_to_para = s_to_p_map[sp_sent.item()]\n",
    "        if sp_sent_to_para in sp_para_top2:\n",
    "            sp_sent_pred.add(sp_sent.item())\n",
    "#             sp_para_pred.add(sp_sent_to_para) \n",
    "#         print(\"sp_sent_pred: \" + str(sp_sent_pred))\n",
    "#         print(\"sp_para_pred: \" + str(sp_para_pred))\n",
    "    return (answers, sp_sent_pred, sp_para_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# def normalize_answer(self, s):\n",
    "\n",
    "#     def remove_articles(text):\n",
    "#         return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "#     def white_space_fix(text):\n",
    "#         return ' '.join(text.split())\n",
    "\n",
    "#     def remove_punc(text):\n",
    "#         exclude = set(string.punctuation)\n",
    "#         return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "#     def lower(text):\n",
    "#         return text.lower()\n",
    "\n",
    "#     return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(self, prediction, ground_truth):\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "    normalized_ground_truth = normalize_answer(ground_truth)\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "\n",
    "    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def exact_match_score(self, prediction, ground_truth):\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def sp_metrics(self, prediction, gold): \n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for e in prediction:\n",
    "        if e in gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1 \n",
    "    for e in gold:\n",
    "        if e not in prediction:\n",
    "            fn += 1 \n",
    "    prec = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0 \n",
    "    return em, prec, recall, f1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# If a validation_step is not defined, this won't be called. Called at the end of the validation loop with the outputs of validation_step.\n",
    "def validation_end(self, outputs):\n",
    "    print(\"validation_end\")\n",
    "    avg_loss = torch.stack([x['vloss'] for x in outputs]).mean()  \n",
    "    avg_answer_loss = torch.stack([x['answer_loss'] for x in outputs]).mean()  \n",
    "    avg_type_loss = torch.stack([x['type_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_para_loss = torch.stack([x['sp_para_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_sent_loss = torch.stack([x['sp_sent_loss'] for x in outputs]).mean()  \n",
    "\n",
    "\n",
    "    answer_scores = [x['answer_score'] for x in outputs] \n",
    "    f1_scores = [x['f1'] for x in outputs]  \n",
    "    em_scores = [x['em'] for x in outputs]  \n",
    "    prec_scores =  [x['prec'] for x in outputs] \n",
    "    recall_scores = [x['recall'] for x in outputs]  \n",
    "    sp_sent_f1_scores = [x['sp_f1'] for x in outputs]   \n",
    "    sp_sent_em_scores = [x['sp_em'] for x in outputs]   \n",
    "    sp_sent_prec_scores = [x['sp_prec'] for x in outputs]   \n",
    "    sp_sent_recall_scores = [x['sp_recall'] for x in outputs]   \n",
    "    joint_f1_scores = [x['joint_f1'] for x in outputs]  \n",
    "    joint_em_scores = [x['joint_em'] for x in outputs]  \n",
    "    joint_prec_scores = [x['joint_prec'] for x in outputs]  \n",
    "    joint_recall_scores = [x['joint_recall'] for x in outputs]\n",
    "\n",
    "\n",
    "\n",
    "    print(f'before sync --> sizes:  {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "    if self.trainer.use_ddp:\n",
    "        torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_answer_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_answer_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_type_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_type_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_para_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_para_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_sent_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_sent_loss /= self.trainer.world_size \n",
    "\n",
    "        answer_scores = self.sync_list_across_gpus(answer_scores, avg_loss.device, torch.float)\n",
    "        f1_scores = self.sync_list_across_gpus(f1_scores, avg_loss.device, torch.float)\n",
    "        em_scores = self.sync_list_across_gpus(em_scores, avg_loss.device, torch.float)\n",
    "        prec_scores = self.sync_list_across_gpus(prec_scores, avg_loss.device, torch.float)\n",
    "        recall_scores = self.sync_list_across_gpus(recall_scores, avg_loss.device, torch.float)\n",
    "\n",
    "        sp_sent_f1_scores = self.sync_list_across_gpus(sp_sent_f1_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_em_scores = self.sync_list_across_gpus(sp_sent_em_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_prec_scores = self.sync_list_across_gpus(sp_sent_prec_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_recall_scores = self.sync_list_across_gpus(sp_sent_recall_scores, avg_loss.device, torch.float)\n",
    "\n",
    "        joint_f1_scores = self.sync_list_across_gpus(joint_f1_scores, avg_loss.device, torch.float)\n",
    "        joint_em_scores = self.sync_list_across_gpus(joint_em_scores, avg_loss.device, torch.float)\n",
    "        joint_prec_scores = self.sync_list_across_gpus(joint_prec_scores, avg_loss.device, torch.float)\n",
    "        joint_recall_scores = self.sync_list_across_gpus(joint_recall_scores, avg_loss.device, torch.float)\n",
    "\n",
    "\n",
    "    print(f'after sync --> sizes: {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "\n",
    "    avg_val_f1 = sum(f1_scores) / len(f1_scores)    \n",
    "    avg_val_em = sum(em_scores) / len(em_scores)    \n",
    "    avg_val_prec = sum(prec_scores) / len(prec_scores)  \n",
    "    avg_val_recall = sum(recall_scores) / len(recall_scores)    \n",
    "    avg_val_sp_sent_f1 = sum(sp_sent_f1_scores) / len(sp_sent_f1_scores)    \n",
    "    avg_val_sp_sent_em = sum(sp_sent_em_scores) / len(sp_sent_em_scores)    \n",
    "    avg_val_sp_sent_prec = sum(sp_sent_prec_scores) / len(sp_sent_prec_scores)  \n",
    "    avg_val_sp_sent_recall = sum(sp_sent_recall_scores) / len(sp_sent_recall_scores)    \n",
    "    avg_val_joint_f1 = sum(joint_f1_scores) / len(joint_f1_scores)  \n",
    "    avg_val_joint_em = sum(joint_em_scores) / len(joint_em_scores)  \n",
    "    avg_val_joint_prec = sum(joint_prec_scores) / len(joint_prec_scores)    \n",
    "    avg_val_joint_recall = sum(joint_recall_scores) / len(joint_recall_scores)  \n",
    "\n",
    "    print(\"avg_loss: \", avg_loss, end = '\\t')   \n",
    "    print(\"avg_answer_loss: \", avg_answer_loss, end = '\\t') \n",
    "    print(\"avg_type_loss: \", avg_type_loss, end = '\\t') \n",
    "    print(\"avg_sp_para_loss: \", avg_sp_para_loss, end = '\\t')   \n",
    "    print(\"avg_sp_sent_loss: \", avg_sp_sent_loss)   \n",
    "    print(\"avg_val_f1: \", avg_val_f1, end = '\\t')   \n",
    "    print(\"avg_val_em: \", avg_val_em, end = '\\t')   \n",
    "    print(\"avg_val_prec: \", avg_val_prec, end = '\\t')   \n",
    "    print(\"avg_val_recall: \", avg_val_recall)   \n",
    "    print(\"avg_val_sp_sent_f1: \", avg_val_sp_sent_f1, end = '\\t')   \n",
    "    print(\"avg_val_sp_sent_em: \" , avg_val_sp_sent_em, end = '\\t')  \n",
    "    print(\"avg_val_sp_sent_prec: \", avg_val_sp_sent_prec, end = '\\t')   \n",
    "    print(\"avg_val_sp_sent_recall: \", avg_val_sp_sent_recall)   \n",
    "    print(\"avg_val_joint_f1: \" , avg_val_joint_f1, end = '\\t')  \n",
    "    print(\"avg_val_joint_em: \", avg_val_joint_em, end = '\\t')   \n",
    "    print(\"avg_val_joint_prec: \", avg_val_joint_prec, end = '\\t')   \n",
    "    print(\"avg_val_joint_recall: \", avg_val_joint_recall)   \n",
    "\n",
    "\n",
    "    logs = {'avg_val_loss': avg_loss, 'avg_val_answer_loss': avg_answer_loss, 'avg_val_type_loss': avg_type_loss, 'avg_val_sp_para_loss': avg_sp_para_loss, 'avg_val_sp_sent_loss': avg_sp_sent_loss,   \n",
    "    'avg_val_f1': avg_val_f1, 'avg_val_em': avg_val_em,  'avg_val_prec': avg_val_prec, 'avg_val_recall': avg_val_recall,    \n",
    "    'avg_val_sp_sent_f1': avg_val_sp_sent_f1, 'avg_val_sp_sent_em': avg_val_sp_sent_em,  'avg_val_sp_sent_prec': avg_val_sp_sent_prec, 'avg_val_sp_sent_recall': avg_val_sp_sent_recall,    \n",
    "    'avg_val_joint_f1': avg_val_joint_f1, 'avg_val_joint_em': avg_val_joint_em,  'avg_val_joint_prec': avg_val_joint_prec, 'avg_val_joint_recall': avg_val_joint_recall \n",
    "    }   \n",
    "\n",
    "    return {'avg_val_loss': avg_loss, 'log': logs}\n",
    "\n",
    "def sync_list_across_gpus(self, l, device, dtype):\n",
    "    l_tensor = torch.tensor(l, device=device, dtype=dtype)\n",
    "    gather_l_tensor = [torch.ones_like(l_tensor) for _ in range(self.trainer.world_size)]\n",
    "    torch.distributed.all_gather(gather_l_tensor, l_tensor)\n",
    "    return torch.cat(gather_l_tensor).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qid, answer = batch\n",
    "\n",
    "    print(\"test_step of qid: \", qid, end=\"\\t\") \n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output = output \n",
    "    loss = answer_loss + 5*type_loss + 10*sp_para_loss + 10*sp_sent_loss\n",
    "\n",
    "    answers_pred, sp_sent_pred, sp_para_pred = self.decode(input_ids, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output)\n",
    "\n",
    "    if(len(answers_pred) != 1):\n",
    "        print(\"len(answers_pred) != 1\")\n",
    "        assert(len(answers_pred) == 1)\n",
    "\n",
    "    pre_answer_score = answers_pred[0]['score']  # (start_logit + end_logit + p_type_score) / 3\n",
    "    pre_answer = normalize_answer(answers_pred[0]['text'])\n",
    "    # print(\"pred answer_score: \" + str(pre_answer_score))\n",
    "    # print(\"pred answer_text: \" + str(pre_answer)) \n",
    "\n",
    "    gold_answer = normalize_answer(answer)\n",
    "\n",
    "    print(\"pre_answer:\\t\", pre_answer, \"\\tgold_answer:\\t\", gold_answer)\n",
    "\n",
    "    return { 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss, 'answer_score': pre_answer_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_end(self, outputs):\n",
    "    print(\"test_end\")\n",
    "    avg_loss = torch.stack([x['vloss'] for x in outputs]).mean()  \n",
    "    avg_answer_loss = torch.stack([x['answer_loss'] for x in outputs]).mean()  \n",
    "    avg_type_loss = torch.stack([x['type_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_para_loss = torch.stack([x['sp_para_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_sent_loss = torch.stack([x['sp_sent_loss'] for x in outputs]).mean()  \n",
    "\n",
    "    answer_scores = [x['answer_score'] for x in outputs]  # [item for sublist in outputs for item in sublist['answer_score']] #torch.stack([x['answer_score'] for x in outputs]).mean() # \n",
    "\n",
    "\n",
    "    print(f'before sync --> sizes:  {len(answer_scores)}')\n",
    "    if self.trainer.use_ddp:\n",
    "        torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_answer_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_answer_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_type_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_type_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_para_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_para_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_sent_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_sent_loss /= self.trainer.world_size \n",
    "\n",
    "#         int_qids = self.sync_list_across_gpus(int_qids, avg_loss.device, torch.int)\n",
    "        answer_scores = self.sync_list_across_gpus(answer_scores, avg_loss.device, torch.float)\n",
    "\n",
    "\n",
    "    print(f'after sync --> sizes: {len(answer_scores)}')\n",
    "    # print(\"answer_scores: \", answer_scores)\n",
    "\n",
    "    # print(\"avg_loss: \", avg_loss, end = '\\t') \n",
    "    # print(\"avg_answer_loss: \", avg_answer_loss, end = '\\t') \n",
    "    # print(\"avg_type_loss: \", avg_type_loss, end = '\\t') \n",
    "    # print(\"avg_sp_para_loss: \", avg_sp_para_loss, end = '\\t') \n",
    "    # print(\"avg_sp_sent_loss: \", avg_sp_sent_loss, end = '\\t')  \n",
    "\n",
    "    logs = {'avg_val_loss': avg_loss, 'avg_val_answer_loss': avg_answer_loss, 'avg_val_type_loss': avg_type_loss, 'avg_val_sp_para_loss': avg_sp_para_loss, 'avg_val_sp_sent_loss': avg_sp_sent_loss\n",
    "           }\n",
    "\n",
    "    return {'avg_val_loss': avg_loss, 'log': logs} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add_model_specific_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "@staticmethod\n",
    "def add_model_specific_args(parser, root_dir):\n",
    "    parser.add_argument(\"--save_dir\", type=str, default='jupyter-hotpotqa')\n",
    "    parser.add_argument(\"--save_prefix\", type=str, required=True)\n",
    "    parser.add_argument(\"--train_dataset\", type=str, required=False, help=\"Path to the training squad-format\")\n",
    "    parser.add_argument(\"--dev_dataset\", type=str, required=True, help=\"Path to the dev squad-format\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2, help=\"Batch size\")\n",
    "    parser.add_argument(\"--gpus\", type=str, default='0',\n",
    "                        help=\"Comma separated list of gpus. Default is gpu 0. To use CPU, use --gpus \"\" \")\n",
    "    parser.add_argument(\"--warmup\", type=int, default=1000, help=\"Number of warmup steps\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.00005, help=\"Maximum learning rate\")\n",
    "    parser.add_argument(\"--val_every\", type=float, default=1.0, help=\"How often within one training epoch to check the validation set.\")\n",
    "    parser.add_argument(\"--val_percent_check\", default=1.00, type=float, help='Percent of validation data used')\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=4, help=\"Number of data loader workers\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=1234, help=\"Seed\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=6, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=4096,\n",
    "                        help=\"Maximum length of seq passed to the transformer model\")\n",
    "    parser.add_argument(\"--max_doc_len\", type=int, default=4096,\n",
    "                        help=\"Maximum number of wordpieces of the input document\")\n",
    "    parser.add_argument(\"--max_num_answers\", type=int, default=64,\n",
    "                        help=\"Maximum number of answer spans per document (64 => 94%)\")\n",
    "    parser.add_argument(\"--max_question_len\", type=int, default=55,\n",
    "                        help=\"Maximum length of the question\")\n",
    "    parser.add_argument(\"--doc_stride\", type=int, default=-1,\n",
    "                        help=\"Overlap between document chunks. Use -1 to only use the first chunk\")\n",
    "    parser.add_argument(\"--ignore_seq_with_no_answers\", action='store_true',\n",
    "                        help=\"each example should have at least one answer. Default is False\")\n",
    "    parser.add_argument(\"--disable_checkpointing\", action='store_true', help=\"No logging or checkpointing\")\n",
    "    parser.add_argument(\"--n_best_size\", type=int, default=20,\n",
    "                        help=\"Number of answer candidates. Used at decoding time\")\n",
    "    parser.add_argument(\"--max_answer_length\", type=int, default=30,\n",
    "                        help=\"maximum num of wordpieces/answer. Used at decoding time\")\n",
    "    parser.add_argument(\"--regular_softmax_loss\", action='store_true', help=\"IF true, use regular softmax. Default is using ORed softmax loss\")\n",
    "    parser.add_argument(\"--test\", action='store_true', help=\"Test only, no training\")\n",
    "    parser.add_argument(\"--model_path\", type=str,\n",
    "                        help=\"Path to the checkpoint directory\")\n",
    "    parser.add_argument(\"--no_progress_bar\", action='store_true', help=\"no progress bar. Good for printing\")\n",
    "    parser.add_argument(\"--attention_mode\", type=str, choices=['tvm', 'sliding_chunks'],\n",
    "                        default='sliding_chunks', help='Which implementation of selfattention to use')\n",
    "    parser.add_argument(\"--fp32\", action='store_true', help=\"default is fp16. Use --fp32 to switch to fp32\")\n",
    "    parser.add_argument('--train_percent', type=float, default=1.0)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHECKPOINT_HYPER_PARAMS_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_NAME',\n",
       " 'CHECKPOINT_HYPER_PARAMS_TYPE',\n",
       " 'T_destination',\n",
       " '_LightningModule__get_hparams_assignment_variable',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_apply',\n",
       " '_auto_collect_arguments',\n",
       " '_call_impl',\n",
       " '_forward_unimplemented',\n",
       " '_get_name',\n",
       " '_get_special_index',\n",
       " '_init_slurm_connection',\n",
       " '_load_from_state_dict',\n",
       " '_load_model_state',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_hparams',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " 'add_model_specific_args',\n",
       " 'add_module',\n",
       " 'amp_scale_loss',\n",
       " 'apply',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'configure_apex',\n",
       " 'configure_ddp',\n",
       " 'configure_optimizers',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'decode',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'exact_match_score',\n",
       " 'example_input_array',\n",
       " 'extra_repr',\n",
       " 'f1_score',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'get_progress_bar_dict',\n",
       " 'get_tqdm_dict',\n",
       " 'grad_norm',\n",
       " 'half',\n",
       " 'hparams',\n",
       " 'init_ddp_connection',\n",
       " 'load_from_checkpoint',\n",
       " 'load_from_metrics',\n",
       " 'load_model',\n",
       " 'load_state_dict',\n",
       " 'loss_computation',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'on_after_backward',\n",
       " 'on_batch_end',\n",
       " 'on_batch_start',\n",
       " 'on_before_zero_grad',\n",
       " 'on_epoch_end',\n",
       " 'on_epoch_start',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_gpu',\n",
       " 'on_hpc_load',\n",
       " 'on_hpc_save',\n",
       " 'on_load_checkpoint',\n",
       " 'on_post_performance_check',\n",
       " 'on_pre_performance_check',\n",
       " 'on_sanity_check_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_train_end',\n",
       " 'on_train_start',\n",
       " 'optimizer_step',\n",
       " 'optimizer_zero_grad',\n",
       " 'or_softmax_cross_entropy_loss_one_doc',\n",
       " 'parameters',\n",
       " 'prepare_data',\n",
       " 'print',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'save_hyperparameters',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'sp_metrics',\n",
       " 'state_dict',\n",
       " 'summarize',\n",
       " 'sync_list_across_gpus',\n",
       " 'tbptt_split_batch',\n",
       " 'teardown',\n",
       " 'test_dataloader',\n",
       " 'test_end',\n",
       " 'test_epoch_end',\n",
       " 'test_step',\n",
       " 'test_step_end',\n",
       " 'tng_dataloader',\n",
       " 'to',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'training_end',\n",
       " 'training_epoch_end',\n",
       " 'training_step',\n",
       " 'training_step_end',\n",
       " 'transfer_batch_to_device',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'val_dataloader',\n",
       " 'validation_end',\n",
       " 'validation_epoch_end',\n",
       " 'validation_step',\n",
       " 'validation_step_end',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CHECKPOINT_HYPER_PARAMS_KEY', 'hyper_parameters'),\n",
       " ('CHECKPOINT_HYPER_PARAMS_NAME', 'hparams_name'),\n",
       " ('CHECKPOINT_HYPER_PARAMS_TYPE', 'hparams_type'),\n",
       " ('T_destination', ~T_destination),\n",
       " ('_LightningModule__get_hparams_assignment_variable',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.__get_hparams_assignment_variable(self)>),\n",
       " ('__abstractmethods__', frozenset()),\n",
       " ('__annotations__',\n",
       "  {'_device': Ellipsis, '_dtype': typing.Union[str, torch.dtype]}),\n",
       " ('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__class__', abc.ABCMeta),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__init__': <function __main__.hotpotqa.__init__(self, args)>,\n",
       "                'load_model': <function __main__.hotpotqa.load_model(self)>,\n",
       "                'train_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>,\n",
       "                'val_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>,\n",
       "                'test_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>,\n",
       "                'forward': <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>,\n",
       "                'loss_computation': <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>,\n",
       "                '_get_special_index': <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>,\n",
       "                'or_softmax_cross_entropy_loss_one_doc': <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>,\n",
       "                '__doc__': None,\n",
       "                '__abstractmethods__': frozenset(),\n",
       "                '_abc_registry': <_weakrefset.WeakSet at 0x7f1da18e02e8>,\n",
       "                '_abc_cache': <_weakrefset.WeakSet at 0x7f1da18e0320>,\n",
       "                '_abc_negative_cache': <_weakrefset.WeakSet at 0x7f1da18e0390>,\n",
       "                '_abc_negative_cache_version': 97,\n",
       "                'configure_ddp': <function __main__.configure_ddp(self, model, device_ids)>,\n",
       "                'configure_optimizers': <function __main__.configure_optimizers(self)>,\n",
       "                'optimizer_step': <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, using_native_amp=None)>,\n",
       "                'training_step': <function __main__.training_step(self, batch, batch_nb)>,\n",
       "                'validation_step': <function __main__.validation_step(self, batch, batch_nb)>,\n",
       "                'decode': <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>,\n",
       "                'f1_score': <function __main__.f1_score(self, prediction, ground_truth)>,\n",
       "                'exact_match_score': <function __main__.exact_match_score(self, prediction, ground_truth)>,\n",
       "                'sp_metrics': <function __main__.sp_metrics(self, prediction, gold)>,\n",
       "                'validation_end': <function __main__.validation_end(self, outputs)>,\n",
       "                'sync_list_across_gpus': <function __main__.sync_list_across_gpus(self, l, device, dtype)>,\n",
       "                'test_step': <function __main__.test_step(self, batch, batch_nb)>,\n",
       "                'test_end': <function __main__.test_end(self, outputs)>,\n",
       "                'add_model_specific_args': <staticmethod at 0x7f1da18d9128>})),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__doc__', None),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__init_subclass__', <function hotpotqa.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqa.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'ABC' objects>),\n",
       " ('_abc_cache', <_weakrefset.WeakSet at 0x7f1da18e0320>),\n",
       " ('_abc_negative_cache', <_weakrefset.WeakSet at 0x7f1da18e0390>),\n",
       " ('_abc_negative_cache_version', 97),\n",
       " ('_abc_registry', <_weakrefset.WeakSet at 0x7f1da18e02e8>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_auto_collect_arguments',\n",
       "  <bound method LightningModule._auto_collect_arguments of <class '__main__.hotpotqa'>>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>),\n",
       " ('_init_slurm_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule._init_slurm_connection(self) -> None>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_load_model_state',\n",
       "  <bound method ModelIO._load_model_state of <class '__main__.hotpotqa'>>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_set_hparams',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule._set_hparams(self, hp:Union[dict, argparse.Namespace, str]) -> None>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('_version', 1),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('amp_scale_loss',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.amp_scale_loss(self, unscaled_loss, optimizer, optimizer_idx)>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, trainer, loss:torch.Tensor, optimizer:torch.optim.optimizer.Optimizer, optimizer_idx:int) -> None>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp:object, model:'LightningModule', optimizers:List[torch.optim.optimizer.Optimizer], amp_level:str) -> Tuple[_ForwardRef('LightningModule'), List[torch.optim.optimizer.Optimizer]]>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.cpu(self) -> torch.nn.modules.module.Module>),\n",
       " ('cuda',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.cuda(self, device:Union[int, NoneType]=None) -> torch.nn.modules.module.Module>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('device', <property at 0x7f1da3cc9b88>),\n",
       " ('double',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.double(self) -> torch.nn.modules.module.Module>),\n",
       " ('dtype', <property at 0x7f1da3cc9ae8>),\n",
       " ('dump_patches', False),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('example_input_array', <property at 0x7f1da3d0a3b8>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.float(self) -> torch.nn.modules.module.Module>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self) -> None>),\n",
       " ('get_progress_bar_dict',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.get_progress_bar_dict(self) -> Dict[str, Union[str, int]]>),\n",
       " ('get_tqdm_dict',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.get_tqdm_dict(self) -> Dict[str, Union[str, int]]>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type:Union[float, int, str]) -> Dict[str, float]>),\n",
       " ('half',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.half(self) -> torch.nn.modules.module.Module>),\n",
       " ('hparams', <property at 0x7f1da3c5e958>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, global_rank:int, world_size:int, is_slurm_managing_tasks:bool=True) -> None>),\n",
       " ('load_from_checkpoint',\n",
       "  <bound method ModelIO.load_from_checkpoint of <class '__main__.hotpotqa'>>),\n",
       " ('load_from_metrics',\n",
       "  <bound method ModelIO.load_from_metrics of <class '__main__.hotpotqa'>>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self) -> None>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self) -> None>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch:Any) -> None>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer:torch.optim.optimizer.Optimizer) -> None>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self) -> None>),\n",
       " ('on_epoch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_start(self) -> None>),\n",
       " ('on_fit_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_fit_end(self)>),\n",
       " ('on_fit_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_fit_start(self)>),\n",
       " ('on_gpu', <property at 0x7f1da3d0a4a8>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self) -> None>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self) -> None>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self) -> None>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self) -> None>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, using_native_amp=None)>),\n",
       " ('optimizer_zero_grad',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.optimizer_zero_grad(self, epoch:int, batch_idx:int, optimizer:torch.optim.optimizer.Optimizer, optimizer_idx:int)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('prepare_data',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.prepare_data(self) -> None>),\n",
       " ('print',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.print(self, *args, **kwargs) -> None>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('save_hyperparameters',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.save_hyperparameters(self, *args, frame=None) -> None>),\n",
       " ('setup',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.setup(self, stage:str)>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode:str='top') -> pytorch_lightning.core.memory.ModelSummary>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch:torch.Tensor, split_size:int) -> list>),\n",
       " ('teardown',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.teardown(self, stage:str)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.test_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('test_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.test_step_end(self, *args, **kwargs) -> Dict[str, torch.Tensor]>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tng_dataloader(self)>),\n",
       " ('to',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.to(self, *args, **kwargs) -> torch.nn.modules.module.Module>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_nb)>),\n",
       " ('training_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_step_end(self, *args, **kwargs) -> Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]>),\n",
       " ('transfer_batch_to_device',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.transfer_batch_to_device(self, batch:Any, device:torch.device) -> Any>),\n",
       " ('type',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.type(self, dst_type:Union[str, torch.dtype]) -> torch.nn.modules.module.Module>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self) -> None>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.validation_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('validation_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.validation_step_end(self, *args, **kwargs) -> Dict[str, torch.Tensor]>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "getmembers(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_LightningModule__get_hparams_assignment_variable',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.__get_hparams_assignment_variable(self)>),\n",
       " ('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_tokens)>),\n",
       " ('_init_slurm_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule._init_slurm_connection(self) -> None>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_set_hparams',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule._set_hparams(self, hp:Union[dict, argparse.Namespace, str]) -> None>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('amp_scale_loss',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.amp_scale_loss(self, unscaled_loss, optimizer, optimizer_idx)>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, trainer, loss:torch.Tensor, optimizer:torch.optim.optimizer.Optimizer, optimizer_idx:int) -> None>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp:object, model:'LightningModule', optimizers:List[torch.optim.optimizer.Optimizer], amp_level:str) -> Tuple[_ForwardRef('LightningModule'), List[torch.optim.optimizer.Optimizer]]>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.cpu(self) -> torch.nn.modules.module.Module>),\n",
       " ('cuda',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.cuda(self, device:Union[int, NoneType]=None) -> torch.nn.modules.module.Module>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('double',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.double(self) -> torch.nn.modules.module.Module>),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.float(self) -> torch.nn.modules.module.Module>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self) -> None>),\n",
       " ('get_progress_bar_dict',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.get_progress_bar_dict(self) -> Dict[str, Union[str, int]]>),\n",
       " ('get_tqdm_dict',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.get_tqdm_dict(self) -> Dict[str, Union[str, int]]>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type:Union[float, int, str]) -> Dict[str, float]>),\n",
       " ('half',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.half(self) -> torch.nn.modules.module.Module>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, global_rank:int, world_size:int, is_slurm_managing_tasks:bool=True) -> None>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self) -> None>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self) -> None>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch:Any) -> None>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer:torch.optim.optimizer.Optimizer) -> None>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self) -> None>),\n",
       " ('on_epoch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_start(self) -> None>),\n",
       " ('on_fit_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_fit_end(self)>),\n",
       " ('on_fit_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_fit_start(self)>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self) -> None>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self) -> None>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint:Dict[str, Any]) -> None>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self) -> None>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self) -> None>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None, using_native_amp=None)>),\n",
       " ('optimizer_zero_grad',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.optimizer_zero_grad(self, epoch:int, batch_idx:int, optimizer:torch.optim.optimizer.Optimizer, optimizer_idx:int)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('prepare_data',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.prepare_data(self) -> None>),\n",
       " ('print',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.print(self, *args, **kwargs) -> None>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('save_hyperparameters',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.save_hyperparameters(self, *args, frame=None) -> None>),\n",
       " ('setup',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.setup(self, stage:str)>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode:str='top') -> pytorch_lightning.core.memory.ModelSummary>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch:torch.Tensor, split_size:int) -> list>),\n",
       " ('teardown',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.teardown(self, stage:str)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.test_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('test_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.test_step_end(self, *args, **kwargs) -> Dict[str, torch.Tensor]>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tng_dataloader(self)>),\n",
       " ('to',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.to(self, *args, **kwargs) -> torch.nn.modules.module.Module>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_nb)>),\n",
       " ('training_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_step_end(self, *args, **kwargs) -> Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]>),\n",
       " ('transfer_batch_to_device',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.transfer_batch_to_device(self, batch:Any, device:torch.device) -> Any>),\n",
       " ('type',\n",
       "  <function pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin.type(self, dst_type:Union[str, torch.dtype]) -> torch.nn.modules.module.Module>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self) -> None>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>.inner_fx(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_epoch_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.validation_epoch_end(self, outputs:Union[List[Dict[str, torch.Tensor]], List[List[Dict[str, torch.Tensor]]]]) -> Dict[str, Dict[str, torch.Tensor]]>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('validation_step_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.validation_step_end(self, *args, **kwargs) -> Dict[str, torch.Tensor]>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions_list = [o for o in getmembers(hotpotqa) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqa,\n",
       " pytorch_lightning.core.lightning.LightningModule,\n",
       " abc.ABC,\n",
       " pytorch_lightning.utilities.device_dtype_mixin.DeviceDtypeModuleMixin,\n",
       " pytorch_lightning.core.grads.GradInformation,\n",
       " pytorch_lightning.core.saving.ModelIO,\n",
       " pytorch_lightning.core.hooks.ModelHooks,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqa)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function configure_optimizers in module __main__:\n",
      "\n",
      "configure_optimizers(self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqa.configure_optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# code, line_no = inspect.getsourcelines(hotpotqa.training_step)\n",
    "# print(''.join(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "    if not args.test:     # if it needs to train, remove exsiting folder\n",
    "        import shutil\n",
    "        save_folder = os.path.join(args.save_dir, args.save_prefix)\n",
    "        if os.path.exists(save_folder):\n",
    "            shutil.rmtree(save_folder, ignore_errors=True)  #delete non-empty folder \n",
    "        \n",
    "    import shutil\n",
    "    save_folder = os.path.join(args.save_dir, args.save_prefix)\n",
    "    if os.path.exists(save_folder):\n",
    "        shutil.rmtree(save_folder, ignore_errors=True)  #delete non-empty folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.args.model_path:  /xdisk/msurdeanu/fanluo/hotpotQA/longformer-base-4096\n",
      "Loaded model with config:\n",
      "LongformerConfig {\n",
      "  \"attention_dilation\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"attention_mode\": \"sliding_chunks\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"autoregressive\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    hotpotqa.__abstractmethods__=set()   # without this, got an error \"Can't instantiate abstract class hotpotqa with abstract methods\" if these two abstract methods are not implemented in the same cell where class hotpotqa defined \n",
    "    model = hotpotqa(args)\n",
    "#     model.to('cuda')    # this is necessary to use gpu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger = TestTubeLogger( # The TestTubeLogger adds a nicer folder structure to manage experiments and snapshots all hyperparameters you pass to a LightningModule.\n",
    "        save_dir=args.save_dir,\n",
    "        name=args.save_prefix,\n",
    "        version=0  # always use version=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(args.save_dir, args.save_prefix, \"checkpoints\"),\n",
    "        save_top_k=5,\n",
    "        verbose=True,\n",
    "        monitor='avg_val_f1',\n",
    "        mode='max',\n",
    "        prefix=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_size:  9.0\n",
      "num_devices:  1\n",
      ">>>>>>> #train_set_size: 90447.0, #steps: 271341.0,  #warmup steps: 1000, #epochs: 6, batch_size: 2 <<<<<<<\n"
     ]
    }
   ],
   "source": [
    "    train_set_size = 9 * args.train_percent # 90447 * args.train_percent   # hardcode dataset size. Needed to compute number of steps for the lr scheduler\n",
    "    print(\"train_set_size: \", train_set_size) \n",
    "\n",
    "    args.gpus = [int(x) for x in args.gpus.split(',')] if args.gpus!='' else None\n",
    "    num_devices = 1 or len(args.gpus)\n",
    "    print(\"num_devices: \", num_devices)\n",
    "\n",
    "    train_set_size = 90447 * args.train_percent    # hardcode dataset size. Needed to compute number of steps for the lr scheduler\n",
    "    args.steps = args.epochs * train_set_size / (args.batch_size * num_devices)\n",
    "\n",
    "    print(f'>>>>>>> #train_set_size: {train_set_size}, #steps: {args.steps},  #warmup steps: {args.warmup}, #epochs: {args.epochs}, batch_size: {args.batch_size * num_devices} <<<<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Multi-processing is handled by Slurm.\n",
      "Multi-processing is handled by Slurm.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "    trainer = pl.Trainer(gpus=args.gpus, distributed_backend='ddp', # if args.gpus and (len(args.gpus) > 1) else None,\n",
    "                             track_grad_norm=-1, max_epochs=args.epochs, early_stop_callback=None,\n",
    "                             accumulate_grad_batches=args.batch_size,\n",
    "                             train_percent_check = args.train_percent,\n",
    "        #                          val_check_interval=args.val_every,\n",
    "                             val_percent_check=args.val_percent_check,\n",
    "                             test_percent_check=args.val_percent_check,\n",
    "                             logger=logger if not args.disable_checkpointing else False,\n",
    "                             checkpoint_callback=checkpoint_callback if not args.disable_checkpointing else False,\n",
    "                             show_progress_bar=args.no_progress_bar,\n",
    "#                              use_amp=not args.fp32, \n",
    "                             amp_level='O2',\n",
    "#                              check_val_every_n_epoch=1\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=ddp\n",
      "distributed_backend=ddp\n",
      "All DDP processes registered. Starting ddp with 1 processes\n",
      "All DDP processes registered. Starting ddp with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Set SLURM handle signals.\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | model       | Longformer | 148 M \n",
      "1 | qa_outputs  | Linear     | 1 K   \n",
      "2 | linear_type | Linear     | 3 K   \n",
      "3 | fnn_sp_sent | Sequential | 591 K \n",
      "4 | fnn_sp_para | Sequential | 591 K \n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | model       | Longformer | 148 M \n",
      "1 | qa_outputs  | Linear     | 1 K   \n",
      "2 | linear_type | Linear     | 3 K   \n",
      "3 | fnn_sp_sent | Sequential | 591 K \n",
      "4 | fnn_sp_para | Sequential | 591 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: small.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  24 october 1632\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ohpc/pub/apps/python/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:260: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0359,  0.0133,  0.0292,  ..., -0.2841, -0.0267,  0.0766],\n",
      "         [ 0.0486, -0.0523, -0.0488,  ...,  0.6019, -0.0301,  0.1249],\n",
      "         [ 0.1347,  0.1540, -0.0192,  ..., -0.6490,  0.0473, -0.2353],\n",
      "         ...,\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  marlboro\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0806,  0.0374,  0.0225,  ..., -0.3244, -0.0426,  0.0531],\n",
      "         [ 0.2363, -0.2201,  0.2304,  ..., -0.3536, -0.2434,  0.3808],\n",
      "         [ 0.0655, -0.0122,  0.0231,  ..., -0.4995,  0.0678,  0.2588],\n",
      "         ...,\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  american\n",
      "validation_end\n",
      "before sync --> sizes:  2, 2, 2\n",
      "after sync --> sizes: 2, 2, 2\n",
      "avg_loss:  tensor(30.3850, device='cuda:0')\tavg_answer_loss:  tensor(7.1404, device='cuda:0')\tavg_type_loss:  tensor(1.7390, device='cuda:0')\tavg_sp_para_loss:  tensor(0.6504, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.8046, device='cuda:0')\n",
      "avg_val_f1:  0.0\tavg_val_em:  0.0\tavg_val_prec:  0.0\tavg_val_recall:  0.0\n",
      "avg_val_sp_sent_f1:  0.25\tavg_val_sp_sent_em:  0.0\tavg_val_sp_sent_prec:  0.25\tavg_val_sp_sent_recall:  0.25\n",
      "avg_val_joint_f1:  0.0\tavg_val_joint_em:  0.0\tavg_val_joint_prec:  0.0\tavg_val_joint_recall:  0.0\n",
      "reading file: small.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688157433f91431992f22baeab2f2f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  lorax\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  transcendentalist\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0556, -0.0241,  0.0461,  ..., -0.3570, -0.0164,  0.0575],\n",
      "         [ 0.3010, -0.1806,  0.1260,  ...,  0.2499, -0.1691,  0.0948],\n",
      "         [ 0.0693,  0.1531, -0.0519,  ..., -0.8308, -0.0125, -0.0931],\n",
      "         ...,\n",
      "         [-0.0143,  0.0637, -0.0129,  ..., -0.0977, -0.0379, -0.0520],\n",
      "         [-0.0354,  0.0706, -0.0012,  ..., -0.1087, -0.0455, -0.0798],\n",
      "         [-0.0199,  0.0402, -0.0142,  ..., -0.0985, -0.0507, -0.0539]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "answer:  ash avildsen and matty beckerman\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.1692,  0.0340,  0.0267,  ..., -0.6724, -0.1038,  0.1050],\n",
      "         [-0.0272,  0.0138,  0.2450,  ..., -0.8455, -0.2534,  0.0969],\n",
      "         [ 0.1589,  0.0141,  0.0483,  ..., -0.2977,  0.0026,  0.1160],\n",
      "         ...,\n",
      "         [-0.0206,  0.0676,  0.0033,  ..., -0.0992, -0.0196, -0.0543],\n",
      "         [-0.0268,  0.0667, -0.0171,  ..., -0.0954, -0.0504, -0.0660],\n",
      "         [-0.0229,  0.0614, -0.0286,  ..., -0.1057, -0.0464,  0.0143]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0369, -0.0275,  0.0358,  ..., -0.2695, -0.0330,  0.1285],\n",
      "         [ 0.3671, -0.4272, -0.0087,  ...,  0.4206, -0.1782,  0.4310],\n",
      "         [-0.0141, -0.0310,  0.1280,  ..., -0.8326,  0.0309,  0.1870],\n",
      "         ...,\n",
      "         [-0.0246,  0.0700, -0.0009,  ..., -0.1100, -0.0541, -0.0686],\n",
      "         [-0.0210,  0.1004, -0.0153,  ..., -0.1036, -0.0159, -0.0628],\n",
      "         [-0.0310,  0.0744, -0.0136,  ..., -0.1076, -0.0406, -0.0692]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0425,  0.0518,  0.0253,  ..., -0.2823, -0.1077,  0.0575],\n",
      "         [ 0.4731, -0.2698,  0.4397,  ..., -0.8812,  0.2623,  0.2030],\n",
      "         [ 0.2302, -0.0284,  0.0125,  ..., -0.3910, -0.0888,  0.0974],\n",
      "         ...,\n",
      "         [-0.0307,  0.0754, -0.0169,  ..., -0.1053, -0.0402,  0.0211],\n",
      "         [-0.0176,  0.0392, -0.0127,  ..., -0.0921, -0.0287, -0.0583],\n",
      "         [-0.0206,  0.0681, -0.0014,  ..., -0.0966, -0.0348, -0.0741]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0645,  0.0182,  0.0117,  ..., -0.2079, -0.0442,  0.0987],\n",
      "         [ 0.2073,  0.0114, -0.0587,  ..., -0.2609,  0.0332,  0.1524],\n",
      "         [ 0.2271,  0.2036, -0.0081,  ..., -0.5083,  0.0378,  0.3131],\n",
      "         ...,\n",
      "         [-0.0307,  0.0662, -0.0188,  ..., -0.0980, -0.0374, -0.0664],\n",
      "         [ 0.0488,  0.0308, -0.2023,  ..., -0.0753,  0.1258, -0.1423],\n",
      "         [ 0.0557,  0.0068,  0.0481,  ..., -0.0603,  0.1380, -0.2485]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-7.0112e-02,  3.2321e-02, -5.0575e-03,  ..., -2.3591e-01,\n",
      "          -3.7368e-02,  7.0638e-02],\n",
      "         [ 1.0982e-01, -2.6244e-02, -7.1537e-02,  ..., -3.4072e-01,\n",
      "           7.9236e-02,  4.0263e-01],\n",
      "         [ 1.2780e-01, -4.7434e-02,  1.9303e-03,  ..., -8.5542e-01,\n",
      "           6.3876e-02,  7.1924e-02],\n",
      "         ...,\n",
      "         [-2.2043e-02,  7.4718e-02,  3.7090e-04,  ..., -9.5973e-02,\n",
      "          -5.1606e-02, -6.5897e-02],\n",
      "         [-7.8855e-02,  1.1483e-01,  2.5764e-02,  ..., -7.8836e-02,\n",
      "          -5.0233e-02, -1.5633e-01],\n",
      "         [-2.8018e-02,  7.2552e-02, -1.2959e-02,  ..., -9.3538e-02,\n",
      "          -1.5722e-02, -5.0651e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0704,  0.0406,  0.0155,  ..., -0.1681, -0.0349,  0.0340],\n",
      "         [ 0.2887, -0.0130,  0.1253,  ..., -0.7115, -0.0932,  0.3851],\n",
      "         [ 0.1156, -0.0410,  0.0042,  ..., -0.2666, -0.0350,  0.0756],\n",
      "         ...,\n",
      "         [-0.0868,  0.1236, -0.0418,  ..., -0.0895,  0.0105, -0.1654],\n",
      "         [-0.0277,  0.0702, -0.0148,  ..., -0.1131, -0.0372, -0.0685],\n",
      "         [-0.0425,  0.1932,  0.0060,  ..., -0.0357, -0.1004, -0.2356]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0354,  0.0513, -0.0245,  ..., -0.3668,  0.0094,  0.0619],\n",
      "         [ 0.0749, -0.0594,  0.1322,  ..., -0.2463, -0.0598,  0.1569],\n",
      "         [ 0.0086, -0.0242,  0.0104,  ..., -0.5469,  0.0376, -0.0119],\n",
      "         ...,\n",
      "         [-0.2304,  0.7016,  0.0434,  ..., -0.4528,  0.0184, -0.0875],\n",
      "         [-0.0404,  0.3467, -0.1793,  ...,  0.0478, -0.0707, -0.0808],\n",
      "         [-0.0192,  0.1824,  0.1011,  ..., -0.0350, -0.0506, -0.2133]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0579,  0.0797, -0.0048,  ..., -0.2217, -0.0402,  0.0937],\n",
      "         [ 0.0804,  0.1234,  0.0093,  ..., -0.3017, -0.2436,  0.3024],\n",
      "         [ 0.1410,  0.1601,  0.0565,  ..., -0.5683, -0.0122,  0.0885],\n",
      "         ...,\n",
      "         [-0.0280,  0.0640, -0.0247,  ..., -0.1101, -0.0363, -0.0688],\n",
      "         [-0.0326,  0.0790, -0.0107,  ..., -0.0939, -0.0503, -0.0674],\n",
      "         [-0.0275,  0.0650, -0.0315,  ..., -0.1031, -0.0379, -0.0750]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.1106, -0.0103,  0.0366,  ..., -0.3671, -0.0898,  0.0655],\n",
      "         [ 0.1210,  0.0428,  0.1013,  ..., -0.4207, -0.0730,  0.2479],\n",
      "         [-0.0758,  0.0504, -0.1213,  ..., -0.5045, -0.2694,  0.1369],\n",
      "         ...,\n",
      "         [ 0.0189,  0.1749,  0.0750,  ..., -0.1533, -0.0350, -0.2362],\n",
      "         [-0.0665,  0.2056, -0.0351,  ..., -0.0933, -0.0637, -0.1430],\n",
      "         [-0.0550,  0.1716,  0.0951,  ..., -0.0538,  0.0068, -0.2469]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.1997,  0.0716, -0.0086,  ..., -0.3736, -0.0572,  0.0385],\n",
      "         [ 0.1203,  0.1857, -0.0060,  ..., -0.2135, -0.0619,  0.2398],\n",
      "         [ 0.1671, -0.0563, -0.0104,  ..., -0.4305,  0.0115,  0.2245],\n",
      "         ...,\n",
      "         [-0.0107,  0.0639, -0.0119,  ..., -0.1114, -0.0375, -0.0636],\n",
      "         [-0.0631,  0.1222, -0.0066,  ..., -0.0720, -0.0340, -0.1824],\n",
      "         [-0.0058,  0.2032, -0.0531,  ..., -0.0905, -0.0206, -0.2055]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[-0.0700,  0.0436,  0.0082,  ..., -0.3051, -0.0559,  0.0539],\n",
      "         [ 0.2410, -0.0468,  0.0752,  ..., -0.2361, -0.3663,  0.2518],\n",
      "         [ 0.0654,  0.0786,  0.0335,  ..., -0.6192, -0.1471, -0.0013],\n",
      "         ...,\n",
      "         [-0.0338,  0.0521,  0.0080,  ..., -0.1055, -0.0455, -0.0716],\n",
      "         [ 0.0204,  0.0287, -0.0211,  ..., -0.0814, -0.0351, -0.1159],\n",
      "         [-0.0050,  0.0707, -0.0179,  ..., -0.0919, -0.0428, -0.0997]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0115,  0.0659,  0.0325,  ..., -0.2188, -0.0811,  0.0254],\n",
      "         [ 0.0904,  0.2203,  0.1969,  ..., -0.1390, -0.0164,  0.2296],\n",
      "         [ 0.0239,  0.0543,  0.0472,  ..., -0.3136, -0.0254,  0.0826],\n",
      "         ...,\n",
      "         [-0.0159,  0.0688, -0.0155,  ..., -0.1012, -0.0427, -0.0744],\n",
      "         [-0.0263,  0.0663, -0.0222,  ..., -0.1093, -0.0407, -0.0618],\n",
      "         [-0.0202,  0.0703, -0.0155,  ..., -0.1052, -0.0435,  0.0162]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0503,  0.0911,  0.0153,  ..., -0.2306, -0.0744,  0.0393],\n",
      "         [ 0.0635,  0.2466, -0.0404,  ...,  0.0911, -0.1341, -0.1173],\n",
      "         [ 0.2291,  0.1893, -0.1566,  ..., -0.4079, -0.2872, -0.0663],\n",
      "         ...,\n",
      "         [ 0.1413,  0.3093,  0.1311,  ...,  0.1171, -0.0240, -0.3974],\n",
      "         [-0.0183,  0.0393,  0.0008,  ..., -0.1117, -0.0356,  0.0287],\n",
      "         [-0.0261,  0.0653, -0.0262,  ..., -0.1093, -0.0475, -0.0704]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0493,  0.0276,  0.0255,  ..., -0.2473, -0.0429,  0.0302],\n",
      "         [ 0.1796,  0.3009,  0.0183,  ..., -0.1676, -0.1409,  0.1646],\n",
      "         [ 0.0875,  0.2003,  0.0391,  ..., -0.7308,  0.0744,  0.2164],\n",
      "         ...,\n",
      "         [ 0.0203,  0.5973, -0.1007,  ..., -0.2471, -0.1127, -0.2953],\n",
      "         [-0.0256,  0.0874, -0.0316,  ..., -0.0965, -0.0501, -0.0764],\n",
      "         [-0.0097,  0.0637, -0.0129,  ..., -0.0993, -0.0261, -0.0533]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0503,  0.2915, -0.0677,  ..., -0.6985, -0.0307,  0.2883],\n",
      "         [ 0.3080, -0.2312, -0.0163,  ..., -0.4106, -0.0718,  0.1162],\n",
      "         [-0.0037, -0.0319,  0.0282,  ..., -0.3745, -0.0246,  0.0828],\n",
      "         ...,\n",
      "         [ 0.0296,  0.0347,  0.0010,  ..., -0.0899, -0.0347, -0.0708],\n",
      "         [-0.0297,  0.0857, -0.0226,  ..., -0.0928, -0.0439, -0.0625],\n",
      "         [-0.0184,  0.0654, -0.0175,  ..., -0.0890, -0.0461, -0.0662]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0660,  0.0872, -0.0329,  ..., -0.1905, -0.0775,  0.0395],\n",
      "         [ 0.1523, -0.0319,  0.2951,  ...,  0.1058, -0.1116,  0.3111],\n",
      "         [-0.0961,  1.1835,  0.1141,  ..., -1.0619,  0.1332,  0.5053],\n",
      "         ...,\n",
      "         [-0.0198,  0.0421, -0.0199,  ..., -0.1040, -0.0384, -0.0579],\n",
      "         [-0.0109,  0.0775,  0.0026,  ..., -0.1299, -0.0275, -0.1203],\n",
      "         [-0.0384,  0.2065, -0.3006,  ...,  0.0096, -0.0045, -0.4715]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0767, -0.0131,  0.0385,  ..., -0.2581, -0.0481,  0.0804],\n",
      "         [ 0.0348, -0.2660,  0.0195,  ..., -0.2727, -0.2246,  0.1746],\n",
      "         [ 0.0481,  0.0451, -0.0014,  ..., -0.3934, -0.0012,  0.0711],\n",
      "         ...,\n",
      "         [ 0.3381,  0.1468, -0.2669,  ..., -0.1753,  0.3484, -0.3646],\n",
      "         [-0.0148,  0.0743, -0.0089,  ..., -0.0986, -0.0290, -0.0718],\n",
      "         [-0.0231,  0.0614, -0.0091,  ..., -0.1024, -0.0408, -0.0509]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0460,  0.0263,  0.0061,  ..., -0.2401, -0.0578,  0.0124],\n",
      "         [ 0.0436, -0.0384,  0.0253,  ..., -0.1224, -0.0349,  0.2314],\n",
      "         [ 0.0261, -0.1098, -0.0142,  ..., -0.1679, -0.0593,  0.0065],\n",
      "         ...,\n",
      "         [ 0.0244,  0.4087, -0.1454,  ..., -0.0356, -0.0438,  0.0419],\n",
      "         [-0.0280,  0.0696, -0.0162,  ..., -0.0975, -0.0421, -0.0661],\n",
      "         [-0.0093,  0.0639, -0.0148,  ..., -0.0939, -0.0355, -0.0621]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0044,  0.1169,  0.0170,  ..., -0.3985, -0.0005,  0.0548],\n",
      "         [ 0.1724,  0.1950,  0.0616,  ..., -0.2019, -0.0282,  0.3706],\n",
      "         [ 0.0560,  0.2277, -0.0187,  ..., -0.4289, -0.0386,  0.1089],\n",
      "         ...,\n",
      "         [ 0.0575,  0.2924, -0.0175,  ..., -0.1548,  0.0092, -0.0423],\n",
      "         [ 0.1155,  0.3535, -0.1809,  ..., -0.5071,  0.1112, -0.2077],\n",
      "         [-0.0094,  0.0593, -0.0155,  ..., -0.0947, -0.0314,  0.0097]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0726,  0.0640, -0.0117,  ..., -0.2106, -0.0494,  0.1057],\n",
      "         [ 0.2421,  0.2590,  0.0826,  ..., -0.4265, -0.0518,  0.3259],\n",
      "         [ 0.0857,  0.0300,  0.0105,  ..., -0.4446, -0.0461,  0.1669],\n",
      "         ...,\n",
      "         [-0.1097,  0.2487, -0.1712,  ..., -0.2676, -0.0820, -0.0329],\n",
      "         [ 0.0153,  0.0648, -0.0239,  ..., -0.1014, -0.0475, -0.0636],\n",
      "         [-0.0388,  0.0420, -0.0178,  ..., -0.1119, -0.0557, -0.0623]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "answer:  st johns\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0600,  0.0740,  0.0020,  ..., -0.2236, -0.0668,  0.0573],\n",
      "         [ 0.2068, -0.1785,  0.1730,  ..., -0.3444, -0.0188,  0.3537],\n",
      "         [ 0.0354,  0.1851,  0.0914,  ..., -0.2866, -0.0796,  0.1032],\n",
      "         ...,\n",
      "         [-0.0182,  0.0638, -0.0130,  ..., -0.0905, -0.0355, -0.0496],\n",
      "         [ 0.3992,  0.0156, -0.1489,  ...,  0.2081,  0.1672, -0.4459],\n",
      "         [-0.0154,  0.0655, -0.0128,  ..., -0.0974, -0.0390, -0.0729]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.4387e-02,  6.6538e-02,  5.8220e-02,  ..., -2.2938e-01,\n",
      "           2.6101e-02,  1.5149e-01],\n",
      "         [ 1.4764e-01, -4.9241e-04,  2.2570e-02,  ..., -1.7059e-01,\n",
      "          -4.2883e-02,  3.5155e-01],\n",
      "         [-7.9259e-03,  5.8492e-02,  1.6064e-04,  ..., -4.2660e-01,\n",
      "           6.9688e-02,  8.3033e-02],\n",
      "         ...,\n",
      "         [-2.2461e-02,  7.0070e-02, -1.0195e-02,  ..., -1.0774e-01,\n",
      "          -3.8634e-02, -6.4924e-02],\n",
      "         [-1.9444e-02,  6.8790e-02, -1.9769e-02,  ..., -1.1689e-01,\n",
      "          -3.6367e-02, -7.7544e-02],\n",
      "         [ 1.0853e-01,  1.0824e-01, -2.5908e-01,  ..., -1.4011e-01,\n",
      "           1.5135e-01, -2.4761e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0848,  0.0221,  0.0094,  ..., -0.2904, -0.0674,  0.0526],\n",
      "         [ 0.0966,  0.2065,  0.0181,  ..., -0.2009, -0.1151,  0.1613],\n",
      "         [ 0.0501,  0.1551, -0.0387,  ..., -0.3753, -0.1002, -0.0207],\n",
      "         ...,\n",
      "         [-0.0277,  0.0691, -0.0192,  ..., -0.0944, -0.0395, -0.0762],\n",
      "         [-0.0124,  0.0972, -0.0165,  ..., -0.0969, -0.0369, -0.0623],\n",
      "         [-0.0386,  0.0606, -0.0109,  ..., -0.0995, -0.0432, -0.0758]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "answer:  louis caldera\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-7.7196e-02, -2.0663e-02, -1.8783e-02,  ..., -2.1419e-01,\n",
      "           1.0520e-03,  4.5517e-02],\n",
      "         [ 2.2059e-01, -1.0360e-01, -8.8972e-02,  ..., -4.0495e-02,\n",
      "           6.0541e-02,  1.2411e-01],\n",
      "         [-1.2358e-01,  1.7154e-04,  4.5007e-03,  ..., -2.7800e-01,\n",
      "           2.7747e-02,  9.3909e-02],\n",
      "         ...,\n",
      "         [ 1.8282e-01,  1.2510e-01,  3.5421e-02,  ..., -1.8629e-01,\n",
      "           1.1664e-01, -2.5891e-01],\n",
      "         [-8.0918e-02,  1.2548e-01, -1.3763e-04,  ..., -1.0703e-01,\n",
      "          -7.5597e-02, -1.9175e-01],\n",
      "         [ 1.6972e-01,  3.2269e-01, -1.7652e-01,  ..., -8.1074e-02,\n",
      "          -1.2889e-01, -4.5611e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0434,  0.0574,  0.0285,  ..., -0.1929, -0.0637,  0.0843],\n",
      "         [ 0.4472,  0.1428,  0.5090,  ...,  0.0849, -0.1502,  0.3349],\n",
      "         [-0.0391, -0.0054,  0.0309,  ..., -0.2656,  0.0079,  0.0163],\n",
      "         ...,\n",
      "         [ 0.0087,  0.0799,  0.0056,  ..., -0.0898, -0.0464, -0.0628],\n",
      "         [-0.0305,  0.0727, -0.0081,  ..., -0.1001, -0.0444, -0.0681],\n",
      "         [ 0.0830,  0.1513, -0.2543,  ...,  0.0859,  0.1499, -0.3894]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[-0.0403,  0.0636,  0.0268,  ..., -0.3033, -0.0554,  0.1116],\n",
      "         [ 0.0708,  0.0951,  0.0430,  ..., -0.0742, -0.0969,  0.3553],\n",
      "         [ 0.2119,  0.3163,  0.3682,  ..., -1.2791, -0.3242,  0.3762],\n",
      "         ...,\n",
      "         [-0.0147,  0.0691, -0.0173,  ..., -0.0952, -0.0330, -0.0804],\n",
      "         [-0.0108,  0.0697, -0.0173,  ..., -0.1155, -0.0522, -0.0836],\n",
      "         [-0.0137,  0.0551, -0.0135,  ..., -0.1068, -0.0267, -0.0505]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0697,  0.0784,  0.0167,  ..., -0.2485, -0.0556,  0.0399],\n",
      "         [ 0.0666, -0.2182,  0.0646,  ..., -0.6221, -0.1236,  0.2031],\n",
      "         [-0.0252, -0.0130,  0.0156,  ..., -0.3133, -0.0667,  0.1274],\n",
      "         ...,\n",
      "         [-0.0757,  0.1126, -0.0201,  ..., -0.0682, -0.0343, -0.1626],\n",
      "         [-0.0217,  0.0637, -0.0053,  ..., -0.1037, -0.0351, -0.0677],\n",
      "         [ 0.1164,  0.0008, -0.1580,  ...,  0.1031,  0.2159, -0.2642]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0307,  0.0804,  0.0151,  ..., -0.1978, -0.0459,  0.1079],\n",
      "         [ 0.0376,  0.0921, -0.0749,  ..., -0.2295, -0.0498,  0.2139],\n",
      "         [ 0.0773,  0.1248, -0.0338,  ..., -0.5214,  0.0598,  0.2253],\n",
      "         ...,\n",
      "         [-0.0367,  0.0683, -0.0159,  ..., -0.1198, -0.0467, -0.0672],\n",
      "         [-0.0237,  0.0729, -0.0196,  ..., -0.1105, -0.0174, -0.0793],\n",
      "         [-0.0764,  0.2763, -0.1947,  ..., -0.3683,  0.0330, -0.0183]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "answer:  1976 to 2009\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[-0.0582,  0.0271,  0.0185,  ..., -0.2656, -0.0942,  0.0725],\n",
      "         [-0.0144,  0.0053,  0.2636,  ..., -0.2397, -0.3713,  0.5817],\n",
      "         [ 0.0134,  0.0493,  0.0111,  ..., -0.4384, -0.0499,  0.0480],\n",
      "         ...,\n",
      "         [-0.0245,  0.1005, -0.0188,  ..., -0.1127, -0.0145, -0.0599],\n",
      "         [-0.0174,  0.0408, -0.0162,  ..., -0.0975, -0.0414, -0.0669],\n",
      "         [-0.0283,  0.0714, -0.0126,  ..., -0.1082, -0.0178, -0.0705]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0118,  0.0734,  0.0204,  ..., -0.2059, -0.0240,  0.0572],\n",
      "         [ 0.1370,  0.2720, -0.1168,  ..., -0.2919,  0.0112,  0.0489],\n",
      "         [ 0.0397,  0.0566,  0.0789,  ..., -0.4607,  0.0238,  0.0421],\n",
      "         ...,\n",
      "         [-0.0386,  0.1811,  0.0719,  ..., -0.0498, -0.0997,  0.0417],\n",
      "         [-0.0260,  0.0817, -0.0184,  ..., -0.1089, -0.0177, -0.0698],\n",
      "         [-0.0072,  0.0745, -0.0217,  ..., -0.1060, -0.0440, -0.0716]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-7.4364e-02,  3.1980e-02,  1.6099e-02,  ..., -4.1474e-01,\n",
      "           1.0616e-03,  1.2535e-01],\n",
      "         [-1.1334e-01, -1.9848e-01,  1.1151e-01,  ..., -5.4755e-01,\n",
      "          -4.7117e-02,  3.2128e-01],\n",
      "         [-4.8774e-02, -7.4337e-02, -2.2756e-02,  ..., -1.9878e+00,\n",
      "          -1.7864e-02,  1.7661e-01],\n",
      "         ...,\n",
      "         [-2.4135e-02,  9.3107e-02, -1.6145e-02,  ..., -9.9465e-02,\n",
      "          -3.2152e-02, -6.0394e-02],\n",
      "         [-2.2410e-02,  6.5348e-02, -1.5754e-02,  ..., -1.0117e-01,\n",
      "          -3.6496e-02, -6.9330e-02],\n",
      "         [-2.2371e-02,  7.4996e-02, -9.3183e-03,  ..., -9.8566e-02,\n",
      "          -3.5910e-02, -4.9250e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0777,  0.0149,  0.0465,  ..., -0.3608, -0.0565,  0.0882],\n",
      "         [ 0.2608,  0.0118,  0.2335,  ..., -0.2585, -0.1422,  0.4697],\n",
      "         [-0.0758, -0.0316,  0.0992,  ..., -0.5849,  0.1187,  0.1904],\n",
      "         ...,\n",
      "         [ 0.0711,  0.1416, -0.3622,  ..., -0.0466,  0.1169, -0.1868],\n",
      "         [-0.0133,  0.0731, -0.0128,  ..., -0.0934, -0.0139,  0.0153],\n",
      "         [-0.0260,  0.0751, -0.0129,  ..., -0.0935, -0.0452, -0.0474]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0496,  0.0923,  0.0101,  ..., -0.2080, -0.0553,  0.1021],\n",
      "         [ 0.2767, -0.0830,  0.0946,  ...,  0.1846, -0.0031,  0.3140],\n",
      "         [-0.1211,  0.0308,  0.0134,  ..., -0.2502,  0.0473,  0.2125],\n",
      "         ...,\n",
      "         [ 0.0110,  0.0841, -0.0143,  ..., -0.0870, -0.0486, -0.0722],\n",
      "         [-0.0176,  0.0728, -0.0189,  ..., -0.1176, -0.0329, -0.0439],\n",
      "         [-0.0256,  0.0684, -0.0027,  ..., -0.0901, -0.0498, -0.0569]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0642,  0.0170,  0.0398,  ..., -0.2264, -0.0452,  0.0721],\n",
      "         [ 0.2042, -0.2670,  0.1177,  ..., -0.4179,  0.0352,  0.3548],\n",
      "         [ 0.0771,  0.0904, -0.1372,  ..., -0.5167, -0.0526,  0.1491],\n",
      "         ...,\n",
      "         [-0.0211,  0.0668, -0.0088,  ..., -0.1037, -0.0387, -0.0515],\n",
      "         [-0.0525,  0.0976, -0.0131,  ..., -0.0778, -0.0246,  0.0228],\n",
      "         [ 0.3750,  0.2933, -0.0406,  ..., -0.0948,  0.1719, -0.4723]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0787,  0.0435,  0.0199,  ..., -0.2139, -0.0430,  0.0460],\n",
      "         [-0.0185,  0.0808,  0.2963,  ...,  0.4695, -0.2224,  0.3316],\n",
      "         [-0.0420,  0.1549,  0.0810,  ..., -0.1282, -0.0178,  0.2386],\n",
      "         ...,\n",
      "         [-0.0266,  0.0711, -0.0083,  ..., -0.0936, -0.0331, -0.0695],\n",
      "         [ 0.0137,  0.0708, -0.0126,  ..., -0.0966, -0.0439, -0.0719],\n",
      "         [-0.0271,  0.0652, -0.0140,  ..., -0.1059, -0.0398, -0.0705]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0059,  0.0621,  0.0588,  ..., -0.1747, -0.0366,  0.0938],\n",
      "         [-0.0748,  0.1649,  0.0956,  ..., -0.0113,  0.0489,  0.1631],\n",
      "         [-0.0677, -0.1953,  0.2109,  ..., -0.3852,  0.0350,  0.1714],\n",
      "         ...,\n",
      "         [-0.0242,  0.0520, -0.0102,  ..., -0.0990, -0.0385, -0.0657],\n",
      "         [ 0.0043,  0.0464, -0.0440,  ..., -0.0763, -0.0587, -0.1113],\n",
      "         [ 0.0034,  0.0725, -0.0110,  ..., -0.1077, -0.0372, -0.0609]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[-0.0749,  0.0662,  0.0140,  ..., -0.3153, -0.0651,  0.0263],\n",
      "         [-0.0272,  0.1229,  0.0744,  ..., -0.2066,  0.2324,  0.3616],\n",
      "         [-0.0054,  0.0617, -0.0324,  ..., -0.2302,  0.0424, -0.0587],\n",
      "         ...,\n",
      "         [ 0.0256,  0.1796,  0.0248,  ..., -0.0979, -0.0725, -0.2026],\n",
      "         [ 0.0876,  0.1111, -0.2825,  ...,  0.0556, -0.0366, -0.3594],\n",
      "         [-0.0259,  0.0722, -0.0094,  ..., -0.1009, -0.0161, -0.0660]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0471, -0.0295,  0.0398,  ..., -0.2729, -0.0392,  0.0147],\n",
      "         [ 0.4519, -0.1052,  0.1470,  ..., -0.5095,  0.1713,  0.5402],\n",
      "         [ 0.1422,  0.0928,  0.0417,  ..., -0.4804, -0.0242,  0.2049],\n",
      "         ...,\n",
      "         [ 0.5320,  0.5471, -0.4120,  ..., -0.2940,  0.1906, -0.2677],\n",
      "         [ 0.0097,  0.0760, -0.0215,  ..., -0.0978, -0.0180, -0.0748],\n",
      "         [-0.0793,  0.1178, -0.0424,  ..., -0.0573, -0.0656,  0.0233]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.1641e-01,  6.6489e-02, -5.1705e-03,  ..., -3.1755e-01,\n",
      "          -4.0173e-02,  7.7437e-02],\n",
      "         [ 7.3356e-03, -6.8304e-02,  1.4749e-01,  ..., -3.1250e-01,\n",
      "          -6.0953e-02,  3.7543e-01],\n",
      "         [ 3.8478e-02,  6.4216e-02,  2.4533e-04,  ..., -2.4724e-01,\n",
      "          -9.1936e-02,  1.5430e-01],\n",
      "         ...,\n",
      "         [-2.1670e-02,  7.3046e-02, -1.0595e-02,  ..., -1.0089e-01,\n",
      "          -4.2012e-02, -7.5072e-02],\n",
      "         [-2.7920e-02,  6.5809e-02, -2.5167e-02,  ..., -1.1013e-01,\n",
      "          -3.6339e-02,  1.9849e-02],\n",
      "         [-2.6344e-02,  7.5805e-02, -2.2437e-02,  ..., -9.9748e-02,\n",
      "          -4.5782e-02, -6.2810e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "answer:  1905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-5.4728e-02,  1.3913e-03,  2.3613e-02,  ..., -5.8015e-01,\n",
      "           1.8563e-02,  1.4894e-01],\n",
      "         [ 1.4574e-01, -8.0592e-02,  2.5095e-01,  ..., -1.4375e-01,\n",
      "           2.8028e-02,  1.0362e-01],\n",
      "         [ 1.0094e-01, -3.0564e-02,  9.6016e-02,  ..., -6.5910e-01,\n",
      "          -3.7110e-02, -3.0453e-02],\n",
      "         ...,\n",
      "         [ 4.9037e-04,  7.0593e-02,  2.3534e-03,  ..., -9.6795e-02,\n",
      "          -4.3533e-02, -6.2386e-02],\n",
      "         [-1.3919e-02,  7.7417e-02,  2.4859e-03,  ..., -1.0999e-01,\n",
      "          -3.5045e-02, -6.1303e-02],\n",
      "         [-2.1549e-02,  5.1460e-02, -1.2580e-02,  ..., -1.1370e-01,\n",
      "          -2.9996e-02, -7.5967e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0448,  0.0377,  0.0187,  ..., -0.2087, -0.0606,  0.0652],\n",
      "         [ 0.1812,  0.0690, -0.0532,  ...,  0.1367,  0.2187,  0.6293],\n",
      "         [ 0.1096,  0.2633, -0.0286,  ..., -0.5570, -0.0251,  0.3372],\n",
      "         ...,\n",
      "         [ 0.1836,  0.1727, -0.1889,  ...,  0.0195,  0.1246, -0.2564],\n",
      "         [-0.0216,  0.0654, -0.0166,  ..., -0.0997, -0.0190, -0.0652],\n",
      "         [ 0.0359,  0.0399, -0.0707,  ..., -0.0944, -0.0037, -0.0987]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0421,  0.0103,  0.0360,  ..., -0.2815, -0.0046,  0.0972],\n",
      "         [ 0.0920, -0.0071,  0.1232,  ..., -0.1087,  0.0740,  0.3037],\n",
      "         [ 0.0398, -0.0817, -0.0071,  ..., -0.3942,  0.0578,  0.1443],\n",
      "         ...,\n",
      "         [-0.0277,  0.0793,  0.0136,  ..., -0.0875, -0.0278, -0.0817],\n",
      "         [-0.0190,  0.0718, -0.0238,  ..., -0.1024, -0.0394, -0.0739],\n",
      "         [-0.0220,  0.0630, -0.0078,  ..., -0.1095, -0.0461, -0.0665]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  magnolia pictures\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.2456,  0.1258,  0.0982,  ..., -0.5122,  0.0782, -0.0122],\n",
      "         [ 0.0143,  0.1718,  0.3318,  ..., -0.4047,  0.0269,  0.1722],\n",
      "         [ 0.0739,  0.2605,  0.0253,  ..., -0.4173,  0.1007, -0.1072],\n",
      "         ...,\n",
      "         [-0.0334,  0.0686, -0.0275,  ..., -0.1083, -0.0406, -0.0680],\n",
      "         [-0.0313,  0.0745, -0.0235,  ..., -0.1013, -0.0377, -0.0666],\n",
      "         [-0.0255,  0.1861,  0.0444,  ..., -0.0823, -0.0694, -0.2125]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0811,  0.0563,  0.0284,  ..., -0.1951,  0.0013,  0.1223],\n",
      "         [ 0.2274, -0.2604,  0.0501,  ..., -0.5349, -0.0728,  0.0892],\n",
      "         [ 0.2204, -0.0487, -0.0142,  ..., -0.2972,  0.0610,  0.0367],\n",
      "         ...,\n",
      "         [-0.0237,  0.0766, -0.0135,  ..., -0.0937, -0.0358, -0.0672],\n",
      "         [-0.0240,  0.0753, -0.0102,  ..., -0.1160, -0.0392, -0.0565],\n",
      "         [-0.0233,  0.0711, -0.0163,  ..., -0.1097, -0.0266, -0.0688]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.1168,  0.1188,  0.0375,  ..., -0.2642, -0.0543,  0.0300],\n",
      "         [ 0.1317,  0.2088,  0.0583,  ..., -0.0431,  0.0067, -0.0214],\n",
      "         [ 0.0862, -0.0325,  0.0249,  ..., -0.0956, -0.0652,  0.0150],\n",
      "         ...,\n",
      "         [ 0.0128,  0.1073,  0.1418,  ...,  0.0952,  0.2021, -0.1662],\n",
      "         [-0.0161,  0.0521, -0.0252,  ..., -0.1066, -0.0324, -0.0696],\n",
      "         [-0.0278,  0.0646, -0.0134,  ..., -0.1020, -0.0270, -0.0771]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0509,  0.0047,  0.0353,  ..., -0.2464, -0.0072,  0.1169],\n",
      "         [ 0.0417, -0.1603,  0.2406,  ..., -0.2844,  0.2103, -0.0157],\n",
      "         [ 0.2253,  0.2541,  0.0757,  ..., -0.7884,  0.3076,  0.1054],\n",
      "         ...,\n",
      "         [-0.0270,  0.0759, -0.0258,  ..., -0.0991, -0.0148, -0.0540],\n",
      "         [-0.0228,  0.0758, -0.0100,  ..., -0.0962, -0.0433, -0.0544],\n",
      "         [ 0.0695,  0.2347, -0.0077,  ...,  0.0103, -0.0088, -0.0899]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0187,  0.0993,  0.0300,  ..., -0.2110, -0.0097,  0.1244],\n",
      "         [ 0.1410,  0.2354,  0.1149,  ...,  0.0040, -0.0332,  0.3636],\n",
      "         [ 0.0468,  0.0508, -0.0405,  ..., -0.2217, -0.0333, -0.0578],\n",
      "         ...,\n",
      "         [ 0.0095,  0.1389,  0.0078,  ..., -0.0289, -0.0255, -0.1256],\n",
      "         [ 0.0026,  0.1503,  0.0839,  ..., -0.0619, -0.0053, -0.2989],\n",
      "         [-0.0266,  0.0666, -0.0041,  ..., -0.0997, -0.0370, -0.0712]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mary i\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0585,  0.0170,  0.0358,  ..., -0.1861, -0.0707,  0.1057],\n",
      "         [ 0.0831,  0.0836, -0.0159,  ...,  0.1127,  0.0431,  0.1650],\n",
      "         [-0.0564,  0.1398,  0.1587,  ..., -0.2925, -0.0344,  0.2340],\n",
      "         ...,\n",
      "         [-0.0764,  0.1224, -0.0098,  ..., -0.0585, -0.0397, -0.1748],\n",
      "         [-0.0119,  0.0709, -0.0138,  ..., -0.0892, -0.0376, -0.0688],\n",
      "         [-0.0373,  0.0707, -0.0340,  ..., -0.1158, -0.0525, -0.0811]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[-0.0273,  0.0735,  0.0317,  ..., -0.2897, -0.0030,  0.1054],\n",
      "         [ 0.2692,  0.0305,  0.1089,  ..., -0.0318,  0.1142,  0.2302],\n",
      "         [ 0.0448,  0.0861,  0.0053,  ..., -0.5672,  0.0825,  0.0918],\n",
      "         ...,\n",
      "         [-0.0256,  0.0723, -0.0080,  ..., -0.1136, -0.0341, -0.0794],\n",
      "         [-0.0188,  0.0668, -0.0166,  ..., -0.1117, -0.0319,  0.0160],\n",
      "         [-0.0224,  0.0538, -0.0173,  ..., -0.0975, -0.0473, -0.0620]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0215,  0.0771,  0.0174,  ..., -0.3119,  0.0084,  0.0972],\n",
      "         [ 0.2686, -0.0534, -0.0396,  ..., -0.3210,  0.0727,  0.2225],\n",
      "         [ 0.1071,  0.1060,  0.0646,  ..., -0.4940,  0.0397,  0.1265],\n",
      "         ...,\n",
      "         [ 0.1876,  0.3117,  0.0371,  ..., -0.3257,  0.0960, -0.3181],\n",
      "         [-0.0224,  0.0629, -0.0157,  ..., -0.0981, -0.0402, -0.0775],\n",
      "         [-0.0218,  0.0729, -0.0215,  ..., -0.0943, -0.0398, -0.0774]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0328, -0.0005,  0.0263,  ..., -0.1943, -0.0340,  0.1016],\n",
      "         [ 0.1863, -0.0454,  0.1096,  ...,  0.1210,  0.0735,  0.2636],\n",
      "         [ 0.1185, -0.0578, -0.0616,  ..., -0.2118, -0.0007,  0.2589],\n",
      "         ...,\n",
      "         [ 0.0238,  0.1159, -0.0207,  ..., -0.0548, -0.0799, -0.1437],\n",
      "         [-0.0158,  0.0614, -0.0147,  ..., -0.0998, -0.0262, -0.0489],\n",
      "         [ 0.0618,  0.0784, -0.0661,  ...,  0.0341,  0.1786, -0.2109]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0437,  0.0157,  0.0442,  ..., -0.2912,  0.0030,  0.0767],\n",
      "         [ 0.0714,  0.1603,  0.1897,  ..., -0.2073, -0.0393,  0.4687],\n",
      "         [ 0.0664,  0.1219,  0.0191,  ..., -0.7565, -0.0118, -0.0341],\n",
      "         ...,\n",
      "         [-0.0150,  0.0708, -0.0112,  ..., -0.1203, -0.0305, -0.0578],\n",
      "         [-0.0277,  0.0680,  0.0044,  ..., -0.0913, -0.0415, -0.0710],\n",
      "         [-0.0126,  0.1642,  0.0418,  ..., -0.0403, -0.0610, -0.2637]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  munster rugby\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0358,  0.0216,  0.1031,  ..., -0.2369, -0.0274,  0.0195],\n",
      "         [ 0.2914, -0.1670,  0.2112,  ..., -0.4656,  0.0837,  0.0311],\n",
      "         [ 0.1135, -0.1142,  0.0322,  ..., -0.6225, -0.0155, -0.1433],\n",
      "         ...,\n",
      "         [-0.0292,  0.0687, -0.0230,  ..., -0.0969, -0.0389, -0.0874],\n",
      "         [-0.1020,  0.4887,  0.1118,  ..., -0.3363, -0.0601,  0.0561],\n",
      "         [-0.0042,  0.0718, -0.0121,  ..., -0.1133, -0.0473, -0.0906]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1454,  0.2513,  0.1689,  ..., -0.2518,  0.3189,  0.0567],\n",
      "         [ 0.6738, -0.2144, -0.1431,  ...,  0.2018,  0.1330,  0.5412],\n",
      "         [ 0.0210, -0.4726, -0.0745,  ..., -0.7897,  0.1139, -0.1728],\n",
      "         ...,\n",
      "         [ 0.1101,  0.4669,  0.0155,  ..., -0.3974,  0.3826, -0.2411],\n",
      "         [-0.0099,  0.0615, -0.0136,  ..., -0.1021, -0.0367, -0.0779],\n",
      "         [ 0.2592,  0.3801,  0.2122,  ..., -0.1548,  0.4593, -0.3227]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-8.0741e-02,  1.0288e-01,  6.6980e-02,  ..., -2.0820e-01,\n",
      "           2.6806e-02,  8.9507e-02],\n",
      "         [ 4.7146e-02,  1.0987e-01,  7.2589e-02,  ...,  1.8861e-01,\n",
      "           7.8587e-02,  7.7554e-02],\n",
      "         [ 2.3541e-02,  5.7425e-02, -2.7033e-05,  ..., -2.5156e-01,\n",
      "          -8.7329e-02, -1.2619e-01],\n",
      "         ...,\n",
      "         [-2.4941e-02,  4.3681e-02, -2.9684e-03,  ..., -1.0312e-01,\n",
      "          -3.1331e-02, -6.8549e-02],\n",
      "         [-1.9537e-02,  5.8712e-02, -1.7231e-02,  ..., -1.1189e-01,\n",
      "          -2.4866e-02, -7.3977e-02],\n",
      "         [-3.4272e-02,  6.5898e-02, -1.6095e-02,  ..., -1.0981e-01,\n",
      "          -4.2578e-02, -7.8240e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mark daniel ronson\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0748,  0.0215,  0.0341,  ..., -0.1738, -0.0714,  0.0518],\n",
      "         [ 0.1810,  0.1360,  0.1066,  ..., -0.2126,  0.0797,  0.2786],\n",
      "         [ 0.0441, -0.0185,  0.0388,  ..., -0.2251,  0.0247,  0.1072],\n",
      "         ...,\n",
      "         [-0.0412,  0.0735,  0.0037,  ..., -0.0864, -0.0440, -0.0709],\n",
      "         [-0.0560,  0.1436, -0.0119,  ..., -0.0816, -0.0598, -0.1782],\n",
      "         [-0.0083,  0.1017, -0.0286,  ..., -0.0891, -0.0498, -0.0785]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0181, -0.0506,  0.1354,  ..., -0.1869,  0.0367, -0.0134],\n",
      "         [ 0.2914, -0.2354,  0.1572,  ...,  0.0696, -0.0302,  0.1675],\n",
      "         [ 0.0996, -0.0957,  0.1230,  ..., -0.2863,  0.0146,  0.0608],\n",
      "         ...,\n",
      "         [-0.1037,  0.2632, -0.1063,  ..., -0.3480,  0.0109, -0.0817],\n",
      "         [-0.0212,  0.0635, -0.0217,  ..., -0.0891, -0.0471, -0.0554],\n",
      "         [-0.0164,  0.0694, -0.0181,  ..., -0.1185, -0.0504,  0.0131]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0058,  0.0351,  0.0272,  ..., -0.2002,  0.0698,  0.0693],\n",
      "         [-0.0421,  0.3043,  0.4077,  ..., -0.0846, -0.0146,  0.3917],\n",
      "         [ 0.0817,  0.1270,  0.0014,  ..., -0.2175,  0.0211,  0.2298],\n",
      "         ...,\n",
      "         [ 0.0487,  0.1984,  0.0563,  ..., -0.1140, -0.0560, -0.2394],\n",
      "         [-0.0152,  0.0703, -0.0127,  ..., -0.1037, -0.0341, -0.0674],\n",
      "         [ 0.1243,  0.0661, -0.1009,  ...,  0.0308,  0.0299, -0.0512]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0860, -0.0108,  0.0459,  ..., -0.3021,  0.0563,  0.1001],\n",
      "         [ 0.0274,  0.4386,  0.1306,  ..., -0.0065,  0.0522,  0.2111],\n",
      "         [ 0.0933,  0.0145, -0.0075,  ..., -0.3475, -0.0771,  0.0580],\n",
      "         ...,\n",
      "         [ 0.1090,  0.1933, -0.2441,  ..., -0.4293,  0.1757, -0.3568],\n",
      "         [-0.0052,  0.0697, -0.0075,  ..., -0.1118, -0.0273, -0.1093],\n",
      "         [ 0.0341,  0.1301, -0.0707,  ..., -0.1150,  0.1308,  0.0267]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1187,  0.0334,  0.0923,  ..., -0.3387, -0.0125,  0.0648],\n",
      "         [ 0.3090, -0.1054,  0.3135,  ..., -0.4188,  0.1274,  0.4418],\n",
      "         [ 0.0686,  0.2235,  0.1169,  ..., -0.4616,  0.0118,  0.2942],\n",
      "         ...,\n",
      "         [-0.1502,  0.2874, -0.0497,  ..., -0.2945, -0.1734, -0.0172],\n",
      "         [-0.0108,  0.0870, -0.0097,  ..., -0.0823, -0.0378, -0.0791],\n",
      "         [ 0.1242, -0.0351,  0.1039,  ..., -0.0305,  0.0890, -0.3254]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0344,  0.1532,  0.0982,  ..., -0.0990,  0.0691,  0.1723],\n",
      "         [ 0.2017,  0.1288,  0.2558,  ...,  0.8677,  0.1961,  0.7537],\n",
      "         [ 0.2164,  0.2031,  0.1343,  ..., -0.0812,  0.0666,  0.2143],\n",
      "         ...,\n",
      "         [-0.0147,  0.0691, -0.0042,  ..., -0.0922, -0.0380, -0.0561],\n",
      "         [-0.0174,  0.0785, -0.0151,  ..., -0.0920, -0.0369, -0.0876],\n",
      "         [-0.0741,  0.2174, -0.0205,  ..., -0.1622,  0.0822,  0.0265]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  szombathelyi haladás\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0456, -0.0140,  0.0729,  ..., -0.2566,  0.0890,  0.2158],\n",
      "         [-0.0042, -0.0358,  0.0755,  ...,  0.0407,  0.2466,  0.3184],\n",
      "         [ 0.0532, -0.1721, -0.1456,  ..., -0.3422,  0.0148,  0.1230],\n",
      "         ...,\n",
      "         [-0.1986,  0.2130,  0.0959,  ...,  0.0592,  0.1021, -0.0737],\n",
      "         [-0.0132,  0.0708, -0.0021,  ..., -0.1036, -0.0379, -0.0601],\n",
      "         [-0.0477,  0.3014, -0.1526,  ...,  0.0124, -0.0507,  0.1879]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.5651e-02,  7.5166e-02,  1.0340e-02,  ..., -2.7054e-01,\n",
      "           7.9199e-02,  5.7550e-02],\n",
      "         [ 5.7907e-02,  3.3867e-01,  3.0217e-01,  ..., -4.7953e-02,\n",
      "           8.5144e-02,  1.6671e-01],\n",
      "         [ 2.0886e-02,  6.2519e-03,  1.3469e-01,  ..., -5.7358e-01,\n",
      "           3.2297e-01,  1.2283e-01],\n",
      "         ...,\n",
      "         [-5.9255e-02,  1.6299e-01, -7.5658e-03,  ..., -6.1320e-02,\n",
      "          -1.8069e-02, -2.3884e-01],\n",
      "         [-6.2744e-02,  5.2662e-02, -9.6168e-03,  ..., -9.8803e-02,\n",
      "           9.5285e-03,  2.8535e-02],\n",
      "         [ 2.2070e-04,  6.4095e-02, -1.0164e-02,  ..., -9.5601e-02,\n",
      "          -4.1991e-02, -6.7949e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0689,  0.1529,  0.0588,  ..., -0.3036,  0.1156,  0.1419],\n",
      "         [ 0.1391, -0.0936,  0.1795,  ..., -0.1761, -0.0419,  0.3750],\n",
      "         [ 0.0310,  0.2040, -0.0511,  ..., -0.2596,  0.1875,  0.1611],\n",
      "         ...,\n",
      "         [-0.0195,  0.0637, -0.0028,  ..., -0.0998, -0.0367, -0.0763],\n",
      "         [-0.0984,  0.3926, -0.0043,  ..., -0.1423,  0.0106,  0.0054],\n",
      "         [ 0.0273,  0.2012,  0.0601,  ..., -0.0089, -0.0600, -0.3345]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1182, -0.0108,  0.0096,  ..., -0.5868,  0.2404,  0.1267],\n",
      "         [ 0.0672, -0.0818, -0.0559,  ..., -0.1021,  0.2091,  0.3245],\n",
      "         [ 0.0210,  0.0034, -0.0097,  ..., -0.7542,  0.0683,  0.0469],\n",
      "         ...,\n",
      "         [-0.0233,  0.0685, -0.0161,  ..., -0.1207, -0.0445, -0.0615],\n",
      "         [-0.0224,  0.0717, -0.0152,  ..., -0.0971, -0.0145, -0.0538],\n",
      "         [-0.0404,  0.1439, -0.1507,  ...,  0.0314,  0.1250, -0.0557]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[-0.0591,  0.0809,  0.0622,  ..., -0.1430,  0.1043,  0.2177],\n",
      "         [-0.0682,  0.0625, -0.0313,  ...,  0.3944,  0.3956,  0.1154],\n",
      "         [ 0.1139, -0.1489,  0.0374,  ..., -0.2482,  0.1116,  0.2962],\n",
      "         ...,\n",
      "         [ 0.0254,  0.1839, -0.1021,  ...,  0.1373,  0.1529, -0.2306],\n",
      "         [-0.0211,  0.0975, -0.0101,  ..., -0.1039, -0.0402,  0.0342],\n",
      "         [-0.0236,  0.0907, -0.0193,  ..., -0.1168, -0.0154, -0.0757]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0325,  0.0447,  0.0025,  ..., -0.3605,  0.1254,  0.0578],\n",
      "         [ 0.2376,  0.2320,  0.2205,  ..., -0.1710,  0.3097,  0.2506],\n",
      "         [-0.0140,  0.1456, -0.0626,  ..., -0.3351, -0.0356,  0.0180],\n",
      "         ...,\n",
      "         [-0.0143,  0.0735, -0.0074,  ..., -0.0993, -0.0319, -0.0667],\n",
      "         [ 0.1135,  0.5197,  0.0506,  ...,  0.3300,  0.4033, -0.6707],\n",
      "         [-0.0101,  0.0588,  0.0032,  ..., -0.1010, -0.0219, -0.0421]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 6.8029e-02,  8.9141e-02, -2.3921e-02,  ..., -1.4583e-01,\n",
      "           3.7283e-02, -2.9343e-02],\n",
      "         [ 3.1569e-01, -1.1586e-01,  7.6120e-02,  ...,  5.4293e-01,\n",
      "           1.8192e-01,  6.2753e-02],\n",
      "         [ 1.0626e-01,  4.6459e-02, -1.0947e-01,  ..., -1.8758e-01,\n",
      "          -3.4720e-02,  7.8936e-03],\n",
      "         ...,\n",
      "         [-1.2675e-02,  5.7136e-02, -8.7162e-03,  ..., -1.0007e-01,\n",
      "          -2.5568e-02, -5.2801e-02],\n",
      "         [-1.3165e-02,  7.2983e-02, -4.5223e-03,  ..., -8.8127e-02,\n",
      "          -3.1020e-02, -6.0991e-02],\n",
      "         [ 2.2487e-04,  6.2941e-02, -1.2080e-02,  ..., -1.0223e-01,\n",
      "          -3.2838e-02, -5.2779e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0779,  0.0603,  0.0614,  ..., -0.2031,  0.1136,  0.0096],\n",
      "         [ 0.0617,  0.3383,  0.2059,  ...,  0.4656,  0.2065,  0.5081],\n",
      "         [ 0.2916,  0.3810, -0.0492,  ..., -0.2026,  0.1579,  0.0649],\n",
      "         ...,\n",
      "         [-0.0935,  0.1179,  0.0035,  ..., -0.0768, -0.0213, -0.1826],\n",
      "         [-0.1969,  0.4845, -0.2009,  ...,  0.1786, -0.2224, -0.3318],\n",
      "         [-0.0229,  0.0744, -0.0138,  ..., -0.0993, -0.0403, -0.0659]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "answer:  1962\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0252,  0.1714,  0.0409,  ..., -0.2878,  0.1234, -0.0549],\n",
      "         [-0.1776,  0.3239,  0.0547,  ...,  0.2888,  0.3380,  0.5658],\n",
      "         [ 0.0348,  0.0323,  0.1303,  ..., -1.0646, -0.0677,  0.1577],\n",
      "         ...,\n",
      "         [-0.0151,  0.0657, -0.0056,  ..., -0.0881, -0.0173, -0.0718],\n",
      "         [-0.0332,  0.0450, -0.0154,  ..., -0.0858, -0.0521, -0.0497],\n",
      "         [-0.0244,  0.0711, -0.0113,  ..., -0.0987, -0.0163,  0.0178]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0306, -0.0006,  0.0899,  ..., -0.1084,  0.1187,  0.1528],\n",
      "         [ 0.2822, -0.1491,  0.2479,  ...,  0.2544,  0.1804,  0.4938],\n",
      "         [-0.0810, -0.0603,  0.2897,  ...,  0.6015,  0.1512,  0.3631],\n",
      "         ...,\n",
      "         [ 0.4873,  0.3079,  0.1193,  ...,  0.0911,  0.3512, -0.0792],\n",
      "         [ 0.0015,  0.0603, -0.0134,  ..., -0.0855, -0.0292, -0.0809],\n",
      "         [-0.0039,  0.0839, -0.0140,  ..., -0.1256, -0.0337, -0.0912]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0815,  0.0135,  0.0885,  ..., -0.2408,  0.1406,  0.1442],\n",
      "         [ 0.1935,  0.0244,  0.2458,  ...,  0.0643,  0.0611,  0.5452],\n",
      "         [ 0.1623,  0.3266, -0.0487,  ..., -0.6942, -0.0025,  0.1369],\n",
      "         ...,\n",
      "         [ 0.0320,  0.3817, -0.0590,  ..., -0.1581, -0.0445, -0.0350],\n",
      "         [-0.0193,  0.0519, -0.0144,  ..., -0.1142, -0.0286, -0.0656],\n",
      "         [-0.0260,  0.0666, -0.0068,  ..., -0.1066, -0.0319, -0.0747]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1306,  0.2392,  0.1031,  ..., -0.0563,  0.1528,  0.1085],\n",
      "         [ 0.3735,  0.2653,  0.0256,  ..., -0.0169,  0.3229, -0.0989],\n",
      "         [-0.0189, -0.0188,  0.0476,  ..., -0.0981,  0.2579, -0.0101],\n",
      "         ...,\n",
      "         [-0.0083,  0.0787, -0.0305,  ..., -0.0971, -0.0414, -0.0035],\n",
      "         [-0.0248,  0.0570, -0.0142,  ..., -0.0953, -0.0377, -0.0783],\n",
      "         [-0.0164,  0.0576, -0.0134,  ..., -0.1008, -0.0393, -0.0680]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1394,  0.1195,  0.0992,  ..., -0.3077,  0.2107,  0.0531],\n",
      "         [ 0.1315,  0.0929,  0.2702,  ..., -0.1794,  0.1408,  0.2202],\n",
      "         [ 0.3658,  0.1445,  0.0653,  ..., -0.9938,  0.1383,  0.1704],\n",
      "         ...,\n",
      "         [-0.0047,  0.0846, -0.0103,  ..., -0.0870, -0.0397, -0.0858],\n",
      "         [-0.0336,  0.0682, -0.0094,  ..., -0.0949, -0.0321, -0.0762],\n",
      "         [-0.0119,  0.0859, -0.0116,  ..., -0.0681, -0.0393, -0.0732]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0245,  0.0309,  0.0790,  ..., -0.0297,  0.2612,  0.1729],\n",
      "         [ 0.0933, -0.0914,  0.0568,  ...,  0.2667,  0.2108,  0.4100],\n",
      "         [-0.0549, -0.0845, -0.0015,  ..., -0.7731,  0.0244,  0.2773],\n",
      "         ...,\n",
      "         [-0.0238,  0.0742, -0.0206,  ..., -0.0992, -0.0466, -0.0792],\n",
      "         [-0.0663,  0.1032, -0.2329,  ...,  0.1686,  0.2156, -0.4630],\n",
      "         [-0.0177,  0.0739, -0.0081,  ..., -0.0884, -0.0350, -0.0734]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1576,  0.1557,  0.0468,  ..., -0.1136,  0.3456,  0.1631],\n",
      "         [ 0.2476, -0.6099, -0.1791,  ...,  0.3516,  0.2184,  0.3273],\n",
      "         [ 0.2369, -0.1948,  0.0713,  ..., -0.6695,  0.0182,  0.0182],\n",
      "         ...,\n",
      "         [-0.0254,  0.1095, -0.0082,  ..., -0.0979, -0.0207, -0.0973],\n",
      "         [ 0.2309,  0.0930,  0.1001,  ...,  0.0427,  0.3513, -0.2429],\n",
      "         [-0.0204,  0.0689, -0.0078,  ..., -0.0872, -0.0145, -0.0717]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0968,  0.1528,  0.0400,  ..., -0.1358,  0.1642, -0.0024],\n",
      "         [-0.0647,  0.1871,  0.0850,  ...,  0.0615, -0.1637,  0.3294],\n",
      "         [ 0.2286,  0.2806,  0.4596,  ..., -0.8185,  0.0582,  0.2303],\n",
      "         ...,\n",
      "         [ 0.1184,  0.0572,  0.1527,  ..., -0.0622, -0.1036, -0.2881],\n",
      "         [-0.0293,  0.0555, -0.0306,  ..., -0.0947, -0.0417, -0.0667],\n",
      "         [-0.0498,  0.0533, -0.0186,  ..., -0.0734,  0.0066, -0.1881]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0091,  0.0709,  0.0315,  ..., -0.0722,  0.0714,  0.1367],\n",
      "         [ 0.1432,  0.2825, -0.0476,  ...,  0.5428,  0.3131,  0.3728],\n",
      "         [ 0.2905,  0.1938,  0.1133,  ..., -0.4481,  0.1796,  0.1301],\n",
      "         ...,\n",
      "         [-0.0164,  0.0755, -0.0132,  ..., -0.1013, -0.0351, -0.0813],\n",
      "         [-0.0274,  0.0734, -0.0103,  ..., -0.0932, -0.0327, -0.0654],\n",
      "         [-0.0210,  0.0707,  0.0089,  ..., -0.0898, -0.0378, -0.0787]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  lorax\n",
      "answer:  24 october 1632\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1960\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1223,  0.0387,  0.0784,  ..., -0.2250,  0.1310,  0.1307],\n",
      "         [ 0.0447,  0.0128, -0.2599,  ...,  1.1360,  0.4129,  0.4261],\n",
      "         [ 0.1170,  0.0107, -0.1647,  ..., -0.6460,  0.3363, -0.2189],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  transcendentalist\n",
      "answer:  ash avildsen and matty beckerman\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1861,  0.0162,  0.0795,  ..., -0.2429,  0.2017,  0.0936],\n",
      "         [ 0.0267, -0.2042,  0.1902,  ...,  0.2075,  0.3003,  0.5581],\n",
      "         [ 0.1175,  0.0013,  0.1160,  ..., -0.3672,  0.2525,  0.3282],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  american\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1781, -0.0318,  0.0659,  ..., -0.1994,  0.2613,  0.1708],\n",
      "         [ 0.3378,  0.1759,  0.2334,  ...,  0.5554,  0.2455,  0.5191],\n",
      "         [ 0.3408,  0.1163,  0.0810,  ..., -0.8387,  0.2831,  0.4377],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0769,  0.0798,  0.1493,  ..., -0.1750,  0.0617,  0.0559],\n",
      "         [ 0.3242, -0.0285,  0.1397,  ...,  0.4356,  0.2192,  0.3658],\n",
      "         [ 0.3379, -0.0361,  0.0262,  ..., -0.5005,  0.1169,  0.1780],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1396,  0.1078,  0.1638,  ..., -0.0146,  0.0334,  0.2326],\n",
      "         [ 0.0114,  0.0865,  0.0640,  ...,  0.8645,  0.4766,  0.5889],\n",
      "         [ 0.3356,  0.3632,  0.2773,  ..., -0.8120,  0.1337,  0.2395],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  farinelli\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0055,  0.0726,  0.1544,  ..., -0.6342,  0.1833,  0.0757],\n",
      "         [ 0.1317, -0.2071, -0.0702,  ...,  0.1745,  0.4399,  0.5103],\n",
      "         [ 0.1080,  0.0209,  0.0285,  ..., -0.8812,  0.1695,  0.0479],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  atom egoyan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1397, -0.0083,  0.0539,  ..., -0.1447,  0.1685,  0.1966],\n",
      "         [ 0.2679,  0.1681,  0.3446,  ...,  0.1599,  0.2290,  0.6481],\n",
      "         [ 0.1009,  0.0185,  0.1149,  ..., -0.0881,  0.1285,  0.0976],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0389, -0.0500,  0.0032,  ..., -0.3860,  0.2308,  0.0803],\n",
      "         [ 0.0559, -0.0026, -0.0525,  ...,  0.5787,  0.0162,  0.7258],\n",
      "         [ 0.0761,  0.0946, -0.1041,  ..., -0.3791,  0.1467, -0.0729],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0669,  0.1199,  0.0973,  ..., -0.0487,  0.1202,  0.2366],\n",
      "         [-0.0091, -0.3661,  0.3190,  ...,  0.4939,  0.3519,  0.5671],\n",
      "         [ 0.3647,  0.2065,  0.0881,  ..., -0.4728,  0.1640,  0.1787],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  lashkaretaiba\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1299, -0.0331,  0.0995,  ..., -0.1864,  0.1051, -0.0053],\n",
      "         [ 0.1830, -0.0671,  0.2892,  ...,  0.1427,  0.3052,  0.6002],\n",
      "         [ 0.1420,  0.0215,  0.0466,  ..., -0.5548,  0.1372,  0.1646],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0610, -0.0296,  0.0045,  ..., -0.1924,  0.1179,  0.0788],\n",
      "         [ 0.0653,  0.0229,  0.0311,  ...,  0.5722,  0.1493,  0.4405],\n",
      "         [ 0.2799, -0.1277, -0.1965,  ..., -0.3167,  0.1252,  0.3351],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  4\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0982, -0.0328,  0.1054,  ..., -0.3011,  0.1453,  0.0821],\n",
      "         [ 0.3076,  0.1939,  0.1840,  ..., -0.0015,  0.1511,  0.5456],\n",
      "         [ 0.1868,  0.0763, -0.0046,  ..., -0.4326,  0.1115,  0.0364],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0370,  0.0941,  0.0419,  ..., -0.1607,  0.1621,  0.1395],\n",
      "         [ 0.1824,  0.3200,  0.0572,  ...,  0.4399,  0.1498,  0.5081],\n",
      "         [ 0.0196,  0.1341,  0.2134,  ..., -0.2241,  0.1150,  0.1503],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  charles manson\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1792,  0.1745,  0.1099,  ...,  0.0517,  0.1900,  0.0249],\n",
      "         [ 0.1450,  0.0454, -0.0676,  ...,  0.8960,  0.5611, -0.0022],\n",
      "         [ 0.3163,  0.0963, -0.1471,  ..., -0.0293,  0.0562,  0.1092],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1619,  0.0088,  0.0581,  ...,  0.0014,  0.1871,  0.0367],\n",
      "         [ 0.5088,  0.1343,  0.2605,  ...,  0.4755,  0.4282,  0.3235],\n",
      "         [ 0.1768,  0.3390,  0.1121,  ..., -0.4461,  0.3215,  0.2797],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.1646,  0.1159,  0.0697,  ..., -0.1900,  0.1015,  0.1582],\n",
      "         [ 0.1885, -0.0215,  0.1758,  ...,  0.3661,  0.1823,  0.4954],\n",
      "         [ 0.0354, -0.1004,  0.0301,  ..., -0.3752,  0.2548,  0.0795],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  camlaren mine\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0756,  0.0449,  0.0455,  ..., -0.0154,  0.1203,  0.1718],\n",
      "         [ 0.2081, -0.0372,  0.2383,  ...,  0.5450,  0.1403,  0.6708],\n",
      "         [ 0.0844,  0.5658, -0.0121,  ..., -0.7494,  0.2725, -0.1131],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0076,  0.0667,  0.1237,  ...,  0.0582,  0.2307,  0.2871],\n",
      "         [-0.1514,  0.0771,  0.0991,  ...,  0.9624,  0.1456,  0.3318],\n",
      "         [ 0.2651,  0.1180, -0.1379,  ...,  0.1776,  0.0930,  0.3359],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0069,  0.0112,  0.0700,  ..., -0.1804,  0.0987,  0.0583],\n",
      "         [-0.1722, -0.5012,  0.0307,  ...,  0.9169,  0.2943,  0.3599],\n",
      "         [ 0.1165, -0.1828, -0.0690,  ..., -0.2458,  0.1935,  0.0735],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  lord voldemort\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0654,  0.1443,  0.0670,  ..., -0.2202,  0.1628,  0.0512],\n",
      "         [ 0.0630,  0.0217,  0.4627,  ...,  0.2382,  0.1984,  0.5738],\n",
      "         [ 0.2219,  0.2666, -0.0119,  ..., -0.3523,  0.1979,  0.0881],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  tokyo japan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1200,  0.0784,  0.0626,  ..., -0.2860,  0.1758,  0.0956],\n",
      "         [ 0.1610,  0.1415,  0.1085,  ...,  0.0651,  0.2074,  0.4319],\n",
      "         [ 0.1531,  0.0604,  0.1612,  ..., -0.3065,  0.0518,  0.1488],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0731,  0.0871, -0.0165,  ..., -0.1064,  0.1924,  0.0514],\n",
      "         [ 0.2320,  0.3099,  0.0241,  ...,  0.3122,  0.2163,  0.4713],\n",
      "         [ 0.0667,  0.2304,  0.1394,  ..., -0.0399,  0.1945,  0.1632],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  st johns\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1827,  0.0812,  0.0347,  ..., -0.0913,  0.1811,  0.2213],\n",
      "         [ 0.1827,  0.0629,  0.2533,  ...,  0.5935,  0.1622,  0.5787],\n",
      "         [ 0.3404,  0.0319, -0.0062,  ..., -0.3868,  0.4086,  0.1963],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0647,  0.0391,  0.0675,  ..., -0.2271,  0.1741,  0.0681],\n",
      "         [ 0.2289,  0.0639,  0.1994,  ..., -0.1333,  0.1913,  0.3269],\n",
      "         [ 0.1091,  0.0687,  0.0674,  ..., -0.2356,  0.0880,  0.1232],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  louis caldera\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0100, -0.0296, -0.0066,  ..., -0.0675,  0.1870,  0.0431],\n",
      "         [ 0.2188, -0.0896, -0.2769,  ...,  0.7722,  0.4784,  0.3563],\n",
      "         [-0.0257, -0.0326, -0.0061,  ..., -0.2347,  0.1743,  0.0250],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0744,  0.1636,  0.0977,  ..., -0.1177,  0.0634,  0.1531],\n",
      "         [ 0.1353,  0.2090,  0.0679,  ...,  1.0635, -0.0285,  0.2138],\n",
      "         [ 0.1218, -0.2180,  0.0333,  ..., -0.1971,  0.1887,  0.0594],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  stockholm stock exchange\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.1439,  0.0218,  0.0182,  ..., -0.1601,  0.0897,  0.0723],\n",
      "         [ 0.3012,  0.0429,  0.2190,  ...,  0.1794,  0.0969,  0.4936],\n",
      "         [ 0.1174,  0.1091,  0.2987,  ..., -0.5293,  0.0025,  0.2966],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0789,  0.0797,  0.1809,  ..., -0.0662,  0.0898,  0.1628],\n",
      "         [ 0.0983, -0.2426,  0.0358,  ...,  0.3007,  0.2801,  0.5216],\n",
      "         [ 0.0166, -0.0757,  0.0178,  ..., -0.1706,  0.1109,  0.1993],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1409,  0.1381, -0.0464,  ..., -0.5331,  0.1485,  0.1518],\n",
      "         [ 0.3145,  0.2022, -0.2031,  ...,  0.5528,  0.0959,  0.5531],\n",
      "         [ 0.2091,  0.1133,  0.0818,  ..., -0.2379,  0.2561,  0.2245],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.0424,  0.1183,  0.0747,  ..., -0.0761,  0.0797,  0.1204],\n",
      "         [-0.0354,  0.0621,  0.2870,  ...,  0.7024,  0.0457,  0.4578],\n",
      "         [ 0.2375,  0.1667, -0.0298,  ..., -0.2181, -0.0079,  0.1304],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1976 to 2009\n",
      "answer:  essex\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0993,  0.0549,  0.0640,  ..., -0.1051,  0.2085,  0.0492],\n",
      "         [ 0.1328,  0.0287,  0.0079,  ...,  0.2911,  0.2918,  0.2095],\n",
      "         [ 0.0746,  0.0461,  0.0071,  ..., -0.2866,  0.2111,  0.0581],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2350, -0.0371, -0.0010,  ..., -0.1080,  0.2220,  0.0688],\n",
      "         [-0.0928, -0.0919, -0.1528,  ...,  0.4495,  0.5191,  0.2889],\n",
      "         [ 0.0294,  0.0770,  0.0642,  ..., -0.6856,  0.2197, -0.0249],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1747,  0.0033,  0.1556,  ..., -0.3151,  0.2001,  0.2772],\n",
      "         [ 0.2404,  0.2551,  0.2977,  ..., -0.2028,  0.0142,  0.1208],\n",
      "         [-0.0921, -0.0806,  0.2643,  ..., -0.5048,  0.2601,  0.1011],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wachovia securities\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0287,  0.1064,  0.0264,  ...,  0.0372,  0.1099,  0.2248],\n",
      "         [ 0.5491, -0.3313,  0.2603,  ...,  1.0237,  0.2083,  0.5710],\n",
      "         [ 0.0413,  0.0328,  0.0115,  ..., -0.1087,  0.3684,  0.2890],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0292, -0.0408,  0.0925,  ..., -0.1619,  0.2170,  0.0869],\n",
      "         [ 0.1549,  0.0106,  0.0835,  ...,  0.2186,  0.1303,  0.3465],\n",
      "         [ 0.0685, -0.0755, -0.0450,  ..., -0.4929,  0.3322,  0.0801],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  hollywood madam\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0151,  0.1032,  0.1193,  ..., -0.1785, -0.1036,  0.2047],\n",
      "         [ 0.4202, -0.2088,  0.2803,  ...,  1.2494, -0.0213,  0.7252],\n",
      "         [ 0.0159,  0.1964,  0.1481,  ..., -0.0032,  0.1892,  0.4565],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.1330,  0.0510,  0.0864,  ..., -0.0082,  0.0996,  0.1258],\n",
      "         [ 0.2993,  0.0452,  0.2689,  ...,  0.7691,  0.0699,  0.7337],\n",
      "         [-0.0504, -0.1281,  0.2550,  ..., -0.4994,  0.0685,  0.1742],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 9.6807e-02,  4.8250e-02,  2.6971e-02,  ..., -2.6039e-01,\n",
      "           7.2705e-02,  5.9993e-02],\n",
      "         [ 7.3081e-03, -9.5510e-02,  3.8012e-04,  ..., -2.5266e-01,\n",
      "           4.7440e-01,  3.3631e-01],\n",
      "         [ 1.5137e-01, -2.7809e-02, -1.6762e-01,  ...,  1.2135e-01,\n",
      "           1.7122e-01, -3.9927e-02],\n",
      "         ...,\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02],\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02],\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  avengers\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1743, -0.1208,  0.0821,  ..., -0.1819,  0.2621,  0.1265],\n",
      "         [ 0.2333, -0.3531,  0.0437,  ...,  0.0219,  0.1232,  0.3847],\n",
      "         [ 0.1641, -0.0012,  0.2319,  ..., -0.4373,  0.1721,  0.0480],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0274,  0.0609, -0.0799,  ..., -0.3162,  0.2417,  0.1610],\n",
      "         [ 0.1397, -0.3877,  0.2526,  ...,  0.0986,  0.0486,  0.4570],\n",
      "         [ 0.1126,  0.0330,  0.0109,  ..., -0.1678,  0.1579,  0.1579],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2415\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1981,  0.0965,  0.1107,  ..., -0.2758,  0.1782,  0.1595],\n",
      "         [ 0.3107, -0.1485,  0.2919,  ...,  0.2065,  0.3139,  0.3356],\n",
      "         [ 0.3143, -0.1982,  0.1549,  ..., -0.6435,  0.3118, -0.0303],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1930, -0.0553,  0.0658,  ..., -0.0639,  0.0646,  0.1724],\n",
      "         [ 0.0558, -0.2791,  0.2239,  ...,  0.5327,  0.4676,  0.4918],\n",
      "         [ 0.2439,  0.4405,  0.0461,  ..., -0.2867,  0.1502,  0.3502],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0671,  0.0179,  0.0714,  ..., -0.1674,  0.1801,  0.0759],\n",
      "         [ 0.1246,  0.0410,  0.1280,  ...,  0.5120,  0.2238,  0.5167],\n",
      "         [ 0.2622, -0.0412,  0.0450,  ..., -0.2760,  0.2545,  0.1434],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  university of mount union\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0464,  0.0702,  0.0266,  ..., -0.1695,  0.2711, -0.0168],\n",
      "         [-0.2041,  0.2709,  0.2301,  ...,  0.3090,  0.2435,  0.4263],\n",
      "         [ 0.1098,  0.2601, -0.0379,  ..., -0.2795,  0.4120, -0.0354],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0959,  0.0826,  0.0702,  ..., -0.1023,  0.1978,  0.1525],\n",
      "         [ 0.2697, -0.1184,  0.2008,  ...,  0.3531,  0.1955,  0.4013],\n",
      "         [ 0.2552, -0.0669,  0.1455,  ..., -0.2931,  0.2671, -0.0212],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1004,  0.1523,  0.0940,  ..., -0.0859,  0.0682,  0.0205],\n",
      "         [ 0.2877,  0.0539,  0.1886,  ...,  1.0060,  0.1268,  0.3437],\n",
      "         [ 0.1407, -0.0055,  0.0604,  ..., -0.0016,  0.2110,  0.1242],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1970\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2277,  0.0129,  0.1038,  ..., -0.1026,  0.2226,  0.1195],\n",
      "         [ 0.1085, -0.3248,  0.2935,  ...,  0.5807,  0.0194,  0.6457],\n",
      "         [ 0.3563, -0.0069, -0.0088,  ..., -0.2095,  0.4066,  0.1164],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1030,  0.2478,  0.1041,  ..., -0.1835,  0.0229,  0.1513],\n",
      "         [-0.1833, -0.0735,  0.0393,  ...,  0.9196,  0.3778,  0.4698],\n",
      "         [ 0.2076, -0.2000, -0.2422,  ..., -0.4705,  0.3623,  0.0158],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  john surtees\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0456, -0.0205,  0.1124,  ..., -0.2254,  0.0043,  0.1232],\n",
      "         [ 0.4844, -0.1616,  0.1997,  ...,  0.7329,  0.0661,  0.6255],\n",
      "         [-0.0355,  0.2134,  0.1615,  ..., -0.1529,  0.1529,  0.2040],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0964,  0.1478,  0.0008,  ..., -0.1311,  0.1601,  0.1698],\n",
      "         [ 0.2283,  0.1711, -0.0912,  ...,  0.1221,  0.1305,  0.4407],\n",
      "         [ 0.0512,  0.1045, -0.0515,  ..., -0.4638,  0.2998,  0.0750],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2323,  0.0777,  0.0445,  ..., -0.2834,  0.2407,  0.0826],\n",
      "         [ 0.3012,  0.4576,  0.1692,  ..., -0.4306,  0.1283,  0.5564],\n",
      "         [ 0.3250,  0.1185,  0.0643,  ..., -0.4626,  0.3408,  0.0940],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0277,  0.0156,  0.0866,  ..., -0.1539, -0.0104,  0.1999],\n",
      "         [ 0.2592, -0.2290,  0.0331,  ...,  0.3524,  0.3131,  0.6145],\n",
      "         [ 0.2465, -0.0704, -0.0168,  ..., -0.2109,  0.1663,  0.1972],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0611,  0.0082,  0.0747,  ..., -0.2790,  0.1157,  0.0852],\n",
      "         [ 0.3381,  0.1846,  0.3484,  ...,  0.2091, -0.0092,  0.5054],\n",
      "         [ 0.0723,  0.0885,  0.0940,  ..., -0.5083,  0.0554,  0.0091],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0844,  0.0334,  0.1266,  ..., -0.2205,  0.1243, -0.0448],\n",
      "         [ 0.2044, -0.1728,  0.2832,  ...,  0.3795,  0.1854,  0.3284],\n",
      "         [ 0.2398, -0.1771,  0.0531,  ..., -0.6390,  0.2230, -0.1669],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  chihuahua\n",
      "answer:  munster rugby\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1190,  0.1244,  0.0608,  ...,  0.1085,  0.2433,  0.0798],\n",
      "         [ 0.2513, -0.1534, -0.1910,  ...,  0.8822,  0.3206,  0.3561],\n",
      "         [ 0.0099, -0.3774, -0.0839,  ..., -0.7563,  0.6349,  0.1200],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  july 16 2012\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0224,  0.2026,  0.0612,  ..., -0.1677,  0.1605,  0.1341],\n",
      "         [-0.0480,  0.2772, -0.0492,  ...,  0.2297,  0.3704,  0.2182],\n",
      "         [ 0.3580,  0.0625, -0.0508,  ..., -0.3476,  0.2088, -0.0123],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.3343e-02,  2.0309e-01, -4.9136e-04,  ...,  5.0670e-02,\n",
      "           3.8593e-02,  5.6632e-02],\n",
      "         [ 5.1553e-02,  3.2699e-02,  2.6760e-01,  ...,  5.9101e-01,\n",
      "           1.9995e-01,  3.9844e-01],\n",
      "         [ 1.5521e-01, -2.4712e-02, -6.5117e-02,  ..., -1.6256e-01,\n",
      "           1.6573e-01, -3.0763e-02],\n",
      "         ...,\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02],\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02],\n",
      "         [-1.9130e-02,  7.4989e-02, -1.1589e-02,  ..., -9.3085e-02,\n",
      "          -3.6578e-02, -8.0036e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ariana grande\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0098, -0.0135,  0.2089,  ..., -0.1763,  0.0608, -0.1216],\n",
      "         [-0.0568,  0.0690,  0.2085,  ...,  0.7876,  0.3741,  0.1299],\n",
      "         [ 0.1110,  0.0336,  0.1676,  ..., -0.1477,  0.0486,  0.0559],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0651,  0.0146,  0.0384,  ..., -0.2126,  0.2175,  0.1122],\n",
      "         [-0.0484,  0.2528,  0.1637,  ..., -0.0197,  0.0524,  0.3820],\n",
      "         [ 0.1295,  0.2162, -0.0291,  ..., -0.2616,  0.2263,  0.2856],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0042,  0.0953,  0.0612,  ..., -0.4015,  0.2999,  0.1969],\n",
      "         [ 0.1061,  0.4105,  0.0880,  ..., -0.0326,  0.2211,  0.2091],\n",
      "         [ 0.1666, -0.0475,  0.0722,  ..., -0.3623,  0.0566, -0.0710],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  goalkeeper\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.2046, -0.0437,  0.0774,  ..., -0.3248,  0.1177,  0.1277],\n",
      "         [ 0.3271, -0.4472, -0.0016,  ...,  0.5241,  0.4249,  0.6725],\n",
      "         [ 0.0868,  0.0955,  0.1364,  ..., -0.5086,  0.0773,  0.2862],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0220,  0.1176,  0.1104,  ...,  0.0365,  0.1451,  0.2101],\n",
      "         [ 0.2802,  0.0211,  0.3125,  ...,  0.8954,  0.3002,  0.4840],\n",
      "         [ 0.3195,  0.3726,  0.1205,  ..., -0.0379,  0.1437,  0.3061],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0650,  0.0017,  0.0222,  ..., -0.2138,  0.0872,  0.2429],\n",
      "         [-0.1877, -0.1334,  0.0565,  ...,  0.5805,  0.4227,  0.4343],\n",
      "         [ 0.0908,  0.0564, -0.0195,  ..., -0.2251,  0.1837,  0.1146],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1191,  0.1272, -0.0473,  ..., -0.1881,  0.2646,  0.0911],\n",
      "         [ 0.0966,  0.2277,  0.1674,  ...,  0.3196,  0.3474,  0.4966],\n",
      "         [ 0.1914,  0.1047, -0.0991,  ..., -0.6027,  0.4106,  0.3255],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')answer:  ring\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  son of ulf jarl\n",
      "answer:  buddleja\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0254,  0.1973,  0.0670,  ..., -0.3077,  0.2389,  0.2158],\n",
      "         [-0.0068, -0.0833,  0.0365,  ...,  0.5319,  0.4032,  0.2401],\n",
      "         [ 0.1580,  0.1521,  0.0585,  ..., -0.3199,  0.3268, -0.0326],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0790,  0.0899,  0.0659,  ..., -0.5367,  0.2757,  0.2486],\n",
      "         [ 0.3431,  0.0914,  0.2383,  ...,  0.2657,  0.1498,  0.6350],\n",
      "         [ 0.1295,  0.1248,  0.0292,  ..., -0.5114,  0.2759,  0.0856],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1685,  0.1343,  0.1509,  ...,  0.0583,  0.2045,  0.2934],\n",
      "         [ 0.1506, -0.0906, -0.2234,  ...,  0.3318,  0.5585,  0.2301],\n",
      "         [ 0.1322, -0.1848, -0.0191,  ..., -0.2357,  0.3554,  0.0475],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.1518,  0.0867,  0.0146,  ..., -0.3602,  0.2441,  0.1222],\n",
      "         [ 0.2164,  0.3344,  0.1650,  ...,  0.0649,  0.2681,  0.3196],\n",
      "         [ 0.0058,  0.1157,  0.0737,  ..., -0.2341, -0.0493,  0.0523],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  fur\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0743,  0.0616, -0.0030,  ..., -0.0762,  0.1300,  0.0265],\n",
      "         [ 0.3702, -0.0449,  0.1887,  ...,  0.4875,  0.1935,  0.2882],\n",
      "         [ 0.1985,  0.1128, -0.0400,  ..., -0.1366,  0.0624,  0.0286],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1534, -0.0030,  0.0893,  ..., -0.0835,  0.1110,  0.1841],\n",
      "         [ 0.1948,  0.0839,  0.2131,  ...,  0.6069,  0.0199,  0.6250],\n",
      "         [ 0.1243,  0.3660,  0.0007,  ..., -0.0342,  0.2094,  0.3909],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-0.0414,  0.1561,  0.0403,  ..., -0.2857,  0.1967,  0.0244],\n",
      "         [-0.0467,  0.0699,  0.0187,  ...,  0.6805,  0.3992,  0.5142],\n",
      "         [ 0.1722,  0.0990, -0.0832,  ..., -1.5169,  0.0542,  0.1596],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1962\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0685,  0.0069,  0.0542,  ..., -0.0232,  0.2741,  0.1880],\n",
      "         [ 0.2891, -0.0905,  0.3116,  ...,  0.9790,  0.0831,  0.4221],\n",
      "         [ 0.1005,  0.3283,  0.2208,  ...,  0.2496,  0.1899,  0.2661],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1894,  0.0915,  0.0966,  ..., -0.1954,  0.1931,  0.1426],\n",
      "         [ 0.0039,  0.4363,  0.0300,  ...,  0.0397,  0.1898,  0.4266],\n",
      "         [ 0.2459,  0.3111,  0.0891,  ..., -0.6368,  0.0146,  0.0888],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1099,  0.1465,  0.1167,  ...,  0.0651,  0.2873,  0.1411],\n",
      "         [ 0.3486,  0.0351, -0.1367,  ...,  1.1056,  0.2728, -0.1639],\n",
      "         [ 0.0580, -0.2771, -0.0119,  ...,  0.1413,  0.3775,  0.1523],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1550,  0.0878,  0.1148,  ..., -0.2992,  0.2326,  0.1716],\n",
      "         [ 0.4757,  0.1080,  0.2616,  ...,  0.3242,  0.3238,  0.5304],\n",
      "         [ 0.3896,  0.0379,  0.1127,  ..., -1.2892,  0.1807,  0.1998],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0271,  0.0022,  0.0349,  ...,  0.0113,  0.2310,  0.1824],\n",
      "         [ 0.2733, -0.2301,  0.0153,  ...,  0.6425,  0.2161,  0.1666],\n",
      "         [-0.0152, -0.0562, -0.0207,  ..., -0.6299,  0.0190,  0.1792],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.0161,  0.0581,  0.0076,  ..., -0.2181,  0.1461, -0.0069],\n",
      "         [ 0.3012, -0.2095, -0.1647,  ...,  0.5594,  0.2979,  0.3157],\n",
      "         [ 0.1876,  0.1064,  0.0232,  ..., -0.4558,  0.1090,  0.1536],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.1047,  0.1378,  0.0720,  ..., -0.1183,  0.1690,  0.1035],\n",
      "         [ 0.0574,  0.3744,  0.1357,  ...,  0.6148,  0.0992,  0.3279],\n",
      "         [ 0.2845,  0.0580,  0.1130,  ..., -0.6507,  0.1270,  0.1286],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1011,  0.0584, -0.0042,  ..., -0.0554,  0.1996,  0.0963],\n",
      "         [ 0.1053,  0.2249,  0.0904,  ...,  0.7017,  0.1805,  0.4147],\n",
      "         [ 0.2511,  0.2710, -0.1127,  ..., -0.6488,  0.3354,  0.0586],\n",
      "         ...,\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800],\n",
      "         [-0.0191,  0.0750, -0.0116,  ..., -0.0931, -0.0366, -0.0800]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned 0.0025316456073447118 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of avg_val_f1 in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch 00000: avg_val_f1 reached 0.00253 (best 0.00253), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_0.ckpt as top 5\n",
      "\n",
      "Epoch 00000: avg_val_f1 reached 0.00253 (best 0.00253), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_0.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_end\n",
      "before sync --> sizes:  79, 79, 79\n",
      "after sync --> sizes: 79, 79, 79\n",
      "avg_loss:  tensor(23.8353, device='cuda:0')\tavg_answer_loss:  tensor(6.2247, device='cuda:0')\tavg_type_loss:  tensor(1.2993, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5808, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.5306, device='cuda:0')\n",
      "avg_val_f1:  0.0025316456073447118\tavg_val_em:  0.0\tavg_val_prec:  0.0021097047042243086\tavg_val_recall:  0.0031645569620253164\n",
      "avg_val_sp_sent_f1:  0.07073538439183295\tavg_val_sp_sent_em:  0.0\tavg_val_sp_sent_prec:  0.0793248948794377\tavg_val_sp_sent_recall:  0.07489451539667347\n",
      "avg_val_joint_f1:  0.0\tavg_val_joint_em:  0.0\tavg_val_joint_prec:  0.0\tavg_val_joint_recall:  0.0\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  doug moench and don perlin\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.0798,  0.0322,  0.0537,  ..., -0.0531,  0.0796,  0.1840],\n",
      "         [ 0.1828,  0.0009,  0.1801,  ...,  0.3336,  0.4799,  0.1633],\n",
      "         [ 0.0437, -0.0134,  0.2785,  ..., -0.2395,  0.0866,  0.2379],\n",
      "         ...,\n",
      "         [ 0.3639,  0.4174, -0.0965,  ..., -0.2048,  0.2178, -0.2909],\n",
      "         [-0.0121,  0.0607, -0.0013,  ..., -0.0896, -0.0277, -0.0656],\n",
      "         [-0.0580,  0.1490, -0.0214,  ..., -0.1003, -0.0385, -0.2166]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "answer:  july 16 2012\n",
      "answer:  atom egoyan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0045,  0.0915, -0.0223,  ..., -0.1549,  0.1750, -0.0527],\n",
      "         [-0.0690, -0.1586,  0.0866,  ..., -0.3443,  0.2207,  0.5781],\n",
      "         [ 0.2158, -0.1452, -0.0370,  ..., -0.3452,  0.1289,  0.0356],\n",
      "         ...,\n",
      "         [-0.0289,  0.0556, -0.0137,  ..., -0.0914, -0.0489, -0.0661],\n",
      "         [ 0.0097,  0.0693, -0.0113,  ..., -0.1036, -0.0221, -0.0626],\n",
      "         [-0.0498,  0.1553, -0.0059,  ..., -0.1084, -0.0500, -0.2253]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0021,  0.1058, -0.0169,  ..., -0.3023,  0.2225,  0.1401],\n",
      "         [ 0.2936,  0.3322, -0.0090,  ...,  0.2556,  0.4669,  0.6455],\n",
      "         [-0.0407,  0.1448,  0.0315,  ..., -0.4303,  0.1633, -0.0438],\n",
      "         ...,\n",
      "         [ 0.3572,  0.2139, -0.1245,  ..., -0.0954,  0.2638, -0.5545],\n",
      "         [-0.0201,  0.0704,  0.0017,  ..., -0.0807, -0.0466, -0.0579],\n",
      "         [-0.0143,  0.0671, -0.0023,  ..., -0.0899, -0.0385, -0.0766]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0514,  0.0710,  0.0726,  ..., -0.2199,  0.2790,  0.1120],\n",
      "         [ 0.0337,  0.1036, -0.0278,  ...,  0.0717,  0.0989,  0.3085],\n",
      "         [ 0.1325,  0.0837,  0.0290,  ..., -0.3527,  0.4114, -0.0213],\n",
      "         ...,\n",
      "         [-0.0440,  0.0972,  0.0199,  ..., -0.0511, -0.0133, -0.1893],\n",
      "         [-0.0265,  0.1586,  0.0241,  ..., -0.1391, -0.0616, -0.2267],\n",
      "         [ 0.0084,  0.1298, -0.0228,  ..., -0.0587, -0.0398, -0.2019]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0859,  0.0826,  0.1112,  ...,  0.0659,  0.0687,  0.2376],\n",
      "         [ 0.5390, -0.1800,  0.0879,  ...,  0.5920,  0.0750,  0.4428],\n",
      "         [ 0.2877,  0.2255,  0.4152,  ..., -0.3701,  0.0327,  0.2911],\n",
      "         ...,\n",
      "         [ 0.0359,  0.3152,  0.0796,  ..., -0.1185, -0.0252,  0.0745],\n",
      "         [-0.0239,  0.0483, -0.0112,  ..., -0.0978, -0.0457, -0.0650],\n",
      "         [-0.0353,  0.0767, -0.0194,  ..., -0.0863, -0.0354, -0.0673]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.2399,  0.0482,  0.1301,  ..., -0.2726,  0.1669,  0.2343],\n",
      "         [ 0.1664, -0.0566,  0.4661,  ...,  0.4236,  0.2078,  0.5887],\n",
      "         [ 0.1031, -0.0070,  0.0110,  ..., -0.3586,  0.1892,  0.3696],\n",
      "         ...,\n",
      "         [-0.0133,  0.0650, -0.0093,  ..., -0.0897, -0.0368, -0.0636],\n",
      "         [-0.0308,  0.0632, -0.0233,  ..., -0.1031, -0.0369, -0.0830],\n",
      "         [-0.0476,  0.1297,  0.0059,  ..., -0.0790, -0.0339, -0.1548]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1831, -0.0222,  0.0264,  ..., -0.2817,  0.3403, -0.0563],\n",
      "         [ 0.2068, -0.2768,  0.1434,  ...,  0.0789,  0.5664,  0.3261],\n",
      "         [ 0.1998,  0.0828,  0.1684,  ..., -0.4978, -0.0297, -0.0050],\n",
      "         ...,\n",
      "         [-0.2093,  0.2945, -0.1425,  ...,  0.0628, -0.0554, -0.0881],\n",
      "         [-0.0475,  0.0806,  0.0146,  ..., -0.0798, -0.0364, -0.0667],\n",
      "         [-0.0255,  0.0683, -0.0093,  ..., -0.1137, -0.0303, -0.0694]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1709,  0.0897,  0.0213,  ..., -0.3525,  0.0930,  0.2145],\n",
      "         [-0.0684,  0.3954, -0.4165,  ...,  0.4661, -0.0157,  0.3187],\n",
      "         [ 0.3183,  0.1169, -0.0064,  ...,  0.2639,  0.2760,  0.2176],\n",
      "         ...,\n",
      "         [ 0.0123,  0.0798,  0.0016,  ..., -0.1168, -0.0049, -0.1181],\n",
      "         [ 0.0116,  0.3425,  0.0767,  ..., -0.0910, -0.0214, -0.4214],\n",
      "         [-0.0179,  0.0574, -0.0245,  ..., -0.0928, -0.0387, -0.0725]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1282, -0.0175,  0.0283,  ..., -0.1740,  0.2757, -0.0967],\n",
      "         [ 0.6424,  0.4991,  0.1418,  ..., -0.0381,  0.5308,  0.1155],\n",
      "         [ 0.1891,  0.2652,  0.2008,  ..., -0.1726,  0.2888,  0.0049],\n",
      "         ...,\n",
      "         [-0.0244,  0.0680, -0.0179,  ..., -0.0951, -0.0364, -0.0717],\n",
      "         [ 0.0216,  0.2759,  0.1270,  ..., -0.2814,  0.0495,  0.0612],\n",
      "         [-0.0093,  0.0928, -0.0074,  ..., -0.1040, -0.0405, -0.0863]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1852,  0.0785, -0.0208,  ..., -0.1188,  0.2572,  0.1128],\n",
      "         [ 0.6080,  0.5488, -0.2958,  ...,  0.5940,  0.3633,  0.3780],\n",
      "         [ 0.3858,  0.1679, -0.0526,  ..., -0.4889,  0.4121,  0.2248],\n",
      "         ...,\n",
      "         [-0.0247,  0.0774, -0.0116,  ..., -0.0998, -0.0363, -0.0712],\n",
      "         [-0.0131,  0.0561, -0.0096,  ..., -0.0953, -0.0270, -0.0608],\n",
      "         [ 0.0164,  0.0491, -0.0269,  ..., -0.1077, -0.0047, -0.1093]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0521,  0.0807,  0.0522,  ..., -0.0966,  0.0513,  0.1946],\n",
      "         [ 0.4615, -0.1907, -0.0962,  ...,  0.7853,  0.0090,  0.4101],\n",
      "         [-0.0583,  0.2677,  0.0875,  ..., -0.0142,  0.0564,  0.1958],\n",
      "         ...,\n",
      "         [-0.0456,  0.1266,  0.0056,  ..., -0.0524, -0.0239, -0.1754],\n",
      "         [-0.0661,  0.2902, -0.1714,  ..., -0.0181, -0.0879, -0.2527],\n",
      "         [ 0.0039,  0.0612, -0.0029,  ..., -0.1091, -0.0143,  0.0147]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.6782e-01,  1.2129e-01,  1.0400e-01,  ..., -8.7078e-02,\n",
      "           2.3910e-01,  1.4977e-01],\n",
      "         [ 1.8759e-01,  2.8482e-01,  5.9270e-02,  ...,  1.0379e+00,\n",
      "           1.7632e-01,  3.0094e-01],\n",
      "         [ 1.6568e-01,  2.1307e-01,  1.0251e-01,  ..., -4.7107e-01,\n",
      "           2.5655e-01,  4.5655e-02],\n",
      "         ...,\n",
      "         [-1.0816e-02,  2.1054e-01,  7.9594e-04,  ..., -1.1868e-01,\n",
      "          -8.5252e-02, -6.0828e-02],\n",
      "         [ 1.7942e-01,  2.0347e-01, -1.4258e-01,  ...,  1.5169e-01,\n",
      "          -1.8949e-01, -1.5058e-01],\n",
      "         [-2.9683e-02,  6.8838e-02, -2.0394e-03,  ..., -1.0137e-01,\n",
      "          -3.1325e-02, -7.8054e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mary i\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1863,  0.0009,  0.0829,  ..., -0.1356,  0.2926,  0.2169],\n",
      "         [ 0.2956, -0.0979, -0.0270,  ..., -0.2203,  0.2136,  0.1177],\n",
      "         [ 0.0372, -0.1105,  0.3449,  ..., -0.3671,  0.3936, -0.0550],\n",
      "         ...,\n",
      "         [ 0.0124,  0.0864, -0.0540,  ..., -0.0410,  0.0033, -0.0530],\n",
      "         [ 0.1219,  0.0601, -0.0496,  ..., -0.0759,  0.1062, -0.0939],\n",
      "         [ 0.0117,  0.0595, -0.0139,  ..., -0.0869, -0.0299, -0.0626]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.5173e-01,  1.1587e-01,  2.6775e-02,  ...,  7.7659e-04,\n",
      "           9.5827e-02,  2.4497e-01],\n",
      "         [ 4.7673e-01, -1.8171e-01,  8.4199e-02,  ...,  9.1155e-01,\n",
      "           3.9647e-01,  8.5174e-01],\n",
      "         [ 1.0700e-01,  8.5615e-02,  5.9156e-02,  ..., -2.7332e-01,\n",
      "           4.0698e-01,  3.3193e-01],\n",
      "         ...,\n",
      "         [-2.5296e-02,  6.6088e-02, -4.2995e-03,  ..., -1.1007e-01,\n",
      "          -3.5322e-02, -8.4992e-02],\n",
      "         [-4.8096e-02,  1.1902e-01, -1.0212e-02,  ..., -5.0856e-02,\n",
      "          -2.7476e-02, -1.8230e-01],\n",
      "         [ 1.5625e-01,  1.9460e-01,  3.7393e-03,  ...,  1.5157e-01,\n",
      "           1.0548e-01, -2.1900e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1750,  0.0645,  0.0791,  ..., -0.1431,  0.3630, -0.0147],\n",
      "         [-0.1040,  0.0652,  0.5040,  ...,  0.1304,  0.2172,  0.2598],\n",
      "         [ 0.3322,  0.0590,  0.1136,  ..., -0.1525,  0.3348, -0.0140],\n",
      "         ...,\n",
      "         [-0.0056,  0.0710, -0.0082,  ..., -0.0925, -0.0348, -0.0802],\n",
      "         [-0.0560,  0.2695, -0.2394,  ..., -0.2166,  0.2886, -0.2066],\n",
      "         [-0.0239,  0.0690, -0.0111,  ..., -0.0961, -0.0404, -0.0801]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0566,  0.0481,  0.0924,  ..., -0.2196,  0.0975,  0.1280],\n",
      "         [ 0.2128,  0.1240,  0.1446,  ...,  0.4030,  0.2619,  0.4072],\n",
      "         [ 0.0086,  0.3351,  0.2140,  ..., -0.2569,  0.0702, -0.0465],\n",
      "         ...,\n",
      "         [ 0.2622,  0.3596,  0.0820,  ...,  0.2933,  0.1008, -0.2691],\n",
      "         [-0.0897,  0.2702,  0.0336,  ...,  0.0814,  0.0436,  0.0757],\n",
      "         [-0.0070,  0.0683,  0.0035,  ..., -0.0932, -0.0311, -0.0617]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2436, -0.0130,  0.1492,  ...,  0.0555,  0.6147,  0.2744],\n",
      "         [ 0.0457, -0.3415, -0.1181,  ...,  0.1130, -0.0795,  0.5302],\n",
      "         [ 0.3836, -0.1947, -0.1398,  ..., -0.4107,  0.2041,  0.2402],\n",
      "         ...,\n",
      "         [-0.0127,  0.0725, -0.0093,  ..., -0.0932, -0.0310, -0.0692],\n",
      "         [-0.0185,  0.0643, -0.0041,  ..., -0.0864, -0.0292, -0.0714],\n",
      "         [-0.0174,  0.0635, -0.0143,  ..., -0.1009, -0.0462, -0.0711]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.1278,  0.1527,  0.0536,  ..., -0.1883,  0.2906,  0.1251],\n",
      "         [ 0.6244,  0.1319, -0.3004,  ...,  0.3569,  0.4349,  0.8010],\n",
      "         [ 0.2412,  0.1617,  0.0187,  ..., -0.2344,  0.3168,  0.0457],\n",
      "         ...,\n",
      "         [-0.0061,  0.0756, -0.0025,  ..., -0.0889, -0.0333, -0.0653],\n",
      "         [ 0.0089,  0.1103,  0.0472,  ..., -0.0856, -0.0587, -0.1951],\n",
      "         [-0.0264,  0.0667, -0.0150,  ..., -0.0979, -0.0286, -0.0739]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.4765e-01,  5.1173e-04,  3.8140e-02,  ..., -1.0686e-01,\n",
      "           2.6454e-01, -8.3842e-02],\n",
      "         [ 1.8927e-01, -1.1163e-01,  2.8776e-01,  ...,  5.2578e-01,\n",
      "           4.1872e-01,  8.1929e-02],\n",
      "         [ 4.0560e-01, -1.9225e-01,  5.6769e-02,  ..., -2.5670e-01,\n",
      "           2.8563e-01, -4.3881e-01],\n",
      "         ...,\n",
      "         [ 1.6518e-02,  6.1555e-02, -1.9818e-02,  ..., -1.0948e-01,\n",
      "          -2.2892e-02, -8.5787e-02],\n",
      "         [ 9.3194e-03,  9.6550e-02, -2.1303e-02,  ..., -5.2478e-02,\n",
      "          -5.4841e-02, -1.1777e-01],\n",
      "         [ 1.1203e-02,  5.7459e-01, -2.5395e-01,  ...,  4.4739e-01,\n",
      "          -4.0598e-02, -7.3566e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0567,  0.1531, -0.0389,  ..., -0.0129,  0.4279,  0.0198],\n",
      "         [-0.0821,  0.3271,  0.0822,  ...,  0.0952,  0.6946,  0.2540],\n",
      "         [ 0.1467,  0.0836, -0.1490,  ...,  0.1843,  0.4235, -0.3423],\n",
      "         ...,\n",
      "         [-0.0249,  0.0686, -0.0139,  ..., -0.0877, -0.0451, -0.0631],\n",
      "         [ 0.0271,  0.4480, -0.1728,  ..., -0.1872,  0.0622, -0.1031],\n",
      "         [-0.0305,  0.1411,  0.1011,  ..., -0.0117, -0.0873, -0.2132]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2866,  0.0213,  0.0465,  ...,  0.0385,  0.4090,  0.1363],\n",
      "         [ 0.1588,  0.2340,  0.1472,  ...,  0.2901,  0.1937,  0.3854],\n",
      "         [ 0.3064,  0.1252,  0.0680,  ..., -0.2066,  0.1897,  0.0806],\n",
      "         ...,\n",
      "         [ 0.3103,  0.2408, -0.1498,  ...,  0.2015,  0.0769, -0.5406],\n",
      "         [-0.1572,  0.4216,  0.0281,  ...,  0.0469,  0.0631, -0.0323],\n",
      "         [ 0.0015,  0.1996,  0.0143,  ..., -0.0884, -0.0910, -0.1684]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  answer:  no\n",
      "tensor([[[ 0.2283,  0.0019,  0.1175,  ..., -0.0851,  0.2490, -0.0084],\n",
      "         [ 0.1205,  0.4017, -0.1264,  ..., -0.3242,  0.1323,  0.1759],\n",
      "         [ 0.3660,  0.1019, -0.0321,  ..., -0.1125,  0.2239,  0.3507],\n",
      "         ...,\n",
      "         [ 0.0228,  0.1840,  0.0433,  ..., -0.0896, -0.0827, -0.2681],\n",
      "         [-0.0089,  0.0599, -0.0168,  ..., -0.0989, -0.0220,  0.0146],\n",
      "         [-0.0029,  0.0611,  0.0019,  ..., -0.1181, -0.0339, -0.0750]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  ring\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.2865,  0.0879,  0.0023,  ..., -0.0193,  0.3097,  0.1442],\n",
      "         [ 0.4966, -0.0982,  0.2555,  ...,  0.3068,  0.3681,  0.3112],\n",
      "         [ 0.4524, -0.1822,  0.0332,  ...,  0.3269,  0.7212,  0.0316],\n",
      "         ...,\n",
      "         [-0.0092,  0.0546, -0.0073,  ..., -0.0893, -0.0263, -0.0644],\n",
      "         [-0.0077,  0.0555, -0.0546,  ..., -0.1193, -0.0094, -0.1379],\n",
      "         [-0.0877,  0.3702, -0.1784,  ..., -0.0427,  0.1297, -0.0206]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.3194, -0.0072, -0.0010,  ..., -0.1606,  0.1898,  0.1516],\n",
      "         [ 0.5920, -0.0008,  0.0306,  ..., -0.0570,  0.0872,  0.3663],\n",
      "         [ 0.1958,  0.0814,  0.2965,  ..., -0.3411,  0.2973,  0.1892],\n",
      "         ...,\n",
      "         [-0.0099,  0.0756, -0.0017,  ..., -0.0877, -0.0335, -0.0659],\n",
      "         [ 0.1545,  0.2779, -0.1779,  ..., -0.1867, -0.0462,  0.0458],\n",
      "         [-0.0412,  0.2548, -0.1076,  ..., -0.3589, -0.0529, -0.0721]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  danny leiner\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0402, -0.0156,  0.0157,  ..., -0.1960,  0.4571,  0.1317],\n",
      "         [ 0.3263, -0.2660,  0.0562,  ...,  0.1326,  0.3991,  0.7692],\n",
      "         [ 0.2954, -0.1540,  0.0097,  ...,  0.1719,  0.3071, -0.0052],\n",
      "         ...,\n",
      "         [ 0.0505,  0.2438, -0.0689,  ...,  0.0395, -0.0808, -0.2271],\n",
      "         [ 0.0495,  0.1909,  0.0355,  ..., -0.0562, -0.0492, -0.2917],\n",
      "         [-0.0858,  0.4511,  0.0122,  ..., -0.3317, -0.0536,  0.0013]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2426,  0.0635,  0.0583,  ..., -0.0068,  0.2173,  0.0466],\n",
      "         [-0.0790, -0.0617, -0.1785,  ...,  1.5498,  0.2789,  0.3608],\n",
      "         [ 0.3235, -0.1176,  0.0301,  ...,  0.0589,  0.6968, -0.4798],\n",
      "         ...,\n",
      "         [-0.0924,  0.2319,  0.0897,  ..., -0.1279, -0.0258, -0.4320],\n",
      "         [-0.0207,  0.0763, -0.0059,  ..., -0.1087, -0.0390, -0.0775],\n",
      "         [-0.0211,  0.0572, -0.0174,  ..., -0.0849, -0.0455, -0.0520]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0793,  0.1101, -0.0031,  ..., -0.1169,  0.4808,  0.0934],\n",
      "         [ 0.1181,  0.5239,  0.2044,  ...,  0.0861,  0.3091,  0.1740],\n",
      "         [ 0.2012,  0.0774,  0.1977,  ..., -0.0409,  0.3074, -0.1980],\n",
      "         ...,\n",
      "         [ 0.0352,  0.2079, -0.1569,  ..., -0.1068, -0.0822,  0.0132],\n",
      "         [-0.0154,  0.0767, -0.0059,  ..., -0.0907, -0.0372, -0.0790],\n",
      "         [-0.0069,  0.0695, -0.0122,  ..., -0.1125, -0.0339, -0.0722]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.3878,  0.1620,  0.0193,  ..., -0.1621,  0.1958, -0.0712],\n",
      "         [ 0.5802, -0.0348,  0.0929,  ...,  0.2573,  0.7179,  0.1945],\n",
      "         [ 0.6205, -0.0953,  0.0766,  ..., -0.9361,  0.9781,  0.8291],\n",
      "         ...,\n",
      "         [-0.0151,  0.0431,  0.0016,  ..., -0.0929, -0.0143, -0.0530],\n",
      "         [-0.0145,  0.0659, -0.0122,  ..., -0.0988, -0.0315, -0.0746],\n",
      "         [-0.0082,  0.0601, -0.0084,  ..., -0.0865, -0.0193, -0.0707]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 6.0580e-01, -6.1249e-02,  2.8251e-03,  ..., -5.7728e-02,\n",
      "           1.1000e+00,  1.4123e-01],\n",
      "         [ 2.8350e-01, -4.5243e-03, -1.2287e-02,  ...,  6.5021e-01,\n",
      "           6.0757e-01,  1.9844e-01],\n",
      "         [ 4.6404e-01,  1.0938e-01, -1.3391e-01,  ...,  6.7794e-01,\n",
      "           3.7566e-01, -1.4870e-01],\n",
      "         ...,\n",
      "         [ 1.2327e-02,  6.6157e-02,  1.2955e-02,  ..., -1.1177e-01,\n",
      "           1.7585e-03, -9.2721e-02],\n",
      "         [-1.0709e-03,  6.2375e-02, -7.1938e-03,  ..., -1.1428e-01,\n",
      "          -3.1356e-02, -7.1105e-02],\n",
      "         [ 8.3952e-02,  9.6689e-02,  1.2035e-02,  ..., -7.4469e-02,\n",
      "          -3.5612e-02, -2.6823e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2975, -0.0510, -0.0633,  ...,  0.0182,  0.5633,  0.2363],\n",
      "         [ 0.1767, -0.0466, -0.0356,  ...,  0.7641,  0.2336,  0.7355],\n",
      "         [ 0.3530, -0.4192, -0.1814,  ...,  0.5673,  0.2205,  0.0083],\n",
      "         ...,\n",
      "         [-0.0025,  0.0685, -0.0134,  ..., -0.0732, -0.0459,  0.0125],\n",
      "         [ 0.1243,  0.0702, -0.2445,  ..., -0.0458,  0.0818, -0.3056],\n",
      "         [ 0.0457,  0.1115, -0.2586,  ...,  0.3193,  0.2667, -0.9312]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.5788e-01,  3.7048e-02, -5.4111e-04,  ...,  2.0729e-01,\n",
      "           6.1752e-01,  1.8289e-01],\n",
      "         [ 1.4218e-01, -3.0544e-01,  2.1430e-01,  ...,  1.3617e+00,\n",
      "           6.6305e-01, -5.1045e-02],\n",
      "         [ 5.0940e-01,  1.4443e-01,  1.1565e-01,  ...,  6.0137e-02,\n",
      "           3.8755e-01,  1.6144e-01],\n",
      "         ...,\n",
      "         [ 1.4463e-02,  6.8108e-02, -2.8251e-03,  ..., -9.6176e-02,\n",
      "          -3.4441e-02, -7.1044e-02],\n",
      "         [-3.4059e-03,  8.1055e-02, -1.3818e-02,  ..., -1.0458e-01,\n",
      "          -7.5498e-03, -9.1760e-02],\n",
      "         [ 1.3256e-01,  4.1189e-01, -3.8825e-02,  ...,  5.6006e-02,\n",
      "           1.4869e-01, -1.8081e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.3465,  0.1650,  0.0323,  ...,  0.0755,  0.7751,  0.1376],\n",
      "         [ 0.4329, -0.0842,  0.3008,  ...,  0.5512,  0.5039,  0.2174],\n",
      "         [ 0.3572,  0.0544,  0.3133,  ...,  1.2849,  0.5187,  0.6638],\n",
      "         ...,\n",
      "         [ 0.0019,  0.0713, -0.0095,  ..., -0.0822, -0.0488, -0.0714],\n",
      "         [-0.0211,  0.0810, -0.0098,  ..., -0.0885, -0.0395, -0.0036],\n",
      "         [-0.0477,  0.2752, -0.0115,  ..., -0.3408,  0.0868, -0.0978]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2112,  0.0698,  0.0165,  ...,  0.1121,  0.7249,  0.0932],\n",
      "         [ 0.7497, -0.0925,  0.2236,  ...,  0.7530,  0.5503,  0.0913],\n",
      "         [ 0.5469, -0.0935,  0.0933,  ...,  0.4318,  0.3708,  0.0864],\n",
      "         ...,\n",
      "         [-0.0032,  0.0744,  0.0040,  ..., -0.1093, -0.0188, -0.1077],\n",
      "         [-0.0249,  0.0630, -0.0206,  ..., -0.0944, -0.0332, -0.0900],\n",
      "         [-0.0202,  0.0776, -0.0130,  ..., -0.0795, -0.0374, -0.0815]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4351,  0.0169,  0.0433,  ...,  0.2142,  0.6844, -0.0746],\n",
      "         [ 0.4609, -0.0757,  0.0428,  ...,  0.8767,  1.0271, -0.2723],\n",
      "         [ 0.5968,  0.1303, -0.0120,  ...,  0.5886,  0.8870,  0.0498],\n",
      "         ...,\n",
      "         [-0.0228,  0.0594, -0.0168,  ..., -0.1002, -0.0198, -0.0776],\n",
      "         [ 0.0278,  0.1471, -0.0676,  ..., -0.0301,  0.0748, -0.2182],\n",
      "         [-0.0216,  0.0577, -0.0151,  ..., -0.0911, -0.0165, -0.0733]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.5163,  0.0972,  0.0766,  ...,  0.1659,  0.7321,  0.2445],\n",
      "         [ 0.2479,  0.3226,  0.0621,  ...,  0.5358,  0.3960,  0.5249],\n",
      "         [ 0.3545,  0.1711,  0.0778,  ..., -0.1990,  0.2532,  0.1996],\n",
      "         ...,\n",
      "         [-0.0193,  0.0383, -0.0130,  ..., -0.1113, -0.0427, -0.0873],\n",
      "         [-0.0717,  0.1218, -0.0190,  ..., -0.0532, -0.0307, -0.1968],\n",
      "         [-0.0014,  0.0532, -0.0083,  ..., -0.0918, -0.0264, -0.0704]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4803, -0.0489, -0.0477,  ...,  0.2859,  0.6829,  0.0636],\n",
      "         [ 0.8775, -0.0692, -0.1776,  ...,  0.8749,  0.7224,  0.9391],\n",
      "         [ 0.5948,  0.1604, -0.0379,  ...,  0.5934,  0.7690, -0.0109],\n",
      "         ...,\n",
      "         [-0.0114,  0.0711, -0.0179,  ..., -0.0878, -0.0360, -0.0754],\n",
      "         [-0.0111,  0.0792,  0.0067,  ..., -0.0868, -0.0340, -0.0732],\n",
      "         [-0.0184,  0.0720,  0.0030,  ..., -0.0862, -0.0264, -0.0787]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5054,  0.1579,  0.0549,  ...,  0.3390,  0.6749,  0.1921],\n",
      "         [ 0.4985,  0.3205,  0.0078,  ...,  0.2927, -0.1634,  0.1559],\n",
      "         [ 0.2891, -0.0494,  0.0988,  ...,  0.6823,  0.4186,  0.5735],\n",
      "         ...,\n",
      "         [-0.0180,  0.0645, -0.0084,  ..., -0.0865, -0.0385, -0.0721],\n",
      "         [-0.0169,  0.0676, -0.0034,  ..., -0.0802, -0.0325, -0.0739],\n",
      "         [-0.1024,  0.3144, -0.0449,  ..., -0.2843,  0.4026, -0.4767]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 3.3966e-01, -5.6286e-02,  1.8237e-02,  ...,  3.7175e-01,\n",
      "           5.0972e-01, -2.5389e-01],\n",
      "         [ 5.2529e-01, -1.4956e-01,  4.0286e-01,  ...,  1.0114e+00,\n",
      "           8.6028e-01,  5.3144e-01],\n",
      "         [ 7.0119e-01, -2.6334e-01, -1.3033e-02,  ...,  2.8743e-01,\n",
      "           6.7835e-01, -4.2164e-02],\n",
      "         ...,\n",
      "         [-1.0178e-02,  4.0190e-02, -2.7610e-04,  ..., -8.8945e-02,\n",
      "          -2.9294e-02, -7.2178e-02],\n",
      "         [-1.7345e-02,  7.5378e-02, -4.9563e-03,  ..., -1.1331e-01,\n",
      "          -1.8459e-02, -8.3124e-02],\n",
      "         [-1.8083e-02,  7.3818e-02, -2.0341e-03,  ..., -8.5642e-02,\n",
      "          -3.7984e-02,  1.5440e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.8304e-01,  1.4462e-01, -3.1373e-02,  ...,  4.9845e-01,\n",
      "           1.5077e+00,  7.9439e-02],\n",
      "         [ 7.7097e-01,  1.5925e-01,  2.0940e-01,  ...,  1.2315e+00,\n",
      "           9.3190e-01, -2.6850e-02],\n",
      "         [ 6.5918e-01, -9.4226e-02,  1.0711e-01,  ...,  3.8169e-01,\n",
      "           9.4818e-01, -3.0780e-01],\n",
      "         ...,\n",
      "         [-2.1831e-04,  7.5065e-02,  4.0360e-03,  ..., -1.1144e-01,\n",
      "          -3.7623e-02, -6.2814e-02],\n",
      "         [-1.4801e-02,  7.0128e-02, -1.7861e-02,  ..., -8.5323e-02,\n",
      "          -3.0519e-02, -7.7688e-02],\n",
      "         [-2.5268e-02,  6.3943e-02, -5.8938e-03,  ..., -8.1060e-02,\n",
      "          -3.9278e-02, -8.1325e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "answer:  szombathelyi haladás\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.7214e-01,  2.4922e-01,  4.4508e-02,  ..., -1.7905e-01,\n",
      "           8.5070e-01,  6.0057e-02],\n",
      "         [ 2.2593e-01,  2.6515e-02,  8.8955e-02,  ...,  1.2974e+00,\n",
      "           8.9545e-01,  2.3547e-01],\n",
      "         [ 6.9781e-01, -2.2970e-01, -4.2030e-02,  ...,  5.3382e-01,\n",
      "           9.3911e-01, -9.5494e-02],\n",
      "         ...,\n",
      "         [-2.5184e-02,  4.1676e-02, -5.5295e-04,  ..., -8.5182e-02,\n",
      "          -3.6613e-02, -8.0763e-02],\n",
      "         [-1.5797e-02,  1.5334e-01,  6.8709e-03,  ..., -9.6891e-02,\n",
      "          -9.6816e-02, -1.6232e-01],\n",
      "         [ 1.4333e-01,  5.2776e-01, -2.3217e-02,  ..., -4.2578e-01,\n",
      "           2.6272e-01, -2.0390e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.4757e-01,  2.0323e-01, -2.2555e-01,  ...,  2.1729e-01,\n",
      "           6.4262e-01,  1.2505e-01],\n",
      "         [ 5.9372e-01, -2.6139e-01, -3.8291e-01,  ...,  7.9879e-01,\n",
      "           1.1079e+00,  7.2382e-02],\n",
      "         [ 4.7673e-01,  5.0992e-02, -1.0043e-01,  ...,  4.1361e-01,\n",
      "           7.6761e-01, -2.2916e-01],\n",
      "         ...,\n",
      "         [-7.7187e-02,  2.3473e-01,  2.8660e-04,  ..., -2.2458e-01,\n",
      "          -2.0154e-01, -4.2165e-01],\n",
      "         [-9.5910e-03,  4.1451e-02, -1.0358e-02,  ..., -9.8377e-02,\n",
      "          -1.2831e-02, -8.8326e-02],\n",
      "         [-1.6740e-02,  6.8677e-02,  5.0730e-04,  ..., -8.6465e-02,\n",
      "          -3.3139e-02, -8.4560e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4863,  0.2049,  0.0810,  ...,  0.1810,  0.8892,  0.1317],\n",
      "         [ 0.3691, -0.3977, -0.0657,  ...,  1.0931,  0.8860,  0.5352],\n",
      "         [ 0.3948,  0.0492, -0.0960,  ...,  0.0117,  0.3997, -0.4457],\n",
      "         ...,\n",
      "         [-0.0149,  0.0716, -0.0102,  ..., -0.1127, -0.0300, -0.0728],\n",
      "         [-0.0093,  0.0745, -0.0076,  ..., -0.0818, -0.0293, -0.0686],\n",
      "         [-0.0286,  0.0765,  0.0145,  ..., -0.0742, -0.0313, -0.0563]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8497,  0.1558,  0.1064,  ...,  0.6190,  1.0923,  0.2147],\n",
      "         [ 0.5632,  0.1825, -0.2706,  ...,  1.3414,  0.6979,  0.5307],\n",
      "         [ 0.5670,  0.0189,  0.1941,  ...,  0.3186,  0.9191, -0.0219],\n",
      "         ...,\n",
      "         [ 0.0314,  0.2944, -0.1259,  ..., -0.2056,  0.0505, -0.1703],\n",
      "         [-0.0135,  0.0696, -0.0026,  ..., -0.0781, -0.0214, -0.0697],\n",
      "         [-0.0043,  0.1038, -0.0030,  ..., -0.0944, -0.0290, -0.0787]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6127,  0.2900,  0.0166,  ...,  0.4345,  1.0861, -0.1422],\n",
      "         [ 0.5059,  0.3610, -0.2041,  ...,  1.4138,  0.8540,  0.2848],\n",
      "         [ 0.4198, -0.4603, -0.0675,  ...,  1.0721,  1.3167, -0.2531],\n",
      "         ...,\n",
      "         [ 0.0095,  0.0620, -0.0134,  ..., -0.0926, -0.0349, -0.0906],\n",
      "         [-0.0031,  0.0618, -0.0030,  ..., -0.0914, -0.0192, -0.0675],\n",
      "         [-0.0092,  0.0764, -0.0199,  ..., -0.0977, -0.0256, -0.1624]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  munster rugby\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2437,  0.1046,  0.0681,  ...,  0.4940,  1.3020, -0.2015],\n",
      "         [ 0.6043,  0.5674, -0.1304,  ...,  0.9644,  0.7531,  0.0145],\n",
      "         [ 0.7334, -0.0038,  0.0619,  ...,  0.2431,  1.4465, -0.0172],\n",
      "         ...,\n",
      "         [ 0.3044,  0.6944,  0.3124,  ..., -0.1883,  0.3561, -0.6946],\n",
      "         [ 0.0494,  0.0844, -0.0437,  ...,  0.0440,  0.0357, -0.3103],\n",
      "         [ 0.0147,  0.1789,  0.0496,  ..., -0.0935, -0.0477, -0.0425]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6058, -0.0779, -0.1092,  ...,  0.6051,  1.0693, -0.1021],\n",
      "         [-0.0755,  0.3340, -0.1005,  ...,  1.4419,  0.4090,  0.2953],\n",
      "         [ 0.7450,  0.1282,  0.0017,  ...,  1.2866,  0.5612, -0.8949],\n",
      "         ...,\n",
      "         [-0.0166,  0.0689, -0.0093,  ..., -0.0859, -0.0237, -0.0705],\n",
      "         [-0.0156,  0.0386, -0.0183,  ..., -0.1095, -0.0356, -0.0812],\n",
      "         [-0.0226, -0.1359, -0.2289,  ...,  0.0751,  0.0562, -0.5150]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0770, -0.1769, -0.0941,  ...,  1.2438,  0.7951, -0.4198],\n",
      "         [ 0.5930,  0.0120, -0.1956,  ...,  0.7619,  1.0084, -0.1446],\n",
      "         [ 0.5477, -0.0391, -0.3188,  ...,  1.4476,  1.0096, -0.6674],\n",
      "         ...,\n",
      "         [-0.0216,  0.0720, -0.0145,  ..., -0.1252, -0.0376, -0.0757],\n",
      "         [ 0.2504,  0.4343,  0.0468,  ...,  0.2413,  0.2888, -0.2988],\n",
      "         [ 0.1856,  0.3336, -0.0309,  ..., -0.1784, -0.1583, -0.7019]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.7845e-01,  2.7445e-01, -1.5710e-01,  ...,  6.5989e-01,\n",
      "           1.2553e+00,  3.6684e-02],\n",
      "         [ 5.0833e-02,  1.2040e-01, -2.2013e-01,  ...,  1.7500e+00,\n",
      "           1.1957e+00, -1.0997e-01],\n",
      "         [ 5.7153e-01,  6.3312e-02,  1.8048e-01,  ..., -9.8098e-02,\n",
      "           5.0324e-01, -3.2651e-01],\n",
      "         ...,\n",
      "         [-1.7472e-02,  1.0422e-01,  2.6573e-03,  ..., -8.6772e-02,\n",
      "          -2.9837e-02, -7.6610e-02],\n",
      "         [-1.2210e-02,  2.4567e-01, -9.6081e-03,  ..., -7.5876e-02,\n",
      "           2.4241e-02, -3.4647e-01],\n",
      "         [ 1.2636e-02,  6.8970e-02, -1.1772e-03,  ..., -8.7508e-02,\n",
      "          -1.3959e-02, -5.1004e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8731, -0.2462, -0.1660,  ...,  0.8290,  1.1468, -0.2466],\n",
      "         [ 0.8609,  0.0966, -0.2227,  ...,  1.6450,  1.0642,  0.2421],\n",
      "         [ 0.6912,  0.0473, -0.0946,  ...,  0.8703,  0.6650, -0.1040],\n",
      "         ...,\n",
      "         [-0.0164,  0.0701, -0.0063,  ..., -0.0958, -0.0484, -0.0984],\n",
      "         [-0.0931,  0.1049,  0.0301,  ..., -0.0611, -0.0899, -0.2340],\n",
      "         [-0.0094,  0.0964, -0.0108,  ..., -0.1045, -0.0352, -0.0794]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5143,  0.0838, -0.1362,  ...,  0.1117,  1.4879, -0.5923],\n",
      "         [ 0.6197,  0.2534, -0.1391,  ...,  1.4418,  0.9563, -0.1376],\n",
      "         [ 0.3936,  0.1691, -0.0479,  ...,  1.4178,  1.0766, -0.7295],\n",
      "         ...,\n",
      "         [-0.1028,  0.2391, -0.0721,  ..., -0.1923, -0.1754,  0.1004],\n",
      "         [-0.0034,  0.0633, -0.0020,  ..., -0.0829, -0.0305, -0.0757],\n",
      "         [-0.0267,  0.0649, -0.0099,  ..., -0.0870, -0.0233, -0.0733]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7336,  0.0255, -0.3711,  ...,  1.1342,  1.4860, -0.0799],\n",
      "         [ 0.0504, -0.2161, -0.2792,  ...,  1.1770,  0.8335,  0.1444],\n",
      "         [ 0.7410,  0.1520, -0.6248,  ...,  1.1098,  1.0579, -0.1970],\n",
      "         ...,\n",
      "         [-0.0191,  0.0686, -0.0072,  ..., -0.0894, -0.0305, -0.0723],\n",
      "         [ 0.1191,  0.1659,  0.0829,  ...,  0.0327, -0.0081, -0.5002],\n",
      "         [ 0.0045,  0.0500,  0.0129,  ..., -0.1149, -0.0414, -0.0500]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8585,  0.0140, -0.1536,  ...,  1.2801,  1.0454, -0.2200],\n",
      "         [ 0.6421,  0.2850, -0.1136,  ...,  1.5180,  1.0577, -0.1908],\n",
      "         [-0.2089,  0.3928,  0.0871,  ...,  1.4292,  1.3201,  0.5981],\n",
      "         ...,\n",
      "         [-0.0036,  0.0625, -0.0096,  ..., -0.0856, -0.0263, -0.0666],\n",
      "         [-0.0511,  0.3740, -0.2629,  ...,  0.2148, -0.1124, -0.1456],\n",
      "         [ 0.1226,  0.4180, -0.0865,  ...,  0.6470,  0.2630, -0.4277]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6005,  0.1811, -0.2793,  ...,  1.5797,  1.6867, -0.2585],\n",
      "         [ 0.4998,  0.3058, -0.1344,  ...,  1.6607,  1.0382,  0.0742],\n",
      "         [ 0.2009,  0.2458,  0.0866,  ...,  1.2136,  0.9317, -0.1566],\n",
      "         ...,\n",
      "         [-0.0127,  0.0362, -0.0058,  ..., -0.0841, -0.0325, -0.0833],\n",
      "         [-0.0077,  0.1772,  0.0777,  ..., -0.0671, -0.1020, -0.2122],\n",
      "         [ 0.0299,  0.4302,  0.0087,  ..., -0.1113, -0.1289,  0.0327]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1471,  0.1386, -0.1806,  ...,  1.4136,  2.0030, -0.5748],\n",
      "         [ 0.4682,  0.0146, -0.1061,  ...,  1.8375,  0.9559, -0.9499],\n",
      "         [ 0.2774,  0.0401, -0.1069,  ...,  1.3507,  1.0422, -0.6596],\n",
      "         ...,\n",
      "         [-0.0156,  0.0622, -0.0218,  ..., -0.0808, -0.0326, -0.0495],\n",
      "         [-0.0500,  0.1497,  0.0021,  ..., -0.0942, -0.0108, -0.2130],\n",
      "         [-0.0066,  0.1042, -0.0124,  ..., -0.0769, -0.0420,  0.0115]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.3763,  0.3860, -0.2054,  ...,  0.4084,  1.7458, -0.3444],\n",
      "         [ 0.7089,  0.0546, -0.4001,  ...,  0.9277,  1.1937, -0.3865],\n",
      "         [ 0.6871,  0.6018,  0.0995,  ...,  1.6348,  0.6880, -0.2434],\n",
      "         ...,\n",
      "         [-0.0199,  0.0856,  0.0268,  ..., -0.0653, -0.0048, -0.1652],\n",
      "         [-0.0058,  0.0652, -0.0106,  ..., -0.0789, -0.0280, -0.0655],\n",
      "         [-0.0243,  0.1096, -0.0501,  ..., -0.1103, -0.0083, -0.1929]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.5521e-01,  1.5651e-01,  1.5542e-01,  ...,  1.7594e+00,\n",
      "           1.7394e+00,  2.1285e-01],\n",
      "         [-1.0210e-01,  3.6160e-01, -3.8259e-01,  ...,  2.4095e+00,\n",
      "           1.1389e+00, -5.0962e-01],\n",
      "         [ 6.3619e-01, -7.8465e-02, -1.2538e-01,  ...,  1.8750e+00,\n",
      "           1.2722e+00, -7.7732e-01],\n",
      "         ...,\n",
      "         [-2.7371e-02,  6.3078e-02, -1.0274e-02,  ..., -7.9063e-02,\n",
      "          -3.5248e-02, -6.8256e-02],\n",
      "         [-3.8574e-02,  1.8880e-01, -3.1958e-01,  ..., -4.2933e-01,\n",
      "           2.8692e-01, -1.9127e-01],\n",
      "         [ 1.4846e-03,  6.7348e-02, -1.2398e-02,  ..., -9.0803e-02,\n",
      "          -3.3472e-02, -8.2743e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  st johns\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9336,  0.0575, -0.2886,  ...,  1.3847,  1.8988, -0.2341],\n",
      "         [ 0.7571, -0.0795,  0.1935,  ...,  1.6407,  0.6944,  0.8981],\n",
      "         [ 0.7700, -0.0406,  0.0736,  ...,  1.0686,  0.7301, -0.0541],\n",
      "         ...,\n",
      "         [ 0.0073,  0.1870,  0.0237,  ..., -0.0687, -0.1168, -0.2696],\n",
      "         [ 0.1186, -0.2815, -0.1335,  ...,  0.2170,  0.0440, -0.5585],\n",
      "         [-0.0208,  0.0643, -0.0158,  ..., -0.0793, -0.0393, -0.0892]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8877,  0.3023, -0.1926,  ...,  1.4692,  1.4104, -0.3200],\n",
      "         [ 0.9531,  0.1563, -0.0281,  ...,  1.9578,  0.8241, -0.1969],\n",
      "         [ 0.8336, -0.2152, -0.0678,  ...,  1.7235,  1.1980, -0.4168],\n",
      "         ...,\n",
      "         [ 0.0125,  0.0704, -0.0146,  ..., -0.0832, -0.0294, -0.0768],\n",
      "         [-0.0069,  0.0781,  0.0211,  ..., -0.0383, -0.0186, -0.0681],\n",
      "         [-0.0044,  0.0970, -0.0051,  ..., -0.0841, -0.0153, -0.0835]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 4.9624e-01,  2.6868e-01, -2.3178e-01,  ...,  1.5420e-01,\n",
      "           1.4447e+00, -9.0969e-02],\n",
      "         [ 1.8221e-01,  3.5562e-01, -1.7078e-01,  ...,  4.2334e-01,\n",
      "           1.1756e+00,  2.6456e-01],\n",
      "         [ 2.9597e-01, -3.6485e-01, -7.2091e-02,  ...,  5.6110e-01,\n",
      "           3.2580e-01,  4.0480e-01],\n",
      "         ...,\n",
      "         [-1.3192e-02,  6.0540e-02,  8.0519e-04,  ..., -7.8457e-02,\n",
      "          -3.2985e-02, -6.2794e-02],\n",
      "         [-1.2222e-02,  6.5427e-02, -3.5523e-02,  ..., -9.3002e-02,\n",
      "          -1.2752e-02, -1.3867e-01],\n",
      "         [-1.3906e-02,  6.7663e-02,  3.2953e-03,  ..., -8.4752e-02,\n",
      "          -2.4586e-02, -8.1843e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7622, -0.2503, -0.2848,  ...,  1.3695,  1.8523,  0.2504],\n",
      "         [ 0.6891, -0.0424, -0.2867,  ...,  1.6650,  1.0331, -0.0766],\n",
      "         [ 0.3652, -0.3183, -0.1565,  ...,  1.0825,  0.6635, -0.4369],\n",
      "         ...,\n",
      "         [-0.1558,  0.4161, -0.0443,  ..., -0.1867, -0.0346, -0.1774],\n",
      "         [-0.0190,  0.0664, -0.0113,  ..., -0.0940, -0.0484, -0.0723],\n",
      "         [-0.0315,  0.1824,  0.0225,  ..., -0.0463, -0.1026, -0.1502]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "answer:  josephine baker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 6.0253e-01,  8.9506e-02,  1.7209e-01,  ...,  9.8133e-01,\n",
      "           1.4493e+00,  7.9466e-02],\n",
      "         [ 4.5881e-01, -4.6948e-02,  1.5306e-01,  ...,  2.4290e+00,\n",
      "           3.4726e-01, -4.7124e-01],\n",
      "         [ 4.5605e-01, -1.7196e-01, -1.2411e-01,  ...,  1.4813e+00,\n",
      "           1.2541e+00, -4.8189e-01],\n",
      "         ...,\n",
      "         [-1.5556e-02,  1.0262e-01, -2.1442e-03,  ..., -8.3349e-02,\n",
      "          -3.6235e-02, -8.0120e-02],\n",
      "         [-9.6662e-02,  2.9972e-01, -1.2477e-01,  ...,  8.3485e-02,\n",
      "          -1.2110e-01, -1.7241e-01],\n",
      "         [ 6.7860e-02,  2.2409e-01, -4.1338e-02,  ..., -6.7456e-02,\n",
      "           4.9643e-03, -3.0883e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  keri russell\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9708,  0.2410, -0.1895,  ...,  1.6641,  1.4922, -0.1671],\n",
      "         [ 0.3776,  0.1860, -0.1759,  ...,  1.8844,  0.1009, -0.0156],\n",
      "         [ 0.5130,  0.3384, -0.2895,  ...,  1.5677,  1.1569, -0.3743],\n",
      "         ...,\n",
      "         [ 0.0102,  0.1707,  0.3551,  ..., -0.6308,  0.2755, -0.1055],\n",
      "         [-0.0111,  0.2151,  0.0364,  ..., -0.0800, -0.0537, -0.1530],\n",
      "         [ 0.0077,  0.1133, -0.0192,  ..., -0.0327, -0.0617, -0.2667]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9913,  0.3402, -0.0408,  ...,  1.7872,  1.0226, -0.2108],\n",
      "         [ 0.1002,  0.0979,  0.3020,  ...,  1.9073,  1.0189, -0.1379],\n",
      "         [ 0.4827,  0.2147, -0.0367,  ...,  1.7179,  0.7976, -0.2442],\n",
      "         ...,\n",
      "         [-0.0129,  0.0616, -0.0076,  ..., -0.0810, -0.0255, -0.0633],\n",
      "         [-0.0097,  0.0568,  0.0077,  ..., -0.1031, -0.0260, -0.1160],\n",
      "         [-0.0089,  0.0704, -0.0079,  ..., -0.0792, -0.0120,  0.0169]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0103,  0.0966,  0.0069,  ...,  2.0518,  1.4564,  0.1950],\n",
      "         [ 0.5666,  0.0568,  0.1559,  ...,  2.0283,  0.9075,  0.6751],\n",
      "         [ 0.4902,  0.3424,  0.1298,  ...,  1.3048,  0.8352,  0.7137],\n",
      "         ...,\n",
      "         [-0.0184,  0.0641, -0.0101,  ..., -0.0837, -0.0356, -0.0788],\n",
      "         [ 0.2979,  0.4414, -0.3057,  ..., -0.1909,  0.4521, -0.2514],\n",
      "         [-0.0137,  0.0649, -0.0131,  ..., -0.0853, -0.0259, -0.0872]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  answer:  christmas\n",
      "tensor([[[ 1.8666e-01,  7.7667e-02,  9.9463e-02,  ...,  1.8104e+00,\n",
      "           1.5130e+00, -4.5170e-01],\n",
      "         [-1.3257e-01,  2.2298e-01, -7.6375e-02,  ...,  1.6030e+00,\n",
      "           4.2452e-01, -2.8485e-01],\n",
      "         [ 3.4940e-01,  1.6912e-01, -9.2287e-02,  ...,  5.6767e-01,\n",
      "           8.0478e-01, -2.8826e-01],\n",
      "         ...,\n",
      "         [ 6.8176e-03,  6.3381e-02, -9.0679e-03,  ..., -9.2267e-02,\n",
      "          -2.4875e-02, -6.1338e-02],\n",
      "         [ 5.2081e-03,  7.9701e-02,  1.2028e-02,  ..., -8.5010e-02,\n",
      "          -1.6332e-02, -7.9064e-02],\n",
      "         [ 3.2314e-03,  5.2535e-02, -1.5313e-03,  ..., -9.0715e-02,\n",
      "          -2.0392e-02, -6.4576e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7861, -0.0790, -0.1767,  ...,  1.9927,  1.6603, -0.3810],\n",
      "         [ 0.2500, -0.1937, -0.3647,  ...,  2.4760,  1.0862, -0.3783],\n",
      "         [ 0.4635, -0.1751, -0.0529,  ...,  1.6202,  0.8752, -0.6614],\n",
      "         ...,\n",
      "         [-0.0174,  0.0640, -0.0032,  ..., -0.0753, -0.0183, -0.0773],\n",
      "         [-0.0026,  0.0729,  0.0032,  ..., -0.0875, -0.0240, -0.0929],\n",
      "         [ 0.0096,  0.0801, -0.0179,  ..., -0.0768, -0.0255, -0.1034]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "answer:  1962\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1221e+00,  9.0987e-02, -2.3801e-01,  ...,  2.4026e+00,\n",
      "           1.5768e+00, -5.7020e-01],\n",
      "         [ 4.1689e-01,  2.8984e-01,  2.1274e-02,  ...,  2.1784e+00,\n",
      "           1.0070e+00, -4.8098e-01],\n",
      "         [ 7.5346e-01,  5.9610e-03, -3.4451e-01,  ...,  1.8491e+00,\n",
      "           1.4594e+00, -8.4495e-01],\n",
      "         ...,\n",
      "         [-1.4219e-02,  9.7093e-02, -5.3397e-03,  ..., -8.7248e-02,\n",
      "          -3.4420e-02,  1.6844e-02],\n",
      "         [-1.6377e-02,  7.1965e-02,  7.4054e-04,  ..., -7.1053e-02,\n",
      "          -1.6543e-02, -7.6069e-02],\n",
      "         [ 2.9243e-02,  1.7308e-01, -2.9524e-01,  ..., -3.2771e-01,\n",
      "           9.1979e-02, -3.1085e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1937\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1991,  0.1558,  0.0090,  ...,  1.9520,  1.2012, -0.1599],\n",
      "         [ 0.9820,  0.2794, -0.3108,  ...,  2.3433,  0.2820, -0.3862],\n",
      "         [ 0.8189,  0.3269, -0.1266,  ...,  1.8263,  0.8641, -0.1983],\n",
      "         ...,\n",
      "         [-0.0209,  0.0638,  0.0040,  ..., -0.0793, -0.0294, -0.0818],\n",
      "         [-0.0891,  0.2620, -0.1507,  ..., -0.2075, -0.1209, -0.0304],\n",
      "         [-0.0100,  0.0636, -0.0024,  ..., -0.0906, -0.0276, -0.0735]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8890,  0.1765, -0.0855,  ...,  1.9067,  1.8939, -0.2987],\n",
      "         [ 0.7911,  0.5205, -0.1904,  ...,  2.2998,  1.2604, -0.3904],\n",
      "         [ 0.2829,  0.2714,  0.0053,  ...,  1.9440,  1.2886, -0.5613],\n",
      "         ...,\n",
      "         [ 0.0436,  0.0811, -0.0275,  ..., -0.0604, -0.0225, -0.0744],\n",
      "         [-0.0203,  0.0733, -0.0148,  ..., -0.0840, -0.0184, -0.0886],\n",
      "         [ 0.0055,  0.1128, -0.0061,  ...,  0.0046, -0.0529,  0.0122]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 9.1734e-01,  2.4029e-01,  2.3543e-01,  ...,  2.1929e+00,\n",
      "           1.6856e+00, -5.9671e-01],\n",
      "         [ 6.9807e-01,  3.7288e-01, -7.7403e-02,  ...,  2.2494e+00,\n",
      "           1.2130e+00, -9.2621e-02],\n",
      "         [ 9.9421e-01,  8.6524e-02, -5.5842e-02,  ...,  1.9104e+00,\n",
      "           9.9325e-01,  1.3344e-01],\n",
      "         ...,\n",
      "         [ 1.2801e-02,  5.9106e-02, -1.1855e-02,  ..., -9.3168e-02,\n",
      "          -1.6120e-02,  1.9350e-02],\n",
      "         [-8.3945e-03,  5.3981e-02,  7.3526e-03,  ..., -7.1422e-02,\n",
      "          -3.4171e-02, -9.2858e-02],\n",
      "         [-1.1472e-02,  6.9025e-02,  1.4061e-03,  ..., -9.6823e-02,\n",
      "          -4.2148e-02, -9.7619e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  transcendentalist\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6514,  0.1071, -0.2029,  ...,  2.3371,  1.3351,  0.1725],\n",
      "         [ 0.8455,  0.1772,  0.0073,  ...,  2.5339,  0.9216, -0.4022],\n",
      "         [ 0.4617,  0.1731, -0.0158,  ...,  1.6968,  1.1092, -0.3050],\n",
      "         ...,\n",
      "         [-0.0146,  0.0793, -0.0138,  ..., -0.1052, -0.0368,  0.0119],\n",
      "         [ 0.0452,  0.2870, -0.3165,  ..., -0.0793, -0.1148, -0.6095],\n",
      "         [-0.0074,  0.0735,  0.0137,  ..., -0.0838, -0.0191, -0.0843]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0590,  0.1445, -0.5199,  ...,  1.7723,  1.6694, -0.7570],\n",
      "         [ 1.1997,  0.1300, -0.3895,  ...,  1.7741,  0.5129, -0.7016],\n",
      "         [ 1.0424,  0.1529, -0.2563,  ...,  2.0940,  0.7847, -0.1276],\n",
      "         ...,\n",
      "         [-0.0122,  0.1457,  0.0186,  ..., -0.1113, -0.0636, -0.2257],\n",
      "         [-0.0163,  0.0036,  0.0246,  ..., -0.0525, -0.0616, -0.0679],\n",
      "         [-0.0141,  0.0740, -0.0023,  ..., -0.0830, -0.0347, -0.0875]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8209,  0.2235, -0.0747,  ...,  2.0589,  1.6433, -0.8413],\n",
      "         [ 0.8642, -0.1390,  0.0900,  ...,  2.3542,  0.8280,  0.0183],\n",
      "         [ 0.6905,  0.1099,  0.0346,  ...,  2.0497,  0.7106, -0.9549],\n",
      "         ...,\n",
      "         [-0.0056,  0.0773, -0.0034,  ..., -0.0621, -0.0387, -0.0680],\n",
      "         [ 0.0064,  0.0631, -0.0076,  ..., -0.1188, -0.0289, -0.1039],\n",
      "         [-0.0033,  0.0622, -0.1391,  ...,  0.0704,  0.0968, -0.2949]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0512e+00,  2.4101e-01,  1.3827e-01,  ...,  2.3791e+00,\n",
      "           1.6024e+00, -1.1917e-01],\n",
      "         [ 5.8095e-01,  2.9086e-01,  6.2666e-03,  ...,  2.4724e+00,\n",
      "           8.0479e-01,  8.5510e-02],\n",
      "         [ 3.8783e-01,  5.1506e-01,  2.0718e-02,  ...,  1.9762e+00,\n",
      "           4.8575e-01, -3.0531e-01],\n",
      "         ...,\n",
      "         [-2.0263e-02,  7.9405e-02, -2.2125e-03,  ..., -8.7818e-02,\n",
      "          -3.7974e-02, -6.1292e-02],\n",
      "         [-2.7707e-03,  9.7903e-02,  1.9123e-02,  ..., -3.1181e-02,\n",
      "          -4.1821e-02, -7.9442e-02],\n",
      "         [ 4.2144e-02,  6.5793e-02, -6.5285e-02,  ..., -1.6540e-02,\n",
      "           8.2215e-03, -1.3648e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1617e+00,  3.0060e-01, -2.9189e-01,  ...,  2.0293e+00,\n",
      "           1.4670e+00, -4.6927e-01],\n",
      "         [ 1.0260e+00,  2.9759e-01, -8.1447e-02,  ...,  2.4540e+00,\n",
      "           4.0855e-01, -3.9591e-02],\n",
      "         [ 7.4291e-01,  3.3060e-01,  6.8411e-02,  ...,  1.9522e+00,\n",
      "           9.5361e-01, -2.1000e-01],\n",
      "         ...,\n",
      "         [-5.1122e-03,  5.7055e-02, -9.9354e-03,  ..., -8.1406e-02,\n",
      "          -3.5059e-02, -7.2392e-02],\n",
      "         [-7.4128e-03,  2.9652e-01,  6.2895e-05,  ..., -1.3112e-01,\n",
      "          -5.1632e-02, -1.0567e-01],\n",
      "         [-2.0795e-02,  6.7258e-02, -7.9138e-03,  ..., -9.3239e-02,\n",
      "          -3.2338e-02, -7.5647e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2503,  0.0812, -0.2162,  ...,  2.2838,  1.4654, -0.2307],\n",
      "         [ 0.9022,  0.0878,  0.2187,  ...,  2.2375,  0.8447, -0.0682],\n",
      "         [ 0.9167,  0.2653, -0.1102,  ...,  1.2510,  0.6486,  0.3778],\n",
      "         ...,\n",
      "         [-0.0157,  0.0787, -0.0099,  ..., -0.0891, -0.0390, -0.0690],\n",
      "         [ 0.0162,  0.1572,  0.0573,  ..., -0.0238, -0.1014, -0.2272],\n",
      "         [-0.0224,  0.0707, -0.0127,  ..., -0.0740, -0.0346, -0.0866]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0773e+00,  2.1625e-03,  1.1133e-01,  ...,  1.8926e+00,\n",
      "           1.8598e+00, -1.7203e-01],\n",
      "         [ 5.0923e-01,  1.9903e-01,  7.9296e-02,  ...,  2.0408e+00,\n",
      "           7.9287e-01,  3.4219e-01],\n",
      "         [ 7.4107e-01,  2.2675e-01, -1.8223e-01,  ...,  9.4036e-01,\n",
      "           6.0434e-01,  5.8126e-02],\n",
      "         ...,\n",
      "         [-1.9386e-03,  5.6287e-02, -5.5123e-03,  ..., -8.9747e-02,\n",
      "          -2.8753e-02, -8.0889e-02],\n",
      "         [-1.6467e-02,  4.8860e-02, -1.4654e-02,  ..., -1.1192e-01,\n",
      "          -2.9802e-02, -9.0097e-02],\n",
      "         [ 1.1748e-01,  2.9027e-01,  3.0645e-02,  ...,  1.2753e-01,\n",
      "          -1.6571e-02,  8.1826e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 8.7691e-01,  7.0820e-02,  5.6339e-02,  ...,  1.5455e+00,\n",
      "           1.6600e+00,  1.9677e-01],\n",
      "         [ 1.1922e-01, -5.5075e-03,  9.3217e-02,  ...,  1.9543e+00,\n",
      "           1.0504e+00,  1.1224e-02],\n",
      "         [ 1.0008e-01, -3.1129e-01,  2.2613e-01,  ...,  1.4101e-01,\n",
      "           4.8871e-01,  5.0828e-01],\n",
      "         ...,\n",
      "         [ 3.7528e-04,  4.0105e-02, -1.4528e-02,  ..., -7.7849e-02,\n",
      "          -3.6214e-02, -8.9916e-02],\n",
      "         [-1.2738e-02,  1.2106e-01, -5.6757e-02,  ..., -4.3087e-02,\n",
      "          -3.0985e-02, -2.3461e-01],\n",
      "         [ 2.2948e-02,  1.4992e-01, -3.1586e-03,  ..., -7.5039e-02,\n",
      "          -1.1230e-01, -1.8679e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0745,  0.0044, -0.1722,  ...,  1.8871,  1.5943, -0.0419],\n",
      "         [ 1.1655,  0.0437,  0.1889,  ...,  2.0268,  0.6545,  0.4030],\n",
      "         [ 0.8651,  0.1444, -0.0547,  ...,  1.8088,  0.9284,  0.0586],\n",
      "         ...,\n",
      "         [-0.0095,  0.0686, -0.0068,  ..., -0.1045, -0.0290,  0.0193],\n",
      "         [-0.0780,  0.2525, -0.0594,  ...,  0.2712,  0.2061, -0.2077],\n",
      "         [ 0.0755, -0.0342,  0.0565,  ...,  0.0746,  0.1235, -0.2001]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  24 october 1632\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0157, -0.0073,  0.0069,  ...,  2.2420,  1.5617, -0.0585],\n",
      "         [ 0.3150,  0.1235, -0.0756,  ...,  2.7772,  0.7563,  0.1382],\n",
      "         [ 0.6393,  0.0845,  0.0436,  ...,  2.1846,  0.9555, -0.1836],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9646,  0.0483,  0.0232,  ...,  2.2332,  1.6064, -0.2231],\n",
      "         [ 0.6372,  0.1479,  0.0846,  ...,  2.4582,  0.7592, -0.0111],\n",
      "         [ 0.7375, -0.1217,  0.1929,  ...,  2.2406,  1.0070, -0.1771],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  marlboro\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9725, -0.0607, -0.0850,  ...,  2.3081,  1.5388,  0.0218],\n",
      "         [ 0.6874,  0.1544,  0.0374,  ...,  2.5267,  0.8002,  0.1451],\n",
      "         [ 0.8265,  0.4157, -0.0415,  ...,  1.5619,  0.8674, -0.0231],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9855,  0.1379,  0.0149,  ...,  2.2508,  1.4757, -0.0468],\n",
      "         [ 0.6845,  0.0236, -0.0064,  ...,  2.5813,  0.8552,  0.1173],\n",
      "         [ 0.6750,  0.0492, -0.2127,  ...,  2.2240,  0.7713, -0.0108],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ghanaian\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0300,  0.1912, -0.0049,  ...,  2.4874,  1.6061,  0.0567],\n",
      "         [ 0.5980,  0.2307,  0.0307,  ...,  2.7127,  0.8472,  0.0342],\n",
      "         [ 0.5725,  0.4537,  0.2256,  ...,  1.7928,  0.8676,  0.0390],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0846,  0.1942,  0.0060,  ...,  1.5070,  1.7418,  0.2923],\n",
      "         [ 0.0663,  0.0732,  0.0556,  ...,  1.9163,  1.0920,  0.4154],\n",
      "         [ 0.4568,  0.1046,  0.1522,  ...,  0.2236,  0.7832,  0.3394],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9938,  0.1166, -0.0366,  ...,  2.2523,  1.6207,  0.0280],\n",
      "         [ 0.6528,  0.2011,  0.0652,  ...,  2.5097,  0.9022,  0.2054],\n",
      "         [ 0.6663,  0.2109, -0.0714,  ...,  2.3547,  0.8813,  0.1572],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9221,  0.1948, -0.0928,  ...,  2.1762,  1.6397, -0.1200],\n",
      "         [ 0.5599,  0.2046,  0.0157,  ...,  2.5355,  0.9166,  0.2573],\n",
      "         [ 0.4266,  0.0525,  0.0174,  ...,  1.9298,  0.8826, -0.0145],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0521,  0.1246, -0.0353,  ...,  2.1802,  1.5649,  0.1665],\n",
      "         [ 0.2043,  0.1832,  0.0885,  ...,  2.3941,  0.9435,  0.1977],\n",
      "         [ 0.9213,  0.0239, -0.0335,  ...,  1.4328,  1.0730, -0.0077],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9525, -0.0193, -0.0316,  ...,  2.2722,  1.6713, -0.5630],\n",
      "         [ 0.8641, -0.0736,  0.0452,  ...,  2.4266,  1.0652, -0.4925],\n",
      "         [ 0.7247,  0.0534, -0.0664,  ...,  2.0814,  1.1002, -0.5341],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6757,  0.1931, -0.1657,  ...,  2.1764,  1.5568, -0.2436],\n",
      "         [ 0.4513,  0.1707,  0.0212,  ...,  2.3876,  0.7915,  0.1031],\n",
      "         [ 0.3967,  0.2400, -0.2206,  ...,  2.1255,  0.7083, -0.0643],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0636e+00,  1.4932e-01, -1.5304e-03,  ...,  2.2697e+00,\n",
      "           1.6451e+00, -3.0709e-01],\n",
      "         [ 9.6797e-01,  2.1466e-01,  1.9269e-02,  ...,  2.4389e+00,\n",
      "           1.0641e+00, -2.9433e-01],\n",
      "         [ 8.7009e-01,  2.9935e-01, -9.6472e-02,  ...,  2.3135e+00,\n",
      "           1.0467e+00, -3.7512e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3718e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3718e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3718e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.8683e-01,  1.3317e-01, -4.1906e-02,  ...,  2.3047e+00,\n",
      "           1.5812e+00, -1.9589e-03],\n",
      "         [ 4.8607e-01,  2.8618e-01,  8.8010e-02,  ...,  2.0588e+00,\n",
      "           6.9867e-01,  2.5962e-01],\n",
      "         [ 4.8103e-01,  2.6771e-01,  1.3512e-01,  ...,  1.7275e+00,\n",
      "           9.5546e-01, -7.3412e-02],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8167,  0.4460,  0.0220,  ...,  2.1395,  1.5259, -0.0717],\n",
      "         [ 0.3805,  0.2862,  0.0374,  ...,  2.4447,  0.8789, -0.1078],\n",
      "         [ 0.4972,  0.0674, -0.1436,  ...,  2.1617,  0.8152, -0.0167],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8371,  0.1801, -0.0948,  ...,  2.0583,  1.7239, -0.1552],\n",
      "         [ 0.6113,  0.2789, -0.0583,  ...,  2.3786,  0.9360,  0.1077],\n",
      "         [ 0.3530,  0.4826,  0.1485,  ...,  1.6019,  0.9075, -0.0397],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0679,  0.1231, -0.0179,  ...,  2.1349,  1.4847, -0.0716],\n",
      "         [ 0.6683,  0.1314,  0.0342,  ...,  2.4920,  0.8227,  0.1662],\n",
      "         [ 0.5531, -0.0140,  0.0805,  ...,  2.0089,  0.7951, -0.1190],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7561,  0.0846,  0.1171,  ...,  2.1329,  1.5359, -0.0570],\n",
      "         [ 0.5108,  0.1781,  0.1682,  ...,  2.5242,  0.7919,  0.2291],\n",
      "         [ 0.4867,  0.2583,  0.0193,  ...,  1.7572,  1.0098, -0.1510],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8829,  0.1644, -0.1051,  ...,  2.2462,  1.5761, -0.0962],\n",
      "         [ 0.3329,  0.2686,  0.0050,  ...,  2.7627,  0.8033, -0.0234],\n",
      "         [ 0.5380,  0.2231, -0.1556,  ...,  2.4106,  0.7590, -0.1340],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 8.6255e-01,  1.4384e-01, -7.6857e-03,  ...,  2.3250e+00,\n",
      "           1.5362e+00,  5.3321e-04],\n",
      "         [ 4.4366e-01,  9.7808e-02, -1.1565e-01,  ...,  2.5276e+00,\n",
      "           9.1826e-01,  1.0552e-01],\n",
      "         [ 4.2328e-01,  1.1230e-01, -2.8239e-01,  ...,  2.1065e+00,\n",
      "           8.6733e-01, -6.8132e-02],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wendy carlos\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8538,  0.0784,  0.1089,  ...,  2.1936,  1.5888, -0.2751],\n",
      "         [ 0.5638,  0.1448,  0.2771,  ...,  2.2887,  1.0370, -0.0417],\n",
      "         [ 0.5946,  0.2792, -0.0194,  ...,  1.9295,  1.0287, -0.1191],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1329,  0.2796, -0.1512,  ...,  2.0848,  1.6255, -0.0287],\n",
      "         [ 0.5117,  0.4076,  0.0074,  ...,  2.2193,  0.7437, -0.1030],\n",
      "         [ 0.8263,  0.0409,  0.0570,  ...,  2.1268,  1.0922, -0.1970],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9196,  0.1021, -0.0835,  ...,  2.1416,  1.6452, -0.2051],\n",
      "         [ 0.5120,  0.2104, -0.0417,  ...,  2.2824,  0.8252,  0.1528],\n",
      "         [ 0.5386,  0.2226,  0.1616,  ...,  2.2166,  1.0886,  0.1526],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  st johns\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0702,  0.1342, -0.0244,  ...,  2.2328,  1.5934,  0.0660],\n",
      "         [ 0.6982,  0.0381,  0.0941,  ...,  2.5050,  0.9729,  0.3161],\n",
      "         [ 0.7111,  0.1041, -0.0936,  ...,  1.9216,  1.1721, -0.1734],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9347,  0.1715, -0.2235,  ...,  2.2755,  1.6201, -0.3429],\n",
      "         [ 0.9543,  0.1819, -0.0685,  ...,  2.5239,  1.0228, -0.1945],\n",
      "         [ 0.7091,  0.2559,  0.0472,  ...,  2.2328,  0.8922, -0.4201],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8880, -0.2038, -0.1361,  ...,  2.3336,  1.6039, -0.0773],\n",
      "         [ 0.4920, -0.1558, -0.0205,  ...,  2.7043,  0.7725,  0.0536],\n",
      "         [ 0.3744, -0.2176,  0.0256,  ...,  2.3522,  1.0359,  0.0993],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9860,  0.3478, -0.0227,  ...,  2.1807,  1.7147, -0.0812],\n",
      "         [ 0.5456,  0.2194,  0.0950,  ...,  2.5441,  0.8712,  0.1421],\n",
      "         [ 0.5062, -0.0235,  0.0342,  ...,  1.9225,  0.9630, -0.0237],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9515,  0.0048, -0.1689,  ...,  2.0362,  1.6244, -0.1795],\n",
      "         [ 0.7964,  0.1375, -0.0661,  ...,  2.3902,  0.8342,  0.0170],\n",
      "         [ 0.4700,  0.1842,  0.1417,  ...,  1.8809,  0.8869, -0.1598],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8835,  0.2668,  0.0197,  ...,  2.2163,  1.5846, -0.0825],\n",
      "         [ 0.5298,  0.1668,  0.0668,  ...,  2.4016,  0.8612,  0.0838],\n",
      "         [ 0.4345,  0.1717,  0.0613,  ...,  1.9723,  0.6871,  0.0279],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8197,  0.1321,  0.1934,  ...,  2.1001,  1.6549,  0.1987],\n",
      "         [ 0.1726,  0.0692,  0.1266,  ...,  2.0796,  0.8562,  0.1300],\n",
      "         [ 0.5089,  0.0276,  0.1652,  ...,  1.8203,  0.7522, -0.0576],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.9655,  0.2130,  0.0538,  ...,  2.3582,  1.4929, -0.2049],\n",
      "         [ 0.6557,  0.1647,  0.1043,  ...,  2.5533,  0.6757,  0.0348],\n",
      "         [ 0.5647,  0.2040, -0.1109,  ...,  2.2336,  0.6690, -0.0757],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  essex\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9711,  0.0716, -0.1873,  ...,  2.3289,  1.6152, -0.2093],\n",
      "         [ 0.4825,  0.1457, -0.1550,  ...,  2.5135,  0.7311, -0.0884],\n",
      "         [ 0.4292,  0.0877, -0.0251,  ...,  1.9801,  0.7831, -0.0493],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1084, -0.1194, -0.3166,  ...,  2.0948,  1.7052, -0.1362],\n",
      "         [ 0.5755,  0.0771, -0.2464,  ...,  2.3666,  0.9574, -0.1222],\n",
      "         [ 0.5555, -0.0573, -0.1597,  ...,  1.9243,  0.7988, -0.3180],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7821,  0.1021,  0.0587,  ...,  1.9704,  1.5782, -0.1466],\n",
      "         [ 0.6485,  0.1352,  0.0743,  ...,  2.2754,  0.8938, -0.0190],\n",
      "         [ 0.4014,  0.0089,  0.3046,  ...,  2.0318,  1.2846, -0.3546],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8781,  0.1520, -0.1496,  ...,  2.2083,  1.5936,  0.0176],\n",
      "         [ 0.5536,  0.0129,  0.0775,  ...,  2.4363,  0.8316,  0.4193],\n",
      "         [ 0.5049, -0.0990, -0.0344,  ...,  1.9675,  0.9520,  0.3610],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.0178e-01,  7.3552e-02,  8.7736e-04,  ...,  2.2855e+00,\n",
      "           1.6973e+00, -6.5336e-02],\n",
      "         [ 5.2002e-01,  1.4634e-01,  2.7662e-02,  ...,  2.4639e+00,\n",
      "           8.2171e-01,  1.6365e-01],\n",
      "         [ 3.9382e-01,  1.1781e-01,  9.2133e-02,  ...,  2.0831e+00,\n",
      "           8.6458e-01, -1.2657e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  hollywood madam\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9307,  0.0886,  0.0734,  ...,  2.0999,  1.3536,  0.1714],\n",
      "         [ 0.7282,  0.0872, -0.0291,  ...,  2.5469,  0.8217,  0.1803],\n",
      "         [ 0.1452,  0.3178,  0.0821,  ...,  1.6078,  0.6453,  0.2969],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0456,  0.0164, -0.0556,  ...,  2.3494,  1.6011, -0.1449],\n",
      "         [ 0.6915,  0.1910,  0.0134,  ...,  2.6067,  0.8536,  0.0504],\n",
      "         [ 0.4071,  0.1508,  0.1250,  ...,  1.6125,  0.8769, -0.1281],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.9221, -0.1060, -0.1803,  ...,  2.2452,  1.5059, -0.1356],\n",
      "         [ 0.6429,  0.0587, -0.0809,  ...,  2.4488,  0.7578, -0.0532],\n",
      "         [ 0.6112, -0.0410, -0.0074,  ...,  2.6200,  0.7597, -0.3233],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0388, -0.3013, -0.1179,  ...,  1.9466,  1.6550, -0.3829],\n",
      "         [ 1.0108, -0.2777,  0.0943,  ...,  2.1920,  1.0537, -0.2519],\n",
      "         [ 0.8453, -0.0848,  0.2000,  ...,  1.8111,  0.9745, -0.5622],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8271,  0.1767, -0.3280,  ...,  2.0015,  1.5063, -0.1941],\n",
      "         [ 0.6342,  0.0162,  0.0289,  ...,  2.3100,  0.7861,  0.1340],\n",
      "         [ 0.5517,  0.0957, -0.1207,  ...,  2.0428,  0.8296,  0.0079],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.7323e-01,  8.2681e-02,  1.4200e-02,  ...,  2.1280e+00,\n",
      "           1.6396e+00, -1.5231e-01],\n",
      "         [ 6.4624e-01,  9.1106e-02,  1.1629e-01,  ...,  2.4108e+00,\n",
      "           9.2634e-01,  7.0820e-02],\n",
      "         [ 7.2685e-01, -2.0349e-02,  3.8281e-04,  ...,  1.8664e+00,\n",
      "           1.1154e+00, -1.1532e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0422,  0.1282, -0.0937,  ...,  2.0248,  1.6258,  0.1101],\n",
      "         [ 0.1342,  0.1618,  0.3599,  ...,  1.9974,  1.0025,  0.2345],\n",
      "         [ 0.7507,  0.2018,  0.2164,  ...,  1.5963,  0.9733,  0.1468],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  shane meadows\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9772,  0.0111, -0.0370,  ...,  2.0669,  1.7444, -0.1162],\n",
      "         [ 0.6123,  0.1972, -0.0165,  ...,  2.5693,  0.8879,  0.0825],\n",
      "         [ 0.5372,  0.0923, -0.0033,  ...,  2.2258,  0.7531, -0.1146],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8156,  0.4243, -0.0925,  ...,  2.0813,  1.5808,  0.1155],\n",
      "         [ 0.1287,  0.5354,  0.0623,  ...,  2.2553,  0.7064,  0.0146],\n",
      "         [ 0.8173,  0.3644, -0.0721,  ...,  2.4909,  1.0717, -0.1213],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1057,  0.1029,  0.0704,  ...,  2.2452,  1.7565, -0.3242],\n",
      "         [ 0.9524,  0.0924,  0.1714,  ...,  2.4082,  1.1017, -0.2393],\n",
      "         [ 1.0672,  0.0305,  0.2200,  ...,  2.1178,  1.2795, -0.5245],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0381,  0.2028,  0.0170,  ...,  2.3101,  1.5812, -0.0723],\n",
      "         [ 0.7583,  0.0061,  0.1062,  ...,  2.6619,  0.8983,  0.0772],\n",
      "         [ 0.8269, -0.3580,  0.1463,  ...,  2.0678,  1.1703, -0.1436],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0231,  0.0790, -0.0126,  ...,  2.2463,  1.5180, -0.0823],\n",
      "         [ 0.7860,  0.1758,  0.0783,  ...,  2.5692,  0.7733,  0.0953],\n",
      "         [ 0.6911,  0.2552, -0.1382,  ...,  2.2942,  0.6939, -0.1203],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.5106e-01,  4.9530e-04, -7.3220e-02,  ...,  2.4199e+00,\n",
      "           1.6521e+00, -5.8286e-01],\n",
      "         [ 7.5068e-01, -9.8003e-02,  1.0946e-01,  ...,  2.7157e+00,\n",
      "           9.8249e-01, -4.3131e-01],\n",
      "         [ 7.3919e-01, -5.7375e-02,  1.7177e-02,  ...,  2.4545e+00,\n",
      "           8.7284e-01, -6.6159e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9217,  0.0633,  0.0687,  ...,  2.0254,  1.4872, -0.0861],\n",
      "         [ 0.6795,  0.0400,  0.0680,  ...,  2.3327,  0.7744,  0.0947],\n",
      "         [ 0.2945,  0.1906,  0.2114,  ...,  1.8361,  0.9580, -0.2554],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.1734,  0.2505, -0.1266,  ...,  2.3876,  1.7077, -0.2087],\n",
      "         [ 1.0382,  0.2647,  0.0079,  ...,  2.6259,  1.1004, -0.1747],\n",
      "         [ 0.9782,  0.1093, -0.0271,  ...,  2.4251,  1.0285, -0.4070],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0898,  0.0819, -0.1427,  ...,  2.0851,  1.6410, -0.2044],\n",
      "         [ 0.6669,  0.3761,  0.0658,  ...,  2.1721,  0.7849,  0.0944],\n",
      "         [ 0.8893,  0.1557, -0.0702,  ...,  1.6531,  1.1811, -0.2338],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8704,  0.0249, -0.1834,  ...,  2.1835,  1.4862, -0.2112],\n",
      "         [ 0.5772, -0.0112, -0.0623,  ...,  2.3095,  0.8264,  0.0809],\n",
      "         [ 0.4850,  0.0246, -0.1246,  ...,  2.0823,  0.9697, -0.1246],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0186,  0.1721, -0.1131,  ...,  2.1768,  1.6303, -0.0461],\n",
      "         [ 0.6489,  0.2620, -0.0472,  ...,  2.5454,  0.8455,  0.0543],\n",
      "         [ 0.5505,  0.2962, -0.0307,  ...,  1.8618,  0.7423, -0.1273],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.5231e-01, -3.9829e-04,  3.7429e-02,  ...,  2.0628e+00,\n",
      "           1.5157e+00, -3.8130e-01],\n",
      "         [ 6.1560e-01,  1.5410e-01,  2.0387e-01,  ...,  2.3381e+00,\n",
      "           8.2257e-01, -7.7731e-03],\n",
      "         [ 5.8875e-01,  2.3175e-01,  3.7776e-02,  ...,  1.9541e+00,\n",
      "           7.0622e-01, -2.3819e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  munster rugby\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.8607,  0.1265, -0.2412,  ...,  1.9834,  1.4797,  0.0600],\n",
      "         [ 0.4065,  0.1023, -0.2261,  ...,  2.4859,  1.0102,  0.2601],\n",
      "         [ 0.4032, -0.5485,  0.1151,  ...,  0.9464,  1.2342,  0.0808],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8094,  0.1453, -0.0745,  ...,  2.3739,  1.6560, -0.6074],\n",
      "         [ 0.5785,  0.0335,  0.1043,  ...,  2.4864,  0.9732, -0.5007],\n",
      "         [ 0.6710,  0.0569, -0.0052,  ...,  2.3526,  0.9929, -0.6282],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9502,  0.2715, -0.1701,  ...,  2.3214,  1.3996, -0.1475],\n",
      "         [ 0.6006,  0.3215, -0.1732,  ...,  2.3202,  0.7915, -0.0441],\n",
      "         [ 0.8339,  0.2687, -0.3815,  ...,  1.8544,  1.1153, -0.5449],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.2621e-01,  2.3594e-01,  7.3575e-02,  ...,  2.1621e+00,\n",
      "           1.5973e+00, -1.6144e-01],\n",
      "         [ 2.2094e-01,  2.5790e-01,  1.3091e-01,  ...,  2.3769e+00,\n",
      "           9.3633e-01,  7.3994e-03],\n",
      "         [ 4.2141e-01,  2.2647e-01,  2.4673e-04,  ...,  2.0447e+00,\n",
      "           9.9387e-01,  1.5201e-01],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9021,  0.0940,  0.0246,  ...,  1.9866,  1.5527, -0.0532],\n",
      "         [ 0.6191,  0.2559,  0.0148,  ...,  2.2234,  0.8057,  0.0761],\n",
      "         [ 0.4082,  0.3051, -0.0994,  ...,  1.8611,  0.9526,  0.1013],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0439,  0.2776, -0.1571,  ...,  2.2432,  1.7188,  0.1707],\n",
      "         [ 0.3297,  0.4634, -0.0182,  ...,  2.2714,  0.9730,  0.3291],\n",
      "         [ 0.7416,  0.1483, -0.0654,  ...,  1.6339,  0.8190, -0.0867],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0754,  0.0952,  0.1429,  ...,  2.1200,  1.5560,  0.0112],\n",
      "         [ 0.6623,  0.1566,  0.1590,  ...,  2.4189,  0.8776,  0.1530],\n",
      "         [ 0.4996,  0.1432,  0.2882,  ...,  1.1568,  0.6841,  0.0677],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0481,  0.2147,  0.1251,  ...,  2.2918,  1.5737, -0.0238],\n",
      "         [ 0.6515,  0.1769,  0.1902,  ...,  2.6206,  0.9219,  0.0602],\n",
      "         [ 0.9383,  0.3833,  0.0673,  ...,  2.1332,  1.1108, -0.1030],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.2946e-01,  2.4574e-01, -1.2319e-01,  ...,  2.0911e+00,\n",
      "           1.6050e+00,  6.7604e-02],\n",
      "         [ 1.7962e-01,  3.5639e-01, -6.1329e-02,  ...,  2.5388e+00,\n",
      "           9.4606e-01, -1.8243e-04],\n",
      "         [ 1.7524e-01,  2.5964e-01, -1.9548e-01,  ...,  1.9720e+00,\n",
      "           9.4155e-01,  2.6343e-02],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3716e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0029e+00,  2.0839e-01, -5.2081e-02,  ...,  2.2585e+00,\n",
      "           1.6565e+00, -4.4075e-02],\n",
      "         [ 6.2405e-01,  2.6917e-01,  9.9889e-02,  ...,  2.2722e+00,\n",
      "           9.1410e-01,  1.0367e-01],\n",
      "         [ 6.3096e-01,  2.4225e-01, -1.5554e-03,  ...,  1.7790e+00,\n",
      "           1.0885e+00, -7.7188e-02],\n",
      "         ...,\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02],\n",
      "         [-1.2619e-02,  7.3738e-02, -5.3717e-03,  ..., -8.0395e-02,\n",
      "          -3.0648e-02, -9.0167e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8082,  0.2854, -0.0180,  ...,  2.1170,  1.6695,  0.0725],\n",
      "         [ 0.5559,  0.1117, -0.0235,  ...,  2.5166,  0.7756,  0.2999],\n",
      "         [ 0.7109,  0.1768, -0.0633,  ...,  2.1134,  1.0479,  0.0504],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9873,  0.0263, -0.2387,  ...,  2.0156,  1.7477,  0.0788],\n",
      "         [ 0.5957,  0.1607, -0.1279,  ...,  2.3916,  0.9533,  0.2603],\n",
      "         [ 0.7437,  0.3292, -0.2433,  ...,  1.9643,  1.0655,  0.0024],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.7312,  0.1233,  0.2440,  ...,  1.8365,  1.6639,  0.3133],\n",
      "         [ 0.3528,  0.0559, -0.2056,  ...,  2.1474,  1.0994,  0.3329],\n",
      "         [ 0.3089, -0.5223,  0.1049,  ...,  1.5389,  1.2067,  0.2158],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.5308,  0.2742, -0.1178,  ...,  1.3033,  1.6538,  0.1559],\n",
      "         [ 0.1557,  0.6470,  0.1747,  ...,  1.2971,  1.0506, -0.1375],\n",
      "         [ 0.2561,  0.3447,  0.0860,  ...,  0.7655,  0.7435, -0.4236],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0765, -0.0143, -0.3337,  ...,  2.2961,  1.6171, -0.4973],\n",
      "         [ 0.9703, -0.0046, -0.1013,  ...,  2.4903,  1.0531, -0.4432],\n",
      "         [ 0.9446,  0.0946, -0.2312,  ...,  2.2276,  0.9529, -0.6322],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9247,  0.1319, -0.0971,  ...,  2.3740,  1.5530, -0.1105],\n",
      "         [ 0.6323,  0.2102,  0.0171,  ...,  2.5647,  0.8098,  0.0529],\n",
      "         [ 0.3094,  0.4240, -0.0914,  ...,  2.1513,  0.6847, -0.1793],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1962\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9684,  0.2656, -0.1638,  ...,  2.0454,  1.6325, -0.0447],\n",
      "         [ 0.6195,  0.1864, -0.1119,  ...,  2.3217,  0.9903,  0.0287],\n",
      "         [ 0.5908,  0.2222, -0.0234,  ...,  0.3728,  0.9067, -0.2004],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0171,  0.1816, -0.0821,  ...,  2.1195,  1.6919,  0.0441],\n",
      "         [ 0.7476,  0.2322,  0.0462,  ...,  2.4302,  0.8136,  0.1102],\n",
      "         [ 0.5924,  0.2867,  0.3631,  ...,  2.4085,  1.0375,  0.0664],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0667,  0.0851, -0.0715,  ...,  2.0595,  1.6201, -0.1072],\n",
      "         [ 0.2708,  0.3889,  0.0127,  ...,  2.0828,  0.7390, -0.1332],\n",
      "         [ 0.6729,  0.2717,  0.0276,  ...,  1.2124,  0.6347, -0.1858],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.9075,  0.1558,  0.1381,  ...,  1.7741,  1.5584,  0.1594],\n",
      "         [ 0.6175,  0.1378,  0.0065,  ...,  2.5603,  0.8859,  0.0076],\n",
      "         [ 0.5500, -0.2342,  0.1311,  ...,  1.6573,  1.0332,  0.1393],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1213,  0.1903, -0.0258,  ...,  1.9404,  1.6765,  0.0122],\n",
      "         [ 0.8519,  0.2316,  0.0363,  ...,  2.3930,  0.9777,  0.1008],\n",
      "         [ 0.9559,  0.0533, -0.1009,  ...,  1.3201,  1.2410, -0.3068],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8640,  0.0811,  0.0374,  ...,  2.1741,  1.5466,  0.2298],\n",
      "         [ 0.5039,  0.0862,  0.0289,  ...,  2.3485,  0.8058,  0.2520],\n",
      "         [ 0.4135,  0.1705,  0.0828,  ...,  1.3676,  0.9234, -0.2166],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8528, -0.0683, -0.0679,  ...,  2.0949,  1.5527, -0.1289],\n",
      "         [ 0.5592, -0.0739,  0.1150,  ...,  2.1666,  0.8369,  0.0628],\n",
      "         [ 0.6815, -0.0453,  0.2478,  ...,  1.5617,  0.9558, -0.0962],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0778,  0.2210, -0.0303,  ...,  2.0745,  1.4848, -0.1442],\n",
      "         [ 0.6914,  0.1718,  0.0924,  ...,  2.5642,  0.7299,  0.0148],\n",
      "         [ 0.5691,  0.0761,  0.0638,  ...,  1.7015,  0.7440, -0.2266],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0363,  0.1034, -0.2046,  ...,  2.4116,  1.5541, -0.1260],\n",
      "         [ 0.6534,  0.2434,  0.0439,  ...,  2.7582,  0.8016,  0.1517],\n",
      "         [ 0.8340,  0.2788, -0.0332,  ...,  2.1187,  0.9513, -0.2231],\n",
      "         ...,\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902],\n",
      "         [-0.0126,  0.0737, -0.0054,  ..., -0.0804, -0.0306, -0.0902]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned 0.02223092921172516 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of avg_val_f1 in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch 00001: avg_val_f1 reached 0.02223 (best 0.02223), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_1.ckpt as top 5\n",
      "\n",
      "Epoch 00001: avg_val_f1 reached 0.02223 (best 0.02223), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_1.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_end\n",
      "before sync --> sizes:  79, 79, 79\n",
      "after sync --> sizes: 79, 79, 79\n",
      "avg_loss:  tensor(14.9075, device='cuda:0')\tavg_answer_loss:  tensor(6.1241, device='cuda:0')\tavg_type_loss:  tensor(0.1913, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5163, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.2664, device='cuda:0')\n",
      "avg_val_f1:  0.02223092921172516\tavg_val_em:  0.0\tavg_val_prec:  0.016089558884312835\tavg_val_recall:  0.0599156120155431\n",
      "avg_val_sp_sent_f1:  0.07371910916099066\tavg_val_sp_sent_em:  0.012658227848101266\tavg_val_sp_sent_prec:  0.07278481088107146\tavg_val_sp_sent_recall:  0.0801687768743008\n",
      "avg_val_joint_f1:  0.0\tavg_val_joint_em:  0.0\tavg_val_joint_prec:  0.0\tavg_val_joint_recall:  0.0\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "answer:  doug moench and don perlin\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "answer:  tokyo japan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.1998e+00,  9.4611e-02, -1.2357e-01,  ...,  2.1242e+00,\n",
      "           1.7148e+00, -1.2807e-01],\n",
      "         [ 7.8665e-01,  1.9270e-01,  4.6443e-02,  ...,  2.2539e+00,\n",
      "           5.2962e-01, -7.0882e-02],\n",
      "         [ 6.9659e-01, -1.6325e-02, -3.4199e-02,  ...,  1.7184e+00,\n",
      "           1.2021e+00, -1.5983e-01],\n",
      "         ...,\n",
      "         [-1.7515e-02,  1.0013e-01,  1.2622e-03,  ..., -8.8583e-02,\n",
      "          -3.1660e-02, -7.0477e-02],\n",
      "         [-3.9176e-03,  7.3534e-02, -1.0613e-02,  ..., -8.3869e-02,\n",
      "          -3.2809e-02, -8.2995e-02],\n",
      "         [-8.0183e-03,  7.8913e-02, -1.0563e-02,  ..., -9.4764e-02,\n",
      "          -3.2491e-02, -8.8062e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.3890e-01,  2.8173e-01,  1.8324e-01,  ...,  1.6087e+00,\n",
      "           1.7607e+00, -9.5352e-02],\n",
      "         [ 7.8913e-01,  1.2923e-01, -6.1822e-02,  ...,  2.2111e+00,\n",
      "           9.1259e-01, -5.1386e-02],\n",
      "         [ 8.8880e-01,  5.3261e-02,  1.2938e-01,  ...,  1.7831e+00,\n",
      "           1.2484e+00, -4.1611e-01],\n",
      "         ...,\n",
      "         [ 1.1579e-04,  9.6456e-02,  3.4180e-03,  ..., -7.7361e-02,\n",
      "          -1.5079e-02, -8.4391e-02],\n",
      "         [-4.6912e-02,  2.5696e-01,  1.5152e-01,  ...,  3.9321e-02,\n",
      "           4.0759e-02, -3.0185e-01],\n",
      "         [ 1.0954e-01,  2.1978e-01,  2.7369e-02,  ..., -3.5053e-01,\n",
      "           1.6565e-03,  2.5924e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0150e+00,  1.1268e-01,  9.9431e-03,  ...,  2.2824e+00,\n",
      "           1.7747e+00, -1.8820e-01],\n",
      "         [ 9.3903e-01,  8.5427e-02,  1.6769e-01,  ...,  2.3619e+00,\n",
      "           6.0800e-01, -5.4267e-02],\n",
      "         [ 4.8241e-01,  1.4334e-01,  1.4021e-01,  ...,  1.2238e+00,\n",
      "           8.3620e-01, -2.6644e-02],\n",
      "         ...,\n",
      "         [-2.3108e-04,  6.7547e-02, -7.3072e-03,  ..., -8.9924e-02,\n",
      "          -4.0975e-02, -7.1880e-02],\n",
      "         [ 7.1532e-02,  2.3487e-01, -3.5482e-01,  ..., -9.5237e-02,\n",
      "           3.2241e-02, -3.8236e-01],\n",
      "         [-2.2563e-02,  1.3018e-01, -3.8332e-02,  ..., -6.5416e-02,\n",
      "          -1.9148e-02, -2.2221e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "answer:  danny leiner\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0514,  0.2510, -0.0478,  ...,  1.9003,  0.7255, -0.0605],\n",
      "         [ 0.8617,  0.0668,  0.0892,  ...,  2.6142,  1.0982, -0.1837],\n",
      "         [ 0.5316,  0.5244, -0.1241,  ...,  2.1982,  0.9458, -0.4381],\n",
      "         ...,\n",
      "         [-0.0047,  0.0299, -0.0081,  ..., -0.0878, -0.0196, -0.0726],\n",
      "         [ 0.2843,  0.2627, -0.1828,  ..., -0.1798, -0.0965,  0.1542],\n",
      "         [ 0.6690,  0.2734, -0.0903,  ..., -0.0906,  0.1568, -0.2934]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "answer:  szombathelyi haladás\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 9.2282e-01,  1.0995e-03,  1.1031e-01,  ...,  1.9765e+00,\n",
      "           1.5123e+00, -2.3919e-01],\n",
      "         [ 8.9771e-01,  4.9357e-02,  4.9688e-02,  ...,  1.8230e+00,\n",
      "           1.1074e+00, -7.2423e-02],\n",
      "         [ 1.1544e+00, -8.8690e-02, -1.0741e-01,  ...,  2.4120e+00,\n",
      "           9.1055e-01, -5.5655e-01],\n",
      "         ...,\n",
      "         [ 6.9036e-03,  6.8971e-02, -3.7277e-03,  ..., -8.0732e-02,\n",
      "          -2.7855e-02, -8.1900e-02],\n",
      "         [ 1.4065e-02,  4.4567e-02, -2.4025e-02,  ..., -1.0936e-01,\n",
      "          -1.5765e-02, -7.9727e-03],\n",
      "         [ 7.2085e-02,  2.0615e-01,  2.6393e-02,  ..., -7.1090e-02,\n",
      "          -6.3533e-02, -2.4767e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9831,  0.1223,  0.0227,  ...,  2.1880,  1.6866, -0.2254],\n",
      "         [ 0.3062, -0.1185,  0.0406,  ...,  2.5476,  0.2186,  0.1089],\n",
      "         [ 0.5042, -0.0551, -0.2436,  ...,  1.9735,  0.6705, -0.3784],\n",
      "         ...,\n",
      "         [ 0.0888,  0.5739,  0.1791,  ..., -0.4751,  0.0693, -0.3160],\n",
      "         [ 0.0090,  0.0435, -0.0123,  ..., -0.0974, -0.0359,  0.0158],\n",
      "         [-0.0026,  0.0576, -0.0038,  ..., -0.0796, -0.0193, -0.0610]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  st johns\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0968, -0.0474,  0.1609,  ...,  2.2562,  1.0481, -0.0135],\n",
      "         [ 0.5196,  0.0802,  0.2179,  ...,  2.5817,  0.6040,  0.2244],\n",
      "         [ 1.1634,  0.0684,  0.2208,  ...,  1.0527,  0.7625,  0.1098],\n",
      "         ...,\n",
      "         [-0.0104,  0.0428, -0.0173,  ..., -0.0742, -0.0292, -0.0773],\n",
      "         [ 0.2857,  0.8501, -0.0098,  ...,  0.0210,  0.1826, -0.5857],\n",
      "         [ 0.1445,  0.3836, -0.0248,  ...,  0.1611,  0.0781, -0.3774]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1849,  0.4295, -0.1712,  ...,  0.4117,  1.5253, -0.3077],\n",
      "         [ 0.7724, -0.1296,  0.1318,  ...,  2.2113,  1.0092, -0.2271],\n",
      "         [ 0.7788,  0.2308,  0.2757,  ...,  2.2928,  1.0437, -0.1668],\n",
      "         ...,\n",
      "         [ 0.0991, -0.3435, -0.1388,  ...,  0.4770,  0.1797, -0.3447],\n",
      "         [ 0.0080,  0.0743,  0.0411,  ..., -0.0726, -0.0349,  0.0085],\n",
      "         [-0.0166,  0.0705, -0.0037,  ..., -0.1099, -0.0295, -0.0827]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3680e+00, -1.7817e-01, -1.1386e-01,  ...,  1.9056e+00,\n",
      "           1.3888e+00, -2.5035e-01],\n",
      "         [ 9.6188e-01, -1.0420e-04,  4.0997e-02,  ...,  1.4362e+00,\n",
      "           9.5479e-01, -2.5026e-01],\n",
      "         [ 8.0660e-01,  2.7117e-02,  2.1798e-02,  ...,  1.5980e+00,\n",
      "           6.8658e-01, -1.2696e-01],\n",
      "         ...,\n",
      "         [ 1.3035e-01,  2.0282e-01, -1.6195e-01,  ..., -1.6540e-02,\n",
      "           1.8594e-01, -2.9500e-01],\n",
      "         [ 4.5843e-03,  5.2002e-02, -1.5141e-03,  ..., -6.6352e-02,\n",
      "          -2.6672e-02, -1.0612e-01],\n",
      "         [-1.7001e-02,  7.0121e-02, -1.4106e-02,  ..., -9.0528e-02,\n",
      "          -3.5649e-02, -8.0082e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.8774,  0.2411, -0.1014,  ...,  1.7946,  1.4012,  0.2128],\n",
      "         [ 0.3664,  0.0118, -0.1391,  ...,  2.5643,  0.9163,  0.2373],\n",
      "         [ 0.3532, -0.3548, -0.2201,  ...,  1.2223,  1.1747,  0.1367],\n",
      "         ...,\n",
      "         [-0.0050,  0.0503, -0.0028,  ..., -0.0750, -0.0199, -0.1123],\n",
      "         [-0.0098,  0.0798, -0.0184,  ..., -0.1091, -0.0248, -0.0997],\n",
      "         [-0.0084,  0.0709, -0.0056,  ..., -0.0763, -0.0324, -0.0895]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  munster rugby\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9073, -0.2340, -0.0230,  ...,  2.0184,  1.1660, -0.5084],\n",
      "         [ 0.8162,  0.0244, -0.0507,  ...,  2.1225,  0.8235,  0.1257],\n",
      "         [ 0.5332, -0.1208,  0.1800,  ...,  1.7329,  1.1090, -0.2185],\n",
      "         ...,\n",
      "         [-0.0585,  0.1536, -0.0872,  ..., -0.0392,  0.0079, -0.2492],\n",
      "         [-0.0271,  0.1759, -0.0536,  ..., -0.0732, -0.0773, -0.0317],\n",
      "         [ 0.0569,  0.1572, -0.0033,  ..., -0.1481,  0.1248, -0.3021]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1776e+00, -9.6950e-02, -1.2520e-02,  ...,  2.0073e+00,\n",
      "           9.3297e-01,  3.8382e-02],\n",
      "         [ 8.2411e-01,  1.9673e-01,  1.4979e-01,  ...,  2.1305e+00,\n",
      "           3.6712e-01,  1.3500e-01],\n",
      "         [ 9.4264e-01, -6.2855e-02,  1.2424e-01,  ...,  1.6916e+00,\n",
      "           9.9730e-01, -4.1354e-01],\n",
      "         ...,\n",
      "         [-7.5517e-03,  3.7952e-02, -8.8171e-04,  ..., -1.1764e-01,\n",
      "          -2.7527e-02, -7.8480e-02],\n",
      "         [-1.7148e-02,  1.0454e-01, -5.8473e-03,  ..., -7.8999e-02,\n",
      "          -3.1420e-02, -8.2419e-02],\n",
      "         [-1.2762e-02,  5.6490e-02, -6.7673e-03,  ..., -7.5070e-02,\n",
      "          -3.1227e-02, -8.3239e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.3574e-01, -2.1618e-01,  1.4469e-01,  ...,  2.3960e+00,\n",
      "           1.4629e+00,  6.2924e-02],\n",
      "         [ 9.5730e-01,  7.3273e-02,  3.9034e-02,  ...,  2.7530e+00,\n",
      "           4.4188e-01, -1.5334e-01],\n",
      "         [ 7.1199e-01, -7.4558e-02, -5.2728e-02,  ...,  1.1030e+00,\n",
      "           8.7457e-01, -2.9271e-01],\n",
      "         ...,\n",
      "         [-7.8987e-03,  5.9175e-02,  6.2065e-04,  ..., -7.1405e-02,\n",
      "          -9.4245e-03, -7.4776e-02],\n",
      "         [ 1.9401e-02,  8.7497e-02, -5.6377e-02,  ..., -1.1577e-01,\n",
      "          -8.7975e-03, -2.0513e-01],\n",
      "         [-2.9306e-02,  1.1155e-01,  1.5241e-02,  ..., -3.7606e-02,\n",
      "          -3.2100e-02, -7.3152e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3540e+00,  5.3905e-02, -1.8747e-01,  ...,  2.3450e+00,\n",
      "           1.2807e+00, -1.0218e-01],\n",
      "         [ 7.2489e-01, -1.2087e-01,  4.6645e-02,  ...,  2.5025e+00,\n",
      "           4.7099e-01,  1.6110e-01],\n",
      "         [ 7.0976e-02, -6.2814e-02,  2.9095e-03,  ...,  2.2112e+00,\n",
      "           3.8982e-01, -7.4436e-01],\n",
      "         ...,\n",
      "         [-4.0820e-02,  1.6681e-01,  8.3945e-02,  ..., -9.4381e-02,\n",
      "          -5.0748e-02,  1.9318e-02],\n",
      "         [-1.8684e-03,  5.5666e-02, -1.5774e-02,  ..., -7.5381e-02,\n",
      "          -2.6689e-02, -1.1123e-01],\n",
      "         [-9.2911e-03,  6.9169e-02, -8.5387e-03,  ..., -8.2533e-02,\n",
      "          -2.8044e-02, -7.3047e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 1.2948,  0.3350, -0.0638,  ...,  0.6089,  0.5052, -0.0980],\n",
      "         [ 0.7964, -0.1476, -0.0131,  ...,  2.3356,  0.7630,  0.1991],\n",
      "         [ 0.7846,  0.0709, -0.0530,  ...,  1.8711,  0.5730, -0.0412],\n",
      "         ...,\n",
      "         [-0.0311,  0.4331, -0.0902,  ..., -0.1227,  0.1991, -0.0533],\n",
      "         [-0.0117,  0.0960, -0.0061,  ..., -0.1161, -0.0341, -0.0864],\n",
      "         [ 0.0355,  0.7742, -0.0598,  ..., -0.6944,  0.3113, -0.3587]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0155e+00, -1.0688e-01, -2.7865e-01,  ...,  2.2793e+00,\n",
      "           1.1051e+00,  1.4748e-01],\n",
      "         [ 7.8157e-01, -1.9358e-01, -1.0991e-01,  ...,  2.7499e+00,\n",
      "           7.0201e-01,  6.8918e-02],\n",
      "         [ 7.6714e-01, -3.0302e-01,  2.1325e-01,  ...,  2.1804e+00,\n",
      "           8.8604e-01,  1.0092e-01],\n",
      "         ...,\n",
      "         [ 5.9507e-03,  5.2366e-02, -1.0825e-03,  ..., -8.6866e-02,\n",
      "          -1.4194e-02, -7.2646e-02],\n",
      "         [-1.6326e-02,  6.9089e-02, -6.3144e-04,  ..., -8.5425e-02,\n",
      "          -3.9016e-02, -8.5944e-02],\n",
      "         [-1.6031e-02,  6.3238e-02, -5.0705e-03,  ..., -7.3769e-02,\n",
      "          -1.0937e-02, -7.8272e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1829, -0.0963, -0.1704,  ...,  2.1021,  0.8136,  0.2571],\n",
      "         [ 0.7910, -0.0206,  0.3780,  ...,  2.3528,  0.9130,  0.1496],\n",
      "         [ 1.1512, -0.6278,  0.0341,  ...,  0.5567,  1.3599,  0.2893],\n",
      "         ...,\n",
      "         [ 0.0222,  0.0574,  0.0030,  ..., -0.0783, -0.0106, -0.0577],\n",
      "         [ 0.0103,  0.0665,  0.0040,  ..., -0.0723, -0.0259,  0.0119],\n",
      "         [-0.0132,  0.0727,  0.0065,  ..., -0.0905, -0.0321, -0.0873]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9548, -0.0976, -0.0527,  ...,  2.1313,  1.1748, -0.1782],\n",
      "         [ 0.8586, -0.3749,  0.2115,  ...,  2.0917,  0.5198, -0.0767],\n",
      "         [ 0.8107, -0.0517,  0.2709,  ...,  1.7276,  0.5991,  0.3890],\n",
      "         ...,\n",
      "         [-0.0158,  0.0702, -0.0062,  ..., -0.1106, -0.0309, -0.0637],\n",
      "         [ 0.0103,  0.0965, -0.0100,  ..., -0.0724, -0.0295, -0.0794],\n",
      "         [-0.0112,  0.0665, -0.0118,  ..., -0.1124, -0.0174, -0.0789]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0706, -0.1740, -0.0070,  ...,  2.2278,  0.8494, -0.4564],\n",
      "         [ 0.7876,  0.0718,  0.2668,  ...,  2.3060,  0.8998,  0.3426],\n",
      "         [ 0.3656, -0.0694,  0.0945,  ...,  2.6680,  0.8572, -0.2772],\n",
      "         ...,\n",
      "         [-0.0143,  0.1441,  0.0181,  ..., -0.1038, -0.0542, -0.0568],\n",
      "         [-0.0045,  0.0697, -0.0044,  ..., -0.0831, -0.0306, -0.0776],\n",
      "         [-0.0067,  0.0944,  0.0094,  ..., -0.0763, -0.0290, -0.0814]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1976 to 2009\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 6.9575e-01,  4.5441e-02, -1.1458e-01,  ...,  1.6458e+00,\n",
      "           1.5662e+00,  9.6446e-02],\n",
      "         [ 6.5105e-02,  2.3393e-01,  1.4095e-01,  ...,  1.9263e+00,\n",
      "           6.9923e-01,  7.6907e-02],\n",
      "         [ 6.1869e-01, -1.1061e-01,  2.1475e-02,  ...,  1.9846e+00,\n",
      "           4.6835e-01,  1.0740e-01],\n",
      "         ...,\n",
      "         [-2.8653e-03,  7.2342e-02, -7.5918e-03,  ..., -8.5639e-02,\n",
      "          -2.8887e-02, -7.6046e-02],\n",
      "         [-1.3013e-02,  4.1118e-02,  1.2056e-03,  ..., -7.0609e-02,\n",
      "          -2.0609e-02, -7.7296e-02],\n",
      "         [-2.0333e-02,  7.0979e-02,  2.8870e-03,  ..., -6.9722e-02,\n",
      "          -2.8419e-02, -7.8923e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  magnolia pictures\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0164e+00, -5.2439e-02, -2.1278e-01,  ...,  1.4609e+00,\n",
      "           1.0920e+00,  2.1322e-01],\n",
      "         [ 4.4760e-01,  1.0345e-01,  2.6820e-01,  ...,  7.9492e-01,\n",
      "           7.3210e-01,  3.7417e-02],\n",
      "         [ 7.4972e-01, -3.0230e-01, -5.0723e-02,  ...,  1.6726e+00,\n",
      "           9.0730e-01,  1.0764e-01],\n",
      "         ...,\n",
      "         [-1.3803e-02,  6.9417e-02,  4.2319e-03,  ..., -7.4071e-02,\n",
      "          -3.8129e-02, -8.3391e-02],\n",
      "         [-1.2566e-02,  7.4497e-02, -4.0891e-03,  ..., -8.1738e-02,\n",
      "          -2.9000e-02, -9.8077e-02],\n",
      "         [-2.5121e-02,  1.3527e-01,  2.4063e-02,  ..., -3.7633e-02,\n",
      "           3.9681e-04, -1.7978e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 7.7110e-01, -2.7809e-01,  4.7460e-01,  ...,  3.6229e-01,\n",
      "           1.0393e+00, -4.4584e-01],\n",
      "         [ 9.2902e-01, -1.2611e-01,  4.5849e-01,  ...,  1.5341e+00,\n",
      "           7.3260e-01, -6.0464e-01],\n",
      "         [ 7.6455e-01,  9.3618e-04,  2.3760e-01,  ...,  1.3648e+00,\n",
      "           3.1032e-01, -5.1623e-01],\n",
      "         ...,\n",
      "         [ 2.5460e-02,  1.9406e-01,  5.9214e-02,  ..., -9.1707e-02,\n",
      "          -5.9973e-02, -2.9592e-02],\n",
      "         [-6.8839e-03,  6.2485e-02, -2.6729e-03,  ..., -9.6291e-02,\n",
      "          -1.1189e-02, -9.0491e-02],\n",
      "         [-1.1039e-02,  7.2105e-02, -1.2851e-02,  ..., -8.1390e-02,\n",
      "          -3.4885e-02, -8.2761e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2063, -0.2500,  0.1001,  ...,  2.0633,  1.4793,  0.0272],\n",
      "         [ 0.6894, -0.2845,  0.1379,  ...,  2.5363,  0.4441, -0.5834],\n",
      "         [ 0.4844, -0.2267, -0.0181,  ...,  1.6643,  0.7989,  0.1024],\n",
      "         ...,\n",
      "         [-0.0160,  0.0687, -0.0085,  ..., -0.0836, -0.0458, -0.0738],\n",
      "         [ 0.1744,  0.1314, -0.0469,  ..., -0.0468,  0.0493, -0.2210],\n",
      "         [ 0.2639,  0.1164,  0.0913,  ...,  0.0478,  0.1744, -0.5869]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0050e+00, -9.4298e-02,  3.1759e-02,  ...,  1.4286e+00,\n",
      "           1.5280e+00, -1.6373e-01],\n",
      "         [ 6.5384e-01,  1.7303e-02,  7.3207e-02,  ...,  1.8055e+00,\n",
      "           1.0315e+00,  2.1775e-01],\n",
      "         [ 6.0781e-01, -2.9282e-01,  3.3518e-01,  ...,  1.8324e+00,\n",
      "           1.3179e+00,  1.2567e-01],\n",
      "         ...,\n",
      "         [-5.7276e-02,  1.0085e-01, -3.2581e-04,  ..., -4.9936e-02,\n",
      "          -3.6276e-02, -2.0575e-01],\n",
      "         [-2.2431e-02,  7.2189e-02, -3.3930e-03,  ..., -8.7709e-02,\n",
      "          -3.4346e-02, -6.3873e-02],\n",
      "         [-4.5830e-03,  7.0189e-02,  4.4156e-03,  ..., -8.7962e-02,\n",
      "          -2.6623e-02, -8.4497e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.9289e-01, -3.3794e-01, -3.3591e-03,  ...,  2.2413e+00,\n",
      "           1.0931e+00, -3.3386e-01],\n",
      "         [ 7.3754e-01, -1.4965e-01,  5.4772e-01,  ...,  2.2927e+00,\n",
      "           5.1335e-01,  5.3817e-01],\n",
      "         [ 6.2510e-01, -3.1485e-01,  1.2224e-01,  ...,  2.3260e+00,\n",
      "           6.9458e-01,  2.5114e-01],\n",
      "         ...,\n",
      "         [ 4.9123e-02, -1.6901e-01, -5.0467e-02,  ...,  5.7476e-01,\n",
      "           1.8133e-01, -2.1333e-01],\n",
      "         [-7.4263e-03,  8.1024e-02, -7.9314e-03,  ..., -7.6606e-02,\n",
      "          -3.4045e-02, -8.4043e-02],\n",
      "         [-7.8184e-04,  7.0578e-02, -6.1053e-03,  ..., -9.1749e-02,\n",
      "          -3.2622e-02, -8.8865e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0542, -0.2226,  0.1517,  ...,  0.2449,  0.9473,  0.0383],\n",
      "         [ 0.9756, -0.1148,  0.1933,  ...,  1.9523,  0.9145, -0.0400],\n",
      "         [ 1.0118, -0.3150,  0.2252,  ...,  2.2698,  0.9256, -0.0568],\n",
      "         ...,\n",
      "         [-0.0201,  0.0601, -0.0087,  ..., -0.0827, -0.0327, -0.0970],\n",
      "         [-0.0085,  0.0400, -0.0059,  ..., -0.0861, -0.0235, -0.0825],\n",
      "         [ 0.0063,  0.0645, -0.0136,  ..., -0.0919, -0.0204, -0.0745]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0882e+00, -5.4034e-01,  8.9390e-02,  ...,  1.9791e+00,\n",
      "           1.1806e+00, -1.1785e-01],\n",
      "         [ 7.9310e-01, -3.0471e-01,  2.9082e-01,  ...,  8.8963e-01,\n",
      "           5.4416e-01, -3.1192e-01],\n",
      "         [ 9.0172e-01, -2.8044e-01,  1.6274e-01,  ...,  2.2984e+00,\n",
      "           1.0481e+00, -1.6255e-01],\n",
      "         ...,\n",
      "         [ 8.0358e-02,  1.2774e-01, -2.8372e-02,  ..., -1.3507e-01,\n",
      "           4.2991e-02, -8.2263e-03],\n",
      "         [-1.5820e-02,  5.6003e-02,  1.0384e-02,  ..., -9.0351e-02,\n",
      "          -2.9860e-02,  1.6773e-02],\n",
      "         [ 2.5322e-03,  7.0012e-02, -2.2042e-03,  ..., -7.7581e-02,\n",
      "          -3.2359e-02, -7.1099e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8754,  0.2227,  0.1119,  ...,  0.5481,  1.6157, -0.1014],\n",
      "         [ 0.6849, -0.1388,  0.0683,  ...,  2.1967,  1.0340,  0.0998],\n",
      "         [ 0.7904, -0.3320, -0.0141,  ...,  0.6822,  0.7091, -0.0267],\n",
      "         ...,\n",
      "         [ 0.0039,  0.0505, -0.0053,  ..., -0.1148, -0.0150, -0.0631],\n",
      "         [-0.0105,  0.0734, -0.0043,  ..., -0.0855, -0.0293, -0.0879],\n",
      "         [-0.0037,  0.0669, -0.0053,  ..., -0.0770, -0.0239, -0.0773]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8654, -0.4875, -0.0228,  ...,  1.5981,  0.8546,  0.0362],\n",
      "         [ 0.8670, -0.5398,  0.3855,  ...,  2.0770,  0.9677, -0.1716],\n",
      "         [ 1.1026, -0.5328, -0.0249,  ...,  2.1431,  1.0268, -0.1463],\n",
      "         ...,\n",
      "         [-0.0091,  0.0849,  0.0264,  ..., -0.0536,  0.0079, -0.1895],\n",
      "         [-0.1226,  0.1256, -0.2673,  ...,  0.2665, -0.0835, -0.4702],\n",
      "         [-0.0126,  0.0666, -0.0103,  ..., -0.0794, -0.0319, -0.0714]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2126e+00, -4.0793e-02, -1.3702e-01,  ...,  1.9475e+00,\n",
      "           7.9357e-01,  1.5582e-01],\n",
      "         [ 8.5975e-01, -1.4736e-01,  2.7057e-01,  ...,  2.4031e+00,\n",
      "           4.7153e-01,  2.4673e-01],\n",
      "         [ 9.2332e-02, -1.3506e-01,  1.3177e-01,  ...,  1.5227e+00,\n",
      "           4.4892e-01, -3.6649e-01],\n",
      "         ...,\n",
      "         [-1.1669e-01,  5.0591e-01,  3.5515e-02,  ..., -4.8153e-01,\n",
      "           1.0601e-01,  7.2887e-02],\n",
      "         [-1.0710e-02,  5.7940e-02, -1.7495e-03,  ..., -1.1321e-01,\n",
      "          -3.2290e-02,  1.5238e-02],\n",
      "         [-2.3509e-01,  2.7387e-01,  2.2574e-02,  ..., -1.3680e-01,\n",
      "           1.7381e-01, -8.6720e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 1.1700e+00, -3.9562e-01,  8.5444e-03,  ...,  1.6464e+00,\n",
      "           1.4633e+00, -3.8970e-02],\n",
      "         [ 8.8468e-01, -4.1631e-01,  2.2023e-02,  ...,  2.0022e+00,\n",
      "           8.9024e-01,  1.4550e-01],\n",
      "         [ 6.4513e-01, -3.6382e-01,  1.8066e-01,  ...,  2.2020e+00,\n",
      "           9.4504e-01, -2.3692e-01],\n",
      "         ...,\n",
      "         [-1.1939e-02,  6.0449e-02,  6.8194e-04,  ..., -7.9142e-02,\n",
      "          -2.4787e-02, -8.7821e-02],\n",
      "         [-2.7809e-04,  6.5676e-02, -5.0577e-03,  ..., -8.0595e-02,\n",
      "          -2.1447e-02, -7.4847e-02],\n",
      "         [-9.9840e-03,  6.8698e-02,  1.3402e-02,  ..., -8.6700e-02,\n",
      "          -1.8779e-02, -7.0810e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)answer:  eric of pomerania\n",
      "\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0801, -0.1781,  0.3038,  ...,  2.1388,  1.2633,  0.3043],\n",
      "         [ 0.6516, -0.0443,  0.3353,  ...,  2.2463,  1.1350,  0.4934],\n",
      "         [ 0.7173, -0.3224,  0.2505,  ..., -0.2147,  1.0515, -0.3893],\n",
      "         ...,\n",
      "         [ 0.0118,  0.1063,  0.0465,  ..., -0.0585, -0.0437, -0.1891],\n",
      "         [ 0.4646,  0.3036, -0.0553,  ..., -0.0756,  0.3508, -0.0967],\n",
      "         [ 0.1624,  0.2476, -0.6155,  ...,  0.1271,  0.2984, -0.1469]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2142e+00, -3.2262e-01,  9.7836e-02,  ...,  1.9334e+00,\n",
      "           1.6495e+00,  2.7158e-01],\n",
      "         [ 1.0063e+00, -2.4956e-01,  2.4036e-01,  ...,  2.4355e+00,\n",
      "           8.0228e-01,  2.8975e-01],\n",
      "         [ 7.9611e-01, -2.9276e-01,  5.2330e-02,  ...,  1.8578e+00,\n",
      "           1.3260e+00,  3.0988e-02],\n",
      "         ...,\n",
      "         [-2.2285e-03,  6.6467e-02,  5.7838e-03,  ..., -1.2270e-01,\n",
      "          -1.6449e-02, -8.4912e-02],\n",
      "         [-5.8858e-03,  7.1497e-02, -4.9044e-03,  ..., -8.6547e-02,\n",
      "          -1.6098e-02, -8.1913e-02],\n",
      "         [-2.0187e-02,  5.1210e-02, -2.6604e-03,  ..., -8.5535e-02,\n",
      "          -1.6220e-02, -6.7869e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0557e+00, -1.0229e-01,  1.6602e-01,  ...,  1.7169e+00,\n",
      "           1.2727e+00,  4.1169e-01],\n",
      "         [ 1.7771e-01, -1.7786e-01,  4.0454e-01,  ...,  2.0629e+00,\n",
      "           4.7760e-01,  2.6999e-01],\n",
      "         [ 4.6823e-01, -9.3748e-03,  4.9026e-01,  ...,  1.0777e+00,\n",
      "           5.0104e-01, -6.0354e-02],\n",
      "         ...,\n",
      "         [-1.7037e-02,  6.8144e-02, -1.7534e-02,  ..., -7.9729e-02,\n",
      "          -4.8298e-02, -8.0926e-02],\n",
      "         [-5.3307e-03,  8.4936e-02, -3.9901e-04,  ..., -1.1576e-01,\n",
      "          -3.5987e-02, -6.9638e-02],\n",
      "         [-1.5045e-02,  7.1714e-02, -3.8940e-03,  ..., -8.8132e-02,\n",
      "          -3.4387e-02, -1.0462e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8898, -0.5216,  0.0580,  ...,  1.7746,  0.8274,  0.7550],\n",
      "         [ 0.9991, -0.2858,  0.0578,  ...,  2.1932,  0.7679, -0.1545],\n",
      "         [ 0.5208, -0.2064,  0.3336,  ...,  1.6742,  0.9690, -0.1877],\n",
      "         ...,\n",
      "         [-0.0063,  0.0372,  0.0036,  ..., -0.0735, -0.0237, -0.0755],\n",
      "         [-0.1056,  0.3133,  0.1970,  ...,  0.2476,  0.0130, -0.1388],\n",
      "         [ 0.0122,  0.0733, -0.0036,  ..., -0.0746, -0.0166, -0.0842]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2334e+00, -3.8544e-01,  3.0283e-01,  ...,  1.7049e+00,\n",
      "           1.1422e+00, -1.9878e-03],\n",
      "         [ 9.2931e-01, -6.6070e-02,  4.2356e-01,  ...,  2.2695e+00,\n",
      "           8.5918e-01,  1.5618e-01],\n",
      "         [ 5.9695e-01, -3.7675e-01,  3.7472e-01,  ...,  1.7927e+00,\n",
      "           9.4533e-01, -3.1231e-02],\n",
      "         ...,\n",
      "         [-8.2441e-03,  6.5656e-02,  2.5402e-03,  ..., -7.9841e-02,\n",
      "          -2.6045e-02, -8.8231e-02],\n",
      "         [-9.2247e-03,  2.3821e-02,  8.1519e-03,  ..., -8.5255e-02,\n",
      "          -2.2754e-02, -7.5706e-02],\n",
      "         [-1.3854e-02,  6.8275e-02, -1.0478e-02,  ..., -8.5929e-02,\n",
      "          -3.1769e-02, -9.3056e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  1962\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0576e+00,  1.4302e-01,  1.7623e-01,  ...,  1.9086e+00,\n",
      "           1.4556e+00, -2.1073e-02],\n",
      "         [ 3.2016e-01, -1.0528e-01,  2.0152e-01,  ...,  2.7372e+00,\n",
      "           7.1541e-01,  7.5015e-02],\n",
      "         [ 7.0881e-01, -2.6846e-01,  3.7322e-02,  ...,  1.9177e+00,\n",
      "           8.6393e-01,  2.9953e-01],\n",
      "         ...,\n",
      "         [-5.5624e-02,  1.1231e-01,  7.0610e-02,  ..., -1.7859e-02,\n",
      "          -6.1876e-03, -2.0681e-01],\n",
      "         [-9.9059e-03,  9.7754e-02, -1.5034e-03,  ..., -8.0234e-02,\n",
      "          -3.5907e-02, -6.6191e-02],\n",
      "         [-1.1325e-02,  6.6563e-02, -3.0937e-04,  ..., -7.6861e-02,\n",
      "          -3.1286e-02, -8.8759e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7963, -0.0246,  0.3541,  ...,  2.0627,  1.2345, -0.1922],\n",
      "         [ 0.2281,  0.1218,  0.0916,  ...,  1.8746,  0.5729,  0.7009],\n",
      "         [-0.1372,  0.1380,  0.3179,  ...,  1.4908,  0.7180,  0.1483],\n",
      "         ...,\n",
      "         [-0.0102,  0.0735, -0.0024,  ..., -0.0749, -0.0328, -0.0790],\n",
      "         [-0.0085,  0.1183,  0.1194,  ..., -0.0530, -0.0068, -0.2472],\n",
      "         [ 0.1338,  0.0688, -0.1634,  ...,  0.2437,  0.0806, -0.4740]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1867e+00, -2.2396e-01,  2.4004e-01,  ...,  2.1045e+00,\n",
      "           1.4513e+00,  3.7992e-02],\n",
      "         [ 1.8129e-01, -1.1477e-01,  6.4243e-01,  ...,  2.1492e+00,\n",
      "           9.0981e-01,  2.3898e-01],\n",
      "         [ 7.7851e-01, -1.0273e-02,  3.9925e-01,  ...,  2.0725e+00,\n",
      "           7.5346e-01,  1.2369e-01],\n",
      "         ...,\n",
      "         [ 9.7852e-03,  6.9474e-02, -5.4349e-03,  ..., -7.8030e-02,\n",
      "          -3.3839e-02, -8.0373e-02],\n",
      "         [-1.1212e-02,  4.2791e-02,  1.3839e-03,  ..., -9.7873e-02,\n",
      "          -3.4293e-02, -9.1602e-02],\n",
      "         [-1.7924e-02,  7.8786e-02,  6.1754e-03,  ..., -8.3038e-02,\n",
      "          -3.0899e-02, -9.8705e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0539e+00, -2.4803e-01, -1.2479e-02,  ...,  1.7797e+00,\n",
      "           1.2016e+00,  3.2416e-01],\n",
      "         [ 7.3462e-01, -2.3520e-01,  1.4859e-01,  ...,  2.4731e+00,\n",
      "           7.3021e-01,  3.9769e-01],\n",
      "         [ 8.0316e-01, -2.4049e-01,  4.5870e-01,  ...,  2.2280e+00,\n",
      "           4.4352e-01, -1.0207e-01],\n",
      "         ...,\n",
      "         [-6.0776e-03,  4.0286e-02, -1.8385e-03,  ..., -8.3054e-02,\n",
      "          -2.3135e-02,  1.4263e-02],\n",
      "         [ 5.8778e-03,  4.9426e-01,  9.0734e-02,  ...,  1.6671e-01,\n",
      "           3.5398e-01, -3.2103e-01],\n",
      "         [-1.3772e-02,  9.7781e-02,  5.4059e-04,  ..., -8.0976e-02,\n",
      "          -3.0273e-02, -7.9110e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1226, -0.2472,  0.2893,  ...,  0.3333,  1.2079, -0.2813],\n",
      "         [ 0.1971,  0.0454,  0.4479,  ...,  2.4580,  0.7393,  0.9758],\n",
      "         [ 0.9384, -0.6191,  0.4616,  ...,  1.7042,  1.1186,  0.3700],\n",
      "         ...,\n",
      "         [-0.0134,  0.1494,  0.0092,  ..., -0.1173, -0.0063, -0.2070],\n",
      "         [-0.0307,  0.0916, -0.0079,  ..., -0.0683, -0.0432, -0.0836],\n",
      "         [ 0.1428,  0.5696, -0.2145,  ..., -0.1975, -0.0176, -0.4988]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.2601e+00, -4.0265e-01,  9.7198e-02,  ...,  2.0197e+00,\n",
      "           1.3617e+00,  6.5844e-02],\n",
      "         [ 8.7501e-01, -5.1059e-01,  1.6457e-01,  ...,  2.3676e+00,\n",
      "           7.0738e-01,  1.0857e-01],\n",
      "         [ 1.0249e-03,  1.9376e-01, -5.8698e-02,  ...,  1.2515e+00,\n",
      "           4.9826e-01, -4.3156e-01],\n",
      "         ...,\n",
      "         [-1.6966e-02,  9.6223e-02,  7.5487e-03,  ..., -7.4857e-02,\n",
      "          -2.8528e-02, -7.5711e-02],\n",
      "         [-7.5104e-03,  6.1455e-02, -4.6973e-03,  ..., -8.4932e-02,\n",
      "          -2.1891e-02, -7.5629e-02],\n",
      "         [ 1.0854e-01,  2.3750e-01,  1.7490e-03,  ...,  3.7757e-01,\n",
      "           4.2750e-02, -2.8101e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3834e+00,  1.0803e-01, -1.6475e-02,  ...,  2.1572e+00,\n",
      "           1.4855e+00, -4.9912e-02],\n",
      "         [ 9.2094e-01, -2.8352e-01,  2.6066e-01,  ...,  1.9457e+00,\n",
      "           6.5688e-01,  1.0496e-01],\n",
      "         [ 1.0802e+00, -5.5152e-01,  1.4150e-01,  ...,  1.6775e+00,\n",
      "           1.1208e+00, -1.2587e-01],\n",
      "         ...,\n",
      "         [-3.0372e-03,  2.4098e-01, -2.4690e-02,  ..., -1.1145e-01,\n",
      "          -2.2772e-03, -2.1992e-02],\n",
      "         [-1.8220e-02,  6.2316e-02, -1.6212e-02,  ..., -8.0208e-02,\n",
      "          -3.5595e-02,  3.3155e-02],\n",
      "         [-1.9157e-01,  4.0641e-01, -4.1297e-04,  ..., -1.3378e-01,\n",
      "          -5.5360e-02,  2.7121e-03]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "answer:  ring\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0631e+00,  2.1826e-02,  2.6445e-01,  ...,  1.9913e+00,\n",
      "           1.4363e+00, -5.2183e-02],\n",
      "         [ 1.5096e-01, -2.0847e-01,  4.0140e-01,  ...,  4.8685e-01,\n",
      "           7.9978e-01,  6.1522e-02],\n",
      "         [ 8.6092e-01, -5.5390e-01, -2.6715e-02,  ...,  2.0052e+00,\n",
      "           1.2894e+00, -1.5002e-01],\n",
      "         ...,\n",
      "         [-1.5380e-04,  6.7257e-02,  3.9591e-03,  ..., -8.0609e-02,\n",
      "          -2.1364e-02, -7.9129e-02],\n",
      "         [-6.3246e-03,  7.3815e-02, -5.4636e-03,  ..., -1.1410e-01,\n",
      "          -3.1401e-02, -7.6669e-02],\n",
      "         [ 6.1531e-02,  1.9735e-01,  6.5640e-02,  ..., -5.9776e-02,\n",
      "          -2.3836e-02, -7.6257e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.5385e+00, -1.6265e-01,  1.2756e-01,  ...,  2.0788e+00,\n",
      "           8.6572e-01,  1.4585e-01],\n",
      "         [ 6.6456e-01,  2.1811e-02,  2.9127e-01,  ...,  2.2930e+00,\n",
      "           9.8208e-01,  2.7235e-01],\n",
      "         [ 1.4349e+00, -3.7727e-01,  1.7858e-01,  ...,  1.8450e+00,\n",
      "           8.5336e-01, -4.7625e-01],\n",
      "         ...,\n",
      "         [ 1.0903e-02,  8.3410e-02, -1.1386e-02,  ..., -7.5010e-02,\n",
      "          -3.4969e-02, -8.4653e-02],\n",
      "         [-8.8980e-03,  7.1455e-02, -1.0562e-02,  ..., -7.4040e-02,\n",
      "          -4.2886e-02, -8.8648e-02],\n",
      "         [-1.3110e-02,  8.6864e-02, -1.5186e-03,  ..., -6.1651e-02,\n",
      "          -4.0127e-02,  1.2288e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4260,  0.0972, -0.1559,  ...,  2.0478,  1.3582,  0.1868],\n",
      "         [ 1.1294, -0.2507,  0.2200,  ...,  2.1748,  0.7185,  0.2245],\n",
      "         [ 0.6608, -0.0921,  0.6265,  ...,  1.3999,  0.7474,  0.0883],\n",
      "         ...,\n",
      "         [-0.0262,  0.1808,  0.0226,  ..., -0.0961, -0.0311, -0.2561],\n",
      "         [ 0.0124,  0.0402, -0.0213,  ..., -0.0846, -0.0419, -0.0712],\n",
      "         [-0.0137,  0.0685,  0.0031,  ..., -0.1113, -0.0217, -0.0781]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.1081e-01, -1.9584e-01, -2.3979e-01,  ...,  3.3302e-01,\n",
      "           1.5998e+00, -2.5787e-01],\n",
      "         [ 7.5792e-01, -3.8776e-01,  4.3735e-02,  ...,  1.7819e+00,\n",
      "           4.5960e-01,  1.9746e-01],\n",
      "         [ 4.0474e-01, -3.0097e-01,  7.7381e-02,  ...,  1.7512e+00,\n",
      "           7.8075e-01, -4.5950e-02],\n",
      "         ...,\n",
      "         [ 1.6502e-03,  6.9034e-02,  2.2832e-03,  ..., -9.3064e-02,\n",
      "          -2.3733e-02, -8.8544e-02],\n",
      "         [-1.1997e-03,  6.0891e-02,  3.9682e-03,  ..., -1.0792e-01,\n",
      "          -3.7047e-02, -8.4018e-02],\n",
      "         [-3.8429e-02,  1.6762e-01, -1.7245e-02,  ..., -4.0759e-02,\n",
      "          -5.8244e-02, -1.8368e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 9.9038e-01,  6.5896e-02,  3.5958e-01,  ...,  1.9156e+00,\n",
      "           1.5626e+00,  5.1210e-02],\n",
      "         [ 5.7674e-01, -3.6970e-02,  4.8391e-01,  ...,  1.7829e+00,\n",
      "           6.0153e-01, -3.2458e-01],\n",
      "         [ 6.3899e-01, -4.8247e-01,  2.5596e-02,  ...,  1.8818e+00,\n",
      "           6.9332e-01,  3.4779e-01],\n",
      "         ...,\n",
      "         [ 1.2267e-02,  6.7020e-02,  6.1037e-03,  ..., -7.6309e-02,\n",
      "          -1.1274e-02, -6.8912e-02],\n",
      "         [-1.1938e-04,  2.0868e-01, -2.4057e-02,  ..., -8.9233e-02,\n",
      "          -8.8383e-02, -2.4543e-01],\n",
      "         [ 1.1973e-03,  7.1151e-02, -8.8383e-03,  ..., -6.7946e-02,\n",
      "          -3.5842e-02, -8.0876e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.4534, -0.0041,  0.0583,  ...,  1.7135,  1.5549,  0.2141],\n",
      "         [-0.0242, -0.2894,  0.1878,  ...,  1.8428,  0.7519, -0.0480],\n",
      "         [ 0.9324, -0.2731, -0.2113,  ...,  1.6999,  0.6100,  0.0661],\n",
      "         ...,\n",
      "         [ 0.0037,  0.0488,  0.0029,  ..., -0.0845, -0.0189, -0.0683],\n",
      "         [-0.0078,  0.0647,  0.0035,  ..., -0.0824, -0.0129, -0.0820],\n",
      "         [-0.0038,  0.0508, -0.0055,  ..., -0.0879, -0.0338, -0.0679]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3415, -0.6697, -0.1981,  ...,  1.7305,  1.5119, -0.1014],\n",
      "         [ 0.6115, -0.3690, -0.1153,  ...,  1.8471,  0.6604, -0.5049],\n",
      "         [ 0.2586, -0.5011,  0.2876,  ...,  1.4368,  0.6946, -0.0026],\n",
      "         ...,\n",
      "         [-0.0197,  0.4697,  0.1607,  ..., -0.2352,  0.0461,  0.0205],\n",
      "         [-0.0214,  0.0409, -0.0027,  ..., -0.1064, -0.0149, -0.0949],\n",
      "         [ 0.2283,  0.4268, -0.2559,  ..., -0.1124,  0.2337, -0.0784]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.1324e+00, -1.9090e-01,  2.6729e-02,  ...,  1.5187e+00,\n",
      "           8.1775e-01, -3.1788e-01],\n",
      "         [ 1.0976e+00, -1.2028e-01,  4.3243e-01,  ...,  2.2636e+00,\n",
      "           1.1267e+00, -1.5465e-01],\n",
      "         [ 8.1218e-01, -3.0965e-01,  3.8574e-01,  ...,  2.0940e+00,\n",
      "           7.3393e-01, -2.4233e-01],\n",
      "         ...,\n",
      "         [-1.0638e-02,  7.3741e-02,  2.0101e-03,  ..., -8.8588e-02,\n",
      "          -2.3861e-02, -7.9736e-02],\n",
      "         [-9.6205e-03,  6.5721e-02, -9.1938e-04,  ..., -8.3473e-02,\n",
      "          -3.0699e-02, -8.0193e-02],\n",
      "         [ 1.9001e-01,  3.0850e-01, -2.5846e-01,  ...,  1.6097e-01,\n",
      "           5.6589e-01, -5.6785e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0957e+00,  1.2760e-01,  8.3134e-02,  ...,  1.9810e+00,\n",
      "           9.1264e-01, -5.6162e-02],\n",
      "         [ 5.9454e-01, -4.8922e-02,  3.1710e-01,  ...,  2.2396e+00,\n",
      "           7.9793e-01,  3.9900e-02],\n",
      "         [ 7.6971e-01, -2.4636e-01,  5.9569e-01,  ...,  2.0013e+00,\n",
      "           9.6875e-01,  2.2514e-01],\n",
      "         ...,\n",
      "         [-1.2165e-01,  2.3650e-01, -1.9189e-02,  ...,  1.4683e-01,\n",
      "          -1.4942e-01, -3.9819e-01],\n",
      "         [ 1.3919e-02,  9.4014e-02,  1.0217e-02,  ..., -9.3480e-03,\n",
      "          -1.2323e-03, -1.8272e-01],\n",
      "         [ 1.5876e-02,  5.9028e-02, -8.3591e-03,  ..., -7.7321e-02,\n",
      "          -4.0525e-02, -8.9580e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1937\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.4321e+00, -2.4429e-01,  4.3087e-01,  ...,  2.2105e+00,\n",
      "           1.5234e+00, -6.3297e-02],\n",
      "         [ 1.0274e+00, -1.0636e-01,  2.5476e-01,  ...,  1.0460e+00,\n",
      "           9.9864e-01, -4.5542e-02],\n",
      "         [ 9.4840e-01, -1.9411e-01,  2.0720e-01,  ...,  1.7307e+00,\n",
      "           8.8780e-01, -8.8813e-02],\n",
      "         ...,\n",
      "         [-2.3662e-02,  6.4372e-02, -6.5886e-03,  ..., -1.0822e-01,\n",
      "          -4.3043e-02, -8.3227e-02],\n",
      "         [-1.2692e-02,  1.0351e-01, -1.7926e-03,  ..., -8.2210e-02,\n",
      "          -3.0964e-02, -8.6306e-02],\n",
      "         [-1.7691e-02,  9.5150e-02,  3.9039e-02,  ..., -2.5740e-02,\n",
      "          -7.2865e-03, -2.1409e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3958e+00, -1.6923e-01,  1.6373e-02,  ...,  1.9005e+00,\n",
      "           1.2790e+00,  3.6197e-01],\n",
      "         [ 1.0172e+00, -3.2146e-01,  3.0827e-01,  ...,  1.8824e+00,\n",
      "           4.2333e-01,  4.8247e-01],\n",
      "         [ 1.2446e+00, -2.7581e-01,  5.2054e-01,  ...,  1.6737e+00,\n",
      "           5.9607e-01,  3.8390e-02],\n",
      "         ...,\n",
      "         [-1.3855e-02,  7.3668e-02,  1.3673e-03,  ..., -7.2054e-02,\n",
      "          -2.5225e-02, -7.6869e-02],\n",
      "         [-6.2668e-03,  7.5233e-02, -4.0145e-03,  ..., -6.0548e-02,\n",
      "          -3.5056e-02,  1.4040e-02],\n",
      "         [-1.7896e-02,  6.9554e-02, -1.7139e-02,  ..., -7.8515e-02,\n",
      "          -3.3053e-02, -7.1819e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1284e+00, -2.3258e-01,  1.8596e-01,  ...,  1.7812e+00,\n",
      "           1.5284e+00,  3.8164e-01],\n",
      "         [ 7.6852e-01, -2.4725e-01,  4.4313e-01,  ...,  1.2679e+00,\n",
      "           1.0015e+00,  3.0861e-01],\n",
      "         [ 7.9880e-01, -3.1980e-01,  1.5150e-01,  ...,  1.5811e+00,\n",
      "           8.9756e-01, -1.3436e-01],\n",
      "         ...,\n",
      "         [-3.2342e-02,  9.9560e-02,  9.5583e-03,  ..., -5.6335e-02,\n",
      "          -7.3317e-03, -1.7354e-01],\n",
      "         [-1.8586e-02,  6.3412e-02, -1.3983e-03,  ..., -9.1795e-02,\n",
      "          -3.8664e-02, -9.5547e-02],\n",
      "         [-3.0134e-03,  7.5137e-02,  5.9503e-03,  ..., -8.5936e-02,\n",
      "          -2.7751e-02, -6.7026e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9532, -0.5695,  0.1907,  ...,  1.6349,  1.5688,  0.0674],\n",
      "         [ 0.6652, -0.1297,  0.5631,  ...,  1.0472,  1.0449,  0.1289],\n",
      "         [ 0.6801, -0.4527,  0.4168,  ...,  1.3470,  0.7847, -0.0478],\n",
      "         ...,\n",
      "         [-0.0242,  0.1061,  0.0534,  ..., -0.0364, -0.0665, -0.1692],\n",
      "         [ 0.0065,  0.0864, -0.0274,  ..., -0.0699, -0.0233, -0.0532],\n",
      "         [-0.0129,  0.0683,  0.0031,  ..., -0.0856, -0.0296,  0.0122]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2919, -0.2388,  0.3327,  ...,  2.0021,  1.4549, -0.0759],\n",
      "         [ 1.3173, -0.3028,  0.3623,  ...,  1.6486,  1.0083,  0.3861],\n",
      "         [ 0.8462, -0.1214,  0.6270,  ...,  0.7920,  1.0716,  0.0354],\n",
      "         ...,\n",
      "         [-0.0172,  0.0767, -0.0051,  ..., -0.0756, -0.0279, -0.0952],\n",
      "         [-0.0118,  0.0817, -0.0109,  ..., -0.0788, -0.0263, -0.0752],\n",
      "         [-0.0144,  0.0674,  0.0026,  ..., -0.0766, -0.0258, -0.0838]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.9368e-01, -2.6817e-01, -1.9584e-02,  ...,  2.0463e+00,\n",
      "           1.4550e+00, -1.4183e-01],\n",
      "         [ 1.0901e+00, -3.3046e-01,  5.9614e-01,  ...,  2.3203e+00,\n",
      "           6.3880e-01, -9.6509e-02],\n",
      "         [ 8.1256e-01, -9.8162e-02,  3.1664e-01,  ...,  2.0932e+00,\n",
      "           6.5191e-01, -2.9305e-01],\n",
      "         ...,\n",
      "         [-3.9132e-03,  3.7515e-02, -9.5714e-03,  ..., -8.5487e-02,\n",
      "          -3.4247e-02, -7.6949e-02],\n",
      "         [ 3.6571e-02,  2.6172e-01, -1.2805e-01,  ...,  3.8922e-02,\n",
      "           6.0033e-03,  7.7788e-02],\n",
      "         [-1.2444e-02,  6.3520e-02,  8.3204e-04,  ..., -7.1976e-02,\n",
      "          -3.3162e-02, -7.0097e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3745e+00, -5.7689e-01,  3.1571e-01,  ...,  2.3521e+00,\n",
      "           6.2842e-01, -3.3278e-01],\n",
      "         [ 3.5835e-01, -3.4732e-01,  2.1774e-01,  ...,  2.6913e+00,\n",
      "           7.7386e-01, -2.5723e-02],\n",
      "         [ 9.9552e-01, -3.0989e-01,  3.7934e-01,  ...,  2.1779e+00,\n",
      "           1.3314e+00, -2.8576e-01],\n",
      "         ...,\n",
      "         [ 5.3412e-03,  7.0734e-02,  2.7933e-04,  ..., -7.4108e-02,\n",
      "          -3.1841e-02, -7.9072e-02],\n",
      "         [-1.1260e-02,  6.9997e-02,  5.6141e-04,  ..., -8.4467e-02,\n",
      "          -2.9344e-02, -8.8297e-02],\n",
      "         [-1.7258e-02,  7.2384e-02, -1.6967e-02,  ..., -6.5455e-02,\n",
      "          -3.5698e-02,  1.0169e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2225e+00, -1.2931e-01,  2.4154e-01,  ...,  2.4012e+00,\n",
      "           1.3716e+00, -2.3617e-01],\n",
      "         [ 2.4666e-01,  2.7025e-01,  5.2760e-01,  ...,  2.6346e+00,\n",
      "           3.2317e-01, -1.3634e-01],\n",
      "         [ 1.2924e+00, -6.0354e-01,  2.8655e-01,  ...,  2.2310e+00,\n",
      "           1.1193e+00,  2.9599e-01],\n",
      "         ...,\n",
      "         [-1.1772e-02,  5.1444e-02,  1.0034e-03,  ..., -9.0986e-02,\n",
      "          -2.2022e-02,  3.1755e-02],\n",
      "         [-1.0269e-03,  8.1704e-02,  6.6876e-03,  ..., -6.9900e-02,\n",
      "          -2.8169e-02, -6.6215e-02],\n",
      "         [-1.5285e-02,  7.0436e-02,  8.7990e-04,  ..., -8.2694e-02,\n",
      "          -3.3634e-02, -9.2680e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 9.8114e-01, -9.0037e-02,  2.4435e-01,  ...,  1.7903e+00,\n",
      "           1.6561e+00,  2.7868e-01],\n",
      "         [ 5.3617e-01, -5.9615e-02,  4.7684e-01,  ...,  2.0651e+00,\n",
      "           7.4665e-01,  2.8181e-01],\n",
      "         [ 1.0409e+00, -2.7667e-01,  2.9780e-01,  ...,  1.7481e+00,\n",
      "           1.1649e+00, -1.0595e-01],\n",
      "         ...,\n",
      "         [ 9.1929e-03,  7.1076e-02, -9.3944e-03,  ..., -9.4503e-02,\n",
      "          -3.3464e-02, -7.7547e-02],\n",
      "         [-1.0997e-02,  6.8750e-02,  4.1173e-03,  ..., -8.4132e-02,\n",
      "          -3.8889e-02, -8.1564e-02],\n",
      "         [ 2.3188e-03,  7.2487e-02,  7.6242e-04,  ..., -1.1287e-01,\n",
      "          -3.0688e-02, -8.3650e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.3580e-01, -1.9952e-01,  5.4985e-02,  ...,  1.5079e+00,\n",
      "           1.6866e+00,  3.1454e-01],\n",
      "         [ 6.0494e-02,  4.6760e-02,  6.3830e-01,  ...,  1.8053e+00,\n",
      "           1.0862e-02,  1.7879e-01],\n",
      "         [ 2.8870e-01, -3.4851e-02,  3.8748e-01,  ..., -1.4389e-03,\n",
      "           6.7722e-01,  3.1027e-01],\n",
      "         ...,\n",
      "         [-1.7824e-02,  7.7467e-02,  8.9132e-03,  ..., -6.6912e-02,\n",
      "          -4.3928e-02, -9.3767e-02],\n",
      "         [-1.3480e-02,  6.6780e-02,  3.5529e-03,  ..., -8.0464e-02,\n",
      "          -2.2925e-02, -8.6371e-02],\n",
      "         [-7.2419e-03,  4.5590e-02,  3.0248e-03,  ..., -6.5901e-02,\n",
      "          -4.3367e-02, -8.5937e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0246e+00, -1.7381e-01,  1.3743e-01,  ...,  2.0994e+00,\n",
      "           1.0169e+00,  1.9224e-01],\n",
      "         [ 5.6439e-01, -2.0636e-01,  2.5270e-01,  ...,  1.9687e+00,\n",
      "           8.0235e-01,  6.8928e-01],\n",
      "         [-9.8732e-02, -3.0246e-01,  6.6691e-01,  ...,  2.0652e+00,\n",
      "           1.1190e+00, -1.4303e-01],\n",
      "         ...,\n",
      "         [-1.1618e-02,  4.2263e-02, -1.4722e-04,  ..., -1.1728e-01,\n",
      "          -2.7302e-02,  1.4383e-02],\n",
      "         [-3.1539e-03,  8.7908e-02, -8.5972e-03,  ..., -9.3690e-02,\n",
      "          -2.9858e-02, -8.5554e-02],\n",
      "         [ 3.0383e-03,  6.8576e-02, -3.2378e-04,  ..., -7.7858e-02,\n",
      "          -3.4882e-02, -9.2911e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9016,  0.0903,  0.2185,  ...,  1.7364,  1.8080, -0.4237],\n",
      "         [ 0.1163, -0.1187,  0.7803,  ...,  1.5854,  1.0317,  0.0911],\n",
      "         [ 0.7084, -0.3242,  0.3903,  ...,  1.6051,  0.9287, -0.6134],\n",
      "         ...,\n",
      "         [-0.0107,  0.0636,  0.0107,  ..., -0.0551, -0.0188, -0.0765],\n",
      "         [ 0.1758,  0.1183, -0.1643,  ..., -0.2854,  0.2769, -0.2860],\n",
      "         [-0.0534,  0.2583, -0.0086,  ...,  0.0795, -0.0731,  0.0722]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ghanaian\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 8.6283e-01, -3.1061e-01, -5.1563e-03,  ...,  2.1403e+00,\n",
      "           1.5078e+00,  3.7180e-01],\n",
      "         [ 1.2427e+00, -2.6687e-01,  7.6026e-02,  ...,  1.0587e+00,\n",
      "           9.1506e-01, -4.0008e-01],\n",
      "         [ 1.1946e+00, -2.7817e-01, -2.5329e-01,  ...,  2.0799e+00,\n",
      "           5.3608e-01, -4.8573e-01],\n",
      "         ...,\n",
      "         [ 9.3352e-02,  5.4649e-01,  3.3052e-01,  ...,  1.9248e-01,\n",
      "           6.8052e-01, -6.9781e-01],\n",
      "         [-2.7094e-02,  9.0571e-02,  1.5018e-02,  ..., -7.6771e-02,\n",
      "          -9.5730e-03, -1.7827e-01],\n",
      "         [ 4.5246e-03,  6.8481e-02,  4.5791e-04,  ..., -6.4368e-02,\n",
      "          -3.9263e-02, -1.0613e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.5475, -0.4373, -0.1787,  ...,  2.0975,  1.2448,  0.0025],\n",
      "         [ 0.1443, -0.0500,  0.2042,  ...,  2.0429,  0.8973,  0.1412],\n",
      "         [ 1.4921, -0.1010,  0.1958,  ...,  1.5217,  0.5916,  0.5689],\n",
      "         ...,\n",
      "         [-0.0258,  0.1657,  0.0283,  ..., -0.0896, -0.0860, -0.2784],\n",
      "         [ 0.0069,  0.0737, -0.0092,  ..., -0.0803, -0.0191, -0.0588],\n",
      "         [-0.0965,  0.4494, -0.3316,  ...,  0.3144, -0.0343,  0.0266]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0710, -0.1352, -0.0890,  ...,  1.8763,  1.3427, -0.0475],\n",
      "         [ 0.7312,  0.1356,  0.1979,  ...,  2.1583,  0.6906, -0.2486],\n",
      "         [ 0.8853, -0.2561,  0.3084,  ...,  1.6402,  0.8418, -0.0642],\n",
      "         ...,\n",
      "         [-0.0198,  0.0675, -0.0143,  ..., -0.0795, -0.0383, -0.0773],\n",
      "         [ 0.0183,  0.0875,  0.0068,  ..., -0.0878, -0.0099, -0.0684],\n",
      "         [ 0.0156,  0.0663, -0.0060,  ..., -0.1109, -0.0256, -0.0843]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1505e+00, -2.1262e-01,  8.3212e-02,  ...,  2.2026e+00,\n",
      "           1.5086e+00,  5.5891e-03],\n",
      "         [ 8.2813e-01, -2.9473e-01,  3.1000e-01,  ...,  2.1384e+00,\n",
      "           6.1535e-01,  6.9163e-01],\n",
      "         [ 3.8521e-02, -3.8592e-01, -1.4666e-01,  ...,  1.7761e+00,\n",
      "           8.0096e-01,  2.0329e-01],\n",
      "         ...,\n",
      "         [-1.8242e-03,  6.9477e-02, -1.1173e-02,  ..., -1.0050e-01,\n",
      "          -4.6369e-02, -8.7475e-02],\n",
      "         [-4.6459e-04,  3.9582e-01, -2.1795e-01,  ...,  2.1963e-01,\n",
      "           1.7911e-01,  2.2947e-01],\n",
      "         [-2.5330e-02,  7.0662e-02, -2.3537e-03,  ..., -7.3428e-02,\n",
      "          -1.9503e-02, -9.8864e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2434e+00,  7.0170e-02, -1.1228e-01,  ...,  2.0666e+00,\n",
      "           8.6012e-01, -2.4926e-01],\n",
      "         [ 1.3454e+00, -8.8468e-02, -3.3570e-02,  ...,  2.3435e+00,\n",
      "           8.3652e-01, -6.6743e-02],\n",
      "         [ 8.6037e-01, -4.3597e-01,  1.9776e-01,  ...,  1.9247e+00,\n",
      "           9.2295e-01,  2.8449e-01],\n",
      "         ...,\n",
      "         [ 1.8070e-03,  5.8450e-02,  1.2374e-02,  ..., -9.6410e-02,\n",
      "          -1.2828e-02, -6.8420e-02],\n",
      "         [-1.9729e-02,  1.0777e-01,  5.8205e-02,  ..., -4.3479e-02,\n",
      "          -8.9497e-03, -2.4341e-01],\n",
      "         [-5.4287e-03,  6.3366e-02, -3.4164e-03,  ..., -8.8949e-02,\n",
      "          -3.2603e-02, -8.4860e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.3411e-01,  9.9854e-02, -1.1427e-02,  ...,  7.2261e-01,\n",
      "           7.6453e-01, -3.2203e-01],\n",
      "         [ 4.4265e-01,  1.5589e-01,  3.0769e-01,  ...,  8.5834e-01,\n",
      "          -1.9134e-01,  7.5430e-01],\n",
      "         [ 9.3346e-01, -6.2924e-03, -3.1051e-01,  ...,  2.1064e+00,\n",
      "           1.1980e+00, -1.3236e-01],\n",
      "         ...,\n",
      "         [-2.7708e-03,  6.6593e-02, -2.8021e-03,  ..., -7.3746e-02,\n",
      "          -2.2103e-02, -5.8096e-02],\n",
      "         [ 1.4609e-03,  6.6507e-02, -6.8175e-04,  ..., -8.8355e-02,\n",
      "          -1.0407e-02, -8.2525e-02],\n",
      "         [ 7.1804e-02,  3.9564e-01, -2.2004e-01,  ...,  1.9162e-01,\n",
      "           2.6913e-01, -4.6424e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "answer:  lashkaretaiba\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7504, -0.0034,  0.0927,  ...,  2.2340,  1.6734,  0.1459],\n",
      "         [ 0.4304,  0.0676,  0.7272,  ...,  2.3507,  0.0863,  0.2260],\n",
      "         [ 0.7864, -0.0831,  0.4178,  ...,  2.0992,  0.8380, -0.0919],\n",
      "         ...,\n",
      "         [-0.0038,  0.0690,  0.0051,  ..., -0.1088, -0.0250, -0.0758],\n",
      "         [ 0.0100,  0.1836,  0.0041,  ..., -0.1104,  0.0028,  0.0367],\n",
      "         [-0.0092,  0.1046, -0.0083,  ..., -0.0771, -0.0215, -0.0782]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 1.0284e+00,  8.4279e-02,  1.0967e-01,  ...,  1.3863e+00,\n",
      "           1.2458e+00,  2.0419e-01],\n",
      "         [ 5.3088e-01,  1.2590e-02,  2.9746e-01,  ...,  2.2705e+00,\n",
      "           7.5086e-01, -1.7144e-01],\n",
      "         [ 8.3273e-01, -5.5202e-01,  2.5933e-01,  ...,  1.7522e+00,\n",
      "           1.1562e+00,  1.5079e-01],\n",
      "         ...,\n",
      "         [ 1.1325e-02,  8.9887e-02,  2.1910e-03,  ..., -8.5580e-02,\n",
      "          -3.0129e-02, -8.5213e-02],\n",
      "         [-1.5390e-02,  8.5412e-02,  1.7156e-03,  ..., -8.4397e-02,\n",
      "          -2.5086e-02, -8.4263e-02],\n",
      "         [-1.4614e-02,  7.0259e-02,  4.3520e-03,  ..., -8.5929e-02,\n",
      "          -3.2685e-02, -9.3164e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.4425, -0.2460,  0.2381,  ...,  1.5735,  1.2937,  0.5107],\n",
      "         [ 0.0547, -0.3717,  0.3236,  ...,  1.5640,  0.7962,  0.2192],\n",
      "         [ 0.2413, -1.1815,  0.4315,  ...,  1.3810,  0.2742,  0.9493],\n",
      "         ...,\n",
      "         [-0.0407,  0.2730,  0.0648,  ..., -0.0435, -0.1201, -0.3744],\n",
      "         [ 0.0127,  0.0681,  0.0112,  ..., -0.0777, -0.0153,  0.0186],\n",
      "         [-0.0114,  0.0710,  0.0022,  ..., -0.1092, -0.0276, -0.0834]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1510e+00, -1.6157e-01,  6.1685e-02,  ...,  1.8364e+00,\n",
      "           1.0018e+00,  5.6397e-01],\n",
      "         [ 8.8306e-01,  8.0997e-02,  1.8236e-01,  ...,  8.1769e-01,\n",
      "           1.1007e+00,  8.1656e-02],\n",
      "         [ 5.8640e-01,  2.0735e-01,  2.9730e-01,  ...,  1.3298e+00,\n",
      "           6.7635e-01,  6.0020e-02],\n",
      "         ...,\n",
      "         [-1.2812e-02,  7.1682e-02, -8.6348e-05,  ..., -7.4096e-02,\n",
      "          -3.3518e-02, -8.2559e-02],\n",
      "         [-6.3446e-03,  7.0471e-02, -1.0337e-03,  ..., -1.0515e-01,\n",
      "          -3.7025e-02, -8.5886e-02],\n",
      "         [-3.8594e-02,  1.3551e-01,  8.9893e-04,  ..., -2.1769e-02,\n",
      "          -5.3216e-02, -1.9003e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0099e+00, -3.6189e-01,  2.5991e-01,  ...,  2.1358e+00,\n",
      "           1.5248e+00,  4.2727e-02],\n",
      "         [ 4.4053e-01, -1.5820e-01,  3.7145e-01,  ...,  2.3902e+00,\n",
      "           9.0866e-01,  1.8960e-01],\n",
      "         [ 5.1831e-01, -1.8955e-01,  4.4134e-01,  ...,  1.2849e+00,\n",
      "           9.5491e-01,  2.9621e-02],\n",
      "         ...,\n",
      "         [ 8.5347e-02,  6.7911e-02, -6.0054e-02,  ..., -7.0711e-04,\n",
      "           6.1209e-03, -2.9259e-01],\n",
      "         [-1.8743e-02,  7.3961e-02, -9.1480e-03,  ..., -7.8093e-02,\n",
      "          -3.2070e-02, -8.8119e-02],\n",
      "         [-1.7650e-02,  6.8771e-02,  1.4199e-03,  ..., -6.9386e-02,\n",
      "          -3.6785e-02, -7.0766e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9514,  0.2266, -0.0556,  ...,  1.9807,  1.5818, -0.1085],\n",
      "         [ 0.6573, -0.1640,  0.1697,  ...,  2.2733,  0.6041,  0.2107],\n",
      "         [-0.1957,  0.0860,  0.3654,  ...,  2.1827,  0.5722,  0.0564],\n",
      "         ...,\n",
      "         [ 0.0099,  0.0568,  0.0043,  ..., -0.1178, -0.0355, -0.0620],\n",
      "         [-0.0121,  0.0673,  0.0024,  ..., -0.0879, -0.0305, -0.0827],\n",
      "         [ 0.2098,  0.0702, -0.0763,  ..., -0.0133,  0.0764, -0.4385]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2492,  0.1571, -0.0323,  ...,  0.7971,  0.9533,  0.5375],\n",
      "         [ 0.0616, -0.0142,  0.2324,  ...,  2.2844,  0.7960, -0.0377],\n",
      "         [ 0.8634,  0.0361,  0.2005,  ...,  2.0948,  1.0431, -0.1709],\n",
      "         ...,\n",
      "         [ 0.0148,  0.0395, -0.0096,  ..., -0.1111, -0.0292, -0.0795],\n",
      "         [ 0.0248,  0.0703, -0.0080,  ..., -0.0850, -0.0387, -0.0786],\n",
      "         [ 0.0095,  0.0689,  0.0049,  ..., -0.0809, -0.0231, -0.0845]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0468e+00, -3.5227e-01,  3.8536e-01,  ...,  2.2259e+00,\n",
      "           1.1384e+00, -1.1921e-01],\n",
      "         [ 8.5152e-01, -2.0505e-01,  5.3616e-01,  ...,  2.3851e+00,\n",
      "           5.6450e-01, -1.0540e-01],\n",
      "         [ 4.5770e-01,  2.0533e-01,  5.0882e-01,  ...,  1.6592e+00,\n",
      "           6.9810e-01, -1.9184e-01],\n",
      "         ...,\n",
      "         [ 1.5215e-02,  7.3541e-02,  1.2407e-02,  ..., -7.7814e-02,\n",
      "          -1.4385e-02, -8.2752e-02],\n",
      "         [ 1.4469e-02,  9.4683e-02, -1.5907e-02,  ..., -6.4592e-02,\n",
      "          -5.0257e-02, -1.5196e-01],\n",
      "         [-7.3856e-02,  4.6943e-01, -5.0536e-02,  ...,  9.0792e-02,\n",
      "           1.9822e-03,  7.3927e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1302e+00, -1.6345e-01,  9.7698e-02,  ...,  2.4855e+00,\n",
      "           1.2229e+00, -2.5374e-02],\n",
      "         [ 6.8932e-01, -2.6157e-05,  5.9923e-01,  ...,  2.3730e+00,\n",
      "           6.9440e-01,  1.3959e-01],\n",
      "         [ 9.0660e-01, -3.5265e-02,  3.1912e-02,  ...,  1.0116e+00,\n",
      "           8.2098e-01, -2.0524e-01],\n",
      "         ...,\n",
      "         [-1.5223e-02,  7.3933e-02, -2.0434e-03,  ..., -7.6627e-02,\n",
      "          -2.4107e-02, -7.0561e-02],\n",
      "         [-1.3181e-02,  8.5251e-02, -1.5928e-02,  ..., -8.3374e-02,\n",
      "          -2.9177e-02, -8.7537e-02],\n",
      "         [-4.5700e-03,  6.8152e-02, -9.3072e-03,  ..., -7.7235e-02,\n",
      "          -2.3849e-02, -8.2206e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  lorax\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1392, -0.2462,  0.2018,  ...,  2.3754,  1.5073, -0.1678],\n",
      "         [ 0.7542, -0.1415,  0.3521,  ...,  2.6846,  0.8395,  0.0527],\n",
      "         [ 0.9877, -0.3482,  0.4417,  ...,  2.3486,  1.0680, -0.3004],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8522, -0.2053,  0.2925,  ...,  2.1326,  1.5178, -0.0583],\n",
      "         [ 0.4041,  0.0070,  0.5372,  ...,  2.1206,  0.5883,  0.2535],\n",
      "         [ 0.4533, -0.2805,  0.5146,  ...,  1.8698,  0.8271,  0.2119],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "answer:  marlboro\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1217, -0.3846,  0.0519,  ...,  2.2674,  1.4819, -0.0333],\n",
      "         [ 1.1184, -0.2143,  0.2375,  ...,  2.3753,  0.9071,  0.0623],\n",
      "         [ 1.1284, -0.0132,  0.1869,  ...,  1.7557,  0.9583, -0.0964],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9091, -0.2136,  0.2384,  ...,  2.3161,  1.4725, -0.0916],\n",
      "         [ 0.7194, -0.2324,  0.4427,  ...,  2.4185,  0.8636,  0.2163],\n",
      "         [ 0.7015, -0.3258,  0.2326,  ...,  2.1841,  0.8359,  0.0486],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9026,  0.0126,  0.2350,  ...,  2.4821,  1.5238,  0.1833],\n",
      "         [ 0.4582,  0.1349,  0.4456,  ...,  2.4522,  0.7773,  0.1299],\n",
      "         [ 0.4101,  0.3687,  0.5706,  ...,  1.5778,  0.8184,  0.2571],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  farinelli\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0077, -0.1086,  0.2700,  ...,  1.6982,  1.6816,  0.3151],\n",
      "         [ 0.0169,  0.0377,  0.4552,  ...,  1.8011,  0.9418,  0.4368],\n",
      "         [ 0.3522, -0.0391,  0.3815,  ...,  0.2557,  0.6306,  0.3857],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  atom egoyan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0386, -0.1446,  0.1687,  ...,  2.3200,  1.5851,  0.1388],\n",
      "         [ 0.5653,  0.0526,  0.3318,  ...,  2.3720,  0.8669,  0.3350],\n",
      "         [ 0.7025, -0.0803,  0.1074,  ...,  2.1936,  0.8492,  0.3500],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  eric of pomerania\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8653, -0.0274,  0.1052,  ...,  2.2703,  1.5536, -0.0620],\n",
      "         [ 0.3323,  0.0262,  0.3083,  ...,  2.4455,  0.7365,  0.4342],\n",
      "         [ 0.2191, -0.1887,  0.3512,  ...,  1.8716,  0.8404,  0.1301],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9766, -0.0656,  0.2406,  ...,  2.2238,  1.4548,  0.2207],\n",
      "         [ 0.0128,  0.0875,  0.5492,  ...,  2.2511,  0.8107,  0.3413],\n",
      "         [ 0.8620, -0.0612,  0.3148,  ...,  1.2394,  0.9822,  0.1929],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0541, -0.2595,  0.2081,  ...,  2.1675,  1.5424, -0.3757],\n",
      "         [ 0.9390, -0.2323,  0.3364,  ...,  2.2528,  0.9290, -0.1917],\n",
      "         [ 0.8115, -0.1349,  0.2376,  ...,  1.8879,  0.9636, -0.2012],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  4\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6672, -0.1084,  0.1910,  ...,  2.1101,  1.4428, -0.3145],\n",
      "         [ 0.7757, -0.0919,  0.4318,  ...,  2.3396,  0.8848, -0.0932],\n",
      "         [ 0.7349, -0.0382,  0.3293,  ...,  2.1724,  0.8469, -0.2106],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.1120, -0.0534,  0.2133,  ...,  2.1414,  1.5563, -0.1262],\n",
      "         [ 1.0199,  0.0835,  0.3626,  ...,  2.2531,  0.9279, -0.0564],\n",
      "         [ 0.8779,  0.0869,  0.0878,  ...,  2.0944,  0.8498, -0.1689],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8839,  0.0262,  0.2106,  ...,  2.2026,  1.4860,  0.0917],\n",
      "         [ 0.2484,  0.2803,  0.7497,  ...,  1.7280,  0.5271,  0.3935],\n",
      "         [ 0.3090,  0.1940,  0.5020,  ...,  1.4155,  0.7827,  0.1951],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7949,  0.3115,  0.2528,  ...,  2.1127,  1.4974, -0.0575],\n",
      "         [ 0.2646,  0.0629,  0.4853,  ...,  2.2047,  0.8573, -0.0488],\n",
      "         [ 0.3773, -0.2450,  0.2204,  ...,  1.9328,  0.8791,  0.1251],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9879, -0.1229,  0.2162,  ...,  2.0955,  1.5854, -0.2275],\n",
      "         [ 0.9728, -0.0689,  0.3708,  ...,  2.2783,  0.9880, -0.0766],\n",
      "         [ 0.6999,  0.0242,  0.3556,  ...,  1.7922,  0.9297, -0.1150],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0129, -0.1197,  0.2257,  ...,  2.1649,  1.4131, -0.0874],\n",
      "         [ 0.5464, -0.0269,  0.4155,  ...,  2.3605,  0.7419,  0.2443],\n",
      "         [ 0.4926, -0.2274,  0.4049,  ...,  1.8221,  0.7789, -0.0335],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8078, -0.1827,  0.2964,  ...,  2.1838,  1.5274, -0.1774],\n",
      "         [ 0.7549, -0.0813,  0.4408,  ...,  2.3607,  0.8804,  0.0028],\n",
      "         [ 0.6648,  0.0213,  0.3000,  ...,  1.8677,  1.0038, -0.2825],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9619, -0.1015,  0.1609,  ...,  2.3285,  1.5136, -0.2397],\n",
      "         [ 0.6556,  0.0259,  0.4772,  ...,  2.6334,  0.7980, -0.0521],\n",
      "         [ 0.8158, -0.0802,  0.3642,  ...,  2.4103,  0.8371, -0.1738],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8412, -0.0347,  0.2599,  ...,  2.1390,  1.3721,  0.1229],\n",
      "         [ 0.2975, -0.0968,  0.3525,  ...,  2.3517,  0.8320,  0.2361],\n",
      "         [ 0.3273, -0.1978,  0.1734,  ...,  1.8885,  0.7960,  0.1193],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  wendy carlos\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8587, -0.0857,  0.4044,  ...,  2.1835,  1.5426, -0.2617],\n",
      "         [ 0.4759,  0.1357,  0.7550,  ...,  2.0079,  0.9259,  0.1240],\n",
      "         [ 0.5792,  0.1705,  0.3361,  ...,  1.8361,  1.0256,  0.0571],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  tokyo japan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2057,  0.0437, -0.0283,  ...,  2.0248,  1.3885, -0.1377],\n",
      "         [ 0.9348,  0.1394,  0.2867,  ...,  2.1028,  0.6805, -0.1389],\n",
      "         [ 0.9886, -0.1730,  0.2588,  ...,  2.1197,  0.9710, -0.2934],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8047, -0.1440,  0.1618,  ...,  2.1578,  1.5254, -0.0088],\n",
      "         [ 0.2516,  0.1256,  0.3260,  ...,  2.0580,  0.6949,  0.4185],\n",
      "         [ 0.3952,  0.0059,  0.3619,  ...,  2.0807,  1.0566,  0.4079],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  st johns\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0821, -0.0803,  0.1721,  ...,  2.2894,  1.5303,  0.1557],\n",
      "         [ 0.5301, -0.0159,  0.4767,  ...,  2.2988,  0.8043,  0.4465],\n",
      "         [ 0.6608,  0.0027,  0.1638,  ...,  1.7511,  1.1218, -0.0147],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8762,  0.0535, -0.0353,  ...,  2.1691,  1.4880, -0.0559],\n",
      "         [ 0.9597,  0.1037,  0.2785,  ...,  2.3851,  0.8869,  0.1410],\n",
      "         [ 0.7467,  0.0897,  0.4049,  ...,  2.0637,  0.8067, -0.0982],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  louis caldera\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0143, -0.6545,  0.0224,  ...,  2.3366,  1.4538, -0.2825],\n",
      "         [ 0.7544, -0.5919,  0.3329,  ...,  2.6719,  0.7827, -0.1205],\n",
      "         [ 0.7872, -0.6567,  0.3855,  ...,  2.5218,  1.0104, -0.1878],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9628,  0.0784,  0.2545,  ...,  2.2868,  1.6467,  0.0038],\n",
      "         [ 0.3958,  0.0628,  0.5647,  ...,  2.4104,  0.7803,  0.2999],\n",
      "         [ 0.4725, -0.3088,  0.4235,  ...,  1.7596,  0.9243,  0.1809],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9221, -0.2322,  0.0391,  ...,  1.9135,  1.5371, -0.0947],\n",
      "         [ 0.7616,  0.0809,  0.3623,  ...,  2.1405,  0.6893,  0.1320],\n",
      "         [ 0.3798,  0.1508,  0.6950,  ...,  1.6420,  0.6815,  0.0732],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8968,  0.0531,  0.2352,  ...,  2.2656,  1.5393,  0.0267],\n",
      "         [ 0.3590,  0.0471,  0.4305,  ...,  2.2377,  0.7560,  0.3294],\n",
      "         [ 0.3131, -0.1425,  0.3216,  ...,  1.8575,  0.6288,  0.2949],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0177, -0.1975,  0.1511,  ...,  2.1334,  1.5381,  0.0490],\n",
      "         [ 0.8429, -0.2604,  0.3128,  ...,  2.1308,  0.8076, -0.0433],\n",
      "         [ 0.8513, -0.3794,  0.2848,  ...,  2.0009,  0.8917, -0.2744],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.9110, -0.0197,  0.2607,  ...,  2.3561,  1.4390, -0.1390],\n",
      "         [ 0.4865,  0.0427,  0.4824,  ...,  2.3712,  0.6034,  0.2656],\n",
      "         [ 0.5253,  0.0819,  0.1881,  ...,  1.9960,  0.6072,  0.1785],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "answer:  1976 to 2009\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0116, -0.1465, -0.0153,  ...,  2.2752,  1.5394, -0.1203],\n",
      "         [ 0.3889, -0.0053,  0.3088,  ...,  2.2851,  0.6183,  0.0990],\n",
      "         [ 0.3490, -0.1477,  0.3483,  ...,  1.7924,  0.7693,  0.1904],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1376, -0.2316, -0.0512,  ...,  2.0438,  1.5226, -0.0560],\n",
      "         [ 0.3253,  0.0386,  0.2823,  ...,  2.1709,  0.8025,  0.1039],\n",
      "         [ 0.4566, -0.2161,  0.1600,  ...,  1.6096,  0.6653, -0.0447],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 7.3843e-01, -1.2399e-01,  3.1318e-01,  ...,  2.0015e+00,\n",
      "           1.4795e+00,  1.3839e-03],\n",
      "         [ 5.3890e-01,  3.8759e-02,  5.0007e-01,  ...,  2.1446e+00,\n",
      "           7.5191e-01,  1.2804e-01],\n",
      "         [ 2.5849e-01, -7.1256e-02,  6.7330e-01,  ...,  1.7531e+00,\n",
      "           1.0923e+00, -1.1377e-01],\n",
      "         ...,\n",
      "         [-1.1403e-02,  7.5863e-02, -3.1761e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5863e-02, -3.1761e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5863e-02, -3.1761e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0042, -0.1090,  0.0187,  ...,  2.3303,  1.4701, -0.2023],\n",
      "         [ 1.0394, -0.2064,  0.3332,  ...,  2.5127,  0.8135,  0.1309],\n",
      "         [ 0.9904, -0.2471,  0.2426,  ...,  2.1485,  0.9285,  0.0366],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  michael caine\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8192, -0.1611,  0.1790,  ...,  2.2261,  1.6296, -0.1353],\n",
      "         [ 0.8288, -0.1317,  0.4054,  ...,  2.4324,  0.9398,  0.0561],\n",
      "         [ 0.6813, -0.2042,  0.3723,  ...,  2.1157,  0.9349, -0.1778],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8260,  0.0072,  0.3452,  ...,  1.7657,  1.0367,  0.3320],\n",
      "         [ 0.5498, -0.0459,  0.3878,  ...,  2.3113,  0.7638,  0.2529],\n",
      "         [ 0.1168,  0.2756,  0.3049,  ...,  1.2462,  0.5488,  0.4727],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0771, -0.1983,  0.1168,  ...,  2.3361,  1.5314, -0.0257],\n",
      "         [ 0.5867,  0.0032,  0.3692,  ...,  2.4222,  0.7962,  0.2513],\n",
      "         [ 0.3883, -0.1088,  0.3870,  ...,  1.1369,  0.7495,  0.1648],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.8745, -0.3386,  0.0169,  ...,  2.1034,  1.4647, -0.0213],\n",
      "         [ 0.5817, -0.0052,  0.3199,  ...,  2.1606,  0.7208,  0.2402],\n",
      "         [ 0.5170, -0.1741,  0.3331,  ...,  2.5074,  0.7879, -0.0634],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0712, -0.4977,  0.0766,  ...,  1.8762,  1.5874, -0.4073],\n",
      "         [ 1.0146, -0.3913,  0.4714,  ...,  1.9713,  0.9722, -0.1130],\n",
      "         [ 0.8987, -0.2421,  0.5378,  ...,  1.5444,  0.9325, -0.4535],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7074,  0.0774, -0.1174,  ...,  1.8561,  1.5172, -0.0519],\n",
      "         [ 0.5026, -0.0987,  0.4692,  ...,  2.0442,  0.6408,  0.2467],\n",
      "         [ 0.4201, -0.1288,  0.3198,  ...,  1.9775,  0.8216,  0.1651],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9227, -0.1589,  0.2494,  ...,  2.0641,  1.5728, -0.1139],\n",
      "         [ 0.5089, -0.0195,  0.5946,  ...,  2.2245,  0.7737,  0.2666],\n",
      "         [ 0.7311, -0.2893,  0.3861,  ...,  1.7108,  1.0827,  0.0248],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.2812, -0.1152,  0.0647,  ...,  2.2206,  1.5391, -0.0329],\n",
      "         [ 0.8535, -0.0547,  0.4801,  ...,  2.2522,  0.9002,  0.2138],\n",
      "         [ 1.0522,  0.0048,  0.3918,  ...,  2.0328,  0.8346,  0.0102],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  shane meadows\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0872, -0.2013,  0.1885,  ...,  2.0512,  1.6609, -0.2401],\n",
      "         [ 0.9805, -0.0954,  0.4347,  ...,  2.4141,  1.0327, -0.1311],\n",
      "         [ 0.9040, -0.2338,  0.3945,  ...,  2.2157,  0.9464, -0.3542],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7737,  0.0992,  0.1637,  ...,  2.4227,  1.4891, -0.0151],\n",
      "         [ 0.0809,  0.3450,  0.6197,  ...,  2.3629,  0.6056,  0.1472],\n",
      "         [ 0.7193,  0.1031,  0.3256,  ...,  2.6545,  0.9730, -0.0129],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1750, -0.1481,  0.3188,  ...,  2.2380,  1.6963, -0.2286],\n",
      "         [ 1.0119, -0.0708,  0.5149,  ...,  2.2470,  1.0028, -0.0518],\n",
      "         [ 1.1536, -0.1779,  0.5684,  ...,  1.8469,  1.2206, -0.3813],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9510, -0.0479,  0.2755,  ...,  2.3717,  1.5119, -0.1340],\n",
      "         [ 0.5707, -0.1916,  0.5066,  ...,  2.4964,  0.7676,  0.1484],\n",
      "         [ 0.6141, -0.5345,  0.4594,  ...,  1.7775,  1.0802,  0.0514],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8556, -0.1556,  0.2442,  ...,  2.2144,  1.4803,  0.0320],\n",
      "         [ 0.5328,  0.0736,  0.5186,  ...,  2.2572,  0.6451,  0.2734],\n",
      "         [ 0.4767,  0.1332,  0.2481,  ...,  2.0131,  0.6559,  0.1685],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9583, -0.2015,  0.1571,  ...,  2.3105,  1.5104, -0.5473],\n",
      "         [ 0.8568, -0.2239,  0.4880,  ...,  2.6082,  0.8689, -0.2963],\n",
      "         [ 0.8578, -0.2236,  0.3832,  ...,  2.3158,  0.7978, -0.5378],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0600, -0.1821,  0.3147,  ...,  2.0126,  1.3983, -0.1847],\n",
      "         [ 1.0202, -0.1124,  0.4544,  ...,  2.2477,  0.8386, -0.0888],\n",
      "         [ 0.6882, -0.0619,  0.6222,  ...,  1.7997,  0.7926, -0.2198],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.2121,  0.0722,  0.0605,  ...,  2.2604,  1.6192, -0.0193],\n",
      "         [ 1.0818,  0.0919,  0.3917,  ...,  2.4115,  0.9873,  0.1076],\n",
      "         [ 1.0087, -0.1255,  0.2721,  ...,  2.2043,  0.9526, -0.1866],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "\n",
      "sequence_output  tensor([[[ 1.0200, -0.1411,  0.0086,  ...,  2.0302,  1.6190, -0.1033],\n",
      "         [ 0.4328,  0.2306,  0.4494,  ...,  1.8971,  0.7066,  0.3477],\n",
      "         [ 0.7639, -0.0237,  0.2845,  ...,  1.4194,  1.1490,  0.0194],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8660, -0.1960,  0.0789,  ...,  2.0961,  1.3734, -0.1433],\n",
      "         [ 0.4678, -0.1273,  0.3721,  ...,  2.1659,  0.7254,  0.2562],\n",
      "         [ 0.5159, -0.2252,  0.2454,  ...,  1.9566,  0.8991,  0.0535],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0731, -0.0897,  0.1254,  ...,  2.1328,  1.4903, -0.0707],\n",
      "         [ 1.0346,  0.0397,  0.4020,  ...,  2.3296,  0.8784, -0.0408],\n",
      "         [ 0.8766,  0.0402,  0.3184,  ...,  1.9059,  0.7707, -0.2452],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8219, -0.1801,  0.2570,  ...,  2.0810,  1.4731, -0.2970],\n",
      "         [ 0.4931,  0.0910,  0.6477,  ...,  2.0182,  0.6982,  0.2213],\n",
      "         [ 0.4853,  0.1072,  0.4367,  ...,  1.7257,  0.6707,  0.0407],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  munster rugby\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.9180,  0.0165, -0.0364,  ...,  2.0929,  1.3283,  0.1094],\n",
      "         [ 0.3095, -0.0447,  0.1324,  ...,  2.4371,  0.8021,  0.3068],\n",
      "         [ 0.2782, -0.7314,  0.4507,  ...,  0.8432,  1.1774,  0.1155],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8540, -0.0725,  0.2087,  ...,  2.2613,  1.5269, -0.4531],\n",
      "         [ 0.6635, -0.2112,  0.5164,  ...,  2.3912,  0.8297, -0.2362],\n",
      "         [ 0.7430, -0.2229,  0.3743,  ...,  2.1838,  0.9177, -0.3775],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8610,  0.1108,  0.0578,  ...,  2.2717,  1.3358, -0.0570],\n",
      "         [ 0.4088,  0.2300,  0.1719,  ...,  2.0133,  0.7046,  0.1197],\n",
      "         [ 0.7703,  0.0843, -0.2082,  ...,  1.5404,  1.1150, -0.3843],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8798,  0.0494,  0.3416,  ...,  2.2672,  1.5312, -0.0576],\n",
      "         [ 0.1441,  0.0694,  0.5838,  ...,  2.2860,  0.7838,  0.2220],\n",
      "         [ 0.4620, -0.0705,  0.3601,  ...,  2.0191,  0.9508,  0.3456],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "tensor([[[ 0.8965, -0.1819,  0.3046,  ...,  2.0000,  1.4406,  0.0085],\n",
      "         [ 0.5167,  0.1021,  0.3971,  ...,  2.0987,  0.6988,  0.1731],\n",
      "         [ 0.3351,  0.0993,  0.2879,  ...,  1.7703,  0.8395,  0.2452],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9891,  0.0593, -0.0299,  ...,  2.2366,  1.7465,  0.2313],\n",
      "         [ 0.2056,  0.3914,  0.2790,  ...,  2.0870,  0.9250,  0.3993],\n",
      "         [ 0.7784, -0.1487,  0.0649,  ...,  1.4917,  0.8354, -0.0632],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0497, -0.1044,  0.4815,  ...,  2.2143,  1.4171,  0.1412],\n",
      "         [ 0.5299,  0.0255,  0.6148,  ...,  2.3810,  0.7530,  0.2754],\n",
      "         [ 0.4318,  0.0956,  0.5865,  ...,  1.0720,  0.5359,  0.2914],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0194, -0.0139,  0.3121,  ...,  2.3170,  1.4586,  0.0385],\n",
      "         [ 0.4972,  0.0402,  0.5205,  ...,  2.4474,  0.8281,  0.2462],\n",
      "         [ 0.9192,  0.3012,  0.2189,  ...,  1.8323,  0.9249,  0.1571],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.5227, -0.0614,  0.0059,  ...,  2.2497,  1.3471, -0.1724],\n",
      "         [ 0.5583, -0.0361,  0.4167,  ...,  2.5080,  0.8385, -0.1168],\n",
      "         [ 0.5349, -0.1072,  0.3515,  ...,  2.2606,  0.9005, -0.2058],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2150e+00, -3.8405e-02,  1.2323e-01,  ...,  2.3221e+00,\n",
      "           1.5544e+00, -1.9168e-01],\n",
      "         [ 1.0885e+00,  8.7091e-04,  4.3915e-01,  ...,  2.3254e+00,\n",
      "           9.2735e-01, -9.7903e-02],\n",
      "         [ 9.8405e-01, -5.8359e-02,  3.0473e-01,  ...,  1.9632e+00,\n",
      "           1.0371e+00, -1.9233e-01],\n",
      "         ...,\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9166,  0.0234,  0.0893,  ...,  1.8970,  1.5297, -0.0122],\n",
      "         [ 0.8842, -0.1742,  0.3594,  ...,  2.1677,  0.8618,  0.1405],\n",
      "         [ 0.9694, -0.2195,  0.2717,  ...,  1.9372,  1.1093, -0.0681],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0013e+00, -2.8179e-01,  1.5742e-03,  ...,  1.8705e+00,\n",
      "           1.6708e+00,  2.4649e-01],\n",
      "         [ 4.5178e-01,  6.5502e-02,  3.1349e-01,  ...,  2.0372e+00,\n",
      "           7.7311e-01,  5.0448e-01],\n",
      "         [ 7.6051e-01,  1.0501e-02,  1.1854e-01,  ...,  1.7489e+00,\n",
      "           1.0016e+00,  1.2644e-01],\n",
      "         ...,\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02],\n",
      "         [-1.1403e-02,  7.5862e-02, -3.1760e-03,  ..., -7.8063e-02,\n",
      "          -3.0298e-02, -9.0846e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.7271, -0.0621,  0.4893,  ...,  1.9482,  1.5504,  0.4262],\n",
      "         [ 0.1439, -0.0583,  0.1799,  ...,  2.1383,  0.8735,  0.3768],\n",
      "         [ 0.2225, -0.7959,  0.3759,  ...,  1.3620,  1.0663,  0.2988],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8032, -0.2284,  0.4284,  ...,  1.8415,  1.4842, -0.4474],\n",
      "         [ 0.6009, -0.0638,  0.6788,  ...,  1.7109,  0.7843, -0.4659],\n",
      "         [ 0.6632, -0.1196,  0.3647,  ...,  1.5738,  0.5278, -0.9040],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0902, -0.1475, -0.1078,  ...,  2.2379,  1.4702, -0.3794],\n",
      "         [ 1.0253, -0.0995,  0.2835,  ...,  2.3588,  0.9317, -0.2324],\n",
      "         [ 0.9875, -0.0233,  0.1470,  ...,  2.1454,  0.8631, -0.4215],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8952, -0.1253,  0.1413,  ...,  2.3407,  1.4228, -0.0365],\n",
      "         [ 0.5476,  0.0735,  0.4030,  ...,  2.2613,  0.6792,  0.1906],\n",
      "         [ 0.2405,  0.2879,  0.2355,  ...,  1.8321,  0.6009,  0.1476],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1962\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9953,  0.0286,  0.0788,  ...,  2.1396,  1.5745, -0.1145],\n",
      "         [ 0.9969, -0.0330,  0.3273,  ...,  2.3102,  1.0210, -0.0138],\n",
      "         [ 0.7328,  0.0579,  0.2131,  ...,  0.8070,  0.8526, -0.3457],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9045, -0.0030,  0.1812,  ...,  2.0932,  1.5801,  0.0703],\n",
      "         [ 0.5287,  0.0639,  0.4881,  ...,  2.1843,  0.6108,  0.1893],\n",
      "         [ 0.4777,  0.1034,  0.7248,  ...,  2.1252,  0.8509,  0.2741],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1813, -0.1031,  0.1462,  ...,  2.0371,  1.5072, -0.0287],\n",
      "         [ 0.7681,  0.1527,  0.3409,  ...,  2.0149,  0.7236, -0.0084],\n",
      "         [ 0.8987,  0.0526,  0.1939,  ...,  1.4040,  0.6581, -0.2019],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.8922, -0.0140,  0.3818,  ...,  1.9810,  1.3968,  0.2993],\n",
      "         [ 0.4272, -0.0520,  0.3432,  ...,  2.5718,  0.6527,  0.1453],\n",
      "         [ 0.5013, -0.4870,  0.4265,  ...,  1.6072,  0.9517,  0.3020],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0620, -0.0468,  0.1885,  ...,  1.8688,  1.6316,  0.0942],\n",
      "         [ 0.6823,  0.0448,  0.4360,  ...,  2.2166,  0.8490,  0.2062],\n",
      "         [ 0.9711, -0.1970,  0.1462,  ...,  0.8336,  1.1785, -0.1441],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7900, -0.1237,  0.2469,  ...,  2.1533,  1.4550,  0.2936],\n",
      "         [ 0.3255,  0.0192,  0.4999,  ...,  2.0734,  0.6185,  0.3518],\n",
      "         [ 0.2869,  0.0552,  0.4156,  ...,  0.9105,  0.7288,  0.0238],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0388, -0.2591,  0.0575,  ...,  2.0961,  1.4009, -0.2431],\n",
      "         [ 0.9424, -0.2940,  0.4066,  ...,  2.2233,  0.8624, -0.0839],\n",
      "         [ 0.9084, -0.2480,  0.4477,  ...,  1.8341,  0.9503, -0.2473],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0727,  0.0311,  0.1065,  ...,  2.0810,  1.4333, -0.2047],\n",
      "         [ 0.5937,  0.0847,  0.4256,  ...,  2.4177,  0.6066,  0.1552],\n",
      "         [ 0.5148, -0.0584,  0.2404,  ...,  1.4299,  0.6431, -0.0748],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9862, -0.1301,  0.0402,  ...,  2.3467,  1.5396, -0.0376],\n",
      "         [ 0.5199,  0.1110,  0.4470,  ...,  2.5400,  0.7412,  0.3317],\n",
      "         [ 0.7203,  0.0058,  0.4051,  ...,  1.9690,  0.9473, -0.0246],\n",
      "         ...,\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908],\n",
      "         [-0.0114,  0.0759, -0.0032,  ..., -0.0781, -0.0303, -0.0908]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned 0.04510631035023098 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of avg_val_f1 in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch 00002: avg_val_f1 reached 0.04511 (best 0.04511), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_2.ckpt as top 5\n",
      "\n",
      "Epoch 00002: avg_val_f1 reached 0.04511 (best 0.04511), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_2.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_end\n",
      "before sync --> sizes:  79, 79, 79\n",
      "after sync --> sizes: 79, 79, 79\n",
      "avg_loss:  tensor(14.3244, device='cuda:0')\tavg_answer_loss:  tensor(5.9333, device='cuda:0')\tavg_type_loss:  tensor(0.1849, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5102, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.2365, device='cuda:0')\n",
      "avg_val_f1:  0.04510631035023098\tavg_val_em:  0.0\tavg_val_prec:  0.03630362026676347\tavg_val_recall:  0.09398734222956096\n",
      "avg_val_sp_sent_f1:  0.07747639281840264\tavg_val_sp_sent_em:  0.0\tavg_val_sp_sent_prec:  0.08462929574749138\tavg_val_sp_sent_recall:  0.08649789079835143\n",
      "avg_val_joint_f1:  0.001100715579865854\tavg_val_joint_em:  0.0\tavg_val_joint_prec:  0.0006027728130545797\tavg_val_joint_recall:  0.006329113924050633\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  american\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  flowering plants\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  son of ulf jarl\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.1951,  0.1007,  0.0184,  ...,  2.1027,  1.5764,  0.1320],\n",
      "         [ 1.0466, -0.2928,  0.4146,  ...,  2.0431,  0.9824, -0.0921],\n",
      "         [ 1.1076, -0.1883,  0.3780,  ...,  1.7901,  0.2141, -0.2738],\n",
      "         ...,\n",
      "         [-0.0037,  0.0686, -0.0110,  ..., -0.1042, -0.0351, -0.0872],\n",
      "         [-0.0121,  0.0751,  0.0035,  ..., -0.0800, -0.0333, -0.0820],\n",
      "         [ 0.1547,  0.3731, -0.0193,  ...,  0.4190,  0.2169, -0.5157]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mary i\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  espn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.2629e-01, -3.6120e-01, -2.0341e-02,  ...,  2.1883e+00,\n",
      "           1.5176e+00, -3.4323e-01],\n",
      "         [ 8.7571e-01, -8.4635e-02,  3.9318e-01,  ...,  1.9883e+00,\n",
      "           5.3459e-01, -3.5353e-01],\n",
      "         [ 3.0761e-01, -1.3995e-01,  2.9057e-01,  ...,  1.9349e+00,\n",
      "           6.7264e-01, -3.0445e-01],\n",
      "         ...,\n",
      "         [-1.3218e-02,  7.6289e-02, -1.3707e-02,  ..., -1.0723e-01,\n",
      "          -2.4978e-02, -1.0085e-01],\n",
      "         [-5.2520e-02,  1.6748e-01,  3.5225e-02,  ..., -6.9334e-02,\n",
      "          -4.9008e-02, -2.3824e-01],\n",
      "         [ 5.9643e-05,  1.9018e-01,  2.2541e-02,  ..., -7.2171e-02,\n",
      "          -5.6843e-02, -2.6747e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3023e+00, -4.2444e-04,  4.0219e-01,  ...,  1.7732e+00,\n",
      "           1.3018e+00, -2.0696e-01],\n",
      "         [ 9.1398e-01, -3.6257e-01,  7.1335e-02,  ...,  2.2524e+00,\n",
      "           8.3900e-01, -2.8469e-01],\n",
      "         [ 7.1602e-01, -3.2792e-01,  6.6053e-01,  ...,  1.5880e+00,\n",
      "           6.6795e-01, -2.8406e-01],\n",
      "         ...,\n",
      "         [-1.2697e-02,  7.2846e-02, -9.9892e-03,  ..., -8.8474e-02,\n",
      "          -3.1060e-02, -8.2591e-02],\n",
      "         [-1.1390e-02,  7.7891e-02,  3.9377e-03,  ..., -1.0629e-01,\n",
      "          -3.0607e-02, -8.6131e-02],\n",
      "         [-1.1466e-02,  7.0902e-02,  3.6226e-03,  ..., -8.5269e-02,\n",
      "          -3.0161e-02, -8.2957e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.5451e-01,  4.9688e-02,  3.5921e-01,  ...,  2.3898e+00,\n",
      "           1.5097e+00, -1.5229e-01],\n",
      "         [ 6.2062e-01, -2.9208e-02,  3.6313e-01,  ...,  2.4580e+00,\n",
      "           7.9456e-01,  5.6561e-01],\n",
      "         [ 7.6496e-01, -4.3730e-03,  1.8588e-01,  ...,  6.7325e-01,\n",
      "           1.1890e+00, -2.9628e-01],\n",
      "         ...,\n",
      "         [ 1.4308e-03,  1.3950e-01,  2.1648e-02,  ..., -1.4518e-02,\n",
      "          -1.0470e-01, -2.0424e-01],\n",
      "         [ 6.0117e-02,  3.0652e-01, -5.4170e-01,  ...,  1.0610e-01,\n",
      "          -7.0791e-04,  2.7042e-01],\n",
      "         [ 1.3474e-02,  5.4853e-02, -9.2684e-03,  ..., -9.5518e-02,\n",
      "          -3.2402e-02, -5.8853e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0129, -0.1565,  0.3740,  ...,  2.1866,  1.4122, -0.0401],\n",
      "         [ 0.8223, -0.2049,  0.0569,  ...,  2.4414,  0.3320, -0.0332],\n",
      "         [ 0.8367,  0.1922,  0.4300,  ...,  1.9009,  0.9270, -0.4206],\n",
      "         ...,\n",
      "         [ 0.0543,  0.3499, -0.1310,  ..., -0.0390,  0.1278, -0.0217],\n",
      "         [-0.0326,  0.1173,  0.0407,  ..., -0.0147, -0.0222, -0.1972],\n",
      "         [-0.0106,  0.0690, -0.0078,  ..., -0.0759, -0.0367, -0.0821]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1721, -0.1801, -0.0879,  ...,  1.6994,  1.6092,  0.0626],\n",
      "         [ 0.8728,  0.1702,  0.2005,  ...,  1.7548,  0.7475, -0.0603],\n",
      "         [ 0.7748,  0.1117,  0.1975,  ...,  1.5182,  0.7959, -0.7055],\n",
      "         ...,\n",
      "         [-0.0078,  0.0684,  0.0048,  ..., -0.1047, -0.0235, -0.0974],\n",
      "         [-0.0132,  0.0414,  0.0035,  ..., -0.0755, -0.0380, -0.0856],\n",
      "         [-0.0125,  0.1035, -0.0033,  ..., -0.0916, -0.0350, -0.0716]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "answer:  1962\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0483e+00, -8.2497e-01, -5.8504e-02,  ...,  2.2307e+00,\n",
      "           1.6121e+00, -2.3449e-01],\n",
      "         [ 6.6246e-01, -8.1089e-01,  1.4610e-01,  ...,  2.2219e+00,\n",
      "           4.0903e-01, -2.2547e-01],\n",
      "         [ 9.8664e-01, -3.2067e-01,  1.0907e-01,  ...,  2.5134e+00,\n",
      "           8.9116e-01, -9.1789e-02],\n",
      "         ...,\n",
      "         [-1.8100e-02,  6.3963e-02, -2.0448e-02,  ..., -8.5926e-02,\n",
      "          -2.5355e-02, -8.1184e-02],\n",
      "         [ 1.3922e-02,  1.2650e-01, -2.1690e-03,  ..., -4.8190e-02,\n",
      "           1.3849e-02, -2.1152e-01],\n",
      "         [-6.6980e-03,  7.0868e-02, -1.0772e-02,  ..., -7.9429e-02,\n",
      "          -3.1705e-02, -6.7122e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.4237e-01,  9.3551e-02, -6.1662e-03,  ...,  1.2613e+00,\n",
      "           1.7453e+00,  5.4599e-02],\n",
      "         [ 6.7331e-01,  1.3415e-01,  2.1025e-01,  ...,  1.3497e+00,\n",
      "           1.2056e+00,  7.8067e-01],\n",
      "         [ 1.0265e+00, -1.7838e-01,  6.1850e-02,  ...,  1.0747e+00,\n",
      "           1.2429e+00,  4.0225e-02],\n",
      "         ...,\n",
      "         [-4.3918e-03,  5.7338e-02,  1.0874e-03,  ..., -8.7993e-02,\n",
      "          -2.4077e-02, -6.8605e-02],\n",
      "         [ 1.0658e-01,  2.5962e-01,  1.1882e-01,  ..., -5.0439e-02,\n",
      "          -6.5078e-04, -3.8903e-01],\n",
      "         [ 1.8334e-02,  2.7281e-02, -4.1654e-03,  ..., -8.8349e-02,\n",
      "          -2.6280e-02, -7.5587e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7835,  0.0538,  0.4544,  ...,  2.4847,  1.1779, -0.1173],\n",
      "         [ 0.3815,  0.1453,  0.5660,  ...,  1.8999,  0.9212,  0.5202],\n",
      "         [ 0.0925, -0.1602,  0.3750,  ...,  1.7785,  0.8473,  0.2340],\n",
      "         ...,\n",
      "         [-0.0051,  0.0792,  0.0068,  ..., -0.0750, -0.0328, -0.0767],\n",
      "         [-0.0053,  0.0782,  0.0072,  ..., -0.0914, -0.0156, -0.0897],\n",
      "         [-0.0089,  0.0732,  0.0054,  ..., -0.0770, -0.0310, -0.0761]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3387, -0.6171, -0.0475,  ...,  2.2908,  1.1651,  0.1556],\n",
      "         [ 1.1234, -0.0427,  0.0741,  ...,  1.9924,  0.7764,  0.7012],\n",
      "         [ 1.5307, -0.0166,  0.0335,  ...,  1.9345,  1.1157,  0.2120],\n",
      "         ...,\n",
      "         [-0.0049,  0.0702,  0.0026,  ..., -0.0714, -0.0325, -0.0759],\n",
      "         [-0.0113,  0.0708, -0.0193,  ..., -0.0808, -0.0401, -0.0817],\n",
      "         [ 0.2289,  0.0238, -0.0551,  ...,  0.2775,  0.1972, -0.2560]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0318e+00, -4.3059e-01,  7.2782e-02,  ...,  2.0564e+00,\n",
      "           1.5835e+00,  1.1178e-02],\n",
      "         [ 6.2002e-01, -1.5181e-01,  5.7146e-01,  ...,  2.4526e+00,\n",
      "           7.1046e-01, -5.8417e-01],\n",
      "         [ 3.7377e-01, -5.5703e-02,  2.1502e-01,  ...,  1.8529e+00,\n",
      "           4.1383e-01, -9.9630e-04],\n",
      "         ...,\n",
      "         [ 1.0883e-02,  6.9682e-02,  3.0563e-03,  ..., -8.2911e-02,\n",
      "          -2.8522e-02, -7.8934e-02],\n",
      "         [-2.1857e-02,  1.5111e-01, -1.5709e-02,  ..., -6.6269e-02,\n",
      "          -7.7095e-02, -2.2514e-01],\n",
      "         [ 1.3791e-02,  7.4052e-02, -7.0440e-03,  ..., -7.5059e-02,\n",
      "          -4.5896e-02,  1.6352e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1976 to 2009\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.0094e-01,  7.2395e-02, -2.0241e-01,  ...,  2.2324e+00,\n",
      "           1.3591e+00, -3.8078e-02],\n",
      "         [ 1.1457e+00, -2.4682e-01, -1.7559e-01,  ...,  2.0572e+00,\n",
      "           8.1795e-01,  1.3595e-02],\n",
      "         [ 8.6237e-01, -2.0140e-01, -7.7904e-02,  ...,  2.1479e+00,\n",
      "           1.3777e+00, -4.4225e-01],\n",
      "         ...,\n",
      "         [-1.7320e-02,  6.5052e-02,  2.1131e-03,  ..., -6.0044e-02,\n",
      "          -3.0976e-02, -8.2471e-02],\n",
      "         [ 2.2727e-02,  5.3698e-01, -1.0503e-01,  ...,  5.2946e-02,\n",
      "           1.4814e-01, -2.5824e-02],\n",
      "         [ 3.8458e-03,  4.1337e-02,  4.1063e-03,  ..., -7.1623e-02,\n",
      "          -3.2826e-02, -7.8839e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.2739,  0.0680, -0.0479,  ...,  0.8373,  1.4382, -0.2369],\n",
      "         [ 1.1573, -0.3924,  0.1412,  ...,  2.4788,  0.5389, -0.1069],\n",
      "         [ 0.7500, -0.2804,  0.3329,  ...,  1.7392,  0.6931, -0.2541],\n",
      "         ...,\n",
      "         [ 0.1927, -0.0801, -0.1428,  ...,  0.5482, -0.0288, -0.4227],\n",
      "         [-0.0078,  0.0433,  0.0030,  ..., -0.1156, -0.0306, -0.0749],\n",
      "         [ 0.0107,  0.0754, -0.0123,  ..., -0.0820, -0.0284, -0.0885]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2166, -0.1377,  0.0298,  ...,  2.0857,  1.2948, -0.2372],\n",
      "         [ 1.0402, -0.0438,  0.4192,  ...,  2.0760,  0.5459, -0.0736],\n",
      "         [ 0.8543, -0.1962,  0.3289,  ...,  1.8446,  0.4764, -0.4586],\n",
      "         ...,\n",
      "         [-0.0188,  0.0818,  0.0027,  ..., -0.0787, -0.0343, -0.0813],\n",
      "         [-0.1091,  0.0532, -0.1852,  ...,  0.1202,  0.0492, -0.4499],\n",
      "         [-0.0420,  0.1480,  0.0364,  ..., -0.0638, -0.0086, -0.2056]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1593, -0.3772, -0.0128,  ...,  1.7459,  1.6259,  0.0783],\n",
      "         [ 0.8321, -0.2374,  0.1725,  ...,  2.1420,  0.7607,  0.2533],\n",
      "         [ 1.1654, -0.2135,  0.2527,  ...,  1.8908,  0.8478,  0.6061],\n",
      "         ...,\n",
      "         [-0.0181,  0.0704, -0.0028,  ..., -0.0907, -0.0317, -0.0848],\n",
      "         [-0.0174,  0.0736, -0.0056,  ..., -0.0758, -0.0186, -0.0799],\n",
      "         [-0.0129,  0.0582, -0.0180,  ..., -0.0805, -0.0481,  0.0304]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3667e+00, -4.3162e-01, -8.0275e-02,  ...,  2.2659e+00,\n",
      "           1.0928e+00, -5.1241e-01],\n",
      "         [ 9.3671e-01, -1.6972e-01,  3.9265e-01,  ...,  2.6725e+00,\n",
      "           1.1218e+00, -4.5771e-01],\n",
      "         [ 1.2263e+00,  8.7327e-02,  2.9693e-01,  ...,  1.7322e+00,\n",
      "           9.7532e-01,  9.0069e-03],\n",
      "         ...,\n",
      "         [-1.1106e-02,  7.2227e-02,  9.8117e-04,  ..., -7.8536e-02,\n",
      "          -2.8197e-02, -7.3361e-02],\n",
      "         [ 1.5466e-02,  8.9419e-02,  1.4304e-02,  ..., -7.3433e-02,\n",
      "          -1.3927e-02, -1.0135e-01],\n",
      "         [ 1.1789e-02,  7.6256e-02, -7.5976e-03,  ..., -8.1912e-02,\n",
      "          -3.1303e-02, -6.4280e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.2869e+00, -3.7957e-01, -1.2798e-01,  ...,  2.0462e+00,\n",
      "           1.5290e+00,  2.2529e-01],\n",
      "         [ 1.0056e+00, -5.1130e-01,  4.6136e-01,  ...,  9.0450e-01,\n",
      "           4.6255e-01, -9.5345e-02],\n",
      "         [ 9.8209e-01, -1.1187e-01,  2.7804e-01,  ...,  1.6775e+00,\n",
      "           8.8601e-01, -2.2055e-01],\n",
      "         ...,\n",
      "         [-1.3985e-02,  7.3286e-02,  2.7043e-03,  ..., -7.6657e-02,\n",
      "          -2.8653e-02, -6.2783e-02],\n",
      "         [-7.9493e-03,  7.9657e-02,  7.3373e-03,  ..., -7.5346e-02,\n",
      "          -2.3210e-02, -7.9945e-02],\n",
      "         [-5.8247e-03,  4.2256e-02,  1.8305e-03,  ..., -8.7675e-02,\n",
      "          -3.4842e-02, -8.4516e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1937\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.6105, -0.1871,  0.3241,  ...,  1.6951,  1.4377, -0.0377],\n",
      "         [ 1.2590, -0.3238,  0.3333,  ...,  2.4146,  0.7753,  0.2870],\n",
      "         [ 0.8907,  0.0103,  0.2161,  ...,  2.0794,  0.6777, -0.3684],\n",
      "         ...,\n",
      "         [ 0.0057,  0.0294,  0.0054,  ..., -0.0856, -0.0190, -0.0648],\n",
      "         [ 0.0318,  0.2383, -0.1363,  ...,  0.1198,  0.0506, -0.0781],\n",
      "         [-0.0148,  0.0570, -0.0069,  ..., -0.0784, -0.0315,  0.0108]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9627, -0.5114,  0.0559,  ...,  2.4639,  1.6454, -0.1641],\n",
      "         [ 0.7961, -0.3430,  0.4840,  ...,  2.3281,  0.9091,  0.3296],\n",
      "         [ 0.8860, -0.7189,  0.1621,  ...,  2.0059,  0.7723, -0.3418],\n",
      "         ...,\n",
      "         [-0.0068,  0.0680, -0.0203,  ..., -0.0914, -0.0316, -0.0882],\n",
      "         [ 0.0630,  0.2366, -0.1384,  ..., -0.3482,  0.0116, -0.0708],\n",
      "         [ 0.1348,  0.3720, -0.2439,  ...,  0.2166,  0.1441, -0.1240]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2013, -0.3382, -0.0509,  ...,  2.3791,  1.3178, -0.4620],\n",
      "         [ 0.7482, -0.4619,  0.5550,  ...,  1.9112,  0.7132, -0.3056],\n",
      "         [ 0.9788, -0.3769,  0.4553,  ...,  2.2549,  0.8900, -0.3646],\n",
      "         ...,\n",
      "         [-0.0106,  0.0728,  0.0047,  ..., -0.0800, -0.0293, -0.0774],\n",
      "         [ 0.0051,  0.0784,  0.0055,  ..., -0.0851, -0.0338, -0.0763],\n",
      "         [ 0.0071,  0.0684,  0.0081,  ..., -0.1069, -0.0424, -0.0669]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.4236, -0.5660,  0.0450,  ...,  1.8685,  1.8725, -0.3916],\n",
      "         [ 1.0881, -0.3861,  0.0917,  ...,  2.1276,  0.6172, -0.1972],\n",
      "         [ 0.9479, -0.6405,  0.2065,  ...,  1.5752,  0.8199, -0.1581],\n",
      "         ...,\n",
      "         [ 0.2857,  0.0501, -0.2782,  ..., -0.1479,  0.1688, -0.1953],\n",
      "         [-0.0047,  0.0753,  0.0050,  ..., -0.0813, -0.0170, -0.0784],\n",
      "         [ 0.0233,  0.2334,  0.0162,  ...,  0.1608,  0.1702, -0.3755]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1451e+00,  1.0852e-01, -4.0387e-02,  ...,  2.1810e+00,\n",
      "           8.2115e-01,  4.8074e-02],\n",
      "         [ 9.2394e-01, -3.1482e-01,  2.5552e-01,  ...,  2.2587e+00,\n",
      "           9.6773e-01,  1.2224e-01],\n",
      "         [ 9.6555e-01, -6.0735e-01, -1.0976e-01,  ...,  1.9624e+00,\n",
      "           6.5690e-01, -2.0839e-01],\n",
      "         ...,\n",
      "         [-1.3398e-02,  6.0620e-02,  2.2071e-03,  ..., -7.6026e-02,\n",
      "          -2.6371e-02, -8.5808e-02],\n",
      "         [ 2.7852e-03,  6.2864e-02,  1.3491e-02,  ..., -8.0507e-02,\n",
      "          -1.2233e-02,  1.7565e-02],\n",
      "         [-1.5685e-02,  6.9189e-02, -5.7768e-03,  ..., -8.2409e-02,\n",
      "          -2.4641e-02, -7.9691e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1051e+00, -4.5422e-01, -3.3442e-01,  ...,  2.5155e+00,\n",
      "           9.6155e-01, -4.1541e-01],\n",
      "         [ 6.9840e-01, -3.7001e-01,  5.4455e-02,  ...,  2.2848e+00,\n",
      "           6.0503e-01, -4.8883e-02],\n",
      "         [ 6.3364e-01, -4.0496e-01,  4.6862e-01,  ...,  2.1362e+00,\n",
      "           8.6837e-01,  5.7875e-01],\n",
      "         ...,\n",
      "         [-9.2226e-03,  6.8185e-02, -2.1345e-02,  ..., -7.0979e-02,\n",
      "          -3.9594e-02, -8.2303e-02],\n",
      "         [-1.1536e-02,  5.0963e-02, -9.0114e-04,  ..., -8.3895e-02,\n",
      "          -1.7159e-02, -9.5028e-02],\n",
      "         [-9.5505e-03,  6.9463e-02,  6.8903e-03,  ..., -6.8334e-02,\n",
      "          -1.2603e-02, -7.4547e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "answer:  doug moench and don perlin\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.1150e+00, -2.3505e-01, -4.9972e-02,  ...,  1.9895e+00,\n",
      "           1.1579e+00, -3.7886e-01],\n",
      "         [ 9.5843e-01, -4.7779e-01,  2.6373e-01,  ...,  1.8869e+00,\n",
      "           8.9230e-01,  7.1620e-03],\n",
      "         [ 9.5581e-01, -2.5883e-01,  2.6061e-01,  ...,  1.8161e+00,\n",
      "           2.9873e-01, -4.3121e-02],\n",
      "         ...,\n",
      "         [-8.8053e-03,  7.0349e-02,  8.8999e-04,  ..., -8.3370e-02,\n",
      "          -2.6254e-02, -8.0345e-02],\n",
      "         [ 5.5681e-03,  1.0818e-01, -1.3612e-03,  ..., -6.3814e-02,\n",
      "          -3.4759e-02, -3.7997e-02],\n",
      "         [-5.3302e-03,  7.3208e-02,  6.5435e-03,  ..., -7.7679e-02,\n",
      "          -3.4946e-02, -8.8175e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.4652e-01, -3.9685e-01,  1.3571e-01,  ...,  1.6100e+00,\n",
      "           1.6181e+00,  1.3426e-01],\n",
      "         [ 1.0512e+00, -3.7077e-01,  4.4680e-01,  ...,  2.3075e+00,\n",
      "           9.1188e-01, -2.2337e-02],\n",
      "         [ 9.3509e-01, -7.4286e-01,  1.4923e-01,  ...,  1.0490e+00,\n",
      "           1.1444e+00, -2.6257e-01],\n",
      "         ...,\n",
      "         [ 4.2758e-03,  7.9880e-02, -1.0166e-03,  ..., -8.1435e-02,\n",
      "          -3.4317e-02, -8.1025e-02],\n",
      "         [-8.1887e-03,  7.6152e-02,  1.4780e-03,  ..., -8.4267e-02,\n",
      "          -3.3707e-02, -8.4265e-02],\n",
      "         [-1.0200e-02,  6.6109e-02,  7.0755e-04,  ..., -7.6492e-02,\n",
      "          -1.7744e-02, -8.0715e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0297, -0.2484, -0.0175,  ...,  1.8254,  1.1262, -0.0375],\n",
      "         [ 0.8883,  0.1022,  0.0924,  ...,  2.0570,  0.7706,  0.0643],\n",
      "         [ 0.4241,  0.0073,  0.0635,  ...,  1.6936,  0.8540,  0.5847],\n",
      "         ...,\n",
      "         [-0.0129,  0.0610,  0.0248,  ..., -0.1002, -0.0372, -0.0864],\n",
      "         [-0.0122,  0.0811, -0.0043,  ..., -0.0803, -0.0372, -0.0808],\n",
      "         [ 0.0961,  0.6414, -0.1320,  ..., -0.5895,  0.1400, -0.3597]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0336, -0.0887,  0.3569,  ...,  1.9460,  2.1223,  0.0769],\n",
      "         [ 0.4803, -0.1741,  0.4904,  ...,  1.9334,  0.9972,  0.1035],\n",
      "         [ 0.4648,  0.1931,  0.3218,  ..., -0.4839,  0.1329,  0.2468],\n",
      "         ...,\n",
      "         [ 0.0152,  0.3269, -0.2002,  ..., -0.0220,  0.0198, -0.2423],\n",
      "         [ 0.0368,  0.2804, -0.0168,  ...,  0.1793, -0.1181, -0.0714],\n",
      "         [ 0.1506,  0.3285, -0.0340,  ...,  0.2234, -0.1056, -0.3205]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8847, -0.2412, -0.1650,  ...,  1.8957,  1.6115,  0.1560],\n",
      "         [-0.0481,  0.1758, -0.0577,  ...,  2.0504,  0.7696,  0.5587],\n",
      "         [ 0.7045, -0.2705,  0.2516,  ...,  0.9359,  0.8612, -0.1446],\n",
      "         ...,\n",
      "         [-0.0097,  0.4037,  0.0439,  ...,  0.2964, -0.0032, -0.1429],\n",
      "         [-0.0146,  0.0394, -0.0068,  ..., -0.0786, -0.0127, -0.0825],\n",
      "         [-0.3721,  0.5949,  0.1046,  ..., -0.0188, -0.1819, -0.0789]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.1102, -0.1155,  0.0487,  ...,  2.6298,  0.9796,  0.2817],\n",
      "         [ 0.9352, -0.2721,  0.0489,  ...,  2.3079,  0.9526, -0.2951],\n",
      "         [ 1.2195, -0.2820,  0.2393,  ...,  2.4878,  1.0829, -0.5350],\n",
      "         ...,\n",
      "         [-0.0139,  0.0414,  0.0037,  ..., -0.0786, -0.0319, -0.0829],\n",
      "         [-0.0380,  0.1244,  0.0220,  ..., -0.0235, -0.0152,  0.0233],\n",
      "         [ 0.0504,  0.2371,  0.0231,  ..., -0.1012, -0.0427, -0.2153]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.4229e+00,  1.6951e-01,  1.7245e-01,  ...,  2.1748e+00,\n",
      "           1.6380e+00,  4.3154e-01],\n",
      "         [ 8.1827e-01, -2.9020e-01,  1.4573e-01,  ...,  2.3235e+00,\n",
      "           7.2850e-01,  6.6108e-01],\n",
      "         [ 1.1855e+00, -1.9242e-01, -6.1598e-02,  ...,  1.7214e+00,\n",
      "           8.9694e-01,  9.8306e-02],\n",
      "         ...,\n",
      "         [-4.0998e-02,  1.4725e-01, -2.1545e-04,  ...,  2.5820e-03,\n",
      "          -2.2697e-02,  3.2483e-02],\n",
      "         [-1.0694e-02,  9.5017e-02, -2.7150e-03,  ..., -1.1074e-01,\n",
      "          -2.6571e-02, -7.9970e-02],\n",
      "         [ 5.2150e-04,  4.1114e-02,  2.0842e-03,  ..., -1.1298e-01,\n",
      "          -2.6024e-02,  1.3031e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3570, -0.5166, -0.0172,  ...,  2.2995,  1.6316,  0.0062],\n",
      "         [ 1.1911,  0.0392,  0.5787,  ...,  2.3677,  1.2533,  0.3998],\n",
      "         [ 1.3830, -0.2806,  0.0872,  ...,  1.9344,  1.3726,  0.1326],\n",
      "         ...,\n",
      "         [-0.0119,  0.0739,  0.0092,  ..., -0.0854, -0.0287,  0.0186],\n",
      "         [-0.0083,  0.0705, -0.0083,  ..., -0.0808, -0.0314, -0.0768],\n",
      "         [-0.0165,  0.0628, -0.0056,  ..., -0.1132, -0.0354, -0.0872]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0349, -0.1609,  0.2268,  ...,  0.7421,  2.0136, -0.6510],\n",
      "         [ 0.9806, -0.0328,  0.4999,  ...,  2.4860,  0.9907,  0.1399],\n",
      "         [ 0.6268, -0.2175,  0.4538,  ...,  2.0274,  1.3881, -0.5305],\n",
      "         ...,\n",
      "         [ 0.1281,  0.1062, -0.0614,  ..., -0.1756,  0.0462, -0.5017],\n",
      "         [-0.0105,  0.1856,  0.0589,  ..., -0.0578, -0.0704, -0.0167],\n",
      "         [ 0.1911,  0.9674, -0.1290,  ..., -0.1757,  0.5083, -0.4353]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0470e+00, -2.3831e-01,  3.0404e-01,  ...,  1.5217e+00,\n",
      "           1.6890e+00,  1.0736e-03],\n",
      "         [ 5.4778e-01,  2.8321e-02,  3.6426e-01,  ...,  5.9023e-01,\n",
      "           9.0309e-01,  1.2210e-01],\n",
      "         [ 1.5969e-02, -2.1837e-03,  5.5719e-01,  ...,  1.6528e+00,\n",
      "           7.5317e-01, -1.5401e-01],\n",
      "         ...,\n",
      "         [ 9.5715e-03,  1.4523e-01,  2.6278e-03,  ..., -7.7608e-02,\n",
      "          -4.1392e-02, -2.4269e-01],\n",
      "         [-4.3653e-05,  1.0060e-01, -2.4608e-04,  ..., -8.1323e-02,\n",
      "          -3.6170e-02, -8.8532e-02],\n",
      "         [-1.2865e-02,  7.2458e-02,  1.2120e-02,  ..., -8.7892e-02,\n",
      "          -3.2029e-02,  1.0181e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.6894, -0.1173,  0.1532,  ...,  2.1518,  1.2576,  0.0435],\n",
      "         [ 0.7214, -0.6398,  0.1284,  ...,  2.1330,  0.5276,  0.7836],\n",
      "         [ 0.5859, -0.4322,  0.3928,  ...,  1.8087,  0.5939,  0.2207],\n",
      "         ...,\n",
      "         [-0.0157,  0.0225,  0.0039,  ..., -0.1130, -0.0157, -0.0860],\n",
      "         [ 0.1706,  0.1656, -0.2520,  ...,  0.2842,  0.0988, -0.3689],\n",
      "         [-0.0079,  0.0754, -0.0028,  ..., -0.0784, -0.0241, -0.0800]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3161, -0.6002,  0.3706,  ...,  2.2256,  1.7795, -0.0086],\n",
      "         [ 0.8103, -0.4286,  0.3367,  ...,  2.0207,  0.9811,  0.0387],\n",
      "         [ 0.3588, -0.3916,  0.3915,  ...,  0.2055,  1.3488, -0.3878],\n",
      "         ...,\n",
      "         [-0.0056,  0.0755,  0.0023,  ..., -0.0759, -0.0293, -0.0902],\n",
      "         [-0.0201,  0.0706, -0.0104,  ..., -0.0764, -0.0167, -0.0526],\n",
      "         [ 0.0075,  0.0582, -0.0035,  ..., -0.0805, -0.0240, -0.0802]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9276, -0.0129, -0.0475,  ...,  1.9598,  1.4376, -0.2151],\n",
      "         [ 1.0668,  0.1033,  0.6127,  ...,  1.8319,  1.0376, -0.1276],\n",
      "         [ 1.0239, -0.2012,  0.2767,  ...,  1.8031,  0.7971, -0.0938],\n",
      "         ...,\n",
      "         [ 0.0080,  0.0698, -0.0056,  ..., -0.1115, -0.0306, -0.0832],\n",
      "         [ 0.3258,  0.3684, -0.0225,  ...,  0.5121, -0.0675, -0.4809],\n",
      "         [ 0.0178,  0.0587, -0.0028,  ..., -0.1192, -0.0479, -0.0577]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2581, -0.1884,  0.4681,  ...,  1.9991,  1.6178, -0.4840],\n",
      "         [ 0.9915, -0.1956,  0.5021,  ...,  2.1752,  1.0299, -0.1071],\n",
      "         [ 1.0112, -0.5398,  0.3532,  ...,  2.0542,  1.3745, -0.4461],\n",
      "         ...,\n",
      "         [-0.0092,  0.0643, -0.0031,  ..., -0.0856, -0.0458, -0.0750],\n",
      "         [ 0.0094,  0.0779, -0.0031,  ..., -0.0790, -0.0452, -0.0820],\n",
      "         [ 0.0116,  0.5530, -0.1519,  ..., -0.1149,  0.0287, -0.0631]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5856, -0.0675, -0.1807,  ...,  2.1269,  1.5336, -0.0095],\n",
      "         [ 0.7428, -0.1513,  0.5023,  ...,  2.1779,  0.2802,  0.3133],\n",
      "         [ 1.0585, -0.2094,  0.2165,  ...,  0.7285,  0.6836,  0.0361],\n",
      "         ...,\n",
      "         [ 0.0037,  0.0709,  0.0052,  ..., -0.0995, -0.0225, -0.0601],\n",
      "         [-0.0255,  0.0972,  0.0065,  ..., -0.0652, -0.0492, -0.1099],\n",
      "         [-0.0065,  0.0692, -0.0033,  ..., -0.0735, -0.0325, -0.0889]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2848, -0.1007,  0.2997,  ...,  2.2342,  1.0078, -0.2444],\n",
      "         [ 0.2577, -0.0250,  0.5702,  ...,  2.1865,  0.9672,  0.0755],\n",
      "         [ 1.1463, -0.2240,  0.1727,  ...,  2.1963,  0.5592, -0.2557],\n",
      "         ...,\n",
      "         [ 0.0098,  0.0422, -0.0109,  ..., -0.0784, -0.0279, -0.0777],\n",
      "         [-0.0333,  0.3041,  0.0803,  ...,  0.0048, -0.1752, -0.2760],\n",
      "         [-0.0040,  0.0759,  0.0087,  ..., -0.0732, -0.0248, -0.0858]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.4110e+00, -9.7511e-04,  1.4248e-01,  ...,  2.0556e+00,\n",
      "           1.9171e+00, -1.8015e-01],\n",
      "         [ 1.0762e+00,  1.0400e-01,  6.8013e-01,  ...,  2.2698e+00,\n",
      "           9.9030e-01, -2.6073e-01],\n",
      "         [ 1.2063e+00, -2.8290e-02,  5.0703e-01,  ...,  2.1550e+00,\n",
      "           1.0057e+00, -2.4313e-01],\n",
      "         ...,\n",
      "         [ 5.2936e-02,  3.9830e-01, -4.0210e-01,  ...,  2.8714e-01,\n",
      "           3.2306e-01, -8.6476e-01],\n",
      "         [ 5.2539e-02,  8.6422e-02,  9.9455e-02,  ..., -9.3467e-02,\n",
      "          -8.7734e-02, -2.9147e-01],\n",
      "         [-1.0254e-02,  6.7027e-02, -1.0031e-02,  ..., -8.1296e-02,\n",
      "          -3.9541e-02, -7.4416e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.8652e-01, -1.1027e-01, -5.7028e-02,  ...,  1.9312e+00,\n",
      "           1.5825e+00, -4.4895e-02],\n",
      "         [ 9.4243e-01, -4.1372e-02,  5.7665e-01,  ...,  9.6489e-01,\n",
      "           8.1269e-01, -2.2997e-03],\n",
      "         [ 7.6251e-01, -3.5588e-01,  3.4284e-01,  ...,  2.2756e+00,\n",
      "           8.7021e-01,  1.3428e-01],\n",
      "         ...,\n",
      "         [-1.4147e-02,  7.8688e-02,  4.7679e-04,  ..., -9.0752e-02,\n",
      "          -3.0477e-02, -9.0034e-02],\n",
      "         [-2.4817e-03,  7.3347e-02, -2.4373e-03,  ..., -7.5460e-02,\n",
      "          -2.6293e-02, -7.3515e-02],\n",
      "         [ 2.1312e-01,  2.7786e-01, -8.0318e-02,  ..., -1.3679e-01,\n",
      "           1.4126e-01, -1.5316e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9532, -0.2084,  0.0911,  ...,  1.8316,  1.5591, -0.3008],\n",
      "         [ 0.9924,  0.0220,  0.1828,  ...,  2.5940,  0.2362, -0.0391],\n",
      "         [ 0.7882, -0.2671,  0.7714,  ...,  1.5815,  0.7741, -0.1594],\n",
      "         ...,\n",
      "         [-0.0353,  0.1406,  0.0155,  ..., -0.0083, -0.0537, -0.1517],\n",
      "         [-0.0197,  0.0829, -0.0169,  ..., -0.1093, -0.0514, -0.0801],\n",
      "         [-0.0186,  0.4433,  0.2983,  ..., -0.1553, -0.0576,  0.2009]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.4252, -0.3688,  0.3428,  ...,  1.7294,  1.5306, -0.1262],\n",
      "         [ 0.6483, -0.1963,  0.4918,  ...,  1.6932,  0.9912, -0.2836],\n",
      "         [ 1.1126, -0.2824,  0.1756,  ...,  1.1447,  0.8351, -0.9213],\n",
      "         ...,\n",
      "         [ 0.0068,  0.0756, -0.0054,  ..., -0.0822, -0.0144,  0.0048],\n",
      "         [-0.0073,  0.0504, -0.0173,  ..., -0.1161, -0.0368, -0.1168],\n",
      "         [-0.0148,  0.0754, -0.0074,  ..., -0.0773, -0.0285, -0.0834]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 7.7922e-01, -1.7151e-01, -5.7134e-02,  ...,  2.1306e+00,\n",
      "           1.5183e+00, -3.0796e-01],\n",
      "         [ 9.1112e-01, -2.7280e-01,  3.7283e-01,  ...,  2.2674e+00,\n",
      "           5.9850e-01, -4.0911e-01],\n",
      "         [ 9.3215e-01, -1.6823e-01,  1.5127e-01,  ...,  8.1941e-01,\n",
      "           1.1423e+00, -4.6804e-01],\n",
      "         ...,\n",
      "         [ 1.0550e-02,  4.0187e-02, -1.2155e-02,  ..., -9.3447e-02,\n",
      "          -3.3394e-02, -8.2339e-02],\n",
      "         [ 6.2436e-03,  7.3542e-02, -2.2530e-03,  ..., -8.1071e-02,\n",
      "          -2.3141e-02, -7.7101e-02],\n",
      "         [-4.9270e-02,  1.1431e-01, -2.1615e-02,  ..., -4.3380e-02,\n",
      "          -2.6274e-02, -2.0531e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.1291e-01,  1.7224e-02,  2.5961e-01,  ...,  2.2828e+00,\n",
      "           9.1312e-01, -3.6045e-01],\n",
      "         [ 9.0683e-01, -1.0088e-01,  5.0953e-01,  ...,  3.7169e-01,\n",
      "           3.7880e-01,  9.6556e-02],\n",
      "         [ 1.1214e+00, -6.2639e-01,  7.4325e-01,  ...,  2.0049e+00,\n",
      "           8.0290e-01, -3.6121e-01],\n",
      "         ...,\n",
      "         [-1.9109e-02,  6.8680e-02, -4.9961e-03,  ..., -9.2939e-02,\n",
      "          -4.4846e-02, -7.5044e-02],\n",
      "         [ 1.8884e-03,  6.2935e-02, -2.5532e-03,  ..., -6.3579e-02,\n",
      "          -3.1092e-02, -8.4353e-02],\n",
      "         [-1.0003e-02,  7.9895e-02, -1.0068e-02,  ..., -7.6981e-02,\n",
      "          -2.8478e-02, -8.3049e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.7720e-01,  9.4619e-02,  5.1091e-01,  ...,  1.7658e+00,\n",
      "           1.7319e+00,  2.1472e-01],\n",
      "         [ 1.1015e+00, -3.7934e-01,  5.1463e-01,  ...,  2.1517e+00,\n",
      "           1.0490e+00, -1.5715e-03],\n",
      "         [ 9.2283e-01, -1.0899e-01,  3.9269e-01,  ...,  1.8616e+00,\n",
      "           1.0017e+00,  7.6424e-02],\n",
      "         ...,\n",
      "         [-1.5030e-04,  7.1572e-02, -6.2877e-04,  ..., -8.1674e-02,\n",
      "          -3.0925e-02, -8.9439e-02],\n",
      "         [ 2.9791e-03,  5.4843e-02,  9.3772e-04,  ..., -8.4817e-02,\n",
      "          -2.3205e-02,  1.1235e-02],\n",
      "         [-7.1620e-03,  9.2302e-02, -9.2734e-03,  ..., -7.5944e-02,\n",
      "          -3.8535e-02, -9.4358e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ash avildsen and matty beckerman\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7574, -0.0413,  0.1218,  ...,  1.7684,  1.5396, -0.0595],\n",
      "         [ 0.2095, -0.0072,  0.3399,  ...,  1.9959,  0.9353,  0.0336],\n",
      "         [ 0.3928, -0.1643,  0.4272,  ...,  1.4512,  0.8185, -0.3003],\n",
      "         ...,\n",
      "         [-0.0073,  0.0732,  0.0041,  ..., -0.0716, -0.0245, -0.0783],\n",
      "         [-0.0081,  0.0392,  0.0050,  ..., -0.0820, -0.0270, -0.0722],\n",
      "         [ 0.0044,  0.0611,  0.0107,  ..., -0.0824, -0.0295, -0.0771]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  lost princess of oz\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.1798e-01, -7.0563e-02, -9.3321e-02,  ...,  2.0050e+00,\n",
      "           1.5802e+00, -5.5982e-01],\n",
      "         [ 5.3664e-01, -9.5912e-02,  5.3912e-01,  ...,  2.0617e+00,\n",
      "           6.9953e-01, -6.1381e-01],\n",
      "         [ 9.2755e-01, -1.7186e-01,  6.7058e-01,  ...,  2.1453e+00,\n",
      "           8.5316e-01, -5.8836e-01],\n",
      "         ...,\n",
      "         [-1.2621e-02,  7.3515e-02,  1.2855e-03,  ..., -8.3610e-02,\n",
      "          -3.0459e-02, -7.7371e-02],\n",
      "         [-1.3787e-03,  3.8802e-02, -8.9691e-03,  ..., -7.6498e-02,\n",
      "          -2.8753e-02, -9.2702e-02],\n",
      "         [-1.1851e-02,  7.4299e-02,  5.2470e-03,  ..., -7.9751e-02,\n",
      "          -3.4014e-02, -8.6742e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.1276, -0.1319, -0.0404,  ...,  1.9671,  1.4669,  0.4621],\n",
      "         [ 0.4590, -0.2169,  0.4416,  ...,  2.3692,  0.7721,  0.4794],\n",
      "         [ 0.6084, -0.6823,  0.4692,  ...,  1.7762,  0.9092,  0.0133],\n",
      "         ...,\n",
      "         [-0.0095,  0.0759,  0.0031,  ..., -0.0748, -0.0282, -0.0779],\n",
      "         [-0.0234,  0.1265,  0.0581,  ...,  0.1491, -0.0412, -0.1044],\n",
      "         [ 0.3478,  0.1474, -0.1356,  ...,  0.3315,  0.0662, -0.2810]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.1524e-01, -2.3972e-01, -2.4032e-03,  ...,  1.8575e+00,\n",
      "           1.3848e+00, -3.7480e-02],\n",
      "         [ 5.6347e-01,  9.2902e-02,  1.1142e-01,  ...,  1.7363e+00,\n",
      "           6.4062e-01, -3.0946e-01],\n",
      "         [ 2.4080e-01,  2.2826e-01,  7.0838e-01,  ...,  1.0490e+00,\n",
      "           6.5252e-01,  7.8435e-02],\n",
      "         ...,\n",
      "         [ 2.1401e-01,  1.5387e-01, -2.6669e-02,  ..., -2.2040e-03,\n",
      "           1.1689e-01, -2.1723e-01],\n",
      "         [-1.4245e-02,  7.4037e-02, -8.8807e-03,  ..., -7.4713e-02,\n",
      "          -2.9304e-02, -8.6151e-02],\n",
      "         [-1.2193e-02,  6.9509e-02,  4.4084e-05,  ..., -8.1574e-02,\n",
      "          -3.1875e-02,  1.0610e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.2001e-01, -1.5635e-01, -3.6470e-02,  ...,  2.2164e+00,\n",
      "           1.1409e+00, -2.7305e-01],\n",
      "         [ 4.7337e-01, -1.4487e-01,  5.1261e-01,  ...,  3.0072e+00,\n",
      "           7.2740e-01, -1.8603e-01],\n",
      "         [ 3.0610e-01, -1.9285e-01,  3.2495e-01,  ...,  1.7328e+00,\n",
      "           6.7479e-01, -1.9762e-01],\n",
      "         ...,\n",
      "         [ 1.1483e-02,  2.6998e-02,  8.0460e-03,  ..., -7.4986e-02,\n",
      "          -3.1976e-02, -6.7329e-02],\n",
      "         [-2.7037e-05,  6.8851e-02,  1.4694e-02,  ..., -1.1220e-01,\n",
      "          -3.1949e-02, -7.6992e-03],\n",
      "         [ 1.7332e-02,  7.5534e-02, -5.4716e-03,  ..., -8.6913e-02,\n",
      "          -2.4830e-02, -8.1457e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2139e+00, -1.9832e-02,  5.6877e-01,  ...,  3.8044e-01,\n",
      "           1.7197e+00, -2.7940e-01],\n",
      "         [ 1.0814e+00, -3.0005e-01,  6.9113e-01,  ...,  2.0963e+00,\n",
      "           8.4540e-01, -1.0689e-01],\n",
      "         [ 1.0456e+00, -9.2009e-02,  1.8505e-01,  ...,  1.2855e+00,\n",
      "           8.3036e-01,  1.6782e-01],\n",
      "         ...,\n",
      "         [ 6.0018e-03,  1.0949e-01,  1.4393e-01,  ..., -9.6622e-02,\n",
      "          -6.2384e-03, -2.7057e-01],\n",
      "         [-1.6406e-03,  6.6787e-02, -5.2198e-03,  ..., -1.0405e-01,\n",
      "          -9.0744e-03, -6.7121e-02],\n",
      "         [-3.5602e-02,  8.2253e-02, -9.2483e-02,  ..., -1.0458e-01,\n",
      "           7.1058e-02, -1.7431e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  magnolia pictures\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8678, -0.2196,  0.1981,  ...,  1.5369,  0.8863,  0.2520],\n",
      "         [ 0.4590, -0.1720,  0.1019,  ...,  2.2403,  0.8671,  0.1248],\n",
      "         [ 0.1319,  0.2294,  0.1034,  ...,  1.2585,  0.6437,  0.9880],\n",
      "         ...,\n",
      "         [ 0.0095,  0.0736, -0.0105,  ..., -0.1100, -0.0263, -0.0873],\n",
      "         [-0.0025,  0.3518, -0.0897,  ..., -0.2826,  0.0119,  0.0132],\n",
      "         [-0.0115,  0.0653, -0.0033,  ..., -0.0806, -0.0299, -0.0772]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9955, -0.1502, -0.1021,  ...,  2.1215,  1.4638, -0.1600],\n",
      "         [ 0.8370, -0.3386,  0.2581,  ...,  1.7556,  0.7167, -0.1362],\n",
      "         [-0.0543, -0.1268,  0.5105,  ...,  1.6389,  0.7358, -0.3943],\n",
      "         ...,\n",
      "         [-0.0548,  0.4473,  0.0514,  ..., -0.4812,  0.0824, -0.0130],\n",
      "         [-0.0116,  0.0225, -0.0059,  ..., -0.0746, -0.0292, -0.0986],\n",
      "         [-0.4327,  0.2091, -0.5598,  ..., -0.2187,  0.2243, -0.4009]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7864, -0.3431,  0.0786,  ...,  1.8619,  1.2072,  0.3512],\n",
      "         [ 0.9163, -0.2453,  0.5614,  ...,  0.9525,  0.5985, -0.3138],\n",
      "         [ 0.6336, -0.0913,  0.5687,  ...,  2.2779,  0.9294,  0.0633],\n",
      "         ...,\n",
      "         [-0.1461,  0.0958, -0.0054,  ...,  0.1213,  0.0748, -0.0916],\n",
      "         [-0.0130,  0.0787, -0.0069,  ..., -0.0798, -0.0386, -0.0780],\n",
      "         [-0.0217,  0.5759, -0.2188,  ..., -0.2462,  0.0801, -0.1232]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9992, -0.3166,  0.5789,  ...,  2.2050,  1.3986, -0.2118],\n",
      "         [ 0.8190,  0.0540,  0.8612,  ...,  1.8872,  0.7478, -0.1308],\n",
      "         [ 0.5680, -0.0349,  0.4418,  ...,  0.4022,  0.7115,  0.2025],\n",
      "         ...,\n",
      "         [-0.0143,  0.0875, -0.0217,  ..., -0.0517, -0.0330,  0.0030],\n",
      "         [-0.0154,  0.0761, -0.0116,  ..., -0.0803, -0.0382, -0.0704],\n",
      "         [-0.0100,  0.0817, -0.0055,  ..., -0.0844, -0.0370, -0.0879]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.3031e+00, -4.9803e-01,  5.7689e-01,  ...,  1.7044e+00,\n",
      "           1.5512e+00, -4.6105e-02],\n",
      "         [ 1.0724e+00, -2.5144e-01,  6.3137e-01,  ...,  8.9633e-01,\n",
      "           1.0564e+00, -3.7736e-01],\n",
      "         [ 6.0492e-01, -2.8006e-01,  5.1957e-01,  ...,  1.7156e+00,\n",
      "           8.2461e-01, -2.5885e-01],\n",
      "         ...,\n",
      "         [-1.2727e-02,  4.1150e-02, -6.3692e-03,  ..., -9.1028e-02,\n",
      "          -3.4467e-02, -8.3379e-02],\n",
      "         [ 1.4035e-01,  2.5042e-02, -1.6043e-01,  ..., -2.4790e-01,\n",
      "           4.2346e-02, -3.1381e-01],\n",
      "         [-1.6903e-02,  6.8751e-02, -1.2383e-03,  ..., -8.5365e-02,\n",
      "          -3.5237e-02, -8.7529e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8501, -0.0835,  0.0828,  ...,  1.4707,  1.2226, -0.1922],\n",
      "         [ 0.7963,  0.1153,  0.6807,  ...,  2.0358,  0.1039,  0.0205],\n",
      "         [ 0.9112,  0.1013,  0.4510,  ...,  0.4813,  0.9083, -0.1379],\n",
      "         ...,\n",
      "         [-0.0165,  0.0687, -0.0101,  ..., -0.0809, -0.0143, -0.0795],\n",
      "         [ 0.0089,  0.0687, -0.0023,  ..., -0.0697, -0.0228,  0.0154],\n",
      "         [-0.0195,  0.0795,  0.0029,  ..., -0.0781, -0.0278, -0.0891]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 4.3348e-01, -9.0709e-02,  3.1261e-01,  ...,  1.6216e+00,\n",
      "           1.1634e+00,  7.2024e-01],\n",
      "         [ 2.7512e-01, -9.3621e-02,  1.8398e-01,  ...,  2.0625e+00,\n",
      "           8.0358e-01,  4.0424e-01],\n",
      "         [ 4.0304e-01, -3.5559e-01,  3.8039e-01,  ...,  1.5435e+00,\n",
      "           9.3073e-01, -4.0164e-01],\n",
      "         ...,\n",
      "         [ 1.7893e-01,  4.7943e-02, -2.4644e-01,  ..., -2.6229e-01,\n",
      "           3.4267e-01, -1.6584e-01],\n",
      "         [ 2.7378e-02,  7.6610e-02,  9.4565e-04,  ..., -7.7358e-02,\n",
      "          -2.2215e-02, -9.1202e-02],\n",
      "         [ 4.0177e-01,  5.1113e-02,  2.6771e-02,  ..., -5.4126e-02,\n",
      "           5.1954e-01, -3.5912e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7745, -0.0845,  0.4184,  ...,  1.7562,  1.6610, -0.9342],\n",
      "         [ 0.4794, -0.2184,  0.6760,  ...,  0.4521,  0.3952, -0.3983],\n",
      "         [ 0.1036,  0.1055,  0.4144,  ...,  0.6807,  0.5759, -0.3475],\n",
      "         ...,\n",
      "         [-0.0145,  0.0410, -0.0075,  ..., -0.0829, -0.0189, -0.0692],\n",
      "         [-0.0050,  0.2484,  0.0233,  ..., -0.2684,  0.2183, -0.1883],\n",
      "         [-0.0037,  0.1993,  0.0621,  ..., -0.0991, -0.0498, -0.1856]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.1802e-01, -2.4095e-01,  4.5071e-01,  ...,  1.7008e+00,\n",
      "           1.4043e+00, -3.1994e-01],\n",
      "         [ 9.1571e-01, -9.2716e-02,  5.3132e-01,  ...,  1.8103e+00,\n",
      "           7.9243e-02,  2.6767e-01],\n",
      "         [ 9.1538e-01, -1.7652e-01,  1.7938e-01,  ...,  1.4165e+00,\n",
      "           9.8190e-01,  2.5302e-01],\n",
      "         ...,\n",
      "         [-2.0824e-02,  7.1002e-02,  2.9167e-03,  ..., -7.6182e-02,\n",
      "          -3.5434e-02, -8.1907e-02],\n",
      "         [-1.7536e-02,  6.6282e-02, -6.8172e-03,  ..., -8.8105e-02,\n",
      "          -2.8683e-02,  1.5073e-02],\n",
      "         [ 1.5050e-02,  7.3761e-02, -3.3826e-04,  ..., -7.5391e-02,\n",
      "          -4.3266e-02, -6.6752e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.8260e-01,  2.0497e-01,  3.1067e-02,  ...,  2.1864e+00,\n",
      "           1.2484e+00, -2.6686e-01],\n",
      "         [ 9.3404e-01,  4.3926e-02,  4.6080e-01,  ...,  2.3067e+00,\n",
      "           9.5767e-01,  3.4512e-01],\n",
      "         [ 7.6428e-01,  3.4155e-02,  5.1997e-01,  ...,  1.8206e+00,\n",
      "           4.1382e-01, -1.2664e-01],\n",
      "         ...,\n",
      "         [-6.8196e-02,  2.3551e-01, -6.1630e-02,  ..., -2.3416e-01,\n",
      "           3.8929e-02, -1.3864e-01],\n",
      "         [-1.2407e-02,  6.2160e-02,  3.0687e-03,  ..., -7.4862e-02,\n",
      "          -3.1592e-02, -8.6803e-02],\n",
      "         [-8.0873e-03,  7.2435e-02,  2.2988e-03,  ..., -6.6952e-02,\n",
      "          -2.6417e-02, -6.4601e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.1486e-01, -3.4871e-01, -1.6614e-03,  ...,  1.4428e+00,\n",
      "           1.1604e+00, -7.3262e-02],\n",
      "         [ 6.8230e-01, -1.3983e-01,  3.3142e-01,  ...,  2.1393e+00,\n",
      "           6.3020e-02,  2.1113e-01],\n",
      "         [ 3.7282e-01, -4.3731e-01, -1.1693e-01,  ...,  1.0713e+00,\n",
      "           3.4151e-01, -6.3618e-02],\n",
      "         ...,\n",
      "         [ 2.0564e-02,  1.2870e-01, -6.9260e-04,  ..., -3.0097e-02,\n",
      "          -3.0002e-02, -2.0918e-01],\n",
      "         [-1.1664e-02,  7.6025e-02, -9.8325e-03,  ..., -7.5819e-02,\n",
      "          -2.9875e-02, -8.3916e-02],\n",
      "         [-1.3824e-02,  1.6465e-01,  8.8704e-03,  ..., -7.1882e-02,\n",
      "          -6.0390e-02, -2.2137e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "answer:  st johns\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9221, -0.3775,  0.0653,  ...,  2.2665,  0.8211, -0.2544],\n",
      "         [ 0.6641, -0.2512,  0.7735,  ...,  1.9188,  0.7071,  0.1371],\n",
      "         [ 0.8700,  0.0902,  0.7841,  ...,  1.9806,  0.3820,  0.0944],\n",
      "         ...,\n",
      "         [ 0.0361, -0.0373, -0.2339,  ..., -0.0684,  0.3248, -0.3563],\n",
      "         [ 0.0495,  0.2832, -0.1477,  ..., -0.4152,  0.1177,  0.0902],\n",
      "         [-0.2661, -0.2270, -0.3850,  ...,  1.1401,  0.0275, -0.2216]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7515, -0.3052,  0.3606,  ...,  1.8069,  1.1111, -0.8357],\n",
      "         [ 0.5016, -0.0941,  0.9024,  ...,  1.8887,  0.6028, -0.6713],\n",
      "         [ 0.9051, -0.0471,  0.6362,  ...,  1.6267,  0.6063, -0.8031],\n",
      "         ...,\n",
      "         [ 0.0033,  0.0642,  0.0028,  ..., -0.1145, -0.0235, -0.0727],\n",
      "         [-0.0784,  0.3339, -0.1070,  ..., -0.4767,  0.1291,  0.1018],\n",
      "         [-0.0059,  0.0696,  0.0035,  ..., -0.0883, -0.0241, -0.0821]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 8.0566e-01,  1.2922e-01,  1.5788e-01,  ...,  3.1879e-01,\n",
      "           1.3372e+00,  1.0891e-01],\n",
      "         [ 5.3187e-01, -2.3081e-01,  4.4398e-01,  ...,  2.3729e+00,\n",
      "           5.1909e-01, -2.9454e-01],\n",
      "         [ 9.5931e-02, -5.8059e-01,  3.6103e-01,  ...,  1.8330e+00,\n",
      "           7.7611e-01, -1.7248e-01],\n",
      "         ...,\n",
      "         [-4.6389e-02,  1.4264e-01,  1.5992e-02,  ..., -3.1363e-02,\n",
      "           9.3024e-04, -1.9487e-01],\n",
      "         [-5.3819e-05,  3.7043e-01, -6.0105e-02,  ..., -6.6670e-02,\n",
      "           2.5094e-02, -1.9831e-03],\n",
      "         [-4.7150e-02,  1.3750e-01, -1.7588e-02,  ..., -2.8210e-02,\n",
      "          -3.6011e-02, -1.9856e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.8061, -0.3089,  0.0045,  ...,  1.9963,  1.0807, -0.2891],\n",
      "         [ 0.0570,  0.1963,  0.2890,  ...,  2.1337,  0.4630,  0.1915],\n",
      "         [ 0.1808, -0.1871,  0.4488,  ...,  0.7436,  0.4684, -0.2885],\n",
      "         ...,\n",
      "         [ 0.0841, -0.1870, -0.3237,  ..., -0.0032,  0.5865, -0.8355],\n",
      "         [-0.0247,  0.0609, -0.0190,  ..., -0.0831, -0.0398, -0.0920],\n",
      "         [-0.0137,  0.0794, -0.0056,  ..., -0.0771, -0.0306, -0.0864]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7232, -0.1725,  0.3088,  ...,  1.4753,  1.1887, -0.0648],\n",
      "         [ 0.9198, -0.0712,  0.4070,  ...,  2.1655,  0.5514, -0.4164],\n",
      "         [ 0.8761, -0.2196,  0.6577,  ...,  2.6381,  0.5352, -0.4927],\n",
      "         ...,\n",
      "         [-0.0134,  0.0270, -0.0070,  ..., -0.0645, -0.0418, -0.0748],\n",
      "         [-0.0093,  0.0628, -0.0070,  ..., -0.0796, -0.0379,  0.0172],\n",
      "         [ 0.1152,  0.2964, -0.0082,  ...,  0.1650, -0.0563, -0.0865]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "answer:  essex\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0587,  0.0923,  0.2732,  ...,  1.8859,  1.1184, -0.0195],\n",
      "         [ 0.5935, -0.0742,  0.5924,  ...,  2.3613,  0.2741,  0.6071],\n",
      "         [ 0.8179,  0.3626,  0.2894,  ...,  1.6162,  0.7070, -0.3580],\n",
      "         ...,\n",
      "         [-0.0463,  0.1200,  0.0275,  ..., -0.0421, -0.0232, -0.1851],\n",
      "         [-0.0067,  0.0666, -0.0111,  ..., -0.0716, -0.0157, -0.0740],\n",
      "         [-0.0191,  0.0426,  0.0035,  ..., -0.0843, -0.0353, -0.0882]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "answer:  danny leiner\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  munster rugby\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9353, -0.1916,  0.0127,  ...,  2.0594,  0.7824,  0.2643],\n",
      "         [ 0.5095, -0.0335,  0.4028,  ...,  2.2098,  0.5518, -0.1500],\n",
      "         [ 0.5185, -0.0878,  0.4287,  ...,  1.9001,  0.8816, -0.3255],\n",
      "         ...,\n",
      "         [-0.0127,  0.0761, -0.0027,  ..., -0.0765, -0.0424, -0.0572],\n",
      "         [-0.0052,  0.0774,  0.0102,  ..., -0.0780, -0.0268, -0.0925],\n",
      "         [ 0.0093,  0.2191, -0.2493,  ...,  0.2997,  0.1086,  0.0666]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7998,  0.1303,  0.5815,  ...,  0.4804,  1.2150, -0.2887],\n",
      "         [ 0.6810,  0.0110,  0.9291,  ...,  1.8641,  0.0510, -0.2731],\n",
      "         [ 0.8738, -0.2167,  0.4019,  ...,  1.0559,  0.2339, -0.7957],\n",
      "         ...,\n",
      "         [ 0.0057,  0.0759,  0.0131,  ..., -0.0668, -0.0102, -0.1249],\n",
      "         [-0.0022,  0.0741, -0.0036,  ..., -0.0778, -0.0259, -0.0733],\n",
      "         [-0.0037,  0.0206,  0.0092,  ..., -0.1180,  0.0230, -0.2403]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.7217,  0.0571,  0.1803,  ...,  1.7626,  0.9842, -0.0049],\n",
      "         [ 0.5120,  0.3103,  0.5413,  ...,  2.3848,  0.4991, -0.0453],\n",
      "         [ 0.2019,  0.3259,  0.4635,  ...,  1.5034,  0.4431, -0.0225],\n",
      "         ...,\n",
      "         [ 0.5710,  0.7171,  0.0568,  ..., -0.2706,  0.4109, -0.3255],\n",
      "         [-0.0178,  0.0806, -0.0046,  ..., -0.0711, -0.0489, -0.1035],\n",
      "         [ 0.0485,  0.0878, -0.0509,  ..., -0.1556, -0.0336, -0.0763]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8884,  0.1617,  0.0905,  ...,  1.9945,  1.1247,  0.3249],\n",
      "         [ 0.0923,  0.1948,  0.5762,  ...,  2.1286,  0.4989, -0.1479],\n",
      "         [ 0.3982,  0.2035,  0.3668,  ..., -0.3366,  0.7184, -0.1561],\n",
      "         ...,\n",
      "         [-0.0152,  0.0778, -0.0082,  ..., -0.0759, -0.0350, -0.0643],\n",
      "         [-0.0100,  0.0819, -0.0059,  ..., -0.0724, -0.0328, -0.0802],\n",
      "         [-0.0243,  0.0727, -0.0103,  ..., -0.0775, -0.0310, -0.1219]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.1300, -0.3841,  0.2213,  ...,  2.4765,  1.1721, -0.0290],\n",
      "         [ 0.4067, -0.0807,  0.2253,  ...,  2.5653,  0.4526,  0.4783],\n",
      "         [ 0.7820,  0.1534,  0.2601,  ...,  0.2285,  0.4214,  0.3707],\n",
      "         ...,\n",
      "         [ 0.0525,  0.2686,  0.0247,  ..., -0.4615,  0.0478, -0.0629],\n",
      "         [ 0.1335,  1.0462,  0.2427,  ...,  0.2296, -0.0216, -0.1751],\n",
      "         [-0.0051,  0.1636,  0.0416,  ..., -0.0782, -0.0799, -0.2557]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0864, -0.2322,  0.2305,  ...,  0.4961,  1.5978, -0.2418],\n",
      "         [-0.0036, -0.0906,  0.2065,  ...,  1.7496,  0.7942,  0.9308],\n",
      "         [ 0.5783,  0.0430,  0.2761,  ...,  1.8676,  0.8401, -0.5323],\n",
      "         ...,\n",
      "         [-0.0029,  0.0983, -0.0035,  ..., -0.0738, -0.0173, -0.0840],\n",
      "         [-0.0088,  0.0789, -0.0030,  ..., -0.0724, -0.0283, -0.0802],\n",
      "         [ 0.0481,  0.0838,  0.0122,  ..., -0.0467, -0.0483, -0.1994]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 7.6075e-01, -2.0022e-01,  3.6629e-01,  ...,  2.1680e+00,\n",
      "           4.2375e-01,  4.5629e-01],\n",
      "         [ 4.2301e-01, -2.2928e-01,  2.8916e-01,  ...,  2.3243e+00,\n",
      "           5.8758e-01,  8.7905e-01],\n",
      "         [ 2.1320e-01, -3.7656e-01, -1.0701e-01,  ...,  1.5447e+00,\n",
      "           6.0723e-01,  2.6846e-01],\n",
      "         ...,\n",
      "         [-7.5511e-03,  7.9838e-02, -1.9043e-03,  ..., -7.5067e-02,\n",
      "          -3.4116e-02, -7.9394e-02],\n",
      "         [-1.0516e-02,  7.3318e-02,  5.1640e-04,  ..., -7.4545e-02,\n",
      "          -1.7832e-02, -8.8288e-02],\n",
      "         [-1.2780e-02,  7.5427e-02, -5.2867e-04,  ..., -8.8581e-02,\n",
      "          -2.7339e-02, -8.5974e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 1.1807, -0.5137,  0.0809,  ...,  2.0600,  0.9505,  0.0403],\n",
      "         [ 0.5636, -0.3077,  0.2623,  ...,  1.6272,  0.1881, -0.0416],\n",
      "         [ 0.6409, -0.1773,  0.4994,  ...,  2.5237,  0.8239, -0.3173],\n",
      "         ...,\n",
      "         [-0.0117,  0.0692, -0.0094,  ..., -0.0686, -0.0304, -0.0862],\n",
      "         [-0.0320, -0.0223, -0.3915,  ...,  0.1085,  0.1124, -0.1167],\n",
      "         [-0.2913,  0.4210, -0.0520,  ..., -0.0802,  0.0595,  0.0891]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7799, -0.6197,  0.1808,  ...,  1.7410,  1.2688, -0.1346],\n",
      "         [ 0.8822, -0.1260,  0.5483,  ...,  0.7068,  0.4260, -0.0662],\n",
      "         [ 1.0101, -0.4351,  0.3333,  ...,  1.7482,  0.3374, -0.1558],\n",
      "         ...,\n",
      "         [-0.0027,  0.0749, -0.0027,  ..., -0.0818, -0.0424, -0.0782],\n",
      "         [ 0.0064,  0.2903, -0.1397,  ..., -0.3773, -0.0215,  0.1453],\n",
      "         [-0.0278,  0.1446, -0.0264,  ..., -0.0502, -0.0714, -0.2694]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-4.4682e-01, -1.2018e-01, -1.2356e-01,  ...,  1.8786e+00,\n",
      "           9.3415e-01,  3.4578e-01],\n",
      "         [ 8.0649e-01, -2.9958e-01,  1.9341e-01,  ...,  2.4227e+00,\n",
      "           4.3247e-01, -3.5200e-01],\n",
      "         [ 6.6008e-01, -4.0219e-01,  1.3009e-01,  ...,  1.8970e+00,\n",
      "           6.1002e-01,  5.3414e-01],\n",
      "         ...,\n",
      "         [ 1.4748e-02,  1.8276e-01,  4.3972e-02,  ..., -1.0147e-01,\n",
      "          -6.1912e-02, -2.2227e-01],\n",
      "         [-2.0637e-02,  3.8874e-02,  2.1332e-03,  ..., -7.8205e-02,\n",
      "          -3.8507e-02, -6.5460e-02],\n",
      "         [-1.5368e-02,  1.7676e-01,  3.3987e-02,  ..., -6.9092e-02,\n",
      "          -6.6887e-02, -2.3757e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  24 october 1632\n",
      "answer:  lorax\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0424, -0.4555,  0.2159,  ...,  2.3180,  1.0504,  0.0623],\n",
      "         [ 0.4636, -0.4041,  0.3853,  ...,  2.7394,  0.5805,  0.2891],\n",
      "         [ 0.7969, -0.6261,  0.5473,  ...,  2.2811,  0.8936, -0.1298],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7798, -0.3558,  0.4647,  ...,  2.0929,  1.0110, -0.1687],\n",
      "         [ 0.3731, -0.1903,  0.6331,  ...,  1.9915,  0.3228,  0.1968],\n",
      "         [ 0.3393, -0.3617,  0.6268,  ...,  1.7429,  0.5651,  0.0788],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  marlboro\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0866, -0.5563,  0.1288,  ...,  2.3207,  1.1278,  0.2046],\n",
      "         [ 0.9445, -0.3062,  0.2802,  ...,  2.5003,  0.6310,  0.3575],\n",
      "         [ 1.0846,  0.0595,  0.2230,  ...,  1.6138,  0.6149,  0.2161],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8844, -0.3193,  0.3303,  ...,  2.4097,  0.9448,  0.0602],\n",
      "         [ 0.8670, -0.3808,  0.3906,  ...,  2.7543,  0.5656,  0.2064],\n",
      "         [ 0.9125, -0.4096,  0.4008,  ...,  2.5034,  0.5405,  0.1074],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7791,  0.0622,  0.2835,  ...,  2.1781,  0.8665,  0.2558],\n",
      "         [ 0.3455, -0.1517,  0.4128,  ...,  2.3400,  0.4834,  0.0201],\n",
      "         [ 0.2764,  0.2179,  0.5135,  ...,  1.5787,  0.5213,  0.1871],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.8804, -0.3069,  0.3072,  ...,  1.4671,  1.3022,  0.3395],\n",
      "         [-0.2186, -0.0279,  0.3145,  ...,  1.5521,  0.6909,  0.4245],\n",
      "         [ 0.1862, -0.1086,  0.3250,  ...,  0.0646,  0.2727,  0.3163],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9885, -0.2249,  0.1501,  ...,  2.1743,  1.0277,  0.3319],\n",
      "         [ 0.5649, -0.2276,  0.4337,  ...,  2.2610,  0.5028,  0.4242],\n",
      "         [ 0.5905, -0.0831,  0.0175,  ...,  1.9773,  0.3406,  0.4179],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7442, -0.0630,  0.1417,  ...,  1.9852,  1.1428, -0.0976],\n",
      "         [ 0.2616, -0.3256,  0.3840,  ...,  2.5293,  0.5200,  0.2648],\n",
      "         [ 0.0767, -0.5011,  0.4670,  ...,  1.8600,  0.7032, -0.0734],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8213, -0.1128,  0.3057,  ...,  2.0259,  0.8854,  0.1803],\n",
      "         [-0.3110, -0.1380,  0.4710,  ...,  2.1001,  0.4447,  0.4483],\n",
      "         [ 0.7764, -0.2143,  0.4313,  ...,  1.1817,  0.6265,  0.1276],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0242, -0.3720,  0.2550,  ...,  2.1990,  1.2474, -0.0938],\n",
      "         [ 0.8245, -0.2403,  0.2098,  ...,  2.4597,  0.6902,  0.1884],\n",
      "         [ 0.6998, -0.1193,  0.1702,  ...,  1.9303,  0.6896,  0.1501],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  4\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.3107, -0.4209,  0.1681,  ...,  1.9905,  0.8832,  0.0231],\n",
      "         [ 0.6628, -0.2960,  0.5830,  ...,  2.4835,  0.4851,  0.1762],\n",
      "         [ 0.7028, -0.3000,  0.5619,  ...,  2.2943,  0.4959,  0.1146],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0281, -0.2003,  0.2897,  ...,  2.2011,  1.2478,  0.0396],\n",
      "         [ 0.8100,  0.0639,  0.2576,  ...,  2.4090,  0.5590,  0.1754],\n",
      "         [ 0.6021,  0.1214, -0.1370,  ...,  1.7155,  0.2661, -0.0438],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6828,  0.0219,  0.2875,  ...,  2.0532,  0.9898,  0.0056],\n",
      "         [-0.0378,  0.2481,  0.5700,  ...,  1.8125,  0.2952,  0.3640],\n",
      "         [ 0.1218,  0.2819,  0.5833,  ...,  0.8715,  0.1576,  0.2345],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  charles manson\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.6247,  0.1395,  0.3750,  ...,  1.9642,  1.0681, -0.0777],\n",
      "         [ 0.1335, -0.1604,  0.3256,  ...,  2.0339,  0.5805, -0.0773],\n",
      "         [ 0.3534, -0.4242,  0.2700,  ...,  1.7529,  0.6903,  0.0427],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9090, -0.4585,  0.2750,  ...,  2.1878,  1.2233,  0.0081],\n",
      "         [ 0.9156, -0.3766,  0.3609,  ...,  2.3854,  0.6883,  0.1968],\n",
      "         [ 0.5601, -0.1255,  0.3621,  ...,  1.5769,  0.6027,  0.0726],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.7286, -0.1275,  0.3707,  ...,  2.0446,  0.8634, -0.1066],\n",
      "         [ 0.3710, -0.2021,  0.4955,  ...,  2.0878,  0.3937,  0.2766],\n",
      "         [ 0.2945, -0.3578,  0.4464,  ...,  1.7067,  0.4777, -0.1324],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6642, -0.4138,  0.2873,  ...,  2.2435,  1.1657,  0.2342],\n",
      "         [ 0.6625, -0.2015,  0.3459,  ...,  2.3620,  0.6246,  0.5267],\n",
      "         [ 0.6168, -0.0367,  0.2086,  ...,  1.8560,  0.8154,  0.1629],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  herman wouk\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5861, -0.3210,  0.2472,  ...,  2.1851,  0.9951, -0.0298],\n",
      "         [ 0.4184, -0.3189,  0.4715,  ...,  2.6710,  0.3550,  0.1531],\n",
      "         [ 0.7448, -0.4994,  0.4673,  ...,  2.4094,  0.5543, -0.0702],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7193, -0.2102,  0.3445,  ...,  1.4984,  0.9017, -0.0096],\n",
      "         [ 0.2827, -0.3859,  0.4250,  ...,  2.1469,  0.5656,  0.2294],\n",
      "         [ 0.3143, -0.4289,  0.2737,  ...,  1.5992,  0.5596,  0.0272],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wendy carlos\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7487, -0.0363,  0.3203,  ...,  2.1652,  1.1115, -0.2989],\n",
      "         [ 0.3469,  0.0531,  0.5592,  ...,  2.0766,  0.5934, -0.0423],\n",
      "         [ 0.4750,  0.1924,  0.4270,  ...,  1.5803,  0.7280, -0.0601],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9896, -0.1939, -0.0626,  ...,  1.8489,  0.9954,  0.0259],\n",
      "         [ 0.6784, -0.0797,  0.2429,  ...,  2.1502,  0.2283,  0.1157],\n",
      "         [ 0.8856, -0.4834,  0.3651,  ...,  2.1106,  0.7166, -0.0298],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8079, -0.2109,  0.2277,  ...,  2.2211,  1.1611, -0.0904],\n",
      "         [ 0.2087, -0.1159,  0.3639,  ...,  2.1966,  0.5096,  0.3711],\n",
      "         [ 0.2484,  0.0289,  0.3689,  ...,  1.8018,  0.7226,  0.4241],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  st johns\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0508, -0.1467,  0.2384,  ...,  2.1588,  1.0387,  0.2158],\n",
      "         [ 0.3422, -0.1933,  0.3826,  ...,  2.1977,  0.5816,  0.3922],\n",
      "         [ 0.4534, -0.1335,  0.2412,  ...,  1.6478,  0.8696,  0.0190],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6250, -0.0185, -0.0611,  ...,  2.2280,  1.0278,  0.3179],\n",
      "         [ 0.8220, -0.1176,  0.3455,  ...,  2.5260,  0.6385,  0.4351],\n",
      "         [ 0.6412, -0.1003,  0.4273,  ...,  2.0939,  0.5121,  0.1584],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8169, -0.9528, -0.0389,  ...,  2.3458,  0.9601, -0.0139],\n",
      "         [ 0.6553, -0.7503,  0.4362,  ...,  2.7521,  0.4703,  0.1269],\n",
      "         [ 0.6965, -0.7771,  0.4638,  ...,  2.4686,  0.7402, -0.0167],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9438,  0.0107,  0.2927,  ...,  2.2760,  1.2177,  0.0514],\n",
      "         [ 0.7936, -0.2033,  0.4074,  ...,  2.7665,  0.6496,  0.2361],\n",
      "         [ 0.8248, -0.4574,  0.3236,  ...,  2.3112,  0.7928, -0.0659],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.7093, -0.2528, -0.1041,  ...,  1.7127,  0.9863,  0.0754],\n",
      "         [ 0.6058, -0.1484,  0.4189,  ...,  2.1963,  0.3834,  0.1562],\n",
      "         [ 0.0916,  0.2686,  0.7518,  ...,  1.4852,  0.2494,  0.3023],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7881,  0.0571,  0.3190,  ...,  2.1546,  1.0865,  0.1600],\n",
      "         [ 0.3021, -0.2727,  0.4055,  ...,  2.2713,  0.5499,  0.2462],\n",
      "         [ 0.2386, -0.3366,  0.3227,  ...,  1.7566,  0.3831,  0.1235],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9757, -0.1772,  0.0720,  ...,  1.7412,  0.9994,  0.0959],\n",
      "         [ 0.7531, -0.4305,  0.1175,  ...,  2.1734,  0.2327,  0.2169],\n",
      "         [ 0.8509, -0.4418,  0.1720,  ...,  1.8120,  0.3303, -0.1538],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])self.tokenizer.sep_token:  </s>\n",
      "\n",
      "sequence_output  tensor([[[ 0.7696, -0.0026,  0.3411,  ...,  2.2082,  0.8703, -0.1178],\n",
      "         [ 0.2985, -0.1469,  0.4424,  ...,  2.3809,  0.3752,  0.2932],\n",
      "         [ 0.3583,  0.1618,  0.2221,  ...,  2.0252,  0.3293,  0.1337],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9533, -0.3011, -0.0054,  ...,  2.4422,  1.0782, -0.0832],\n",
      "         [ 0.2001, -0.1909,  0.3372,  ...,  2.2605,  0.3169,  0.1391],\n",
      "         [ 0.3913, -0.4584,  0.5111,  ...,  1.7802,  0.7288,  0.1859],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.5621e-01, -3.5807e-01,  9.9974e-04,  ...,  1.9511e+00,\n",
      "           1.1317e+00,  1.2264e-01],\n",
      "         [-1.0297e-01, -6.7056e-02,  3.1040e-01,  ...,  2.0608e+00,\n",
      "           5.0995e-01,  1.8526e-01],\n",
      "         [ 3.0415e-01, -3.8004e-01,  5.1323e-02,  ...,  1.1059e+00,\n",
      "           4.9868e-01, -6.6627e-02],\n",
      "         ...,\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.6245, -0.3320,  0.3152,  ...,  1.9181,  1.1538,  0.1307],\n",
      "         [ 0.4305, -0.2300,  0.4887,  ...,  1.9715,  0.4406,  0.2024],\n",
      "         [ 0.1164, -0.0895,  0.4165,  ...,  1.2909,  0.7929, -0.0577],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9043, -0.1352, -0.0208,  ...,  2.4337,  1.0503,  0.1580],\n",
      "         [ 0.9500, -0.3776,  0.3089,  ...,  2.6060,  0.5698,  0.5628],\n",
      "         [ 0.8796, -0.3525,  0.2098,  ...,  2.1073,  0.6934,  0.5080],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "\n",
      "sequence_output  tensor([[[ 7.0235e-01, -3.3872e-01,  2.4736e-01,  ...,  2.2099e+00,\n",
      "           1.2192e+00,  1.0923e-01],\n",
      "         [ 7.7536e-01, -2.9308e-01,  3.6965e-01,  ...,  2.6330e+00,\n",
      "           6.4457e-01,  3.2381e-01],\n",
      "         [ 6.6695e-01, -4.1363e-01,  3.3940e-01,  ...,  2.1313e+00,\n",
      "           6.7228e-01, -7.8304e-04],\n",
      "         ...,\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  hollywood madam\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.3646,  0.1523,  0.1813,  ...,  0.5636,  0.0637,  0.3630],\n",
      "         [ 0.4072, -0.2231,  0.4126,  ...,  2.2300,  0.5027,  0.2326],\n",
      "         [ 0.1516, -0.0567,  0.0087,  ...,  1.1210,  0.3621,  0.6423],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9997, -0.2998,  0.0561,  ...,  2.1817,  0.9199,  0.1023],\n",
      "         [ 0.4023, -0.2850,  0.4430,  ...,  2.3255,  0.4484,  0.1615],\n",
      "         [ 0.1225, -0.5433,  0.2818,  ...,  0.5381,  0.2467,  0.1232],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.8392, -0.4378, -0.0154,  ...,  1.9314,  1.0207, -0.0185],\n",
      "         [ 0.4246, -0.2458,  0.3217,  ...,  2.1246,  0.5175,  0.1057],\n",
      "         [ 0.3543, -0.3489,  0.5135,  ...,  2.4599,  0.7138, -0.2162],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8968, -0.6598, -0.0707,  ...,  1.6680,  1.2759, -0.2144],\n",
      "         [ 0.7493, -0.4849,  0.4078,  ...,  1.9387,  0.7863,  0.2912],\n",
      "         [ 0.7819, -0.3678,  0.4997,  ...,  1.2898,  0.7356, -0.1726],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6963, -0.0257, -0.1786,  ...,  1.7162,  1.1264, -0.0915],\n",
      "         [ 0.4273, -0.3386,  0.4857,  ...,  1.9525,  0.4199,  0.0660],\n",
      "         [ 0.3572, -0.3401,  0.5028,  ...,  1.8124,  0.6060,  0.1118],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8681, -0.2300,  0.2059,  ...,  1.8259,  1.2320, -0.0711],\n",
      "         [ 0.3851, -0.2847,  0.6758,  ...,  2.0323,  0.4899,  0.1922],\n",
      "         [ 0.5632, -0.4111,  0.4679,  ...,  1.3227,  0.7983, -0.1512],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.3689, -0.3299,  0.1089,  ...,  2.2924,  0.9874,  0.1366],\n",
      "         [ 0.7725, -0.2270,  0.4735,  ...,  2.2715,  0.6031,  0.5345],\n",
      "         [ 0.9938, -0.0229,  0.2594,  ...,  2.0433,  0.4774,  0.3486],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  shane meadows\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9213, -0.4628,  0.2351,  ...,  2.1727,  1.2705,  0.0762],\n",
      "         [ 0.7603, -0.2727,  0.4837,  ...,  2.5962,  0.6719,  0.3277],\n",
      "         [ 0.7241, -0.4557,  0.4503,  ...,  2.4059,  0.7180,  0.0714],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.6740, -0.0298,  0.1684,  ...,  2.1853,  1.1095, -0.0029],\n",
      "         [-0.1306, -0.1003,  0.5517,  ...,  2.2884,  0.3328,  0.4419],\n",
      "         [ 0.7054, -0.1909,  0.4920,  ...,  2.4610,  0.7534,  0.2496],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9717, -0.3089,  0.3222,  ...,  2.2771,  1.3036,  0.0631],\n",
      "         [ 0.8024, -0.2130,  0.4021,  ...,  2.3617,  0.6961,  0.2653],\n",
      "         [ 0.9772, -0.3155,  0.6187,  ...,  1.7468,  0.8596,  0.0256],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7853, -0.1481,  0.4102,  ...,  2.2800,  1.0967, -0.2869],\n",
      "         [ 0.5330, -0.4913,  0.5781,  ...,  2.3479,  0.5953,  0.0878],\n",
      "         [ 0.3504, -0.5707,  0.4893,  ...,  1.6289,  0.7533, -0.1903],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7366, -0.2802,  0.3173,  ...,  2.1759,  1.0366,  0.0394],\n",
      "         [ 0.4349, -0.0974,  0.4791,  ...,  2.3513,  0.3535,  0.3608],\n",
      "         [ 0.2998,  0.0201,  0.3085,  ...,  1.9930,  0.3844,  0.1422],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "\n",
      "sequence_output  tensor([[[ 0.9392, -0.1788,  0.2119,  ...,  2.3701,  1.0733, -0.2903],\n",
      "         [ 0.7174, -0.4726,  0.4961,  ...,  2.7015,  0.6821, -0.0901],\n",
      "         [ 0.7303, -0.4354,  0.4134,  ...,  2.3656,  0.6465, -0.3151],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7431, -0.2184,  0.3934,  ...,  1.7930,  0.8205,  0.0666],\n",
      "         [ 0.8231, -0.2898,  0.4070,  ...,  2.3470,  0.5346,  0.1705],\n",
      "         [ 0.4637, -0.0270,  0.6157,  ...,  1.8307,  0.3467,  0.1290],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.1553, -0.0094,  0.0923,  ...,  2.2597,  1.2318,  0.3264],\n",
      "         [ 0.9144,  0.0254,  0.3805,  ...,  2.4325,  0.6082,  0.4361],\n",
      "         [ 0.9500, -0.1674,  0.2460,  ...,  2.0473,  0.5826,  0.0809],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0612, -0.2960, -0.0634,  ...,  1.8680,  1.2211, -0.1338],\n",
      "         [ 0.4484, -0.0128,  0.4140,  ...,  1.9519,  0.4536,  0.2347],\n",
      "         [ 0.7615, -0.2088,  0.4104,  ...,  1.2773,  0.8984,  0.1119],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6105, -0.1765, -0.0305,  ...,  1.5494,  0.8488, -0.2565],\n",
      "         [ 0.3491, -0.3468,  0.4457,  ...,  2.1912,  0.5454,  0.0176],\n",
      "         [ 0.3736, -0.4119,  0.3988,  ...,  1.7933,  0.7200, -0.0337],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7097, -0.2734,  0.1086,  ...,  1.9015,  0.8763,  0.1906],\n",
      "         [ 0.7720, -0.0996,  0.4709,  ...,  2.4067,  0.5225,  0.2308],\n",
      "         [ 0.6637,  0.0933,  0.2616,  ...,  1.5297,  0.2721, -0.0807],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7060, -0.2077,  0.3021,  ...,  2.0925,  1.0265, -0.4473],\n",
      "         [ 0.4700, -0.2293,  0.5030,  ...,  2.1213,  0.3912,  0.0621],\n",
      "         [ 0.3801, -0.1328,  0.4043,  ...,  1.6685,  0.4304, -0.0617],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  munster rugby\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.6928, -0.1229,  0.2254,  ...,  1.8356,  0.9088,  0.1641],\n",
      "         [ 0.1343, -0.2161,  0.0088,  ...,  2.2727,  0.4929,  0.2968],\n",
      "         [ 0.1372, -0.9410,  0.4374,  ...,  0.6327,  0.9952,  0.1876],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6491, -0.1604,  0.2067,  ...,  2.2373,  1.1194, -0.3101],\n",
      "         [ 0.6170, -0.5295,  0.4813,  ...,  2.5587,  0.4950,  0.1233],\n",
      "         [ 0.7640, -0.5193,  0.4420,  ...,  2.1963,  0.5962, -0.1028],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6364,  0.0058, -0.0053,  ...,  2.3518,  0.8841, -0.1505],\n",
      "         [ 0.3247, -0.0605,  0.1097,  ...,  2.1407,  0.4785, -0.0184],\n",
      "         [ 0.7213, -0.1494, -0.2052,  ...,  1.4540,  0.8913, -0.4353],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6890, -0.2385,  0.4285,  ...,  2.1061,  0.9897,  0.0158],\n",
      "         [ 0.0599, -0.2603,  0.4542,  ...,  2.0100,  0.3460,  0.2410],\n",
      "         [ 0.3027, -0.3808,  0.4362,  ...,  1.8587,  0.5881,  0.2764],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "\n",
      "sequence_output  tensor([[[ 0.7551, -0.2915,  0.4768,  ...,  1.8716,  0.9740, -0.0610],\n",
      "         [ 0.4240, -0.1064,  0.4501,  ...,  1.9309,  0.3805,  0.2246],\n",
      "         [ 0.1284,  0.1120,  0.2178,  ...,  1.2356,  0.3169,  0.3152],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.6548, -0.0300,  0.0549,  ...,  1.9058,  1.2010,  0.2950],\n",
      "         [-0.1613,  0.5011,  0.2493,  ...,  1.8556,  0.4379,  0.4366],\n",
      "         [ 0.5753, -0.2457, -0.0216,  ...,  1.0242,  0.3949, -0.2137],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.9894, -0.1628,  0.6891,  ...,  2.0743,  0.9565,  0.1754],\n",
      "         [ 0.4072, -0.2243,  0.6072,  ...,  2.2715,  0.4322,  0.3165],\n",
      "         [ 0.4088,  0.0307,  0.4637,  ...,  0.7566,  0.2172,  0.2929],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9191, -0.1532,  0.4111,  ...,  2.2610,  1.0326,  0.0821],\n",
      "         [ 0.4755, -0.2277,  0.5475,  ...,  2.3256,  0.5953,  0.2267],\n",
      "         [ 0.7575,  0.2950,  0.3070,  ...,  1.5105,  0.5650,  0.2186],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.0051, -0.1070,  0.0501,  ...,  1.8857,  0.6187, -0.0394],\n",
      "         [ 0.2091, -0.2656,  0.3733,  ...,  2.3844,  0.4694,  0.0686],\n",
      "         [ 0.4510, -0.5040,  0.4274,  ...,  1.9386,  0.6335,  0.0063],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2157, -0.2436,  0.1047,  ...,  2.4579,  1.2363, -0.0190],\n",
      "         [ 0.8995, -0.1609,  0.4360,  ...,  2.4681,  0.5736,  0.1637],\n",
      "         [ 0.8605, -0.1875,  0.4237,  ...,  1.9646,  0.7479,  0.0753],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6212, -0.0180,  0.1416,  ...,  1.7684,  1.1806,  0.2987],\n",
      "         [ 0.8025, -0.3295,  0.3722,  ...,  2.4141,  0.5053,  0.4283],\n",
      "         [ 0.8581, -0.4210,  0.3442,  ...,  1.9326,  0.7520,  0.1178],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  buddleja\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9761, -0.4242, -0.1696,  ...,  1.5258,  1.3208,  0.3078],\n",
      "         [ 0.4122, -0.1861,  0.2440,  ...,  2.0414,  0.4689,  0.4487],\n",
      "         [ 0.7863, -0.1874,  0.0362,  ...,  1.2699,  0.5501,  0.0619],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 4.7080e-01, -2.7773e-01,  4.6903e-01,  ...,  1.9024e+00,\n",
      "           1.1717e+00,  5.8220e-01],\n",
      "         [ 3.2142e-02, -1.3741e-01,  6.3192e-04,  ...,  2.0443e+00,\n",
      "           6.4093e-01,  4.0032e-01],\n",
      "         [ 1.4608e-01, -1.0448e+00,  2.9559e-01,  ...,  1.1492e+00,\n",
      "           8.2993e-01,  2.2676e-01],\n",
      "         ...,\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02],\n",
      "         [-1.2144e-02,  7.9184e-02, -3.4980e-03,  ..., -7.7751e-02,\n",
      "          -3.0967e-02, -8.9990e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.5104, -0.4099,  0.3630,  ...,  1.8406,  1.1433, -0.1449],\n",
      "         [ 0.2955, -0.1497,  0.6631,  ...,  1.5642,  0.4397, -0.0138],\n",
      "         [ 0.4671, -0.1402,  0.3836,  ...,  1.1044, -0.1321, -0.5950],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9741, -0.3817, -0.2903,  ...,  2.2385,  1.0741, -0.3429],\n",
      "         [ 0.9346, -0.3784,  0.1794,  ...,  2.5848,  0.6973, -0.0393],\n",
      "         [ 0.9318, -0.2830,  0.1425,  ...,  2.3159,  0.6973, -0.1906],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8812, -0.2912,  0.2020,  ...,  2.3181,  0.8543, -0.0541],\n",
      "         [ 0.5668, -0.1603,  0.3906,  ...,  2.2429,  0.3971,  0.3084],\n",
      "         [ 0.2206,  0.2571,  0.0055,  ...,  1.3248,  0.1303,  0.0727],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1962\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6099,  0.0296,  0.0904,  ...,  1.8593,  1.0927,  0.1541],\n",
      "         [ 0.8247, -0.3319,  0.3034,  ...,  2.4501,  0.6987,  0.2147],\n",
      "         [ 0.3005,  0.2195,  0.1088,  ..., -0.0860,  0.2788, -0.1054],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6747, -0.1185,  0.2518,  ...,  2.0273,  1.2025,  0.0078],\n",
      "         [ 0.4062, -0.2843,  0.5079,  ...,  2.2312,  0.3082,  0.0759],\n",
      "         [ 0.2199, -0.2200,  0.7093,  ...,  2.1479,  0.5386,  0.0397],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9572, -0.3167,  0.2947,  ...,  2.1396,  1.0389,  0.2894],\n",
      "         [ 0.3323,  0.1497,  0.3989,  ...,  2.1037,  0.2079,  0.4835],\n",
      "         [ 0.5165,  0.1406,  0.2740,  ...,  1.0945,  0.0733,  0.2850],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.5963, -0.2166,  0.5177,  ...,  1.8602,  0.9381,  0.3468],\n",
      "         [ 0.3142, -0.3139,  0.3432,  ...,  2.4357,  0.3226,  0.1597],\n",
      "         [ 0.1964, -0.7035,  0.6153,  ...,  1.3588,  0.8504,  0.4461],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0012, -0.1976,  0.2172,  ...,  1.5936,  1.1263,  0.2588],\n",
      "         [ 0.6112, -0.2007,  0.5169,  ...,  2.1095,  0.5656,  0.2271],\n",
      "         [ 1.0263, -0.1729,  0.2219,  ..., -0.0265,  0.5903, -0.0559],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6135, -0.1669,  0.3877,  ...,  1.8392,  1.0888,  0.3077],\n",
      "         [ 0.2180, -0.2061,  0.4569,  ...,  2.0693,  0.3410,  0.3202],\n",
      "         [ 0.0175, -0.0542,  0.2659,  ...,  0.6050,  0.3684, -0.0219],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0250, -0.4253, -0.0183,  ...,  1.9926,  0.8541,  0.0072],\n",
      "         [ 0.8354, -0.5590,  0.0962,  ...,  2.3141,  0.6883,  0.2994],\n",
      "         [ 0.9196, -0.5014,  0.2046,  ...,  1.8939,  0.7655,  0.1275],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9518,  0.1035,  0.1354,  ...,  2.0739,  0.9395, -0.1571],\n",
      "         [ 0.3315, -0.1335,  0.4621,  ...,  2.5003,  0.4247,  0.2733],\n",
      "         [ 0.2367, -0.0596,  0.1897,  ...,  1.6608,  0.4943, -0.0812],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8949, -0.1426,  0.0260,  ...,  2.3668,  1.1350, -0.1116],\n",
      "         [ 0.4382, -0.1369,  0.5060,  ...,  2.4666,  0.5425,  0.2740],\n",
      "         [ 0.6299, -0.1839,  0.5972,  ...,  1.8346,  0.7656,  0.0629],\n",
      "         ...,\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900],\n",
      "         [-0.0121,  0.0792, -0.0035,  ..., -0.0778, -0.0310, -0.0900]]],\n",
      "       device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned 0.07498217939953261 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of avg_val_f1 in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch 00003: avg_val_f1 reached 0.07498 (best 0.07498), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_3.ckpt as top 5\n",
      "\n",
      "Epoch 00003: avg_val_f1 reached 0.07498 (best 0.07498), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_3.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_end\n",
      "before sync --> sizes:  79, 79, 79\n",
      "after sync --> sizes: 79, 79, 79\n",
      "avg_loss:  tensor(13.6986, device='cuda:0')\tavg_answer_loss:  tensor(5.5226, device='cuda:0')\tavg_type_loss:  tensor(0.1473, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5094, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.2346, device='cuda:0')\n",
      "avg_val_f1:  0.07498217939953261\tavg_val_em:  0.012658227848101266\tavg_val_prec:  0.07027059779325619\tavg_val_recall:  0.14767932514601115\n",
      "avg_val_sp_sent_f1:  0.07333735329440877\tavg_val_sp_sent_em:  0.0\tavg_val_sp_sent_prec:  0.0655213990543462\tavg_val_sp_sent_recall:  0.09282700472240206\n",
      "avg_val_joint_f1:  0.010678595144160186\tavg_val_joint_em:  0.0\tavg_val_joint_prec:  0.011644742439819288\tavg_val_joint_recall:  0.0200421942185752\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  wendy carlos\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  keri russell\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  shane meadows\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  scottie pippen\n",
      "answer:  john surtees\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0851e+00, -7.4419e-01,  3.9176e-02,  ...,  1.7785e+00,\n",
      "           1.3656e+00, -3.0196e-01],\n",
      "         [ 8.3928e-01, -4.7229e-01,  6.5439e-01,  ...,  2.2454e+00,\n",
      "           4.3393e-01,  1.8840e-01],\n",
      "         [ 9.0414e-01, -6.4163e-02,  5.1893e-01,  ...,  1.5234e+00,\n",
      "           4.8768e-01, -6.0512e-02],\n",
      "         ...,\n",
      "         [ 1.6760e-03,  5.9350e-02,  5.5407e-03,  ..., -9.9079e-02,\n",
      "          -1.8725e-02, -7.4803e-02],\n",
      "         [ 2.0007e-01,  2.9800e-01,  1.0929e-01,  ..., -4.3735e-01,\n",
      "          -4.3823e-02, -8.9747e-02],\n",
      "         [ 9.7209e-03,  7.7232e-02, -4.0603e-03,  ..., -9.3188e-02,\n",
      "          -3.7645e-02, -8.8727e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1970\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.9574,  0.0418, -0.1245,  ...,  1.7784,  0.8586,  0.0309],\n",
      "         [ 0.6069, -0.1751,  0.2823,  ...,  2.1625,  0.4726, -0.1309],\n",
      "         [ 0.4491,  0.2727,  0.5965,  ...,  1.8530,  0.1867,  0.7559],\n",
      "         ...,\n",
      "         [-0.0116,  0.0685, -0.0035,  ..., -0.0807, -0.0236, -0.0747],\n",
      "         [ 0.0080,  0.0690, -0.0113,  ..., -0.0875, -0.0522, -0.0838],\n",
      "         [-0.0196,  0.0741,  0.0124,  ..., -0.0968, -0.0351, -0.0690]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.4081, -0.3986,  0.2274,  ...,  2.1309,  1.1433, -0.0705],\n",
      "         [ 0.7625,  0.0929,  0.4573,  ...,  2.6641,  0.4563,  0.3059],\n",
      "         [ 1.0318, -0.0307,  0.1804,  ...,  2.0117,  0.8122,  0.0270],\n",
      "         ...,\n",
      "         [-0.0120,  0.0646, -0.0047,  ..., -0.1188, -0.0321,  0.0307],\n",
      "         [-0.1018,  0.5648, -0.0316,  ..., -0.1800, -0.0336,  0.0892],\n",
      "         [ 0.1314,  0.3024, -0.2151,  ..., -0.2275, -0.1927, -0.1306]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.5631e-01, -6.7168e-02,  2.7763e-01,  ...,  2.1637e+00,\n",
      "           1.3022e+00,  7.2236e-02],\n",
      "         [ 3.4856e-02, -3.6460e-02,  5.5474e-01,  ...,  1.9897e+00,\n",
      "           4.7107e-01, -1.7547e-01],\n",
      "         [ 1.9656e-01, -3.9991e-01,  1.2196e-01,  ...,  1.6071e+00,\n",
      "           5.4642e-01,  1.8635e-01],\n",
      "         ...,\n",
      "         [-1.3952e-02,  8.6005e-02, -1.1682e-02,  ..., -8.1503e-02,\n",
      "          -3.7600e-02, -6.4996e-02],\n",
      "         [ 2.2123e-01,  9.1253e-02, -5.0261e-02,  ...,  1.8042e-01,\n",
      "           1.9749e-01, -3.9000e-01],\n",
      "         [-1.4552e-02,  8.5080e-02,  7.2082e-04,  ..., -7.7668e-02,\n",
      "          -4.2793e-02, -8.5885e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.0601,  0.0628,  0.0208,  ...,  0.7433,  1.2270,  0.1148],\n",
      "         [ 0.2287,  0.1535,  0.4279,  ...,  0.9215,  0.7780,  0.1558],\n",
      "         [ 0.8557, -0.2464,  0.2705,  ...,  2.1096,  0.6735, -0.2143],\n",
      "         ...,\n",
      "         [-0.0128,  0.0731,  0.0081,  ..., -0.0822, -0.0353, -0.0848],\n",
      "         [-0.0084,  0.0742,  0.0037,  ..., -0.0730, -0.0299, -0.0788],\n",
      "         [ 0.1623,  0.1884, -0.1987,  ..., -0.0742, -0.0996, -0.8330]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.7913e-01, -3.6532e-01,  4.8971e-01,  ...,  2.0225e+00,\n",
      "           1.0256e+00,  9.7375e-02],\n",
      "         [ 1.0697e+00, -2.0799e-01,  2.2980e-01,  ...,  2.9167e+00,\n",
      "           4.6440e-01,  2.5696e-01],\n",
      "         [ 3.3028e-01,  7.2933e-02,  1.8694e-01,  ...,  2.3449e+00,\n",
      "           2.9277e-01, -3.0925e-01],\n",
      "         ...,\n",
      "         [-1.3597e-02,  4.0380e-02,  4.3293e-03,  ..., -9.0737e-02,\n",
      "          -3.3590e-02, -8.4888e-02],\n",
      "         [-1.8228e-02,  7.7720e-02,  2.0753e-03,  ..., -8.4801e-02,\n",
      "          -2.8388e-02, -8.4801e-02],\n",
      "         [-1.7413e-02,  7.8170e-02, -1.4537e-03,  ..., -7.8025e-02,\n",
      "          -4.4964e-02, -9.1430e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8113, -0.0301, -0.0605,  ...,  2.6265,  0.8172,  0.0078],\n",
      "         [ 0.7479,  0.1298,  0.0582,  ...,  2.5765,  0.6372, -0.1830],\n",
      "         [ 1.6030, -0.2331, -0.1581,  ...,  2.0637,  0.7079, -0.3172],\n",
      "         ...,\n",
      "         [-0.0116,  0.0341,  0.0120,  ..., -0.0821, -0.0322, -0.0833],\n",
      "         [-0.0422,  0.2108,  0.0733,  ..., -0.0763, -0.0219, -0.1745],\n",
      "         [-0.0026,  0.2716, -0.1731,  ...,  0.0106,  0.0521, -0.0628]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.9003e-01, -1.9908e-01, -1.9944e-02,  ...,  2.0789e+00,\n",
      "           9.4180e-01, -2.0529e-02],\n",
      "         [ 7.5868e-01, -1.6731e-01,  4.3542e-01,  ...,  1.8446e+00,\n",
      "           5.8391e-01,  5.1570e-01],\n",
      "         [ 3.7673e-01, -4.6276e-01,  3.0822e-01,  ...,  1.8220e+00,\n",
      "           4.2905e-01, -2.6339e-01],\n",
      "         ...,\n",
      "         [ 3.6354e-02,  1.6530e-01, -6.0166e-02,  ..., -9.5783e-02,\n",
      "           2.5425e-02, -3.1302e-01],\n",
      "         [-4.1521e-02,  1.2839e-01,  1.2166e-03,  ..., -5.4232e-02,\n",
      "           7.0011e-04, -1.5530e-01],\n",
      "         [ 1.3773e-02,  8.1674e-02, -1.9591e-03,  ..., -1.0717e-01,\n",
      "          -3.2263e-02, -8.4587e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0528, -0.2833,  0.2629,  ...,  2.0799,  1.2015, -0.5403],\n",
      "         [ 0.9762, -0.1638,  0.3764,  ...,  2.2047,  0.3044, -0.3320],\n",
      "         [ 0.6156, -0.1091,  0.1510,  ...,  1.6324,  0.4318, -0.4304],\n",
      "         ...,\n",
      "         [-0.0198,  0.0617, -0.0240,  ..., -0.0803, -0.0361,  0.0324],\n",
      "         [-0.0211,  0.0727,  0.0058,  ..., -0.0776, -0.0328, -0.0915],\n",
      "         [-0.0635,  0.1402, -0.0709,  ..., -0.0525,  0.0094, -0.2262]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.3148e+00, -2.4424e-01,  9.1446e-02,  ...,  2.0348e+00,\n",
      "           7.1923e-01,  2.4359e-01],\n",
      "         [ 8.9156e-01, -1.7861e-02,  4.1896e-01,  ...,  2.7351e+00,\n",
      "           2.2854e-01,  6.6482e-01],\n",
      "         [ 5.7007e-01,  1.4826e-01,  5.3352e-01,  ...,  2.2974e+00,\n",
      "           4.3156e-01,  3.6689e-01],\n",
      "         ...,\n",
      "         [-2.0774e-02,  1.8214e-01, -6.8640e-03,  ..., -8.4728e-02,\n",
      "          -1.7764e-01, -2.2168e-01],\n",
      "         [-4.7408e-03,  7.8753e-02, -1.5171e-04,  ..., -7.3143e-02,\n",
      "          -3.2288e-02, -9.0950e-02],\n",
      "         [ 2.5258e-01,  3.5763e-01, -3.9577e-02,  ..., -3.3508e-01,\n",
      "           1.5316e-01, -2.8188e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0911e+00, -2.1623e-01,  3.5543e-01,  ...,  2.2356e+00,\n",
      "           1.2899e+00, -3.3713e-01],\n",
      "         [ 2.9393e-01, -1.3923e-01,  4.0135e-01,  ...,  2.0414e+00,\n",
      "           3.5276e-01, -2.8517e-02],\n",
      "         [ 3.7499e-01, -4.8349e-01,  1.3701e-01,  ...,  1.7617e+00,\n",
      "           6.0022e-01,  1.0891e-01],\n",
      "         ...,\n",
      "         [-1.0003e-02,  7.1902e-02,  6.2872e-04,  ..., -8.3670e-02,\n",
      "          -3.2251e-02, -8.5150e-02],\n",
      "         [-4.2080e-03,  8.5141e-02,  6.6775e-03,  ..., -7.4727e-02,\n",
      "          -1.5802e-02, -8.2363e-02],\n",
      "         [ 1.1216e-02,  3.9444e-02,  9.3662e-04,  ..., -8.3231e-02,\n",
      "          -3.2771e-02, -7.2466e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "answer:  ring\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.5626e-01, -3.6829e-01,  5.3116e-02,  ...,  2.5037e+00,\n",
      "           1.1966e+00,  2.6080e-01],\n",
      "         [ 5.1147e-01, -6.0672e-01,  2.2179e-01,  ...,  2.6980e+00,\n",
      "           5.2007e-01,  9.4756e-02],\n",
      "         [ 6.5196e-01, -6.2443e-01,  1.1110e-01,  ...,  2.0074e+00,\n",
      "           4.2645e-01,  1.0532e-01],\n",
      "         ...,\n",
      "         [-3.4594e-03,  3.8708e-01, -1.6496e-01,  ...,  3.0651e-01,\n",
      "           5.0998e-02, -7.2549e-01],\n",
      "         [-1.6062e-02,  6.9801e-02,  1.1424e-03,  ..., -7.5871e-02,\n",
      "          -3.2349e-02, -8.3155e-02],\n",
      "         [-9.5857e-03,  6.4091e-02,  1.1371e-02,  ..., -7.9974e-02,\n",
      "          -1.5236e-02, -7.0131e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8769, -0.4088,  0.2186,  ...,  2.5557,  1.3862,  0.3934],\n",
      "         [ 0.7168, -0.2625,  0.0868,  ...,  2.7166,  0.4964,  0.3149],\n",
      "         [ 0.5947, -0.5365,  0.1767,  ...,  2.0779,  0.4593, -0.0831],\n",
      "         ...,\n",
      "         [ 0.0153,  0.0863, -0.0062,  ..., -0.0578, -0.0236, -0.0707],\n",
      "         [-0.0097,  0.0734,  0.0039,  ..., -0.0803, -0.0278, -0.0701],\n",
      "         [-0.3256,  0.3782,  0.0195,  ...,  0.0975,  0.3562, -0.1388]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.7669,  0.1282,  0.2095,  ...,  1.8963,  0.9949,  0.1085],\n",
      "         [ 0.7137, -0.3150,  0.2616,  ...,  2.0661,  0.5892,  0.3183],\n",
      "         [ 0.7523, -0.4448,  0.2610,  ...,  0.9987,  0.5051,  0.2907],\n",
      "         ...,\n",
      "         [-0.0105,  0.0715, -0.0065,  ..., -0.0904, -0.0257, -0.0837],\n",
      "         [-0.0556,  0.1527, -0.0052,  ..., -0.1307, -0.0246, -0.2137],\n",
      "         [-0.0145,  0.0861,  0.0032,  ..., -0.0737, -0.0300, -0.0895]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "answer:  24 october 1632\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.4584e-01, -6.0529e-01,  2.9155e-01,  ...,  2.7581e+00,\n",
      "           1.0102e+00,  1.8673e-01],\n",
      "         [ 8.3589e-01, -4.6602e-01,  1.9514e-01,  ...,  2.6285e+00,\n",
      "           6.3388e-01, -2.1334e-01],\n",
      "         [ 7.3175e-01, -1.1816e-01,  4.2929e-02,  ...,  2.4990e+00,\n",
      "           6.3161e-01, -6.4825e-03],\n",
      "         ...,\n",
      "         [-6.1485e-03,  7.0841e-02,  4.0439e-03,  ..., -7.4321e-02,\n",
      "          -2.4267e-02, -8.2117e-02],\n",
      "         [-2.3307e-02,  4.8004e-02, -7.7730e-04,  ..., -1.1025e-01,\n",
      "          -5.1829e-02, -8.0099e-02],\n",
      "         [ 2.4986e-03,  5.6520e-02, -6.7903e-03,  ..., -6.9598e-02,\n",
      "          -3.1372e-02,  1.5387e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.3696e+00, -6.9500e-01, -5.9184e-01,  ...,  2.7079e+00,\n",
      "           5.7676e-01,  2.1345e-03],\n",
      "         [ 1.8459e-01, -4.4737e-01, -2.4886e-01,  ...,  3.1398e+00,\n",
      "           5.1784e-01, -7.1792e-02],\n",
      "         [ 1.0607e+00, -4.4318e-01, -4.1837e-01,  ...,  2.4233e+00,\n",
      "           6.8785e-01, -1.0344e-01],\n",
      "         ...,\n",
      "         [-5.0205e-03,  6.9906e-02, -8.5189e-03,  ..., -7.4499e-02,\n",
      "          -3.4829e-02, -5.9535e-02],\n",
      "         [ 1.8142e-01,  1.0970e-01, -1.1867e-01,  ..., -9.8168e-02,\n",
      "           2.8848e-01, -3.0949e-01],\n",
      "         [ 1.3957e-02,  6.2668e-02,  2.0677e-03,  ..., -9.2867e-02,\n",
      "          -1.8981e-02, -6.2393e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.2899e+00, -4.9660e-01, -8.4060e-02,  ...,  7.5344e-01,\n",
      "           1.4621e+00, -2.0407e-01],\n",
      "         [ 7.5833e-01, -2.6028e-01,  5.5047e-02,  ...,  2.4881e+00,\n",
      "           2.1856e-01,  2.9410e-01],\n",
      "         [ 5.4018e-01, -1.7944e-01,  7.6929e-02,  ...,  1.7659e+00,\n",
      "           4.9951e-01,  4.1035e-02],\n",
      "         ...,\n",
      "         [-4.5800e-02,  1.2742e-01,  2.3134e-02,  ..., -4.9285e-02,\n",
      "          -9.3639e-04, -2.0701e-01],\n",
      "         [-1.4116e-02,  7.8000e-02,  2.4471e-03,  ..., -7.8806e-02,\n",
      "          -2.8204e-02, -7.6967e-02],\n",
      "         [-1.5000e-02,  2.0204e-01,  5.7327e-02,  ...,  1.0839e-01,\n",
      "          -7.1663e-02, -3.1299e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  no\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0598, -0.4133,  0.1589,  ...,  2.4581,  0.7843, -0.3982],\n",
      "         [ 0.4673, -0.3501,  0.0547,  ...,  2.2454,  0.3914,  0.3923],\n",
      "         [ 0.3709, -0.3611, -0.0476,  ...,  1.9552,  0.2966, -0.1052],\n",
      "         ...,\n",
      "         [-0.0075,  0.0973,  0.0042,  ..., -0.0865, -0.0309, -0.0917],\n",
      "         [ 0.0041,  0.0477,  0.0052,  ..., -0.0912, -0.0296, -0.0887],\n",
      "         [-0.0030,  0.0430, -0.0037,  ..., -0.0566, -0.0165, -0.0850]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8549, -0.6814, -0.0938,  ...,  2.1938,  1.2652,  0.1642],\n",
      "         [ 0.5847, -0.3002,  0.2665,  ...,  2.2304,  0.5996,  0.3381],\n",
      "         [ 0.3575, -0.6367,  0.0438,  ...,  2.5167,  0.5374,  0.1604],\n",
      "         ...,\n",
      "         [-0.0058,  0.0770, -0.0047,  ..., -0.0949, -0.0432, -0.0738],\n",
      "         [-0.0092,  0.2072,  0.0570,  ..., -0.0357, -0.0925, -0.0498],\n",
      "         [-0.0489,  0.1309,  0.0115,  ..., -0.0589, -0.0330, -0.2017]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.7305e-01, -2.0974e-01,  1.9306e-01,  ...,  2.3975e+00,\n",
      "           1.2734e+00,  1.6619e-01],\n",
      "         [ 1.4815e-01, -2.4609e-01,  2.4605e-01,  ...,  2.1772e+00,\n",
      "           3.7058e-01,  2.4823e-01],\n",
      "         [ 1.6737e-01, -3.2432e-01,  6.3152e-01,  ...,  2.3676e+00,\n",
      "           3.9431e-01,  4.1689e-01],\n",
      "         ...,\n",
      "         [ 1.0686e-02,  4.8431e-02,  3.7971e-03,  ..., -8.2037e-02,\n",
      "          -3.1431e-02, -8.3154e-02],\n",
      "         [-3.7892e-02,  1.3911e-01,  2.4305e-02,  ..., -3.1224e-02,\n",
      "          -1.3740e-02, -1.4128e-01],\n",
      "         [-1.3716e-02,  7.4617e-02, -1.6521e-03,  ..., -9.1376e-02,\n",
      "          -4.1118e-02, -7.0550e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n",
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  mary i\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9760, -1.2504, -0.4214,  ...,  2.0299,  0.8578,  0.1410],\n",
      "         [ 0.6997, -1.1549,  0.2525,  ...,  3.1994,  0.1092, -0.0560],\n",
      "         [ 0.4853, -0.6038,  0.2879,  ...,  0.9490,  0.5621, -0.1956],\n",
      "         ...,\n",
      "         [-0.0126,  0.0738,  0.0053,  ..., -0.0778, -0.0356, -0.0843],\n",
      "         [-0.0036,  0.0401, -0.0188,  ..., -0.0832, -0.0289, -0.0658],\n",
      "         [-0.0068,  0.1533, -0.0558,  ..., -0.1266, -0.0089, -0.0998]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9555, -0.0487, -0.1142,  ...,  2.1953,  0.7495,  0.3790],\n",
      "         [-0.0370, -0.2748,  0.1646,  ...,  1.7426,  0.2603,  0.6772],\n",
      "         [ 0.6406, -0.4351,  0.2119,  ...,  2.1433,  0.3348, -0.3127],\n",
      "         ...,\n",
      "         [-0.0857,  0.2659,  0.2162,  ...,  0.2578,  0.1456,  0.1266],\n",
      "         [-0.0055,  0.3533, -0.1718,  ...,  0.2065,  0.0032, -0.4366],\n",
      "         [-0.0127,  0.0273, -0.0103,  ..., -0.0835, -0.0304, -0.0842]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  munster rugby\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3592e+00, -4.7113e-01,  1.0582e-01,  ...,  2.6558e+00,\n",
      "           9.8514e-01,  3.8190e-01],\n",
      "         [-1.5053e-01, -4.0712e-01,  1.3109e-01,  ...,  2.6939e+00,\n",
      "           3.3373e-01, -7.8028e-02],\n",
      "         [ 4.1249e-01, -7.2432e-01,  3.7851e-01,  ...,  2.2279e+00,\n",
      "           8.0164e-01, -4.6557e-01],\n",
      "         ...,\n",
      "         [ 3.5514e-01,  6.4631e-01, -2.5140e-02,  ..., -5.0827e-02,\n",
      "           2.9398e-01, -4.3324e-01],\n",
      "         [-1.6230e-02,  7.0140e-02,  3.2342e-03,  ..., -7.5450e-02,\n",
      "          -4.0259e-02,  1.9462e-02],\n",
      "         [-1.4735e-02,  5.9850e-02, -1.1521e-03,  ..., -8.0126e-02,\n",
      "          -1.2168e-02, -7.5042e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.0065e-01, -2.3575e-01, -4.3000e-01,  ...,  1.7117e+00,\n",
      "           9.3158e-01,  3.3640e-01],\n",
      "         [ 3.0476e-01, -5.4901e-01, -3.2413e-02,  ...,  2.4111e+00,\n",
      "           5.4173e-01,  1.8612e-02],\n",
      "         [-5.3787e-02, -4.5877e-01,  5.9046e-02,  ...,  1.8368e+00,\n",
      "           3.5054e-01, -2.8362e-01],\n",
      "         ...,\n",
      "         [-8.8345e-03,  2.7264e-02,  2.5423e-03,  ..., -8.2214e-02,\n",
      "          -3.3606e-02, -8.1438e-02],\n",
      "         [-1.4007e-02,  3.9191e-02, -8.0362e-04,  ..., -7.9996e-02,\n",
      "          -2.8252e-02, -7.7513e-02],\n",
      "         [-3.9577e-02,  1.3330e-01,  1.5544e-02,  ..., -3.2098e-02,\n",
      "          -1.3591e-02, -1.8962e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.1567e-01, -1.6882e-01, -9.4591e-02,  ...,  2.2345e+00,\n",
      "           7.8296e-01,  4.1055e-02],\n",
      "         [ 9.6930e-01, -3.6112e-01,  3.2416e-02,  ...,  2.6787e+00,\n",
      "           6.2754e-01,  1.6151e-01],\n",
      "         [ 6.8701e-01, -1.5119e-01, -2.3805e-01,  ...,  1.9894e+00,\n",
      "           5.9264e-01,  2.3835e-01],\n",
      "         ...,\n",
      "         [-2.5394e-03,  7.6026e-02, -8.4090e-03,  ..., -8.3704e-02,\n",
      "          -2.9736e-02, -7.4294e-02],\n",
      "         [-5.4890e-03,  7.2917e-02,  6.7842e-03,  ..., -1.1827e-01,\n",
      "          -2.6696e-02, -8.0086e-02],\n",
      "         [-1.3528e-02,  3.5137e-01, -1.9412e-01,  ..., -3.1701e-01,\n",
      "          -7.2425e-02, -1.1863e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 0.5256, -0.3540,  0.2013,  ...,  2.0676,  1.1625,  0.2505],\n",
      "         [ 0.2856, -0.2913,  0.3637,  ...,  1.2769,  0.4167,  0.1786],\n",
      "         [ 0.4206, -0.8517,  0.2368,  ...,  0.0222,  0.9891,  0.2165],\n",
      "         ...,\n",
      "         [-0.0161,  0.0881,  0.0196,  ..., -0.0585, -0.0299, -0.0842],\n",
      "         [-0.0151,  0.0794, -0.0055,  ..., -0.0726, -0.0209, -0.0812],\n",
      "         [ 0.0098,  0.0379, -0.0075,  ..., -0.0755, -0.0322, -0.0857]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.1061e+00, -5.8376e-01, -5.2331e-01,  ...,  2.2000e+00,\n",
      "           1.0611e+00,  7.0385e-02],\n",
      "         [ 1.2450e-01, -5.3841e-01,  2.1541e-02,  ...,  2.2024e+00,\n",
      "           4.9071e-01,  3.1488e-01],\n",
      "         [ 5.8299e-01, -6.5522e-01,  2.7594e-01,  ...,  4.9406e-01,\n",
      "           5.7863e-01, -5.9006e-02],\n",
      "         ...,\n",
      "         [ 9.6701e-02,  1.1882e-01, -4.2248e-02,  ..., -1.9627e-01,\n",
      "           7.5036e-02, -1.7813e-01],\n",
      "         [-4.6079e-03,  6.5732e-02, -1.7755e-03,  ..., -7.6689e-02,\n",
      "          -3.3849e-02, -6.8349e-02],\n",
      "         [ 1.6978e-02,  8.2218e-02, -6.0542e-03,  ..., -7.7787e-02,\n",
      "          -3.7695e-02, -9.0766e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.4125e-01,  5.9316e-02, -1.6538e-01,  ...,  2.4689e+00,\n",
      "           1.2399e+00, -1.4505e-01],\n",
      "         [ 5.0705e-01, -2.3856e-01,  8.4411e-02,  ...,  2.5240e+00,\n",
      "           5.3833e-01, -2.6543e-01],\n",
      "         [ 4.6763e-01,  2.1246e-01,  1.2483e-01,  ..., -4.0701e-02,\n",
      "          -1.0737e-01, -1.6721e-02],\n",
      "         ...,\n",
      "         [ 9.4352e-03,  5.5283e-02,  4.9242e-04,  ..., -1.1512e-01,\n",
      "          -2.5555e-02, -6.4949e-02],\n",
      "         [-9.1398e-03,  8.2522e-02, -6.0614e-03,  ..., -1.0596e-01,\n",
      "          -1.9809e-02, -9.9806e-02],\n",
      "         [ 1.7873e-01,  1.6766e-01, -4.9569e-02,  ..., -2.3220e-01,\n",
      "           2.5180e-01, -6.5462e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5988, -0.2839, -0.4070,  ...,  2.0203,  0.7760, -0.5578],\n",
      "         [-0.2285, -0.3306, -0.1589,  ...,  2.2860,  0.0325, -0.0809],\n",
      "         [ 0.3874, -0.4716,  0.2908,  ...,  1.9932,  0.6926,  0.5376],\n",
      "         ...,\n",
      "         [-0.0175,  0.0794, -0.0126,  ..., -0.0777, -0.0417, -0.0852],\n",
      "         [-0.1193,  0.7307, -0.0641,  ..., -0.3041, -0.0369, -0.1235],\n",
      "         [-0.1557,  0.6543,  0.0871,  ...,  0.3242, -0.2005, -0.0243]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mark daniel ronson\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0856e-01, -5.4640e-01,  2.7803e-01,  ...,  2.0136e+00,\n",
      "           8.1999e-01, -2.9485e-01],\n",
      "         [ 2.5370e-01, -5.5697e-01,  5.5015e-01,  ...,  1.8616e+00,\n",
      "           1.3876e-01,  6.8052e-01],\n",
      "         [ 2.6345e-01, -1.2028e-01,  7.1933e-03,  ...,  2.1760e+00,\n",
      "           2.8961e-01,  2.5636e-01],\n",
      "         ...,\n",
      "         [-1.5912e-02,  6.6546e-02,  8.2139e-04,  ..., -7.9362e-02,\n",
      "          -1.8142e-02, -6.4641e-02],\n",
      "         [-3.8980e-02,  2.0901e-01,  2.7924e-02,  ..., -2.0711e-02,\n",
      "          -1.3099e-02, -2.1157e-01],\n",
      "         [-9.6167e-02,  4.1551e-01, -1.1832e-01,  ..., -3.8492e-01,\n",
      "           1.2086e-01, -7.7273e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0326e+00, -8.5543e-02, -1.8560e-01,  ...,  1.3628e+00,\n",
      "           1.3320e+00, -5.8237e-01],\n",
      "         [ 2.8672e-01, -6.4272e-01,  2.0351e-01,  ...,  2.1449e+00,\n",
      "           5.3461e-01, -3.0109e-01],\n",
      "         [ 8.5306e-01, -7.2907e-01,  3.1326e-01,  ...,  1.7952e+00,\n",
      "           1.0884e+00, -6.2001e-01],\n",
      "         ...,\n",
      "         [-1.0067e-02,  7.2603e-02,  1.1815e-02,  ..., -8.5441e-02,\n",
      "          -2.1634e-02, -1.0211e-01],\n",
      "         [ 7.9319e-03,  7.3931e-02, -1.6219e-03,  ..., -8.0141e-02,\n",
      "          -2.7615e-02, -8.0896e-02],\n",
      "         [-1.6587e-02,  1.2219e-01,  3.3618e-02,  ..., -7.6544e-02,\n",
      "          -7.4264e-03, -1.8784e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-0.3107,  0.0859, -0.3250,  ...,  2.3454,  0.3343,  0.0231],\n",
      "         [ 0.2075,  0.0811,  0.0820,  ...,  2.0535,  0.2307, -0.3291],\n",
      "         [ 0.6199, -0.6574, -0.0878,  ...,  2.0488,  0.5466, -0.1504],\n",
      "         ...,\n",
      "         [-0.0058,  0.0610,  0.0108,  ..., -0.0795, -0.0082, -0.0629],\n",
      "         [-0.0095,  0.1492,  0.0276,  ..., -0.1183, -0.1169, -0.1804],\n",
      "         [-0.0520,  0.2946,  0.1232,  ...,  0.0024, -0.0480, -0.3577]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 4.1775e-01, -5.5607e-01,  3.4546e-01,  ...,  1.3810e+00,\n",
      "           1.5699e+00,  1.4161e-01],\n",
      "         [ 1.8139e-01,  4.4987e-02, -3.7299e-01,  ...,  1.2891e+00,\n",
      "           5.1351e-01,  1.3938e-01],\n",
      "         [ 9.2321e-02, -7.1086e-01, -8.9781e-02,  ...,  1.6956e+00,\n",
      "           9.7713e-01, -1.9143e-01],\n",
      "         ...,\n",
      "         [-9.4744e-03,  7.0456e-02, -1.1381e-02,  ..., -9.4242e-02,\n",
      "          -4.1023e-02, -9.1167e-02],\n",
      "         [-1.4301e-02,  6.4333e-02,  4.9820e-03,  ..., -7.8892e-02,\n",
      "          -2.2347e-02, -7.7801e-02],\n",
      "         [ 9.0796e-03,  6.9294e-02, -1.3487e-03,  ..., -5.5544e-02,\n",
      "          -3.3969e-02, -8.8782e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0274, -0.1179, -0.1876,  ...,  0.5640,  1.0802,  0.1665],\n",
      "         [ 0.6180, -0.4732,  0.2348,  ...,  2.6698,  0.5631, -0.2350],\n",
      "         [ 0.3981,  0.2431,  0.3879,  ...,  1.4135,  0.5698, -0.2228],\n",
      "         ...,\n",
      "         [ 0.2167,  0.2030,  0.0162,  ...,  0.3371,  0.0493, -0.3608],\n",
      "         [ 0.0124,  0.0380, -0.0344,  ..., -0.0134, -0.0329, -0.2135],\n",
      "         [-0.0176,  0.0519,  0.0052,  ..., -0.0737, -0.0310, -0.0580]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0545, -0.5778,  0.0902,  ...,  1.8856,  1.1943, -0.3011],\n",
      "         [ 0.6775, -0.4353,  0.1163,  ...,  2.2699,  0.4641, -0.0619],\n",
      "         [ 0.1538,  0.0200,  0.5498,  ...,  0.0539,  0.5561, -0.1243],\n",
      "         ...,\n",
      "         [ 0.2085,  0.7894,  0.1520,  ..., -0.3666,  0.4571, -0.1507],\n",
      "         [-0.0118,  0.1031,  0.0086,  ..., -0.0758, -0.0312, -0.0752],\n",
      "         [ 0.0255,  0.2061,  0.0360,  ..., -0.1383, -0.0378, -0.3028]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "answer:  1962\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0580, -0.6946, -0.0364,  ...,  0.2827,  0.7424, -0.5366],\n",
      "         [ 0.6292, -0.4957,  0.1684,  ...,  2.4871,  0.7139, -0.2507],\n",
      "         [ 0.3434, -0.3339,  0.2402,  ...,  1.5473,  0.3336, -0.1910],\n",
      "         ...,\n",
      "         [-0.0189,  0.1184,  0.0043,  ..., -0.0215, -0.0226, -0.2094],\n",
      "         [ 0.1972,  0.2804, -0.0333,  ...,  0.0974,  0.1140, -0.3935],\n",
      "         [ 0.0057,  0.0646,  0.0029,  ..., -0.0787, -0.0209, -0.0706]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2276,  0.1006, -0.2404,  ...,  1.7101,  1.4013, -0.2029],\n",
      "         [ 0.5560, -0.2889,  0.1105,  ...,  1.8524,  0.4191,  0.0374],\n",
      "         [ 0.9530, -0.6633,  0.1186,  ...,  1.8319,  0.8018, -0.2028],\n",
      "         ...,\n",
      "         [-0.0089,  0.0416, -0.0132,  ..., -0.0788, -0.0307, -0.0693],\n",
      "         [-0.0254,  0.0709,  0.0023,  ..., -0.1100, -0.0239, -0.0990],\n",
      "         [ 0.0164,  0.2979,  0.1139,  ..., -0.0305, -0.0952,  0.0901]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  4\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.0929e-01, -4.5250e-01, -5.8019e-01,  ...,  1.7013e+00,\n",
      "           1.0348e+00, -1.0396e-01],\n",
      "         [ 1.8184e-01, -1.9372e-01, -2.9682e-01,  ...,  2.0651e+00,\n",
      "           4.8997e-01, -4.4175e-01],\n",
      "         [ 7.4295e-01, -4.4075e-01,  2.3658e-01,  ...,  2.7709e+00,\n",
      "           7.7568e-01, -7.7691e-01],\n",
      "         ...,\n",
      "         [ 1.3538e-02,  8.1496e-02,  2.5599e-03,  ..., -7.2057e-02,\n",
      "          -1.9679e-02, -7.7635e-02],\n",
      "         [-1.7517e-02,  6.3995e-02,  6.4496e-03,  ..., -7.0818e-02,\n",
      "          -3.5833e-02, -8.4630e-02],\n",
      "         [-2.5637e-02,  2.7828e-01,  1.3422e-02,  ..., -9.5473e-05,\n",
      "          -1.0221e-01, -3.4008e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "answer:  flowering plants\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  answer:  herman wouk\n",
      "tensor([[[ 9.2548e-01, -1.4881e+00, -5.2375e-01,  ...,  1.2417e+00,\n",
      "           1.0759e+00, -6.6871e-02],\n",
      "         [ 5.1569e-01, -5.5444e-01,  1.8138e-01,  ...,  2.1352e+00,\n",
      "           7.4048e-01,  9.7284e-03],\n",
      "         [ 6.3106e-01, -6.8112e-01, -2.5064e-01,  ...,  1.6967e+00,\n",
      "           4.6706e-01, -3.0311e-02],\n",
      "         ...,\n",
      "         [-2.0973e-03,  6.4206e-02,  2.3098e-02,  ...,  1.5839e-02,\n",
      "          -7.8405e-03, -9.9107e-02],\n",
      "         [-1.3159e-02,  1.2083e-01,  1.5624e-02,  ..., -2.6476e-02,\n",
      "          -3.3229e-02, -2.0057e-01],\n",
      "         [ 9.5752e-03,  1.2331e-01,  4.1096e-02,  ..., -1.8600e-02,\n",
      "          -1.5049e-02,  3.9302e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 7.2100e-01, -5.4476e-01,  1.5956e-02,  ...,  2.2730e+00,\n",
      "           9.3134e-01, -1.8426e-01],\n",
      "         [-5.9646e-02, -7.0125e-01,  1.9336e-01,  ...,  1.8500e+00,\n",
      "           6.8883e-01,  6.8446e-03],\n",
      "         [-4.2945e-01, -9.5684e-01, -4.7604e-02,  ...,  5.5864e-01,\n",
      "           7.0610e-01, -1.5675e-01],\n",
      "         ...,\n",
      "         [-3.5284e-04,  7.1189e-02,  4.8206e-02,  ..., -7.5976e-02,\n",
      "           2.2058e-02, -2.8171e-01],\n",
      "         [-2.4199e-02,  7.4742e-02, -2.2319e-03,  ..., -6.9481e-02,\n",
      "          -3.7099e-02,  5.5696e-03],\n",
      "         [-7.3883e-03,  5.7635e-02, -2.7901e-03,  ..., -8.3481e-02,\n",
      "          -3.0310e-02, -7.3964e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "answer:  marlboro\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.3383e-01, -6.7491e-02, -2.9481e-01,  ...,  2.2270e+00,\n",
      "           6.8437e-01,  1.1504e-01],\n",
      "         [ 4.1608e-01, -3.2222e-01,  5.8157e-01,  ...,  2.1597e+00,\n",
      "           4.1110e-01, -4.6320e-01],\n",
      "         [ 1.2722e-01,  3.9718e-01,  3.2241e-01,  ...,  1.3415e+00,\n",
      "           3.2956e-01,  1.0517e-01],\n",
      "         ...,\n",
      "         [ 4.3045e-02,  2.9439e-01,  2.4977e-02,  ..., -1.0830e-02,\n",
      "          -5.1853e-02, -1.8586e-01],\n",
      "         [-1.4872e-02,  1.1465e-01,  1.4441e-02,  ..., -7.1360e-02,\n",
      "          -5.1494e-02, -2.6398e-01],\n",
      "         [-8.7390e-04,  6.5802e-02,  1.0148e-03,  ..., -8.4397e-02,\n",
      "          -2.1554e-02,  2.0117e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.8253e-01, -5.4039e-01, -1.2940e-01,  ...,  2.1896e+00,\n",
      "           1.0711e+00, -8.2655e-01],\n",
      "         [ 4.5878e-01, -8.0260e-01, -1.0042e-01,  ...,  2.2950e+00,\n",
      "           9.2676e-01, -3.4924e-01],\n",
      "         [ 5.7558e-01, -6.2814e-01, -1.1257e-01,  ...,  1.9331e+00,\n",
      "           5.0048e-01,  2.6445e-01],\n",
      "         ...,\n",
      "         [-1.2870e-02,  7.3177e-02, -2.5888e-04,  ..., -6.9188e-02,\n",
      "          -4.2207e-02, -7.5262e-02],\n",
      "         [ 4.2650e-02, -2.4767e-02, -7.7802e-02,  ..., -9.4149e-02,\n",
      "           1.3086e-01, -1.4863e-01],\n",
      "         [-1.7372e-02,  4.2765e-02,  2.8942e-03,  ..., -8.2968e-02,\n",
      "          -3.4454e-02, -8.6237e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  tokyo japan\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 4.4127e-01,  1.0031e-01, -2.5388e-01,  ...,  1.9140e+00,\n",
      "           9.4454e-01, -2.8775e-01],\n",
      "         [ 3.8623e-01, -4.3631e-01,  3.0659e-01,  ...,  5.3472e-01,\n",
      "           1.0032e+00, -7.4572e-02],\n",
      "         [-1.6314e-01,  1.2593e-01, -1.5735e-02,  ...,  7.9436e-01,\n",
      "           2.9213e-01,  3.6893e-01],\n",
      "         ...,\n",
      "         [-9.7077e-02,  1.5969e-01, -1.6329e-01,  ..., -1.6628e-01,\n",
      "          -3.9924e-02, -2.3418e-01],\n",
      "         [-1.3190e-02,  7.8639e-02, -1.2545e-02,  ..., -7.2502e-02,\n",
      "          -4.4534e-02, -9.7927e-02],\n",
      "         [-5.6177e-04,  6.6135e-02,  1.3517e-02,  ..., -8.0544e-02,\n",
      "          -1.9644e-02, -8.3844e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.6004, -0.3597, -0.5454,  ...,  1.9544,  1.0854, -0.0958],\n",
      "         [ 0.4992, -0.0774,  0.0415,  ...,  0.6632,  0.4727, -0.0374],\n",
      "         [ 0.5347, -0.1553,  0.1924,  ...,  1.7027,  0.3834, -0.3752],\n",
      "         ...,\n",
      "         [ 0.0582,  0.1565,  0.0728,  ..., -0.0314, -0.1024, -0.0588],\n",
      "         [-0.0914, -0.1383, -0.5897,  ...,  0.3818,  0.1426, -0.8813],\n",
      "         [-0.0128,  0.0717,  0.0045,  ..., -0.0862, -0.0267, -0.0737]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n",
      "answer:  danny leiner\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  louis caldera\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.3432e+00, -1.4583e-03, -2.5706e-01,  ...,  2.3194e+00,\n",
      "           1.0275e+00, -5.1404e-01],\n",
      "         [ 7.6752e-01, -2.2230e-01, -2.2037e-01,  ...,  2.1959e+00,\n",
      "           5.6894e-01, -2.5664e-01],\n",
      "         [ 6.0744e-01, -3.4020e-01,  9.3053e-02,  ...,  1.7587e+00,\n",
      "           8.3849e-01, -6.1652e-01],\n",
      "         ...,\n",
      "         [ 4.8670e-02,  1.5923e-03, -1.4029e-01,  ...,  1.0983e-01,\n",
      "           2.8035e-01, -2.3155e-01],\n",
      "         [-2.0936e-02,  7.0128e-02,  1.7405e-03,  ..., -8.7622e-02,\n",
      "          -2.5310e-02,  1.6997e-02],\n",
      "         [ 1.5195e-02,  3.2417e-01,  6.8661e-03,  ...,  6.1064e-02,\n",
      "           5.0201e-02, -3.6953e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.3321e-01, -3.3753e-02, -1.6043e-01,  ...,  1.5365e+00,\n",
      "           1.0944e+00, -1.6085e-01],\n",
      "         [ 5.7004e-01, -6.6164e-01, -1.4053e-01,  ...,  2.4154e+00,\n",
      "           4.5792e-01, -6.5711e-01],\n",
      "         [ 3.0849e-01, -5.1597e-01, -3.6582e-01,  ...,  2.0263e+00,\n",
      "           7.3343e-01, -4.4547e-01],\n",
      "         ...,\n",
      "         [ 2.2110e-01,  1.8626e-01, -2.4429e-01,  ...,  5.6868e-01,\n",
      "           3.6055e-01, -7.0245e-01],\n",
      "         [ 2.4973e-02, -2.8271e-03, -1.9799e-01,  ...,  1.3370e-01,\n",
      "           3.3502e-01, -2.3140e-01],\n",
      "         [ 1.2099e-02,  7.3855e-02,  1.0524e-03,  ..., -8.1343e-02,\n",
      "          -2.8988e-02, -8.6376e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.2026, -0.6421,  0.2054,  ...,  1.7551,  1.3755,  0.0127],\n",
      "         [ 0.3609, -0.4284,  0.0156,  ...,  2.0066,  0.7713, -0.1801],\n",
      "         [ 0.0949, -0.1990, -0.0213,  ...,  1.4364,  1.0639, -0.2200],\n",
      "         ...,\n",
      "         [ 0.5033,  0.5974, -0.2477,  ..., -0.6534,  0.5006, -0.3042],\n",
      "         [-0.0086,  0.0764,  0.0025,  ..., -0.0726, -0.0214,  0.0171],\n",
      "         [ 0.1176,  0.3477, -0.0757,  ..., -0.0693,  0.0679, -0.3312]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1991, -0.2856,  0.1448,  ...,  2.3063,  1.3928, -0.4361],\n",
      "         [ 0.6459, -0.4722,  0.2543,  ...,  2.7200,  0.7975, -0.1166],\n",
      "         [ 0.5920, -0.6111,  0.0861,  ...,  1.8161,  0.7727, -0.4020],\n",
      "         ...,\n",
      "         [-0.0371,  0.1026, -0.0712,  ..., -0.1021, -0.1033, -0.2008],\n",
      "         [ 0.0034,  0.0728, -0.0125,  ..., -0.1254, -0.0315, -0.0757],\n",
      "         [-0.0091,  0.0664, -0.0079,  ..., -0.0830, -0.0397, -0.0824]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.0341e+00, -3.9705e-01, -2.6319e-01,  ...,  2.1442e+00,\n",
      "           1.0463e+00, -4.2807e-01],\n",
      "         [ 7.5219e-01, -3.9001e-01,  1.3879e-01,  ...,  2.1200e+00,\n",
      "           4.4362e-01,  1.7444e-01],\n",
      "         [ 6.6661e-01, -5.7464e-01, -3.9587e-01,  ...,  9.1353e-01,\n",
      "           5.2915e-01, -4.1195e-01],\n",
      "         ...,\n",
      "         [-1.8799e-01,  9.2326e-02,  1.3441e-02,  ..., -1.0148e-01,\n",
      "           8.4925e-02, -1.6954e-01],\n",
      "         [-1.2426e-02,  6.0586e-02, -1.1496e-04,  ..., -7.9733e-02,\n",
      "          -2.8594e-02, -8.8250e-02],\n",
      "         [ 2.8997e-02,  1.0835e-01,  6.5545e-02,  ..., -2.3262e-02,\n",
      "           1.4838e-02, -1.4071e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "answer:  essex\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4546, -0.3943, -0.6960,  ...,  1.7239,  1.0120, -0.7108],\n",
      "         [ 0.1165, -0.4391,  0.5861,  ...,  2.1696,  0.5709, -0.1287],\n",
      "         [ 0.4232, -0.4171, -0.1127,  ...,  1.9751,  0.7733, -0.2462],\n",
      "         ...,\n",
      "         [ 0.0078,  0.0647,  0.0122,  ..., -0.0961, -0.0207,  0.0165],\n",
      "         [-0.0182,  0.0993, -0.0037,  ..., -0.0870, -0.0359, -0.0741],\n",
      "         [-0.0254,  0.0722,  0.0047,  ..., -0.0811, -0.0438, -0.0989]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.8129e-01, -3.9037e-01, -2.3555e-01,  ...,  6.0154e-01,\n",
      "           1.1871e+00, -6.7257e-01],\n",
      "         [ 8.9452e-01, -4.6461e-01,  6.8193e-03,  ...,  2.6258e+00,\n",
      "           8.1304e-01, -6.0515e-01],\n",
      "         [ 1.1088e+00, -4.2681e-01, -8.9009e-02,  ...,  2.0159e+00,\n",
      "           7.8322e-01, -3.6813e-01],\n",
      "         ...,\n",
      "         [ 1.0689e-03,  5.7120e-02, -1.8106e-03,  ..., -7.5602e-02,\n",
      "          -1.3498e-02, -7.7082e-02],\n",
      "         [-1.4704e-02,  3.9884e-02,  7.1100e-04,  ..., -8.3127e-02,\n",
      "          -3.8286e-02,  1.6960e-02],\n",
      "         [-1.2423e-02,  6.7880e-02, -1.4170e-02,  ..., -8.8414e-02,\n",
      "          -2.5298e-02, -7.5289e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.6794e-01, -3.8449e-01,  5.5781e-02,  ...,  1.7517e+00,\n",
      "           1.4527e+00,  3.8312e-01],\n",
      "         [ 2.7568e-01, -1.5224e-01,  3.0129e-01,  ...,  1.9217e+00,\n",
      "           5.5304e-01,  3.7688e-01],\n",
      "         [ 4.4275e-01, -7.6137e-01, -3.1754e-02,  ...,  2.3008e+00,\n",
      "           7.6424e-01, -5.3681e-01],\n",
      "         ...,\n",
      "         [ 1.9885e-01,  3.1538e-01,  1.8598e-02,  ..., -1.0447e-01,\n",
      "           7.1134e-02, -3.7242e-01],\n",
      "         [ 4.1735e-04,  9.7902e-02, -3.4152e-03,  ..., -7.9274e-02,\n",
      "          -2.6414e-02, -8.3088e-02],\n",
      "         [ 1.7760e-01,  4.0502e-02, -1.5164e-01,  ..., -9.9101e-03,\n",
      "           2.1915e-01, -2.7145e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.5792, -0.4152, -0.2588,  ...,  1.4764,  1.2478, -0.3776],\n",
      "         [ 0.5121, -0.2130,  0.3817,  ...,  0.7927,  0.5353, -0.3601],\n",
      "         [ 0.3455,  0.0555,  0.1316,  ...,  1.4891, -0.0348, -0.2281],\n",
      "         ...,\n",
      "         [-0.0202,  0.0722, -0.0110,  ..., -0.1142, -0.0298, -0.0775],\n",
      "         [-0.0086,  0.0727,  0.0055,  ..., -0.0667, -0.0245, -0.0783],\n",
      "         [-0.0053,  0.0702,  0.0133,  ..., -0.0838, -0.0107, -0.0741]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 0.7573, -0.6761, -0.0701,  ...,  1.8504,  1.5676, -0.6122],\n",
      "         [ 0.2352, -0.5322,  0.2891,  ...,  1.9595,  0.5240, -0.5065],\n",
      "         [ 0.0059, -0.0942,  0.2467,  ...,  1.5341,  0.8277, -0.8459],\n",
      "         ...,\n",
      "         [-0.0075,  0.0746, -0.0023,  ..., -0.0781, -0.0227, -0.0934],\n",
      "         [-0.0264,  0.0771, -0.0021,  ..., -0.0775, -0.0373, -0.0888],\n",
      "         [-0.0240,  0.1229, -0.0304,  ...,  0.1483, -0.0508, -0.0510]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 7.6447e-01, -3.5943e-01, -6.1237e-02,  ...,  1.9113e+00,\n",
      "           7.3869e-01, -8.0138e-01],\n",
      "         [ 2.6409e-02, -6.0948e-01,  7.0297e-02,  ...,  2.1775e+00,\n",
      "           7.4431e-01, -5.7506e-01],\n",
      "         [ 4.3475e-01,  2.7131e-02, -2.0287e-01,  ...,  1.6766e+00,\n",
      "           7.1425e-01,  1.2289e-01],\n",
      "         ...,\n",
      "         [-2.8272e-02,  5.6594e-01, -8.4954e-03,  ..., -2.3711e-01,\n",
      "          -3.4328e-02, -1.2795e-01],\n",
      "         [ 1.1306e-02,  8.2153e-02, -3.9082e-03,  ..., -1.2754e-01,\n",
      "          -4.8719e-02, -5.3560e-02],\n",
      "         [-1.3730e-02,  7.3337e-02,  3.1640e-04,  ..., -7.4914e-02,\n",
      "          -1.8189e-02, -8.4936e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.1715e-01, -2.2336e-01, -1.7228e-01,  ...,  2.2884e+00,\n",
      "           1.4237e+00, -7.5224e-01],\n",
      "         [-1.6658e-01, -3.8409e-01,  2.7700e-01,  ...,  2.7640e+00,\n",
      "           6.8885e-01, -6.2114e-01],\n",
      "         [ 3.8753e-01, -5.6948e-01,  1.6846e-01,  ...,  1.8490e+00,\n",
      "           8.2775e-01, -7.1770e-01],\n",
      "         ...,\n",
      "         [-1.0433e-02,  7.7365e-02,  6.7118e-03,  ..., -7.3549e-02,\n",
      "          -2.8731e-02, -8.5606e-02],\n",
      "         [-5.1534e-02,  1.7691e-01, -7.1400e-03,  ..., -4.3685e-02,\n",
      "          -2.5536e-02, -2.0358e-01],\n",
      "         [-1.0388e-02,  7.3793e-02,  1.4095e-03,  ..., -8.0326e-02,\n",
      "          -3.5981e-02,  1.5047e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.7407e-01, -4.8335e-01,  1.2060e-01,  ...,  2.0547e+00,\n",
      "           1.4301e+00,  5.1952e-01],\n",
      "         [ 1.6624e-01,  9.2799e-02,  2.0663e-01,  ...,  2.1864e+00,\n",
      "           7.1133e-01,  9.0885e-02],\n",
      "         [ 5.3598e-01, -1.7446e-01, -6.0264e-03,  ...,  1.5009e+00,\n",
      "           1.0471e+00, -3.9316e-01],\n",
      "         ...,\n",
      "         [-3.8265e-02,  1.1998e-01,  2.9921e-02,  ..., -9.5692e-03,\n",
      "          -7.8848e-03,  1.4359e-02],\n",
      "         [-4.0607e-03,  1.9540e-01,  4.0787e-02,  ..., -6.1933e-02,\n",
      "          -5.3576e-02, -2.2539e-01],\n",
      "         [ 2.1003e-02,  7.2559e-02,  1.0935e-04,  ..., -7.8986e-02,\n",
      "          -2.2706e-02, -9.2420e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  answer:  2006\n",
      "tensor([[[ 2.5451e-01, -1.1231e-01, -3.6706e-01,  ...,  1.6126e+00,\n",
      "           1.4637e+00, -7.0995e-01],\n",
      "         [ 9.6811e-01, -5.1509e-01, -3.9265e-02,  ...,  2.3991e+00,\n",
      "           2.8384e-01, -4.6472e-01],\n",
      "         [-1.7224e-01, -3.6301e-01,  3.6795e-02,  ...,  1.1990e+00,\n",
      "           7.5194e-01, -8.6513e-01],\n",
      "         ...,\n",
      "         [ 1.1275e-03,  6.9467e-02, -7.4301e-03,  ..., -1.2783e-01,\n",
      "          -4.0521e-02, -7.5085e-02],\n",
      "         [-1.1690e-01,  1.9981e-01,  1.6889e-02,  ..., -9.5931e-02,\n",
      "           9.1905e-02,  1.2204e-01],\n",
      "         [-1.0206e-01,  1.1595e-01, -9.9393e-02,  ..., -1.3806e-01,\n",
      "           7.5028e-02, -1.0603e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.8568, -0.3243, -0.3727,  ...,  0.6935,  1.8145, -0.3374],\n",
      "         [ 0.6657, -0.0800,  0.1703,  ...,  1.5577,  0.6772, -0.3832],\n",
      "         [ 0.3144, -0.4296, -0.0572,  ..., -0.0885,  1.2933, -0.6224],\n",
      "         ...,\n",
      "         [-0.0415,  0.1291, -0.0046,  ..., -0.0278, -0.0370, -0.2218],\n",
      "         [-0.0085,  0.0725, -0.0105,  ..., -0.0662, -0.0392, -0.0787],\n",
      "         [-0.0038,  0.0610,  0.0076,  ..., -0.0885, -0.0252, -0.0846]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1937\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4455, -0.2398,  0.0112,  ...,  0.3134,  1.2155,  0.0715],\n",
      "         [ 0.5507, -0.0959,  0.2522,  ...,  2.4540,  0.3990, -0.2729],\n",
      "         [ 0.2085,  0.1451, -0.3550,  ...,  1.7482, -0.0446, -0.3502],\n",
      "         ...,\n",
      "         [-0.0129,  0.0693, -0.0378,  ..., -0.0817, -0.0477, -0.1364],\n",
      "         [-0.0215,  0.0672,  0.0050,  ..., -0.0947, -0.0348, -0.0831],\n",
      "         [ 0.1715,  0.4198, -0.1440,  ..., -0.3397,  0.4329, -0.2245]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.6769, -0.0198, -0.1151,  ...,  2.0034,  1.4271, -0.5235],\n",
      "         [ 0.4757, -0.3027,  0.2377,  ...,  1.8640,  0.4796, -0.1773],\n",
      "         [ 0.3240, -0.5507,  0.1028,  ...,  1.4683,  0.4683, -0.5685],\n",
      "         ...,\n",
      "         [-0.0045,  0.0712,  0.0064,  ..., -0.0730, -0.0224, -0.0781],\n",
      "         [ 0.0124,  0.0636,  0.0040,  ..., -0.0725, -0.0312, -0.0787],\n",
      "         [-0.0236,  0.1132,  0.0279,  ..., -0.0667, -0.0872, -0.2378]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "answer:  st johns\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 3.4290e-01, -1.1059e-01,  5.1554e-02,  ...,  1.7858e+00,\n",
      "           1.6430e+00, -6.1505e-01],\n",
      "         [ 4.8907e-02,  1.7104e-01, -2.8731e-01,  ...,  7.2760e-01,\n",
      "           2.9012e-01, -2.5272e-01],\n",
      "         [ 2.3863e-01,  1.1839e-01, -1.9221e-01,  ...,  1.3302e+00,\n",
      "           5.0784e-01, -6.4301e-01],\n",
      "         ...,\n",
      "         [-2.1134e-02,  1.0187e-01, -1.2452e-03,  ..., -7.8461e-02,\n",
      "          -3.5303e-02, -8.5420e-02],\n",
      "         [-1.0070e-02,  1.8749e-01, -1.0253e-02,  ..., -5.6437e-02,\n",
      "          -1.0831e-01, -2.1458e-01],\n",
      "         [-1.2129e-02,  6.6731e-02,  4.9591e-03,  ..., -9.1454e-02,\n",
      "          -3.0452e-02, -7.8222e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  hollywood madam\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.3547e-01,  1.2673e-01, -7.2172e-02,  ...,  1.0840e+00,\n",
      "           4.7189e-01,  4.8810e-02],\n",
      "         [ 2.4055e-01, -2.0847e-02,  7.1674e-02,  ...,  2.0239e+00,\n",
      "           4.8158e-01, -3.9393e-01],\n",
      "         [ 5.2563e-01,  1.4369e-01, -1.2650e-01,  ...,  6.4447e-01,\n",
      "           7.2997e-01,  6.3246e-01],\n",
      "         ...,\n",
      "         [ 3.9596e-02,  3.7349e-01, -2.1269e-02,  ...,  9.7056e-02,\n",
      "           7.0613e-02, -8.0643e-04],\n",
      "         [ 2.4601e-03,  7.4194e-02, -3.6189e-03,  ..., -8.5292e-02,\n",
      "          -2.9057e-02, -7.4144e-02],\n",
      "         [-6.9775e-03,  6.5243e-02,  6.5373e-03,  ..., -8.3631e-02,\n",
      "          -2.6329e-02, -8.1180e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.7400e-01, -1.0669e-01,  1.7437e-02,  ...,  1.9220e+00,\n",
      "           1.2825e+00, -4.3605e-01],\n",
      "         [-1.0190e-01,  8.1293e-02,  2.6351e-01,  ...,  1.4005e+00,\n",
      "           7.6207e-02,  1.3685e-01],\n",
      "         [ 4.5229e-01,  3.8478e-02,  2.6508e-02,  ...,  1.0399e+00,\n",
      "           3.5440e-01,  1.6745e-01],\n",
      "         ...,\n",
      "         [-1.0110e-02,  6.7302e-02, -8.6120e-03,  ..., -7.1257e-02,\n",
      "          -3.2484e-02, -6.1363e-02],\n",
      "         [-7.7964e-03,  9.7652e-02, -1.3076e-03,  ..., -7.8614e-02,\n",
      "          -3.0116e-02, -6.6230e-02],\n",
      "         [ 1.5394e-01,  2.7908e-01, -1.1737e-01,  ..., -4.4916e-01,\n",
      "           3.0946e-01, -2.8653e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.1720e-01, -6.5997e-02, -8.5049e-02,  ...,  2.3668e+00,\n",
      "           1.1823e+00, -2.2544e-01],\n",
      "         [ 2.3082e-01, -2.9403e-01,  4.2777e-01,  ...,  7.7988e-01,\n",
      "           6.2956e-01, -3.0264e-01],\n",
      "         [ 2.9496e-01, -3.9236e-01,  3.0744e-01,  ...,  1.8985e+00,\n",
      "           4.0869e-01, -4.6256e-01],\n",
      "         ...,\n",
      "         [-6.6925e-03,  9.9109e-02, -9.2491e-04,  ..., -7.2838e-02,\n",
      "          -2.3046e-02, -8.2362e-02],\n",
      "         [-3.7528e-03,  2.2503e-01, -1.7972e-02,  ..., -6.8659e-02,\n",
      "          -1.2129e-01, -1.7001e-01],\n",
      "         [-5.4543e-03,  7.7363e-02,  2.4260e-03,  ..., -6.5004e-02,\n",
      "          -2.8763e-02, -8.2791e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.2747e-01, -1.2794e-01, -2.3343e-01,  ...,  1.8084e+00,\n",
      "           8.4396e-01, -9.5572e-01],\n",
      "         [ 4.0990e-01,  2.3155e-01,  5.0321e-01,  ...,  1.3082e+00,\n",
      "           9.3999e-01, -7.6447e-01],\n",
      "         [ 4.4826e-01,  1.1984e-01,  2.7947e-01,  ...,  9.2732e-01,\n",
      "           6.4478e-01, -4.8353e-01],\n",
      "         ...,\n",
      "         [ 1.5968e-04,  7.6832e-02,  4.0715e-03,  ..., -8.3675e-02,\n",
      "          -2.5557e-02, -8.6370e-02],\n",
      "         [-4.1598e-03,  6.7217e-02,  6.4060e-03,  ..., -8.5320e-02,\n",
      "          -2.5618e-02, -8.1694e-02],\n",
      "         [-1.4951e-02,  7.1047e-02, -1.6048e-03,  ..., -7.1891e-02,\n",
      "           7.1204e-04, -1.0027e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.9998e-01, -2.7571e-01,  3.7848e-02,  ...,  2.0221e+00,\n",
      "           1.0242e+00, -6.1035e-01],\n",
      "         [ 6.2373e-01,  1.6206e-01,  1.4882e-01,  ...,  2.2221e+00,\n",
      "           4.5714e-01, -2.8275e-01],\n",
      "         [ 5.9911e-01, -2.2997e-01,  1.3084e-01,  ...,  1.2755e+00,\n",
      "           7.4687e-01, -2.6879e-01],\n",
      "         ...,\n",
      "         [ 6.3233e-01,  7.3087e-01, -7.7163e-02,  ..., -7.3674e-02,\n",
      "           2.5299e-01, -1.7723e-01],\n",
      "         [-1.6532e-02,  7.0816e-02, -7.6891e-04,  ..., -8.1516e-02,\n",
      "          -3.2989e-02, -8.8598e-02],\n",
      "         [-3.4563e-02,  3.3169e-01,  6.9335e-03,  ..., -1.4131e-01,\n",
      "          -1.0077e-01, -2.9892e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.9089, -0.1967,  0.0701,  ...,  2.5241,  1.3221, -0.5183],\n",
      "         [ 0.5634, -0.0385,  0.2447,  ...,  2.1021,  0.3150, -0.2217],\n",
      "         [ 0.4938,  0.3405, -0.0049,  ...,  0.9580,  0.6166, -0.4409],\n",
      "         ...,\n",
      "         [-0.0373,  0.1390,  0.0215,  ..., -0.0325, -0.0090, -0.2041],\n",
      "         [-0.0130,  0.0805, -0.0117,  ..., -0.0674, -0.0374, -0.0964],\n",
      "         [-0.0430,  0.2251,  0.0683,  ..., -0.0818, -0.0764, -0.2264]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.2118e-01, -8.3333e-02,  1.8038e-01,  ...,  4.8159e-01,\n",
      "           8.4974e-01, -2.6464e-01],\n",
      "         [-3.5430e-01,  5.4657e-02,  3.5656e-01,  ...,  1.5348e+00,\n",
      "           3.0262e-01, -1.8142e-01],\n",
      "         [ 1.2384e-01,  4.0822e-01, -1.9234e-02,  ...,  1.1027e-01,\n",
      "           4.6324e-01,  4.1752e-02],\n",
      "         ...,\n",
      "         [ 2.0051e-02,  8.0555e-02, -1.6851e-02,  ..., -9.0338e-02,\n",
      "          -1.9014e-02, -7.6817e-02],\n",
      "         [-1.4804e-02,  1.3938e-01, -8.0890e-02,  ..., -9.4002e-02,\n",
      "          -5.1984e-02, -8.3284e-02],\n",
      "         [-1.2516e-02,  7.3632e-02,  2.6173e-05,  ..., -8.1653e-02,\n",
      "          -3.7342e-02, -8.2190e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "answer:  doug moench and don perlin\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  magnolia pictures\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 0.6194,  0.1787,  0.1316,  ...,  2.0890,  1.0334, -0.7622],\n",
      "         [ 0.5623,  0.1176,  0.3224,  ...,  2.4384,  0.5865, -0.4794],\n",
      "         [ 0.3952,  0.4158, -0.3611,  ...,  1.0494,  0.4577, -0.5771],\n",
      "         ...,\n",
      "         [-0.0149,  0.0696, -0.0035,  ..., -0.0929, -0.0324, -0.0785],\n",
      "         [-0.0161,  0.0686,  0.0103,  ..., -0.0785, -0.0253, -0.0856],\n",
      "         [-0.0165,  0.0594,  0.0025,  ..., -0.0800, -0.0418, -0.0775]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.8813e-01,  5.7404e-02,  4.4656e-01,  ...,  1.5720e+00,\n",
      "           7.2958e-01, -2.9141e-01],\n",
      "         [ 2.9711e-01, -3.3658e-01,  4.9253e-01,  ...,  1.7665e+00,\n",
      "           3.7231e-01, -5.8552e-02],\n",
      "         [ 5.9596e-03,  8.9051e-02, -6.0504e-03,  ...,  1.2628e+00,\n",
      "           2.3431e-01, -7.6552e-01],\n",
      "         ...,\n",
      "         [ 4.1045e-01,  3.8099e-01, -2.6271e-01,  ...,  5.4854e-01,\n",
      "           2.6370e-04, -3.7842e-01],\n",
      "         [ 2.6427e-01,  4.0194e-01, -2.4878e-01,  ..., -4.7040e-02,\n",
      "           3.7199e-01, -6.4178e-01],\n",
      "         [ 7.5677e-04,  5.8846e-02, -7.1398e-03,  ..., -8.4481e-02,\n",
      "          -1.7844e-02, -6.8768e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.0755e-01,  3.7998e-01, -7.8645e-02,  ...,  1.6081e+00,\n",
      "           1.4515e+00, -7.8867e-01],\n",
      "         [-5.8309e-02, -1.1329e-01,  5.8465e-01,  ...,  2.2934e+00,\n",
      "           5.2203e-01, -5.2937e-01],\n",
      "         [ 2.7715e-01,  1.0003e-01,  3.2138e-01,  ...,  2.1964e+00,\n",
      "           1.0094e+00, -6.7319e-01],\n",
      "         ...,\n",
      "         [ 1.0419e-02,  1.6554e-01, -3.9038e-01,  ...,  5.2168e-01,\n",
      "           2.7788e-01, -4.5271e-01],\n",
      "         [-2.1503e-03,  6.2751e-02,  4.9210e-03,  ..., -7.5298e-02,\n",
      "          -9.7316e-03, -7.3311e-02],\n",
      "         [ 1.6468e-02,  6.8513e-02,  5.3553e-03,  ..., -5.5785e-02,\n",
      "          -2.8369e-02, -9.5877e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 0.4977, -0.1163, -0.4630,  ...,  1.8940,  0.2902, -0.2758],\n",
      "         [-0.1202,  0.1345,  0.1845,  ...,  1.1439,  0.0869,  0.1034],\n",
      "         [-0.1713, -0.1980, -0.0118,  ...,  0.6173,  0.2038, -0.1340],\n",
      "         ...,\n",
      "         [ 0.1054,  0.0458, -0.0936,  ..., -0.1170,  0.0566, -0.2375],\n",
      "         [-0.0353,  0.3189, -0.1217,  ..., -0.2524,  0.1037, -0.1610],\n",
      "         [-0.0051,  0.0694,  0.0196,  ..., -0.0458, -0.0287, -0.0699]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.5731e-01,  2.5234e-02, -2.6232e-01,  ...,  1.3145e+00,\n",
      "           8.9486e-01, -3.5062e-01],\n",
      "         [-1.0324e-01,  3.7224e-01,  2.8617e-01,  ...,  1.9953e+00,\n",
      "           1.0244e-01, -2.8219e-01],\n",
      "         [ 1.3682e-01, -3.6714e-01, -7.7839e-02,  ...,  6.2896e-01,\n",
      "           1.0053e+00, -4.5145e-01],\n",
      "         ...,\n",
      "         [-1.7882e-02,  7.5152e-02, -9.3933e-03,  ..., -8.8445e-02,\n",
      "          -3.8748e-02, -8.5540e-02],\n",
      "         [-1.1701e-02,  7.3661e-02, -1.2698e-03,  ..., -8.1224e-02,\n",
      "          -3.5820e-02, -8.1678e-02],\n",
      "         [-3.3775e-01,  8.7138e-01,  8.1695e-03,  ...,  5.7560e-04,\n",
      "           1.0839e-01, -1.1274e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.6167e-01,  1.9743e-01,  2.1197e-01,  ...,  1.8325e+00,\n",
      "           4.5322e-01, -4.9730e-01],\n",
      "         [-3.7700e-01, -2.9232e-01,  4.3749e-01,  ...,  1.4699e+00,\n",
      "           7.4524e-01, -5.9103e-01],\n",
      "         [ 1.1309e-01, -1.9123e-01,  4.8600e-01,  ...,  1.6168e+00,\n",
      "           8.1297e-01, -5.0575e-01],\n",
      "         ...,\n",
      "         [-1.1191e-03,  7.4333e-02,  7.0805e-03,  ..., -8.1800e-02,\n",
      "          -2.8659e-02, -8.7993e-02],\n",
      "         [-8.8517e-02,  1.1613e-02,  3.3204e-03,  ..., -3.5642e-01,\n",
      "           3.1559e-02, -1.4699e-01],\n",
      "         [ 1.2918e-01,  3.1385e-01, -3.8772e-02,  ..., -1.0099e-01,\n",
      "           3.6578e-02, -2.4657e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 3.5369e-01,  4.7943e-01, -1.7919e-01,  ...,  2.3155e-01,\n",
      "           6.5502e-01, -6.1775e-01],\n",
      "         [ 2.3969e-02,  8.0628e-02,  4.0490e-01,  ...,  2.9501e+00,\n",
      "           4.4497e-01, -3.0574e-01],\n",
      "         [ 5.4992e-01,  1.7431e-01,  6.4992e-02,  ...,  1.8837e+00,\n",
      "           6.6524e-01, -7.0002e-01],\n",
      "         ...,\n",
      "         [-8.9777e-03,  7.1144e-02, -6.9282e-03,  ..., -7.7825e-02,\n",
      "          -5.2779e-02, -7.4710e-02],\n",
      "         [ 1.2854e-03,  1.0841e-01,  5.2166e-03,  ..., -7.2124e-02,\n",
      "          -1.7918e-02, -8.2386e-02],\n",
      "         [-1.9368e-02,  7.0620e-02, -1.0736e-03,  ..., -7.6831e-02,\n",
      "          -3.6595e-02, -8.7421e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.0823,  0.0802, -0.0671,  ...,  0.5646,  0.2694, -0.0756],\n",
      "         [ 0.0990, -0.0777,  0.2209,  ...,  2.6490,  0.7493,  0.4393],\n",
      "         [ 0.1265,  0.2188,  0.1453,  ...,  1.5049, -0.1751, -0.4568],\n",
      "         ...,\n",
      "         [-0.0098,  0.0795, -0.0064,  ..., -0.0724, -0.0345, -0.0636],\n",
      "         [-0.0491,  0.1127,  0.0649,  ..., -0.0532, -0.0358, -0.2400],\n",
      "         [-0.0205,  0.0787, -0.0034,  ..., -0.0643, -0.0440, -0.0936]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.4375e-01,  3.7924e-01, -4.6085e-02,  ...,  1.3093e+00,\n",
      "           8.4330e-01, -4.3443e-01],\n",
      "         [ 2.8195e-01, -2.5391e-01,  2.9293e-01,  ...,  2.4148e+00,\n",
      "           8.0318e-01, -3.0785e-01],\n",
      "         [-2.7216e-01, -6.0440e-02,  3.9705e-01,  ...,  8.0530e-01,\n",
      "           1.8992e-01, -3.6776e-01],\n",
      "         ...,\n",
      "         [-6.8760e-03,  7.3327e-02, -8.7850e-04,  ..., -7.7449e-02,\n",
      "          -4.2367e-02, -8.8441e-02],\n",
      "         [-1.4544e-01,  3.7482e-01,  7.0905e-02,  ...,  2.4611e-02,\n",
      "          -1.9944e-02, -1.0856e-01],\n",
      "         [-1.1653e-02,  7.1890e-02, -4.6974e-03,  ..., -7.0948e-02,\n",
      "          -2.6433e-02, -7.9866e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.5967e-01,  3.9728e-01, -2.1671e-01,  ..., -3.2667e-01,\n",
      "           6.4225e-01, -6.3524e-01],\n",
      "         [ 1.3165e-01,  2.4839e-01,  2.5663e-01,  ...,  2.2387e+00,\n",
      "           4.0315e-01, -3.2466e-01],\n",
      "         [ 1.5660e-02,  5.4556e-01,  1.7275e-01,  ...,  6.5615e-01,\n",
      "           4.3751e-01, -2.1128e-01],\n",
      "         ...,\n",
      "         [-1.4488e-02,  7.2069e-02,  9.0009e-03,  ..., -7.0549e-02,\n",
      "          -3.1231e-02, -8.6703e-02],\n",
      "         [-2.7518e-03,  9.2107e-02,  7.0117e-03,  ..., -6.7925e-02,\n",
      "          -3.4046e-02, -1.0319e-01],\n",
      "         [ 1.1075e-03,  7.5755e-02, -5.9359e-03,  ..., -7.7773e-02,\n",
      "          -3.1251e-02, -8.5857e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  danny leiner\n",
      "answer:  24 october 1632\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  espn\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1937\n",
      "answer:  doug moench and don perlin\n",
      "answer:  1960\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.5204e-01, -1.4802e-01,  1.7774e-01,  ...,  1.1993e+00,\n",
      "           7.3000e-01, -5.8875e-01],\n",
      "         [ 4.2601e-02, -3.1535e-01,  4.3814e-01,  ...,  2.3781e+00,\n",
      "           3.0025e-01, -3.7053e-01],\n",
      "         [ 4.0260e-01, -4.6786e-01,  5.4614e-01,  ...,  1.7339e+00,\n",
      "           5.9967e-01, -8.1272e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1331, 768])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  transcendentalist\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.4059e-01, -2.0926e-01,  1.8806e-01,  ...,  1.6342e+00,\n",
      "           7.9426e-01, -7.7314e-01],\n",
      "         [ 4.3919e-01, -2.5802e-01,  5.2464e-01,  ...,  1.9299e+00,\n",
      "           2.8035e-01, -4.4941e-01],\n",
      "         [ 3.9895e-02, -1.9802e-01,  6.8965e-01,  ...,  1.3562e+00,\n",
      "           7.2146e-01, -2.3491e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "answer:  marlboro\n",
      "answer:  ash avildsen and matty beckerman\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  american\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.4552e-01, -3.7716e-01,  9.8742e-02,  ...,  2.0565e+00,\n",
      "           9.1699e-01, -3.2126e-01],\n",
      "         [ 5.6655e-01, -3.5516e-01,  4.4867e-01,  ...,  2.0754e+00,\n",
      "           4.9986e-01, -1.1686e-01],\n",
      "         [ 4.5544e-01,  2.5678e-01,  3.8384e-01,  ...,  1.0608e+00,\n",
      "           5.9687e-01,  1.2570e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1450, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  keri russell\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.0984e-01,  1.7856e-01,  3.2336e-01,  ...,  1.2117e+00,\n",
      "           5.4173e-01, -4.5870e-01],\n",
      "         [ 3.6285e-01, -3.7336e-01,  3.3510e-01,  ...,  2.3598e+00,\n",
      "           5.2158e-01, -2.4094e-01],\n",
      "         [ 1.6593e-01, -1.5458e-01,  3.1470e-01,  ...,  2.0453e+00,\n",
      "           4.9421e-01, -2.2524e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ghanaian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.0207e-01,  3.7735e-01,  2.2798e-01,  ...,  1.5968e+00,\n",
      "           2.5941e-01,  1.5666e-01],\n",
      "         [ 2.0439e-01, -2.7782e-01,  5.2128e-01,  ...,  2.1956e+00,\n",
      "           3.6755e-01, -6.6502e-01],\n",
      "         [-4.8265e-02,  2.9664e-01,  6.4676e-01,  ...,  1.2446e+00,\n",
      "           4.7677e-01, -3.7221e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1388, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  farinelli\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.1336e-01, -3.2660e-01,  2.6818e-01,  ..., -9.0787e-03,\n",
      "           8.7718e-01,  2.2441e-03],\n",
      "         [-3.7212e-01,  3.7662e-01,  1.2892e-01,  ...,  9.9717e-01,\n",
      "           6.8399e-01,  2.9363e-02],\n",
      "         [-8.0372e-02,  4.0265e-02,  1.1042e-01,  ..., -6.5719e-02,\n",
      "           3.0008e-01,  2.9307e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 928, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  atom egoyan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.4078e-01,  1.5800e-01, -2.7468e-01,  ...,  1.0982e+00,\n",
      "           6.5512e-01, -1.4035e-01],\n",
      "         [ 4.0917e-01, -2.0369e-01,  3.6711e-01,  ...,  2.2688e+00,\n",
      "           4.5164e-01, -1.6825e-01],\n",
      "         [ 1.7506e-01,  3.5770e-01, -1.5873e-01,  ...,  1.5727e+00,\n",
      "           2.4622e-01,  1.1098e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1288, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  eric of pomerania\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 7.1945e-02,  3.5766e-01,  1.0426e-01,  ...,  9.7694e-01,\n",
      "           7.5967e-01, -4.2193e-01],\n",
      "         [ 3.7441e-02, -1.7210e-01,  3.7972e-01,  ...,  2.7897e+00,\n",
      "           5.2582e-01, -3.9701e-01],\n",
      "         [-1.4662e-01, -3.0923e-01,  3.7608e-01,  ...,  1.8500e+00,\n",
      "           6.1000e-01, -5.3277e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1063, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  flowering plants\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.9501e-02,  3.0134e-01,  1.2734e-01,  ...,  1.1234e+00,\n",
      "           6.1933e-01, -1.1520e-01],\n",
      "         [-3.9318e-01, -1.2880e-01,  5.9712e-01,  ...,  2.1821e+00,\n",
      "           4.0817e-01,  4.1271e-02],\n",
      "         [ 7.8656e-01,  8.5545e-02,  2.2403e-01,  ...,  5.8448e-01,\n",
      "           6.7730e-01, -2.3229e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1266, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lashkaretaiba\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.5349e-02,  1.0047e-01,  3.7114e-01,  ...,  1.1217e+00,\n",
      "           8.1596e-01, -3.1374e-01],\n",
      "         [ 2.8293e-01, -6.6612e-02,  2.1982e-01,  ...,  2.0330e+00,\n",
      "           5.9800e-01, -1.1849e-01],\n",
      "         [-2.4561e-02,  2.4157e-01,  3.1664e-01,  ...,  1.2794e+00,\n",
      "           5.4321e-01,  7.5178e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1080, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  4\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-3.8568e-01, -1.5193e-01, -3.0746e-01,  ...,  9.8616e-01,\n",
      "           7.4141e-01, -5.0354e-01],\n",
      "         [ 2.7916e-01, -2.5774e-01,  6.5576e-01,  ...,  1.6394e+00,\n",
      "           3.2092e-01, -3.9893e-01],\n",
      "         [ 1.0669e-01, -2.3957e-01,  5.7003e-01,  ...,  1.4232e+00,\n",
      "           3.4625e-01, -1.9702e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1208, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  loop parkway\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 1.3295e-01, -4.9933e-02,  4.3143e-02,  ...,  1.1559e+00,\n",
      "           1.0104e+00, -5.0248e-01],\n",
      "         [ 4.0220e-01,  2.5271e-02,  2.9043e-01,  ...,  1.9227e+00,\n",
      "           4.0332e-01, -2.4640e-01],\n",
      "         [ 7.2030e-03,  3.2751e-01, -4.3138e-02,  ...,  1.3787e+00,\n",
      "           3.4341e-01, -3.0526e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1718, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  jeff daniels\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.1502e-01,  1.9213e-01,  1.6815e-01,  ...,  1.4340e+00,\n",
      "           7.6540e-01, -1.4260e-01],\n",
      "         [-1.0755e-01, -1.0518e-02,  5.3686e-01,  ...,  1.5926e+00,\n",
      "           2.8034e-01, -3.2352e-01],\n",
      "         [-1.0696e-01,  4.5614e-01,  4.0805e-01,  ...,  7.1473e-01,\n",
      "           2.7118e-01,  6.9967e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1148, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  charles manson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.9424e-01,  1.3386e-01,  4.5493e-01,  ...,  1.1230e+00,\n",
      "           8.0358e-01, -5.2924e-01],\n",
      "         [ 2.9766e-02, -1.4804e-01,  4.0239e-01,  ...,  1.6967e+00,\n",
      "           6.4010e-01, -7.1847e-01],\n",
      "         [ 4.2031e-02, -4.1804e-01,  3.0095e-01,  ...,  1.5238e+00,\n",
      "           5.4987e-01, -6.4716e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 973, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  russia\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.9233e-01, -2.1587e-01,  1.1284e-01,  ...,  1.8054e+00,\n",
      "           1.0843e+00, -5.7231e-01],\n",
      "         [ 3.7947e-01, -2.9408e-01,  2.6206e-01,  ...,  1.7179e+00,\n",
      "           3.7736e-01, -3.7913e-01],\n",
      "         [-2.1454e-01,  2.9652e-01,  2.9736e-01,  ..., -9.5610e-02,\n",
      "           5.3376e-01, -8.8985e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  stephen gyllenhaal and naomi achs\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 7.1969e-02,  3.3267e-01, -1.3791e-02,  ...,  1.2737e+00,\n",
      "           4.1892e-01, -4.9534e-01],\n",
      "         [ 4.2479e-01, -3.0012e-01,  5.1721e-01,  ...,  2.1970e+00,\n",
      "           4.5288e-01, -1.8547e-01],\n",
      "         [-2.0761e-02, -2.8237e-01,  4.3280e-01,  ...,  1.6607e+00,\n",
      "           4.4867e-01, -3.6416e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1907, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  camlaren mine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.5807e-01, -1.9121e-01,  3.0019e-01,  ...,  1.9204e+00,\n",
      "           9.2815e-01, -5.3765e-01],\n",
      "         [ 1.9954e-01, -2.8823e-01,  4.9788e-01,  ...,  2.1598e+00,\n",
      "           4.2594e-01,  1.8053e-01],\n",
      "         [-1.6124e-01,  2.1900e-01,  4.8818e-01,  ...,  8.6983e-01,\n",
      "           8.1336e-01, -2.0173e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1181, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  herman wouk\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.5634e-01,  5.1630e-01, -1.0805e-01,  ...,  1.5184e+00,\n",
      "           6.4464e-01, -2.3778e-01],\n",
      "         [-4.1595e-01, -4.1691e-02,  6.9524e-01,  ...,  2.3077e+00,\n",
      "           4.2728e-01, -4.9361e-01],\n",
      "         [ 5.2433e-03, -2.6497e-01,  2.4335e-01,  ...,  1.9733e+00,\n",
      "           3.8082e-01, -6.3942e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1182, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 3.1262e-01,  9.9474e-02, -2.3898e-02,  ...,  2.8247e-01,\n",
      "           3.3704e-01, -2.6041e-01],\n",
      "         [ 3.6527e-02, -3.9759e-01,  5.0281e-01,  ...,  1.7338e+00,\n",
      "           3.1778e-01, -5.4635e-01],\n",
      "         [-2.2839e-01, -2.9846e-01,  2.6755e-01,  ...,  9.3952e-01,\n",
      "           1.9672e-01, -4.3901e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 957, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  wendy carlos\n",
      "answer:  lord voldemort\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.6388e-01,  2.5055e-01,  1.2840e-01,  ...,  1.6055e+00,\n",
      "           1.0030e+00, -7.1105e-01],\n",
      "         [ 1.8952e-01, -3.8626e-02,  7.1590e-01,  ...,  1.8582e+00,\n",
      "           5.7927e-01, -5.0440e-01],\n",
      "         [ 4.0336e-02,  4.0370e-01,  4.7854e-01,  ...,  1.2755e+00,\n",
      "           7.1903e-01, -4.6863e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1423, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  tokyo japan\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 8.6428e-02,  1.4331e-01, -1.0076e-01,  ...,  1.0814e+00,\n",
      "           3.5903e-01, -1.8223e-01],\n",
      "         [-1.7483e-01,  1.1967e-01,  3.2596e-01,  ...,  1.5693e+00,\n",
      "           1.4287e-01, -4.5040e-01],\n",
      "         [ 2.6925e-01, -4.2267e-01,  4.0849e-01,  ...,  1.8306e+00,\n",
      "           9.2044e-01, -4.1581e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1343, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.6130e-01, -1.5968e-02, -1.1384e-01,  ...,  1.4982e+00,\n",
      "           9.3534e-01, -6.2587e-01],\n",
      "         [ 1.3084e-01, -9.7181e-02,  3.2904e-01,  ...,  2.1923e+00,\n",
      "           3.1391e-01, -7.7222e-02],\n",
      "         [ 2.1257e-03,  3.3018e-01,  1.6510e-01,  ...,  1.2972e+00,\n",
      "           4.6555e-01,  6.3278e-03],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1062, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  st johns\n",
      "answer:  square enix\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.0165e-01,  1.5739e-01,  1.6462e-01,  ...,  1.7730e+00,\n",
      "           8.8054e-01, -1.6051e-01],\n",
      "         [ 4.2479e-01, -3.2132e-01,  3.7316e-01,  ...,  2.2364e+00,\n",
      "           6.5289e-01, -4.6739e-03],\n",
      "         [ 4.0042e-01, -6.2669e-02,  4.2252e-01,  ...,  1.4076e+00,\n",
      "           9.0427e-01, -3.8896e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1456, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  paul winters\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.6622e-02,  5.9907e-01, -2.7633e-01,  ...,  1.1684e+00,\n",
      "           5.6041e-01, -2.1930e-01],\n",
      "         [ 3.0668e-01, -3.6579e-02,  2.7516e-01,  ...,  2.1789e+00,\n",
      "           4.1828e-01, -7.8668e-02],\n",
      "         [-2.5050e-01,  3.6384e-01,  6.4811e-01,  ...,  9.2760e-01,\n",
      "           4.7249e-01, -6.9516e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1074, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  louis caldera\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.0566e-01, -5.4904e-01, -1.2662e-01,  ...,  1.5867e+00,\n",
      "           7.2881e-01, -4.0479e-01],\n",
      "         [ 3.4076e-01, -7.3435e-01,  6.9753e-01,  ...,  2.3552e+00,\n",
      "           3.1881e-01, -2.6286e-01],\n",
      "         [ 1.2449e-01, -5.3279e-01,  6.4986e-01,  ...,  2.0946e+00,\n",
      "           6.9903e-01, -2.6498e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1140, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  stockholm stock exchange\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.3920e-01,  3.1655e-01,  3.1294e-01,  ...,  9.0247e-01,\n",
      "           1.0279e+00, -8.4851e-02],\n",
      "         [ 1.3122e-01, -2.3693e-01,  3.9883e-01,  ...,  2.2003e+00,\n",
      "           4.3352e-01, -1.2378e-01],\n",
      "         [-6.2178e-02, -3.7297e-01,  2.3511e-01,  ...,  1.3988e+00,\n",
      "           6.6166e-01, -3.2445e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1060, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  neil burger\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 3.4599e-02,  3.3027e-01, -3.3168e-01,  ...,  1.3346e+00,\n",
      "           4.5496e-01, -4.2043e-01],\n",
      "         [ 7.2414e-01, -3.3482e-01,  3.1918e-01,  ...,  2.0978e+00,\n",
      "           3.9661e-01, -4.5221e-01],\n",
      "         [-2.0686e-01,  3.9170e-01,  1.0122e+00,  ...,  1.2127e+00,\n",
      "           1.7118e-01, -9.2153e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1791, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.8212e-01,  6.7096e-01,  6.6725e-02,  ...,  1.5072e+00,\n",
      "           5.7160e-01, -8.0985e-02],\n",
      "         [-5.5962e-02, -2.4302e-01,  4.7573e-01,  ...,  1.8871e+00,\n",
      "           4.7069e-01, -3.4611e-01],\n",
      "         [-3.7442e-01, -2.0733e-02,  2.8254e-01,  ...,  1.4831e+00,\n",
      "           3.4458e-01,  2.7106e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1291, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.6566e-01,  1.3304e-01, -1.4485e-01,  ..., -1.4011e-01,\n",
      "           3.1635e-01, -1.3884e-01],\n",
      "         [-3.7379e-01, -1.9546e-01,  3.7906e-01,  ...,  1.6662e+00,\n",
      "           1.7133e-01, -2.5259e-01],\n",
      "         [ 2.6181e-01,  3.5599e-01,  1.4925e-01,  ...,  8.5362e-01,\n",
      "           3.6417e-01, -3.2423e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 842, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  austria\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 1.0305e-01,  2.5078e-01,  3.1729e-01,  ...,  1.7015e+00,\n",
      "           6.8133e-01, -3.8950e-01],\n",
      "         [ 4.6738e-01, -2.8876e-01,  2.8265e-01,  ...,  2.3429e+00,\n",
      "           4.7947e-01, -5.6762e-02],\n",
      "         [ 1.8456e-01,  2.2513e-01,  6.2199e-02,  ...,  1.7823e+00,\n",
      "           4.6849e-01, -1.1064e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2298, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  essex\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.9640e-01, -2.2377e-01, -2.2062e-01,  ...,  1.9025e+00,\n",
      "           1.0550e+00, -7.1573e-01],\n",
      "         [ 3.1449e-01, -3.6138e-01,  4.1171e-01,  ...,  2.1776e+00,\n",
      "           4.6664e-01, -1.3015e-01],\n",
      "         [ 1.8151e-01, -3.6413e-01,  5.0236e-01,  ...,  1.5685e+00,\n",
      "           8.3463e-01, -2.0270e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1283, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  scottie pippen\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.3734e-01, -1.0448e-01, -2.4447e-01,  ...,  1.3416e+00,\n",
      "           8.4140e-01, -1.7328e-01],\n",
      "         [-8.6048e-02, -4.1826e-02,  2.9357e-01,  ...,  1.6349e+00,\n",
      "           5.1818e-01, -2.9541e-01],\n",
      "         [-2.2099e-01, -6.9958e-02, -6.2547e-02,  ...,  1.0742e+00,\n",
      "           6.0196e-01, -4.6442e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1421, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  wachovia securities\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.1527e-01, -2.2407e-01, -3.8329e-02,  ...,  1.0258e+00,\n",
      "           1.2904e+00, -3.4764e-01],\n",
      "         [ 3.0326e-01, -3.4352e-01,  6.1245e-01,  ...,  1.8761e+00,\n",
      "           5.3184e-01, -3.8080e-01],\n",
      "         [ 3.6427e-02,  2.0847e-03,  2.9746e-01,  ...,  9.2681e-01,\n",
      "           6.8289e-01, -1.3210e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1002, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.4895e-01,  8.5839e-02, -1.7631e-01,  ...,  1.6185e+00,\n",
      "           8.3490e-01, -4.4928e-01],\n",
      "         [ 5.0454e-01, -2.9817e-01,  2.8972e-01,  ...,  2.0593e+00,\n",
      "           4.1893e-01,  1.7191e-02],\n",
      "         [ 2.1873e-01, -1.4319e-01,  2.0040e-01,  ...,  1.3220e+00,\n",
      "           6.3135e-01,  1.3164e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1163, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  michael caine\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.3907e-02, -1.5000e-01,  2.1944e-01,  ...,  1.1886e+00,\n",
      "           1.1152e+00, -5.0372e-01],\n",
      "         [ 3.2404e-01, -1.9709e-01,  2.1652e-01,  ...,  2.1334e+00,\n",
      "           4.7718e-01, -2.0971e-01],\n",
      "         [-4.7454e-02, -2.9657e-01,  3.1056e-01,  ...,  1.5127e+00,\n",
      "           6.2165e-01, -3.0169e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1326, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  hollywood madam\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-2.4296e-02,  1.9469e-01, -9.2838e-02,  ...,  1.7975e-01,\n",
      "           1.8925e-02,  3.5463e-01],\n",
      "         [ 1.5016e-01, -2.5745e-01,  6.4209e-01,  ...,  1.2922e+00,\n",
      "           2.5783e-01, -7.8626e-01],\n",
      "         [-6.1323e-02,  3.4983e-01,  1.8891e-02,  ...,  7.3464e-01,\n",
      "           5.8203e-01,  5.2032e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 781, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  toledo\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 2.5478e-01,  1.7024e-01, -2.7734e-01,  ...,  9.8687e-01,\n",
      "           7.9919e-01, -3.3776e-01],\n",
      "         [ 2.1543e-01, -3.5051e-01,  4.6946e-01,  ...,  2.0889e+00,\n",
      "           3.5547e-01, -3.1629e-01],\n",
      "         [-1.3961e-01, -1.9144e-01,  2.6592e-01,  ...,  1.3405e-01,\n",
      "           2.2680e-01, -1.0751e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1657, 768])\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "answer:  dog\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 9.4278e-02,  2.3806e-01,  1.1683e-03,  ...,  8.0209e-01,\n",
      "           3.1108e-01, -1.2495e-01],\n",
      "         [ 6.0738e-01, -2.9345e-01,  2.4379e-01,  ...,  2.1002e+00,\n",
      "           5.7549e-01, -3.5004e-01],\n",
      "         [ 2.8124e-01, -3.2886e-01,  5.1188e-01,  ...,  2.4840e+00,\n",
      "           7.6951e-01, -4.6802e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0497e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7541e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  avengers\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.3378e-01, -5.0248e-01, -1.9350e-01,  ...,  1.6179e+00,\n",
      "           1.2925e+00, -5.5352e-01],\n",
      "         [ 3.7954e-01, -2.8459e-01,  4.4226e-01,  ...,  1.6803e+00,\n",
      "           9.2095e-01,  1.2753e-02],\n",
      "         [ 3.0918e-01, -9.8315e-02,  4.8618e-01,  ...,  1.1521e+00,\n",
      "           8.5043e-01, -3.9155e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  2415\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-6.3161e-02,  1.2302e-01, -3.2626e-01,  ...,  5.7173e-01,\n",
      "           7.3424e-01, -1.3806e-01],\n",
      "         [ 3.1095e-01, -4.8444e-01,  4.5390e-01,  ...,  1.6602e+00,\n",
      "           2.2902e-01, -4.6244e-01],\n",
      "         [ 1.9028e-02, -2.7656e-01,  4.2519e-01,  ...,  1.4676e+00,\n",
      "           4.5780e-01, -3.1880e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1436, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.3358e-01,  1.2603e-01, -1.7041e-01,  ...,  1.1628e+00,\n",
      "           1.0439e+00, -6.3539e-01],\n",
      "         [ 3.2591e-01, -4.3938e-01,  8.5135e-01,  ...,  1.7763e+00,\n",
      "           3.9721e-01, -3.4001e-01],\n",
      "         [ 2.8321e-01, -3.8667e-01,  4.4398e-01,  ...,  8.9067e-01,\n",
      "           6.2816e-01, -5.6126e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1296, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.0304e+00, -4.6898e-01, -4.9191e-02,  ...,  1.0424e+00,\n",
      "           6.5477e-01, -2.9349e-01],\n",
      "         [-3.0985e-01, -3.0234e-01,  8.0988e-01,  ...,  1.4925e+00,\n",
      "           7.6697e-01, -2.3100e-01],\n",
      "         [ 3.5665e-01, -4.8836e-02,  3.0127e-01,  ...,  8.3892e-01,\n",
      "           6.9741e-01,  4.5254e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 819, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  shane meadows\n",
      "answer:  2006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.5578e-01, -4.7531e-02, -1.1876e-02,  ...,  1.1966e+00,\n",
      "           1.1618e+00, -4.0116e-01],\n",
      "         [ 2.6357e-01, -1.8783e-01,  3.7257e-01,  ...,  2.1038e+00,\n",
      "           3.5924e-01, -4.6624e-02],\n",
      "         [-1.2432e-01, -2.3816e-01,  2.2095e-01,  ...,  1.9408e+00,\n",
      "           5.0257e-01, -1.4682e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1101, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  university of mount union\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.3873e-01,  1.3767e-01, -5.1724e-02,  ...,  1.5762e+00,\n",
      "           1.1412e+00, -6.5209e-01],\n",
      "         [-2.7702e-01, -1.5661e-01,  4.2538e-01,  ...,  1.9151e+00,\n",
      "           3.6589e-01,  2.0023e-02],\n",
      "         [ 4.6645e-01, -2.0414e-02,  4.5043e-01,  ...,  2.2467e+00,\n",
      "           7.6241e-01, -2.7803e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 800, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  magnolia pictures\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.9023e-01, -2.1002e-01,  4.4520e-02,  ...,  1.7342e+00,\n",
      "           1.3665e+00, -5.1715e-01],\n",
      "         [ 4.5368e-01, -2.4704e-01,  2.3303e-01,  ...,  1.8428e+00,\n",
      "           5.0527e-01, -1.1399e-01],\n",
      "         [ 5.7933e-01, -2.3682e-01,  4.1701e-01,  ...,  7.8219e-01,\n",
      "           8.2615e-01, -2.2113e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1192, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1970\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.8949e-01,  2.2743e-01,  3.5688e-01,  ...,  1.7010e+00,\n",
      "           9.0451e-01, -7.2413e-01],\n",
      "         [ 4.9181e-01, -6.5261e-01,  5.5880e-01,  ...,  2.2567e+00,\n",
      "           4.6962e-01, -4.5068e-01],\n",
      "         [ 2.3411e-01, -2.4715e-01,  4.4523e-01,  ...,  1.1988e+00,\n",
      "           4.9731e-01, -3.9994e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1391, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  varazdat samuel varaz samuelian\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.7256e-02,  6.2156e-02,  2.3095e-02,  ...,  1.9271e+00,\n",
      "           8.5274e-01, -7.1901e-01],\n",
      "         [ 3.3486e-01, -8.9652e-02,  5.2032e-01,  ...,  2.2787e+00,\n",
      "           3.7658e-01, -1.4114e-01],\n",
      "         [ 3.9490e-02,  3.5442e-01,  3.7228e-01,  ...,  1.8282e+00,\n",
      "           2.6739e-01, -2.0014e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1290, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  darlington\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.4456e-01,  4.1973e-01,  2.2950e-01,  ...,  7.9804e-01,\n",
      "           2.2314e-01, -3.3611e-01],\n",
      "         [ 3.2794e-01, -3.9417e-01,  5.6172e-01,  ...,  2.2606e+00,\n",
      "           4.2983e-01, -6.0302e-01],\n",
      "         [ 2.4783e-01, -2.2359e-01,  3.9419e-01,  ...,  1.7357e+00,\n",
      "           4.2417e-01, -7.5981e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1229, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  john surtees\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-2.1115e-01,  1.5381e-01,  1.8136e-01,  ...,  7.1412e-01,\n",
      "           4.5206e-01, -3.2205e-01],\n",
      "         [ 3.6767e-01, -4.3584e-01,  3.3413e-01,  ...,  2.0753e+00,\n",
      "           5.3986e-01, -3.9474e-01],\n",
      "         [-3.7808e-01,  1.8785e-01,  7.1711e-01,  ...,  1.2237e+00,\n",
      "           6.3658e-01, -3.7651e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1225, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mary i\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 3.9730e-01,  7.7385e-01, -7.5304e-02,  ...,  1.7634e+00,\n",
      "           1.1614e+00, -1.1448e-01],\n",
      "         [ 5.1123e-01, -4.2843e-04,  3.4971e-01,  ...,  1.9570e+00,\n",
      "           4.2522e-01, -4.0550e-02],\n",
      "         [ 1.0499e-01, -5.6239e-02,  2.7256e-01,  ...,  1.5590e+00,\n",
      "           5.6259e-01, -2.8495e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1699, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  josephine baker\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 5.6680e-01, -1.9437e-01, -3.7169e-01,  ...,  1.2741e+00,\n",
      "           1.0889e+00, -6.0130e-01],\n",
      "         [ 3.9919e-01, -1.0348e-01,  4.1432e-01,  ...,  1.8826e+00,\n",
      "           4.4374e-01, -2.2587e-01],\n",
      "         [ 4.5378e-01, -1.9109e-01,  5.2391e-01,  ...,  1.3241e+00,\n",
      "           9.6178e-01, -3.6750e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1471, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.5382e-02,  2.6558e-01, -1.8690e-01,  ...,  8.4998e-01,\n",
      "           3.0586e-01, -6.2284e-01],\n",
      "         [ 2.5734e-01, -4.7744e-01,  5.3246e-01,  ...,  1.9501e+00,\n",
      "           5.1536e-01, -5.6353e-01],\n",
      "         [ 2.2112e-02, -2.5201e-01,  2.4021e-01,  ...,  1.4537e+00,\n",
      "           6.9235e-01, -4.6856e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1269, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  lost princess of oz\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.5592e-01,  1.8448e-01, -2.0561e-01,  ...,  2.8642e-01,\n",
      "           3.1901e-01, -4.3737e-01],\n",
      "         [ 8.6708e-02,  7.4479e-02,  5.0219e-01,  ...,  2.1700e+00,\n",
      "           3.0407e-01, -3.9763e-01],\n",
      "         [-1.2984e-01,  6.6849e-01,  1.4852e-01,  ...,  8.0591e-01,\n",
      "           4.1747e-01, -4.2206e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1065, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  chihuahua\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.2743e-01, -2.2804e-03, -1.0871e-01,  ...,  1.9131e+00,\n",
      "           1.0277e+00, -1.0201e+00],\n",
      "         [ 5.3249e-01, -3.8220e-01,  3.9335e-01,  ...,  2.1007e+00,\n",
      "           4.4766e-01, -3.5683e-01],\n",
      "         [ 1.2716e-01, -1.0642e-01,  3.0682e-01,  ...,  1.4667e+00,\n",
      "           3.7821e-01, -3.9003e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1367, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "answer:  munster rugby\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 3.1403e-01,  2.7473e-01,  1.3987e-02,  ...,  1.5703e+00,\n",
      "           4.6700e-01, -3.9529e-01],\n",
      "         [-1.4007e-01, -1.4189e-01, -1.4878e-02,  ...,  2.0932e+00,\n",
      "           3.8330e-01, -2.6283e-01],\n",
      "         [-1.3817e-01, -9.2703e-01,  3.7216e-01,  ...,  8.5735e-02,\n",
      "           8.6943e-01, -4.5224e-01],\n",
      "         ...,\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 508, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  july 16 2012\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.6518e-01,  2.7928e-01, -2.3010e-01,  ...,  1.1473e+00,\n",
      "           9.9973e-01, -7.4766e-01],\n",
      "         [ 3.3736e-01, -5.9587e-01,  4.6923e-01,  ...,  2.0700e+00,\n",
      "           3.6964e-01, -3.1683e-01],\n",
      "         [ 1.5032e-01, -2.7275e-01,  3.6673e-01,  ...,  1.5518e+00,\n",
      "           3.0827e-01, -4.6469e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1205, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  ariana grande\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-7.4131e-02,  5.3539e-01, -7.7385e-03,  ...,  1.9469e+00,\n",
      "           4.7257e-01, -3.6099e-01],\n",
      "         [ 3.5562e-01, -9.4136e-02,  1.5281e-01,  ...,  1.9865e+00,\n",
      "           4.2454e-01, -5.2520e-01],\n",
      "         [-4.5633e-02,  1.5467e-01, -1.9626e-01,  ...,  1.2309e+00,\n",
      "           9.3832e-01, -7.0646e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1480, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  barry hearn\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.0391e-01, -9.7661e-02,  1.7518e-01,  ...,  1.2006e+00,\n",
      "           6.2361e-01, -7.0683e-01],\n",
      "         [-1.3513e-01, -2.6641e-01,  6.2878e-01,  ...,  1.6665e+00,\n",
      "           2.6409e-01, -1.8399e-01],\n",
      "         [-2.8850e-02, -2.1501e-02,  3.8612e-01,  ...,  1.4106e+00,\n",
      "           4.5801e-01, -3.3592e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1103, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  wandsworth town wandsworth london england\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.6572e-01,  3.0135e-01,  1.0531e-01,  ...,  9.3146e-01,\n",
      "           5.1822e-01, -4.5353e-01],\n",
      "         [ 3.6802e-01, -2.5565e-01,  4.1470e-01,  ...,  1.8084e+00,\n",
      "           2.3831e-01, -2.8580e-01],\n",
      "         [-1.8086e-01,  4.4225e-01,  2.3653e-01,  ...,  1.0550e+00,\n",
      "           4.2108e-01,  1.0845e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1233, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 2.4241e-01,  2.6561e-01, -3.4274e-01,  ...,  6.1217e-01,\n",
      "           9.2520e-01,  1.6695e-01],\n",
      "         [-4.4910e-01,  7.2923e-01,  1.4994e-01,  ...,  1.7243e+00,\n",
      "           2.5048e-01, -9.0566e-02],\n",
      "         [ 1.0647e-01,  1.6470e-01,  3.9853e-02,  ...,  7.5068e-01,\n",
      "           2.4166e-01, -3.6777e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.1903e-01,  8.6584e-02,  6.8907e-01,  ...,  1.4872e+00,\n",
      "           9.4423e-01, -3.9364e-01],\n",
      "         [ 2.8687e-01, -2.0956e-01,  7.4331e-01,  ...,  2.1772e+00,\n",
      "           5.1549e-01, -1.1218e-01],\n",
      "         [ 2.0720e-01,  2.0322e-01,  3.5484e-01,  ...,  6.1822e-02,\n",
      "           2.4615e-01, -1.6134e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 992, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  goalkeeper\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.8262e-01,  2.3088e-01,  3.5672e-01,  ...,  1.4268e+00,\n",
      "           6.1499e-01, -3.2304e-01],\n",
      "         [ 4.4063e-01, -3.0311e-01,  5.4019e-01,  ...,  2.2608e+00,\n",
      "           4.8338e-01, -2.6330e-01],\n",
      "         [ 5.1788e-01,  7.0099e-01,  2.5742e-01,  ...,  1.1392e+00,\n",
      "           3.2745e-01, -3.7744e-02],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1393, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  christmas\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  szombathelyi haladás\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-2.7290e-01,  3.8575e-01,  1.5126e-02,  ...,  1.0338e+00,\n",
      "           3.2483e-01,  1.0454e-01],\n",
      "         [-7.2214e-01, -1.2168e-02,  5.6574e-01,  ...,  1.2897e+00,\n",
      "           2.7939e-02, -6.6053e-01],\n",
      "         [-1.5036e-01, -3.6920e-01,  4.2181e-01,  ...,  6.0600e-01,\n",
      "           4.0917e-01, -3.4312e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 656, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  ring\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 6.9467e-01,  1.4150e-01, -9.5886e-02,  ...,  1.7616e+00,\n",
      "           1.3122e+00, -3.8852e-01],\n",
      "         [ 3.4354e-01, -1.6776e-01,  4.6840e-01,  ...,  1.9151e+00,\n",
      "           5.8496e-01, -3.6283e-01],\n",
      "         [-5.8938e-02, -1.1382e-01,  5.9027e-01,  ...,  1.2378e+00,\n",
      "           7.5509e-01, -4.5894e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1336, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.1744e-01,  5.4916e-01,  1.2116e-01,  ...,  7.4815e-01,\n",
      "           9.4148e-01, -2.4539e-01],\n",
      "         [ 4.3647e-01, -4.7826e-01,  4.2685e-01,  ...,  2.1446e+00,\n",
      "           4.5940e-01, -2.0538e-01],\n",
      "         [ 3.2336e-01, -4.1653e-01,  4.3762e-01,  ...,  1.5110e+00,\n",
      "           7.0443e-01, -4.1328e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1213, 768])\n",
      "answer:  son of ulf jarl\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  buddleja\n",
      "self.tokenizer.sep_token:  </s>\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 4.5514e-01, -7.7997e-02, -2.8946e-01,  ...,  5.7392e-01,\n",
      "           8.1237e-01, -2.3342e-01],\n",
      "         [ 3.3130e-01, -2.5018e-01,  3.0445e-01,  ...,  1.7788e+00,\n",
      "           3.3465e-01, -1.3010e-01],\n",
      "         [ 2.2567e-01,  2.9248e-01, -1.6414e-02,  ...,  1.1038e+00,\n",
      "           5.2996e-01, -4.1933e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2001\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 1.7298e-01, -2.5635e-01,  2.7738e-01,  ...,  1.7856e+00,\n",
      "           1.1890e+00,  2.2186e-01],\n",
      "         [-9.1545e-04, -4.0648e-01, -2.2836e-01,  ...,  1.8530e+00,\n",
      "           7.6849e-01,  5.2001e-02],\n",
      "         [-7.6837e-02, -1.0268e+00,  7.8348e-02,  ...,  7.0815e-01,\n",
      "           8.4452e-01, -5.9143e-02],\n",
      "         ...,\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 457, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  fur\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 1.3725e-01, -7.1662e-02, -1.0664e-01,  ...,  1.0641e+00,\n",
      "           1.3437e+00, -4.2876e-01],\n",
      "         [-4.5175e-01,  4.2031e-01,  6.5162e-01,  ...,  1.2419e+00,\n",
      "           6.8713e-01, -3.0332e-01],\n",
      "         [ 2.6171e-01,  3.8957e-01,  1.0930e-01,  ...,  6.5748e-01,\n",
      "           8.2656e-02, -5.7811e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 570, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "answer:  no\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 5.6646e-01, -4.2082e-02, -3.5530e-01,  ...,  1.3773e+00,\n",
      "           1.0771e+00, -3.8541e-01],\n",
      "         [ 5.9976e-01, -3.2374e-01,  2.0673e-01,  ...,  1.8008e+00,\n",
      "           4.8476e-01, -5.3276e-01],\n",
      "         [ 2.8198e-01, -9.4696e-02,  1.6645e-01,  ...,  1.4862e+00,\n",
      "           4.8437e-01, -4.5273e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1597, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  19th\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-8.7277e-03, -4.2221e-02, -3.0134e-01,  ...,  6.0228e-01,\n",
      "           3.1191e-01, -2.4622e-01],\n",
      "         [ 6.0138e-01, -2.4495e-01,  3.7904e-01,  ...,  2.2778e+00,\n",
      "           4.6330e-01, -3.5248e-01],\n",
      "         [-5.4290e-02,  5.1291e-01, -5.2593e-02,  ...,  1.1347e+00,\n",
      "          -2.7801e-02, -3.3081e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1236, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "answer:  1962\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-1.1966e-01,  5.9825e-01, -1.5095e-02,  ...,  3.9604e-01,\n",
      "           5.8016e-01, -3.4536e-01],\n",
      "         [ 3.9461e-01, -3.7919e-01,  3.7346e-01,  ...,  1.7048e+00,\n",
      "           4.3132e-01, -5.7651e-01],\n",
      "         [ 1.0527e-01,  4.0104e-01, -1.0533e-02,  ..., -9.4881e-01,\n",
      "           1.1066e-01, -3.8050e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1167, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[-9.2955e-02,  2.6992e-01,  7.8628e-02,  ...,  1.0739e+00,\n",
      "           1.1773e+00, -4.2382e-01],\n",
      "         [ 2.2504e-01, -3.6285e-01,  3.9936e-01,  ...,  1.9561e+00,\n",
      "           2.2305e-01, -5.4020e-01],\n",
      "         [ 1.1391e-01,  2.4561e-02,  6.4177e-01,  ...,  1.9644e+00,\n",
      "           6.4460e-01, -2.2831e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1176, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 1.9977e-02,  2.2706e-01,  8.1088e-02,  ...,  1.3812e+00,\n",
      "           5.6507e-01, -1.9139e-01],\n",
      "         [-4.6589e-01,  3.1808e-01,  8.0837e-01,  ...,  1.2226e+00,\n",
      "           2.8616e-01, -3.6811e-01],\n",
      "         [ 3.3312e-01,  4.2245e-01,  5.6109e-02,  ...,  2.0793e-01,\n",
      "           1.3103e-01, -3.0385e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1457, 768])\n",
      "size of input_ids: torch.Size([1, 512])\n",
      "size of sequence_output: torch.Size([1, 512, 768])\n",
      "sequence_output  tensor([[[ 1.5437e-01,  1.3683e-01,  1.2137e-01,  ...,  1.1172e+00,\n",
      "           3.1697e-01, -4.6267e-01],\n",
      "         [-3.9385e-01, -5.2099e-01,  2.4351e-01,  ...,  2.1544e+00,\n",
      "          -8.6612e-03, -6.0165e-01],\n",
      "         [-3.6505e-02, -6.8815e-01,  4.3394e-01,  ...,  7.4713e-01,\n",
      "           5.4102e-01, -3.6621e-01],\n",
      "         ...,\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1995e-02,  7.7738e-02, -4.0493e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 392, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 2.6801e-01,  4.3415e-01, -1.8222e-01,  ...,  8.2570e-01,\n",
      "           6.2362e-01, -6.2555e-02],\n",
      "         [ 3.5628e-01, -2.9623e-01,  5.4804e-01,  ...,  1.9588e+00,\n",
      "           4.3130e-01, -4.8128e-01],\n",
      "         [ 5.2636e-01,  3.8602e-01,  2.3157e-01,  ...,  2.1025e-01,\n",
      "           6.6262e-01, -3.3205e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1141, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 9.5079e-02, -1.2471e-01,  3.2284e-01,  ...,  1.0165e+00,\n",
      "           9.7670e-01, -7.9531e-02],\n",
      "         [ 1.8594e-01, -2.8081e-01,  5.2926e-01,  ...,  2.0235e+00,\n",
      "           3.4915e-01, -2.4106e-01],\n",
      "         [-1.4341e-01,  1.3538e-01,  2.7861e-01,  ...,  1.0315e-01,\n",
      "           2.1519e-01, -3.9846e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1116, 768])\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[ 5.5028e-01,  1.5098e-02,  1.9388e-02,  ...,  7.3744e-01,\n",
      "           5.4773e-01, -1.9681e-01],\n",
      "         [-7.6853e-02, -4.9146e-01,  4.0839e-01,  ...,  1.2982e+00,\n",
      "           1.0020e+00, -5.5861e-02],\n",
      "         [ 6.2689e-01, -3.9830e-01,  3.1276e-01,  ...,  8.2242e-01,\n",
      "           9.3776e-01, -3.3810e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0507e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 808, 768])\n",
      "size of input_ids: torch.Size([1, 2048])\n",
      "size of sequence_output: torch.Size([1, 2048, 768])\n",
      "sequence_output  tensor([[[ 4.9496e-01,  1.0994e-01,  6.7140e-02,  ...,  1.6104e+00,\n",
      "           9.1060e-01, -6.2231e-01],\n",
      "         [ 3.6862e-01, -3.1093e-01,  4.5319e-01,  ...,  2.5868e+00,\n",
      "           4.8964e-01, -7.7866e-02],\n",
      "         [-1.0354e-01,  7.6914e-02,  2.8106e-01,  ...,  1.4468e+00,\n",
      "           4.2816e-01, -3.6223e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0490e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1632, 768])\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 3.7624e-01, -8.1750e-02, -1.5902e-01,  ...,  1.8679e+00,\n",
      "           1.0362e+00, -5.7451e-01],\n",
      "         [ 4.9611e-01, -2.8711e-01,  3.7427e-01,  ...,  2.2744e+00,\n",
      "           5.1317e-01, -2.7655e-01],\n",
      "         [ 5.2773e-01, -1.5491e-01,  4.0883e-01,  ...,  1.5707e+00,\n",
      "           7.2472e-01, -4.2878e-01],\n",
      "         ...,\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02],\n",
      "         [-1.1996e-02,  7.7738e-02, -4.0489e-04,  ..., -7.5476e-02,\n",
      "          -3.0758e-02, -8.7542e-02]]], device='cuda:0')\n",
      "size of sequence_output after removing padding: torch.Size([1, 1242, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned 0.10302699894844732 must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of avg_val_f1 in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch 00004: avg_val_f1 reached 0.10303 (best 0.10303), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_4.ckpt as top 5\n",
      "\n",
      "Epoch 00004: avg_val_f1 reached 0.10303 (best 0.10303), saving model to /xdisk/msurdeanu/fanluo/hotpotQA/Data/jupyter-hotpotqa/hotpotqa-longformer_jupyter/_ckpt_epoch_4.ckpt as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_end\n",
      "before sync --> sizes:  79, 79, 79\n",
      "after sync --> sizes: 79, 79, 79\n",
      "avg_loss:  tensor(13.1980, device='cuda:0')\tavg_answer_loss:  tensor(5.0585, device='cuda:0')\tavg_type_loss:  tensor(0.1420, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5090, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.2339, device='cuda:0')\n",
      "avg_val_f1:  0.10302699894844732\tavg_val_em:  0.05063291139240506\tavg_val_prec:  0.0959462461686587\tavg_val_recall:  0.16962025324000587\n",
      "avg_val_sp_sent_f1:  0.0750251165296458\tavg_val_sp_sent_em:  0.012658227848101266\tavg_val_sp_sent_prec:  0.06962025373042384\tavg_val_sp_sent_recall:  0.08438818628274941\n",
      "avg_val_joint_f1:  0.024532501974815053\tavg_val_joint_em:  0.012658227848101266\tavg_val_joint_prec:  0.021057560026079794\tavg_val_joint_recall:  0.04092827014908006\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  inside men\n",
      "self.tokenizer.sep_token:  </s>\n",
      "answer:  1976 to 2009\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  mark daniel ronson\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1024])\n",
      "answer:  amélie simone mauresmo born 5 july 1979 is french former professional tennis player and former world no 1 mauresmo won two grand slam singles titles at australian open and at wimbledon and also won silver medal at 2004 summer olympics\n",
      "answer:  lorax\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  2415\n",
      "answer:  essex\n",
      "size of sequence_output: torch.Size([1, 1024, 768])\n",
      "sequence_output  tensor([[[-1.6972e-01,  3.9349e-01, -3.0833e-01,  ...,  5.2735e-01,\n",
      "           1.1318e+00,  1.0421e-01],\n",
      "         [-3.8376e-01, -1.5592e-01,  7.2065e-02,  ...,  2.4093e+00,\n",
      "           4.6870e-01, -3.8607e-01],\n",
      "         [ 2.3044e-01,  2.4818e-01, -2.1593e-01,  ...,  1.2018e+00,\n",
      "          -4.4376e-02, -2.7210e-01],\n",
      "         ...,\n",
      "         [-6.2527e-03,  6.8859e-02, -6.1430e-06,  ..., -8.9973e-02,\n",
      "          -2.6774e-02, -7.4597e-02],\n",
      "         [ 5.0700e-03,  7.8757e-02,  3.5003e-03,  ..., -7.6503e-02,\n",
      "          -3.1417e-02, -8.6045e-02],\n",
      "         [-1.0307e-02,  7.5250e-02, -1.3774e-02,  ..., -1.0600e-01,\n",
      "          -2.3847e-02, -8.9610e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 785, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  transcendentalist\n",
      "answer:  szombathelyi haladás\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  1970\n",
      "answer:  buddleja\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1581,  0.0379, -0.2165,  ...,  0.6083,  1.1037, -0.0909],\n",
      "         [-0.0652,  0.0873,  0.5160,  ...,  2.0246,  0.5834,  0.0576],\n",
      "         [ 0.1888,  0.4392,  0.0154,  ...,  1.1220,  0.6489,  0.0672],\n",
      "         ...,\n",
      "         [ 0.0117,  0.0532,  0.0040,  ..., -0.0729, -0.0104, -0.0614],\n",
      "         [-0.0188,  0.0705,  0.0074,  ..., -0.0657, -0.0288, -0.0865],\n",
      "         [-0.0759,  0.6515,  0.1816,  ...,  0.1585,  0.2337, -0.1912]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1064, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  atom egoyan\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.1943, -0.5365,  0.1293,  ...,  2.1342,  1.3900, -0.4716],\n",
      "         [ 0.2384, -0.1365,  0.4445,  ...,  0.8428,  1.2300, -0.3556],\n",
      "         [ 0.1806,  0.1537,  0.3577,  ...,  0.0162,  0.5099,  0.2759],\n",
      "         ...,\n",
      "         [-0.0233,  0.1735,  0.0411,  ..., -0.0395, -0.0440, -0.1787],\n",
      "         [-0.0058,  0.1750,  0.0814,  ..., -0.0847, -0.0533, -0.2356],\n",
      "         [-0.0598,  0.1250,  0.0208,  ..., -0.0242, -0.0098,  0.0156]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1025, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "answer:  farinelli\n",
      "size of input_ids: torch.Size([1, 2560])\n",
      "size of sequence_output: torch.Size([1, 2560, 768])\n",
      "sequence_output  tensor([[[ 2.5295e-01,  4.9743e-01, -1.0449e-01,  ...,  2.8595e-03,\n",
      "           5.0493e-01, -1.9250e-01],\n",
      "         [ 6.7729e-01, -2.5343e-01,  1.6201e-01,  ...,  1.8969e+00,\n",
      "           8.3795e-01, -7.8136e-01],\n",
      "         [ 2.9287e-01, -9.2158e-02,  6.5133e-01,  ...,  2.1445e+00,\n",
      "           8.7010e-01, -4.8837e-01],\n",
      "         ...,\n",
      "         [ 9.0784e-02,  9.1647e-02, -1.6532e-01,  ...,  2.5251e-01,\n",
      "           3.7523e-02, -4.0187e-01],\n",
      "         [-3.4235e-04,  6.5577e-02, -4.0629e-04,  ..., -8.6663e-02,\n",
      "          -1.6617e-02, -6.0055e-02],\n",
      "         [-1.1676e-02,  7.3993e-02, -1.0849e-03,  ..., -1.1366e-01,\n",
      "          -2.4726e-02, -8.6972e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 2396, 768])\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n",
      "size of input_ids: torch.Size([1, 1536])\n",
      "size of sequence_output: torch.Size([1, 1536, 768])\n",
      "sequence_output  tensor([[[ 0.4241,  0.0631,  0.1620,  ...,  1.5212,  1.1824, -0.6066],\n",
      "         [ 0.1706, -0.6063,  0.3974,  ...,  2.1256,  0.7686, -0.1550],\n",
      "         [ 0.2809, -0.1006,  0.1443,  ...,  1.2561,  0.4143, -0.3290],\n",
      "         ...,\n",
      "         [ 0.0358,  0.1499,  0.0120,  ..., -0.1733,  0.0468, -0.0645],\n",
      "         [ 0.1093,  0.2269,  0.0791,  ..., -0.2378,  0.0154, -0.3241],\n",
      "         [-0.0135,  0.0703,  0.0082,  ..., -0.0719, -0.0283,  0.0151]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n",
      "size of sequence_output after removing padding: torch.Size([1, 1152, 768])\n",
      "answer:  1905\n",
      "self.tokenizer.sep_token:  </s>\n",
      "self.tokenizer.sep_token == '</s>':  True\n"
     ]
    }
   ],
   "source": [
    "#     if not args.test: \n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "### To install apex ### \n",
    "#     !git clone https://github.com/NVIDIA/apex\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/apex/\")\n",
    "#     !module load cuda101/neuralnet/7/7.6.4  \n",
    "#     !module load cuda10.1/toolkit/10.1.243 \n",
    "#     !conda install -c conda-forge cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf201901 cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf202003 cudatoolkit-dev --yes\n",
    "#     !which nvcc\n",
    "#     !python -m pip install -v --no-cache-dir ./\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('save_dir', 'jupyter-hotpotqa')\n",
      "('save_prefix', 'hotpotqa-longformer_jupyter')\n",
      "('train_dataset', 'small.json')\n",
      "('dev_dataset', 'small.json')\n",
      "('batch_size', 2)\n",
      "('gpus', '0')\n",
      "('warmup', 1000)\n",
      "('lr', 5e-05)\n",
      "('val_every', 1.0)\n",
      "('val_percent_check', 1.0)\n",
      "('num_workers', 4)\n",
      "('seed', 1234)\n",
      "('epochs', 6)\n",
      "('max_seq_len', 4096)\n",
      "('max_doc_len', 4096)\n",
      "('max_num_answers', 64)\n",
      "('max_question_len', 55)\n",
      "('doc_stride', -1)\n",
      "('ignore_seq_with_no_answers', False)\n",
      "('disable_checkpointing', False)\n",
      "('n_best_size', 20)\n",
      "('max_answer_length', 30)\n",
      "('regular_softmax_loss', False)\n",
      "('test', False)\n",
      "('model_path', '/xdisk/msurdeanu/fanluo/hotpotQA/longformer-base-4096')\n",
      "('no_progress_bar', False)\n",
      "('attention_mode', 'sliding_chunks')\n",
      "('fp32', False)\n",
      "('train_percent', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# debug: check args\n",
    "import shlex\n",
    "argString ='--train_dataset small.json --dev_dataset small.json  \\\n",
    "    --gpus 0 --num_workers 4 \\\n",
    "    --max_seq_len 4096 --doc_stride -1  \\\n",
    "    --save_prefix hotpotqa-longformer_jupyter  --model_path /xdisk/msurdeanu/fanluo/hotpotQA/longformer-base-4096'\n",
    "# hotpot_dev_distractor_v1.json\n",
    "\n",
    "import argparse \n",
    "if __name__ == \"__main__\":\n",
    "    main_arg_parser = argparse.ArgumentParser(description=\"hotpotqa\")\n",
    "    parser = hotpotqa.add_model_specific_args(main_arg_parser, os.getcwd())\n",
    "    args = parser.parse_args(shlex.split(argString)) \n",
    "    for arg in vars(args):\n",
    "        print((arg, getattr(args, arg)))\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "config = LongformerConfig.from_pretrained('/xdisk/msurdeanu/fanluo/hotpotQA/longformer-base-4096') \n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Longformer.from_pretrained('/xdisk/msurdeanu/fanluo/hotpotQA/longformer-base-4096', config=config)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TEXT = ' '.join(['Hello world! '] * 1000)  # long input document\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(SAMPLE_TEXT)).unsqueeze(0)  # batch of size 1\n",
    "\n",
    "# TVM code doesn't work on CPU. Uncomment this if `config.attention_mode = 'tvm'`\n",
    "model = model.cuda() \n",
    "input_ids = input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device) # initialize to local attention\n",
    "attention_mask[:, [1, 4, 21,]] =  2  # Set global attention based on the task. For example,\n",
    "                                     # classification: the <s> token\n",
    "                                     # QA: question tokens\n",
    "\n",
    "# padding seqlen to the nearest multiple of 512. Needed for the 'sliding_chunks' attention\n",
    "input_ids, attention_mask = pad_to_window_size(\n",
    "        input_ids, attention_mask, config.attention_window[0], tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotpotqa",
   "language": "python",
   "name": "hotpotqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "593px",
    "left": "1926px",
    "right": "20px",
    "top": "158px",
    "width": "612px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
