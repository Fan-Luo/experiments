{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert hotpotqa to squard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Longformer: use the following input format with special tokens:  “[CLS] [q] question [/q] [p] sent1,1 [s] sent1,2 [s] ... [p] sent2,1 [s] sent2,2 [s] ...” \n",
    "where [s] and [p] are special tokens representing sentences and paragraphs. The special tokens were added to the RoBERTa vocabulary and randomly initialized before task finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to convert hotpotqa to squard format modified from  https://github.com/chiayewken/bert-qa/blob/master/run_hotpot.py\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def create_example_dict(context, answers, id, is_impossible, question, is_sup_fact, is_supporting_para):\n",
    "    return {\n",
    "        \"context\": context,\n",
    "        \"qas\": [                        # each context corresponds to only one qa in hotpotqa\n",
    "            {\n",
    "                \"answers\": answers,\n",
    "                \"id\": id,\n",
    "                \"is_impossible\": is_impossible,\n",
    "                \"question\": question,\n",
    "                \"is_sup_fact\": is_sup_fact,\n",
    "                \"is_supporting_para\": is_supporting_para\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def create_para_dict(example_dicts):\n",
    "    if type(example_dicts) == dict:\n",
    "        example_dicts = [example_dicts]   # each paragraph corresponds to only one [context, qas] in hotpotqa\n",
    "    return {\"paragraphs\": example_dicts}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_hotpot_to_squad_format(json_dict, gold_paras_only=False):\n",
    "    \n",
    "    \"\"\"function to convert hotpotqa to squard format.\n",
    "\n",
    "\n",
    "    Note: A context corresponds to several qas in SQuard. In hotpotqa, one question corresponds to several paragraphs as context. \n",
    "          \"paragraphs\" means different: each paragraph in SQuard contains a context and a list of qas; while 10 paragraphs in hotpotqa concatenated into a context for one question.\n",
    "\n",
    "    Args:\n",
    "        json_dict: The original data load from hotpotqa file.\n",
    "        gold_paras_only: when is true, only use the 2 paragraphs that contain the gold supporting facts; if false, use all the 10 paragraphs\n",
    " \n",
    "\n",
    "    Returns:\n",
    "        new_dict: The converted dict of hotpotqa dataset, use it as a dict would load from SQuAD json file\n",
    "                  usage: input_data = new_dict[\"data\"]   https://github.com/google-research/bert/blob/eedf5716ce1268e56f0a50264a88cafad334ac61/run_squad.py#L230\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_dict = {\"data\": []} \n",
    "    for example in json_dict: \n",
    "\n",
    "        support_para = set(\n",
    "            para_title for para_title, _ in example[\"supporting_facts\"]\n",
    "        )\n",
    "        sp_set = set(list(map(tuple, example['supporting_facts'])))\n",
    "        \n",
    "        raw_contexts = example[\"context\"]\n",
    "        if gold_paras_only: \n",
    "            raw_contexts = [lst for lst in raw_contexts if lst[0] in support_para]\n",
    "            \n",
    "        contexts = [\" <s> \".join(lst[1]) for lst in raw_contexts]    # extra space is fine, which would be ignored latter. most sentences has already have heading space, there are several no heading space \n",
    "        context = \" <p> \" + \" <p> \".join(contexts)\n",
    "        \n",
    "        is_supporting_para = []  # a boolean list with 10 True/False elements, one for each paragraph\n",
    "        is_sup_fact = []         # a boolean list with True/False elements, one for each context sentence\n",
    "        for para_title, para_lines in raw_contexts:\n",
    "            is_supporting_para.append(para_title in support_para)   \n",
    "            for sent_id, sent in enumerate(para_lines):\n",
    "                is_sup_fact.append( (para_title, sent_id) in sp_set )\n",
    "\n",
    "\n",
    "        answer = example[\"answer\"].strip() \n",
    "        if answer.lower() == 'yes':\n",
    "            answers = [{\"answer_start\": -1, \"answer_end\": -1, \"text\": answer}] \n",
    "        elif answer.lower() == 'no':\n",
    "            answers = [{\"answer_start\": -2, \"answer_end\": -2, \"text\": answer}] \n",
    "        else:\n",
    "            answers = []          # keep all the occurences of answer in the context\n",
    "            for m in re.finditer(re.escape(answer), context):    \n",
    "                answer_start, answer_end = m.span() \n",
    "                answers.append({\"answer_start\": answer_start, \"answer_end\": answer_end, \"text\": answer})\n",
    "             \n",
    "        if(len(answers) > 0): \n",
    "            new_dict[\"data\"].append(\n",
    "                create_para_dict(\n",
    "                    create_example_dict(\n",
    "                        context=context,\n",
    "                        answers=answers,\n",
    "                        id = example[\"_id\"],\n",
    "                        is_impossible=(answers == []),\n",
    "                        question=example[\"question\"],\n",
    "                        is_sup_fact = is_sup_fact,\n",
    "                        is_supporting_para = is_supporting_para \n",
    "                    )\n",
    "                )\n",
    "            ) \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"context\": \" <p> Radio City is India's first private FM radio station and was started on 3 July 2001. <s>  It broadcasts on 91.1 (earlier 91.0 in most cities) megahertz from Mumbai (where it was started in 2004), Bengaluru (started first in 2001), Lucknow and New Delhi (since 2003). <s>  It plays Hindi, English and regional songs. <s>  It was launched in Hyderabad in March 2006, in Chennai on 7 July 2006 and in Visakhapatnam October 2007. <s>  Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features. <s>  The Radio station currently plays a mix of Hindi and Regional music. <s>  Abraham Thomas is the CEO of the company. <p> Football in Albania existed before the Albanian Football Federation (FSHF) was created. <s>  This was evidenced by the team's registration at the Balkan Cup tournament during 1929-1931, which started in 1929 (although Albania eventually had pressure from the teams because of competition, competition started first and was strong enough in the duels) . <s>  Albanian National Team was founded on June 6, 1930, but Albania had to wait 16 years to play its first international match and then defeated Yugoslavia in 1946. <s>  In 1932, Albania joined FIFA (during the 12\\u201316 June convention ) And in 1954 she was one of the founding members of UEFA. <p> Echosmith is an American, Corporate indie pop band formed in February 2009 in Chino, California. <s>  Originally formed as a quartet of siblings, the band currently consists of Sydney, Noah and Graham Sierota, following the departure of eldest sibling Jamie in late 2016. <s>  Echosmith started first as \\\"Ready Set Go!\\\" <s>  until they signed to Warner Bros. <s>  Records in May 2012. <s>  They are best known for their hit song \\\"Cool Kids\\\", which reached number 13 on the \\\"Billboard\\\" Hot 100 and was certified double platinum by the RIAA with over 1,200,000 sales in the United States and also double platinum by ARIA in Australia. <s>  The song was Warner Bros. <s>  Records' fifth-biggest-selling-digital song of 2014, with 1.3 million downloads sold. <s>  The band's debut album, \\\"Talking Dreams\\\", was released on October 8, 2013. <p> Women's colleges in the Southern United States refers to undergraduate, bachelor's degree\\u2013granting institutions, often liberal arts colleges, whose student populations consist exclusively or almost exclusively of women, located in the Southern United States. <s>  Many started first as girls' seminaries or academies. <s>  Salem College is the oldest female educational institution in the South and Wesleyan College is the first that was established specifically as a college for women. <s>  Some schools, such as Mary Baldwin University and Salem College, offer coeducational courses at the graduate level. <p> The First Arthur County Courthouse and Jail, was perhaps the smallest court house in the United States, and serves now as a museum. <p> Arthur's Magazine (1844\\u20131846) was an American literary periodical published in Philadelphia in the 19th century. <s>  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others. <s>  In May 1846 it was merged into \\\"Godey's Lady's Book\\\". <p> The 2014\\u201315 Ukrainian Hockey Championship was the 23rd season of the Ukrainian Hockey Championship. <s>  Only four teams participated in the league this season, because of the instability in Ukraine and that most of the clubs had economical issues. <s>  Generals Kiev was the only team that participated in the league the previous season, and the season started first after the year-end of 2014. <s>  The regular season included just 12 rounds, where all the teams went to the semifinals. <s>  In the final, ATEK Kiev defeated the regular season winner HK Kremenchuk. <p> First for Women is a woman's magazine published by Bauer Media Group in the USA. <s>  The magazine was started in 1989. <s>  It is based in Englewood Cliffs, New Jersey. <s>  In 2011 the circulation of the magazine was 1,310,696 copies. <p> The Freeway Complex Fire was a 2008 wildfire in the Santa Ana Canyon area of Orange County, California. <s>  The fire started as two separate fires on November 15, 2008. <s>  The \\\"Freeway Fire\\\" started first shortly after 9am with the \\\"Landfill Fire\\\" igniting approximately 2 hours later. <s>  These two separate fires merged a day later and ultimately destroyed 314 residences in Anaheim Hills and Yorba Linda. <p> William Rast is an American clothing line founded by Justin Timberlake and Trace Ayala. <s>  It is most known for their premium jeans. <s>  On October 17, 2006, Justin Timberlake and Trace Ayala put on their first fashion show to launch their new William Rast clothing line. <s>  The label also produces other clothing items such as jackets and tops. <s>  The company started first as a denim line, later evolving into a men\\u2019s and women\\u2019s clothing line.\",\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"answer_start\": 2990,\n",
      "              \"answer_end\": 3007,\n",
      "              \"text\": \"Arthur's Magazine\"\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5a7a06935542990198eaf050\",\n",
      "          \"is_impossible\": false,\n",
      "          \"question\": \"Which magazine was started first Arthur's Magazine or First for Women?\",\n",
      "          \"is_sup_fact\": [\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false\n",
      "          ],\n",
      "          \"is_supporting_para\": [\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            true,\n",
      "            false,\n",
      "            false\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# debug: check whether convert_hotpot_to_squad_format() works\n",
    "import os\n",
    "os.chdir('/xdisk/msurdeanu/fanluo/hotpotQA/')\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/hotpot_train_v1.1.json | ../jq-linux64 -c '.[0:16]' > small.json\n",
    "#!cat /xdisk/msurdeanu/fanluo/hotpotQA/hotpot_train_v1.1.json | ../jq-linux64 -c '.[17:30]' > small_dev.json\n",
    "\n",
    "import json\n",
    "with open(\"small.json\", \"r\", encoding='utf-8') as f:  \n",
    "    json_dict = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "    print(json.dumps(json_dict[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### longfomer's fine-tuning\n",
    "\n",
    "\n",
    "- For answer span extraction we use BERT’s QA model with addition of a question type (yes/no/span) classification head over the first special token ([CLS]).\n",
    "\n",
    "- For evidence extraction we apply 2 layer feedforward networks on top of the representations corresponding to sentence and paragraph tokens to get the corresponding evidence prediction scores and use binary cross entropy loss to train the model.\n",
    "\n",
    "- We combine span, question classification, sentence, and paragraphs losses and train the model in a multitask way using linear combination of losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Section2: This is modified from longfomer's fine-tuning with triviaqa.py from https://github.com/allenai/longformer/blob/master/scripts/triviaqa.py\n",
    "# !conda install transformers --yes\n",
    "# !conda install cudatoolkit=10.0 --yes\n",
    "# !python -m pip install git+https://github.com/allenai/longformer.git\n",
    "####requirements.txt:torch>=1.2.0, transformers>=3.0.2, tensorboardX, pytorch-lightning==0.6.0, test-tube==0.7.5\n",
    "# !conda install -c conda-forge regex --force-reinstall --yes\n",
    "# !conda install pytorch-lightning -c conda-forge\n",
    "# !pip install jdc \n",
    "# !pip install test-tube \n",
    "# !conda install ipywidgets --yes\n",
    "# !conda update --force conda --yes  \n",
    "# !jupyter nbextension enable --py widgetsnbextension \n",
    "# !conda install jupyter --yes\n",
    "\n",
    "# need to run this every time start this notebook, to add python3.7/site-packages to sys.pat, in order to import ipywidgets, which is used when RobertaTokenizer.from_pretrained('roberta-base') \n",
    "import sys\n",
    "sys.path.insert(-1, '/xdisk/msurdeanu/fanluo/miniconda3/lib/python3.7/site-packages')\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.overrides.data_parallel import LightningDistributedDataParallel\n",
    "from pytorch_lightning.logging import TestTubeLogger    # sometimes pytorch_lightning.loggers works instead\n",
    "\n",
    "\n",
    "from longformer.longformer import Longformer\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "import jdc\n",
    "from more_itertools import locate\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqaDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_, \\_\\_getitem\\_\\_ and \\_\\_len\\_\\_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hotpotqaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Largely based on\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
    "    and\n",
    "    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride,\n",
    "                 max_num_answers, ignore_seq_with_no_answers, max_question_len):\n",
    "        assert os.path.isfile(file_path)\n",
    "        self.file_path = file_path\n",
    "        with open(self.file_path, \"r\", encoding='utf-8') as f:\n",
    "            print(f'reading file: {self.file_path}')\n",
    "            self.data_json = convert_hotpot_to_squad_format(json.load(f))['data']\n",
    "#             print(self.data_json[0])\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_doc_len = max_doc_len\n",
    "        self.doc_stride = doc_stride\n",
    "        self.max_num_answers = max_num_answers\n",
    "        self.ignore_seq_with_no_answers = ignore_seq_with_no_answers\n",
    "        self.max_question_len = max_question_len\n",
    "\n",
    "        print(tokenizer.all_special_tokens)\n",
    "        print(tokenizer.all_special_ids)\n",
    "    \n",
    "        # A mapping from qid to an int, which can be synched across gpus using `torch.distributed`\n",
    "        if 'train' not in self.file_path:  # only for the evaluation set \n",
    "            self.val_qid_string_to_int_map =  \\\n",
    "                {\n",
    "                    entry[\"paragraphs\"][0]['qas'][0]['id']: index\n",
    "                    for index, entry in enumerate(self.data_json)\n",
    "                }\n",
    "        else:\n",
    "            self.val_qid_string_to_int_map = None\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_json)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data_json[idx]\n",
    "        tensors_list = self.one_example_to_tensors(entry, idx)\n",
    "        assert len(tensors_list) == 1\n",
    "        return tensors_list[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### one_example_to_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     106,
     122,
     147,
     162
    ]
   },
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    def one_example_to_tensors(self, example, idx):\n",
    "        def is_whitespace(c):\n",
    "            if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "                return True\n",
    "            return False\n",
    "        tensors_list = []\n",
    "        for paragraph in example[\"paragraphs\"]:  # example[\"paragraphs\"] only contains one paragraph in hotpotqa\n",
    "            paragraph_text = paragraph[\"context\"]\n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            for c in paragraph_text:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        doc_tokens.append(c) # add a new token\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c  # append the character to the last token\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question_text = qa[\"question\"]\n",
    "                print(\"question text: \", question_text)  \n",
    "                sp_sent = qa[\"is_sup_fact\"]\n",
    "                sp_para = qa[\"is_supporting_para\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                \n",
    "                p_list = list(locate(doc_tokens , lambda x: x == \"<p>\")) \n",
    "                assert(len(p_list) == len(sp_para))\n",
    "                s_list = list(locate(doc_tokens , lambda x: x == \"<s>\"))\n",
    "#                 \n",
    "#                 if(len(s_list) + len(p_list) != len(sp_sent)):\n",
    "#                     print(\"len(s_list):\", len(s_list))\n",
    "#                     print(\"len(p_list):\", len(p_list))\n",
    "#                     print(\"len(sp_sent):\", len(sp_sent))\n",
    "#                     print(\"sp_sent\", sp_sent)\n",
    "#                     print(\"paragraph_text\", paragraph_text)\n",
    "#                     print(\"doc_tokens\", doc_tokens)\n",
    "                assert(len(s_list) + len(p_list) == len(sp_sent) )\n",
    "                \n",
    "                # keep all answers in the document, not just the first matched answer. It also added the list of textual answers to make evaluation easy.\n",
    "                answer_spans = []\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    orig_answer_text = answer[\"text\"]\n",
    "                    print(\"orig_answer_text: \", orig_answer_text)\n",
    "                    answer_start = answer[\"answer_start\"]\n",
    "                    answer_end = answer[\"answer_end\"]  \n",
    "                    if(answer_start >= 0 and answer_end > 0):\n",
    "                        try:\n",
    "                            start_word_position = char_to_word_offset[answer_start]\n",
    "                            end_word_position = char_to_word_offset[answer_end-1]\n",
    "#                             print(\"answer by start_word_position and end_word_position: \", doc_tokens[start_word_position: end_word_position+1])\n",
    "                        except:\n",
    "                            print(f'error: Reading example {idx} failed')\n",
    "                            start_word_position = -3\n",
    "                            end_word_position = -3\n",
    "                            \n",
    "                    else:\n",
    "                        start_word_position = answer[\"answer_start\"]\n",
    "                        end_word_position = answer[\"answer_end\"]\n",
    "                    answer_spans.append({'start': start_word_position, 'end': end_word_position})\n",
    "\n",
    "                    \n",
    "                # ===== Given an example, convert it into tensors  =============\n",
    "                query_tokens = self.tokenizer.tokenize(question_text)\n",
    "                query_tokens = query_tokens[:self.max_question_len]\n",
    "                tok_to_orig_index = []\n",
    "                orig_to_tok_index = []\n",
    "                all_doc_tokens = []\n",
    "                \n",
    "                # each original token in the context is tokenized to multiple sub_tokens\n",
    "                for (i, token) in enumerate(doc_tokens):\n",
    "                    orig_to_tok_index.append(len(all_doc_tokens))\n",
    "                    # hack: the line below should have been `self.tokenizer.tokenize(token')`\n",
    "                    # but roberta tokenizer uses a different subword if the token is the beginning of the string\n",
    "                    # or in the middle. So for all tokens other than the first, simulate that it is not the first\n",
    "                    # token by prepending a period before tokenizing, then dropping the period afterwards\n",
    "                    sub_tokens = self.tokenizer.tokenize(f'. {token}')[1:] if i > 0 else self.tokenizer.tokenize(token)\n",
    "                    for sub_token in sub_tokens:\n",
    "                        tok_to_orig_index.append(i)\n",
    "                        all_doc_tokens.append(sub_token)\n",
    "                \n",
    "                # all sub tokens, truncate up to limit\n",
    "                all_doc_tokens = all_doc_tokens[:self.max_doc_len-3]\n",
    "\n",
    "                # The -3 accounts for [CLS], [q], [/q]  \n",
    "                max_tokens_per_doc_slice = self.max_seq_len - len(query_tokens) - 3\n",
    "                assert max_tokens_per_doc_slice > 0\n",
    "                if self.doc_stride < 0:                           # default\n",
    "                    # negative doc_stride indicates no sliding window, but using first slice\n",
    "                    self.doc_stride = -100 * len(all_doc_tokens)  # large -negtive value for the next loop to execute once\n",
    "                \n",
    "                # inputs to the model\n",
    "                input_ids_list = []\n",
    "                input_mask_list = []\n",
    "                segment_ids_list = []\n",
    "                start_positions_list = []\n",
    "                end_positions_list = []\n",
    "                q_type_list = []\n",
    "                sp_sent_list =  [1 if ss else 0 for ss in sp_sent]\n",
    "                sp_para_list = [1 if sp else 0 for sp in sp_para]\n",
    "                \n",
    "                for slice_start in range(0, len(all_doc_tokens), max_tokens_per_doc_slice - self.doc_stride):    # execute once by default\n",
    "                    slice_end = min(slice_start + max_tokens_per_doc_slice, len(all_doc_tokens))\n",
    "\n",
    "                    doc_slice_tokens = all_doc_tokens[slice_start:slice_end]\n",
    "                    tokens = [\"<cls>\"] + [\"<q>\"] + query_tokens + [\"</q>\"] + doc_slice_tokens   \n",
    "#                     print(\"tokens: \", tokens)\n",
    "                    segment_ids = [0] * (len(query_tokens) + 3) + [1] *  len(doc_slice_tokens) \n",
    "                    assert len(segment_ids) == len(tokens)\n",
    "\n",
    "                    input_ids = self.tokenizer.convert_tokens_to_ids(tokens)   \n",
    "                    input_mask = [1] * len(input_ids)\n",
    "\n",
    "                    if self.doc_stride >= 0:  # no need to pad if document is not strided\n",
    "                        # Zero-pad up to the sequence length.\n",
    "                        padding_len = self.max_seq_len - len(input_ids)\n",
    "                        input_ids.extend([self.tokenizer.pad_token_id] * padding_len)\n",
    "                        input_mask.extend([0] * padding_len)\n",
    "                        segment_ids.extend([0] * padding_len)\n",
    "\n",
    "                        assert len(input_ids) == self.max_seq_len\n",
    "                        assert len(input_mask) == self.max_seq_len\n",
    "                        assert len(segment_ids) == self.max_seq_len\n",
    "\n",
    "                    # ===== answer positions tensors  ============\n",
    "                    doc_offset = len(query_tokens) + 3 - slice_start  # where context starts\n",
    "                    start_positions = []\n",
    "                    end_positions = []\n",
    "                    q_type = None\n",
    "                    assert(len(answer_spans) > 0)\n",
    "                    for answer_span in answer_spans:\n",
    "                        start_position = answer_span['start']   # reletive to context\n",
    "                        end_position = answer_span['end']\n",
    "                        if(start_position >= 0):\n",
    "                            tok_start_position_in_doc = orig_to_tok_index[start_position]  # sub_tokens postion reletive to context\n",
    "                            not_end_of_doc = int(end_position + 1 < len(orig_to_tok_index))\n",
    "                            tok_end_position_in_doc = orig_to_tok_index[end_position + not_end_of_doc] - not_end_of_doc\n",
    "                            if tok_start_position_in_doc < slice_start or tok_end_position_in_doc > slice_end:\n",
    "                                assert(\"this answer is outside the current slice\")   # only has one slice with the large negative doc_stride\n",
    "                                continue                                \n",
    "                            start_positions.append(tok_start_position_in_doc + doc_offset)   # sub_tokens postion reletive to begining of all the tokens, including query sub tokens  \n",
    "                            end_positions.append(tok_end_position_in_doc + doc_offset)\n",
    "#                             print(\"answer by start_positions and end_positions: \", tokens[tok_start_position_in_doc + doc_offset: tok_end_position_in_doc + doc_offset+1])\n",
    "                            if(q_type != None and q_type != 0):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 0\n",
    "                \n",
    "                        elif(start_position == -1):\n",
    "                            if(q_type != None and q_type != 1):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 1\n",
    "                            start_positions.append(-1)  # -1 is the IGNORE_INDEX, will be ignored\n",
    "                            end_positions.append(-1)     \n",
    "                        elif(start_position == -2):\n",
    "                            if(q_type != None and q_type != 2):\n",
    "                                assert(\"inconsistance q_type\")\n",
    "                            q_type = 2\n",
    "                            start_positions.append(-1)\n",
    "                            end_positions.append(-1)     \n",
    "                        else:\n",
    "                            assert(\"unknown start_positions\")\n",
    "                            continue\n",
    "                    assert len(start_positions) == len(end_positions)\n",
    "                    \n",
    "                    \n",
    "                    if self.ignore_seq_with_no_answers and len(start_positions) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # answers from start_positions and end_positions if > self.max_num_answers\n",
    "                    start_positions = start_positions[:self.max_num_answers]\n",
    "                    end_positions = end_positions[:self.max_num_answers]\n",
    "\n",
    "                    # -1 padding up to self.max_num_answers\n",
    "                    padding_len = self.max_num_answers - len(start_positions)\n",
    "                    start_positions.extend([-1] * padding_len)\n",
    "                    end_positions.extend([-1] * padding_len)\n",
    "\n",
    "                    # replace duplicate start/end positions with `-1` because duplicates can result into -ve loss values\n",
    "                    found_start_positions = set()\n",
    "                    found_end_positions = set()\n",
    "                    for i, (start_position, end_position) in enumerate(zip(start_positions, end_positions)):\n",
    "                        if start_position in found_start_positions:\n",
    "                            start_positions[i] = -1\n",
    "                        if end_position in found_end_positions:\n",
    "                            end_positions[i] = -1\n",
    "                        found_start_positions.add(start_position)\n",
    "                        found_end_positions.add(end_position)\n",
    "\n",
    "                    input_ids_list.append(input_ids)\n",
    "                    input_mask_list.append(input_mask)\n",
    "                    segment_ids_list.append(segment_ids)\n",
    "                    start_positions_list.append(start_positions)\n",
    "                    end_positions_list.append(end_positions)\n",
    "                    q_type_list.append(q_type)\n",
    "                if (input_ids_list is None):\n",
    "                    print(\"input_ids_list is None\")\n",
    "                if (input_mask_list is None):\n",
    "                    print(\"input_mask_list is None\")\n",
    "                if (segment_ids_list is None):\n",
    "                    print(\"segment_ids_list is None\")\n",
    "                if (start_positions_list is None):\n",
    "                    print(\"start_positions_list is None\")\n",
    "                if (end_positions_list is None):\n",
    "                    print(\"end_positions_list is None\")\n",
    "                if (q_type_list is None):\n",
    "                    print(\"q_type_list is None\")\n",
    "                if (sp_sent_list is None):\n",
    "                    print(\"sp_sent_list is None\")\n",
    "                if (sp_para_list is None):\n",
    "                    print(\"sp_para_list is None\")\n",
    "                if (qa['id'] is None):\n",
    "                    print(\"qa['id'] is None\")\n",
    "                tensors_list.append((torch.tensor(input_ids_list), torch.tensor(input_mask_list), torch.tensor(segment_ids_list),\n",
    "                                     torch.tensor(start_positions_list), torch.tensor(end_positions_list), torch.tensor(q_type_list),\n",
    "                                      torch.tensor([sp_sent_list]),  torch.tensor([sp_para_list]),\n",
    "                                     qa['id']))    \n",
    "#                 tensors_list.append((doc_tokens))\n",
    "        return tensors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### collate_one_doc_and_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to hotpotqaDataset\n",
    "    @staticmethod\n",
    "    def collate_one_doc_and_lists(batch):\n",
    "        num_metadata_fields = 1  # qids  \n",
    "        fields = [x for x in zip(*batch)]\n",
    "        stacked_fields = [torch.stack(field) for field in fields[:-num_metadata_fields]]  # don't stack metadata fields\n",
    "        stacked_fields.extend(fields[-num_metadata_fields:])  # add them as lists not torch tensors\n",
    "\n",
    "        # always use batch_size=1 where each batch is one document\n",
    "        # will use grad_accum to increase effective batch size\n",
    "        assert len(batch) == 1\n",
    "        fields_with_batch_size_one = [f[0] for f in stacked_fields]\n",
    "        return fields_with_batch_size_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'collate_one_doc_and_lists',\n",
       " 'one_example_to_tensors']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__class__', type),\n",
       " ('__delattr__', <slot wrapper '__delattr__' of 'object' objects>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__doc__': '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    ',\n",
       "                '__init__': <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>,\n",
       "                '__len__': <function __main__.hotpotqaDataset.__len__(self)>,\n",
       "                '__getitem__': <function __main__.hotpotqaDataset.__getitem__(self, idx)>,\n",
       "                'one_example_to_tensors': <function __main__.one_example_to_tensors(self, example, idx)>,\n",
       "                'collate_one_doc_and_lists': <staticmethod at 0x7f01e4391470>})),\n",
       " ('__dir__', <method '__dir__' of 'object' objects>),\n",
       " ('__doc__',\n",
       "  '\\n    Largely based on\\n    https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\\n    and\\n    https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\\n    '),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__init_subclass__', <function hotpotqaDataset.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <slot wrapper '__repr__' of 'object' objects>),\n",
       " ('__setattr__', <slot wrapper '__setattr__' of 'object' objects>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqaDataset.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'Dataset' objects>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers\n",
    "getmembers(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__add__', <function torch.utils.data.dataset.Dataset.__add__(self, other)>),\n",
       " ('__getitem__', <function __main__.hotpotqaDataset.__getitem__(self, idx)>),\n",
       " ('__init__',\n",
       "  <function __main__.hotpotqaDataset.__init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)>),\n",
       " ('__len__', <function __main__.hotpotqaDataset.__len__(self)>),\n",
       " ('collate_one_doc_and_lists',\n",
       "  <function __main__.collate_one_doc_and_lists(batch)>),\n",
       " ('one_example_to_tensors',\n",
       "  <function __main__.one_example_to_tensors(self, example, idx)>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import isfunction\n",
    "functions_list = [o for o in getmembers(hotpotqaDataset) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqaDataset, torch.utils.data.dataset.Dataset, object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqaDataset)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'example', 'idx'], varargs=None, varkw=None, defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getfullargspec(hotpotqaDataset.one_example_to_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class hotpotqaDataset in module __main__:\n",
      "\n",
      "class hotpotqaDataset(torch.utils.data.dataset.Dataset)\n",
      " |  Largely based on\n",
      " |  https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/reading_comprehension/triviaqa.py\n",
      " |  and\n",
      " |  https://github.com/huggingface/transformers/blob/master/examples/run_squad.py\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      hotpotqaDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __init__(self, file_path, tokenizer, max_seq_len, max_doc_len, doc_stride, max_num_answers, ignore_seq_with_no_answers, max_question_len)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  one_example_to_tensors(self, example, idx)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  collate_one_doc_and_lists(batch)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqaDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class hotpotqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \\_\\_init\\_\\_,  forward, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class hotpotqa(pl.LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super(hotpotqa, self).__init__()\n",
    "        self.args = args\n",
    "        self.hparams = args\n",
    "\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        num_new_tokens = self.tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<cls>\", \"<p>\", \"<q>\", \"</q>\"]})\n",
    "#         print(self.tokenizer.all_special_tokens)\n",
    "        self.tokenizer.model_max_length = self.args.max_seq_len\n",
    "        self.model = self.load_model()\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.num_labels = 2\n",
    "        self.qa_outputs = torch.nn.Linear(self.model.config.hidden_size, self.num_labels)\n",
    "        \n",
    "        self.dense_type = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_type = torch.nn.Linear(self.model.config.hidden_size, 3)   #  question type (yes/no/span) classification \n",
    "        self.dense_sp_sent = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_sp_sent = torch.nn.Linear(self.model.config.hidden_size, 1)    \n",
    "        self.dense_sp_para = torch.nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "        self.linear_sp_para = torch.nn.Linear(self.model.config.hidden_size, 1) \n",
    "        self.train_dataloader_object = self.val_dataloader_object = self.test_dataloader_object = None\n",
    "    \n",
    "    def load_model(self):\n",
    "#         model = Longformer.from_pretrained(self.args.model_path)\n",
    "        model = Longformer.from_pretrained('longformer-base-4096')\n",
    "        for layer in model.encoder.layer:\n",
    "            layer.attention.self.attention_mode = self.args.attention_mode\n",
    "            self.args.attention_window = layer.attention.self.attention_window\n",
    "\n",
    "        print(\"Loaded model with config:\")\n",
    "        print(model.config)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        model.train()\n",
    "        return model\n",
    "\n",
    "#%%add_to hotpotqa    # does not seems to work for the @pl.data_loader decorator, missing which causes error \"validation_step() takes 3 positional arguments but 4 were given\"    \n",
    "###################################################### dataloaders ########################################################### \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        if self.train_dataloader_object is not None:\n",
    "            return self.train_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.train_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=self.args.ignore_seq_with_no_answers)\n",
    "\n",
    "#         sampler = torch.utils.data.distributed.DistributedSampler(dataset) if self.trainer.use_ddp else None\n",
    "#         dl = DataLoader(dataset, batch_size=1, shuffle=(sampler is None),\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,   # set shuffle=False, otherwise it will sample a different subset of data every epoch with train_percent_check\n",
    "        num_workers=self.args.num_workers, sampler=None,\n",
    "                        num_workers=self.args.num_workers, sampler=sampler,\n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "        self.train_dataloader_object = dl\n",
    "        return self.train_dataloader_object\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        if self.val_dataloader_object is not None:\n",
    "            return self.val_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=False)  # evaluation data should keep all examples\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(dataset) if self.trainer.use_ddp else None\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=(sampler is None),\n",
    "                        num_workers=self.args.num_workers, sampler=sampler,\n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "        self.val_dataloader_object = dl\n",
    "        return self.val_dataloader_object\n",
    "\n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        if self.test_dataloader_object is not None:\n",
    "            return self.test_dataloader_object\n",
    "        dataset = hotpotqaDataset(file_path=self.args.dev_dataset, tokenizer=self.tokenizer,\n",
    "                                  max_seq_len=self.args.max_seq_len, max_doc_len=self.args.max_doc_len,\n",
    "                                  doc_stride=self.args.doc_stride,\n",
    "                                  max_num_answers=self.args.max_num_answers,\n",
    "                                  max_question_len=self.args.max_question_len,\n",
    "                                  ignore_seq_with_no_answers=False)  # evaluation data should keep all examples\n",
    "\n",
    "        dl = DataLoader(dataset, batch_size=1, shuffle=False,\n",
    "                        num_workers=self.args.num_workers, sampler=None,\n",
    "                        collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "        self.test_dataloader_object = dl\n",
    "        return self.test_dataloader_object\n",
    "\n",
    "#%%add_to hotpotqa  \n",
    "    def forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para):\n",
    "#         print(\"size of input_ids: \" + str(input_ids.size())) \n",
    "#         print(\"size of attention_mask: \" + str(attention_mask.size()))\n",
    "#         print(\"size of segment_ids: \" + str(segment_ids.size()))\n",
    "#         print(\"size of start_positions: \" + str(start_positions.size()))\n",
    "#         print(\"size of end_positions:\" + str(end_positions.size()))\n",
    "#         print(\"q_type: \" + str(q_type))\n",
    "#         print(\"size of sp_sent: \" + str(sp_sent.size()))\n",
    "#         print(\"size of sp_para: \" + str(sp_para.size()))\n",
    "        if(input_ids.size(0) > 1):\n",
    "            assert(\"multi rows per document\")\n",
    "        # Each batch is one document, and each row of the batch is a chunck of the document.    ????\n",
    "        # Make sure all rows have the same question length.\n",
    "        \n",
    "#         size of input_ids: torch.Size([1, 1495])\n",
    "#         size of attention_mask: torch.Size([1, 1495])\n",
    "#         size of segment_ids: torch.Size([1, 1495])\n",
    "#         size of start_positions: torch.Size([1, 64])   # multiple occurences of the same answer string, -1 padding up to self.max_num_answers\n",
    "#         size of end_positions: torch.Size([1, 64])\n",
    "#         size of q_type: torch.Size([1, 1])\n",
    "#         size of sp_sent: torch.Size([1, 40])           # number of sentences in context\n",
    "#         size of sp_para: torch.Size([1, 10])\n",
    "#         print(\"input: \", self.tokenizer.convert_ids_to_tokens(input_ids[0].tolist()) )\n",
    "        # local attention everywhere\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "        \n",
    "        # global attention for the cls and all question tokens\n",
    "        question_end_index = self._get_special_index(input_ids, \"</q>\")\n",
    "        if(question_end_index.size(0) == 1):\n",
    "            attention_mask[:,:question_end_index.item()] = 2  # from <cls> until </q>\n",
    "        else:\n",
    "            attention_mask[:,:question_end_index[0].item()] = 2\n",
    "            print(\"more than 1 <q> in: \", self.tokenizer.convert_ids_to_tokens(input_ids[0].tolist()) )\n",
    "        \n",
    "        # global attention for the sentence and paragraph special tokens  \n",
    "        p_index = self._get_special_index(input_ids, \"<p>\")\n",
    "#         print(\"size of p_index: \" + str(p_index.size()))\n",
    "        attention_mask[:, p_index] = 2\n",
    "              \n",
    "        s_index = self._get_special_index(input_ids, \"<s>\")\n",
    "#         print(\"size of s_index: \" + str(s_index.size()))\n",
    "        attention_mask[:, s_index] = 2\n",
    "        \n",
    "#         print(\"p_index:\", p_index) \n",
    "#         print(\"attention_mask: \", attention_mask)\n",
    "        \n",
    "\n",
    "        # sliding_chunks implemenation of selfattention requires that seqlen is multiple of window size\n",
    "        input_ids, attention_mask = pad_to_window_size(\n",
    "            input_ids, attention_mask, self.args.attention_window, self.tokenizer.pad_token_id)\n",
    "\n",
    "        sequence_output = self.model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask)[0]\n",
    "\n",
    "        # The pretrained hotpotqa model wasn't trained with padding, so remove padding tokens\n",
    "        # before computing loss and decoding.\n",
    "        padding_len = input_ids[0].eq(self.tokenizer.pad_token_id).sum()\n",
    "        if padding_len > 0:\n",
    "            sequence_output = sequence_output[:, :-padding_len]\n",
    "#         print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "              \n",
    "        \n",
    "        ###################################### layers on top of sequence_output ##################################\n",
    "        \n",
    "\n",
    "        ### 1. answer start and end positions classification ###   \n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "#         print(\"size of logits: \" + str(logits.size())) \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "#         print(\"size of start_logits: \" + str(start_logits.size())) \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "#         print(\"size of start_logits after squeeze: \" + str(start_logits.size())) \n",
    "        end_logits = end_logits.squeeze(-1)\n",
    " \n",
    "        ### 2. type classification, similar as class LongformerClassificationHead(nn.Module) https://huggingface.co/transformers/_modules/transformers/modeling_longformer.html#LongformerForSequenceClassification.forward ### \n",
    "#         print(\"size of sequence_output[:,0]: \" + str(sequence_output[:,0].size()))\n",
    "        type_logits = self.dense_type(sequence_output[:,0])\n",
    "#         print(\"size of type_logits after dense: \" + str(type_logits.size()))\n",
    "        # Non-linearity\n",
    "        type_logits = torch.tanh(type_logits) \n",
    "#         print(\"size of type_logits after tanh: \" + str(type_logits.size()))\n",
    "        type_logits = self.linear_type(type_logits)\n",
    "#         print(\"size of type_logits: \" + str(type_logits.size()))\n",
    "        \n",
    "        ### 3. supporting paragraph classification ### \n",
    "        sp_para_output = torch.tensor([], device=input_ids.device) \n",
    "        sp_para_output = sequence_output[:,p_index,:]\n",
    "#         print(\"size of sp_para_output: \" + str(sp_para_output.size()))      \n",
    "              \n",
    "        sp_para_output_t = self.dense_sp_para(sp_para_output)\n",
    "#         print(\"size of sp_para_output_t after dense: \" + str(sp_para_output_t.size()))   \n",
    "        # Non-linearity\n",
    "        sp_para_output_t = torch.tanh(sp_para_output_t) \n",
    "#         print(\"size of sp_para_output_t after tanh: \" + str(sp_para_output_t.size()))\n",
    "        sp_para_output_t = self.linear_sp_para(sp_para_output_t)\n",
    "#         print(\"size of sp_para_output_t: \" + str(sp_para_output_t.size()))   \n",
    "        \n",
    "        # linear_sp_sent generates a single score for each sentence, instead of 2 scores for yes and no. \n",
    "        # Argument the score with additional score=0. The same way did in the HOTPOTqa paper\n",
    "        sp_para_output_aux = torch.zeros(sp_para_output_t.shape, dtype=torch.float, device=sp_para_output_t.device) \n",
    "#         print(\"size of sp_para_output_aux: \" + str(sp_para_output_aux.size()))   \n",
    "        predict_support_para = torch.cat([sp_para_output_aux, sp_para_output_t], dim=-1).contiguous()\n",
    "#         print(\"size of predict_support_para: \" + str(predict_support_para.size()))              \n",
    "            \n",
    "        ### 4. supporting fact classification ###     \n",
    "        # the first sentence in a paragraph is leading by <p>, other sentences are leading by <s>\n",
    "        sent_indexes = torch.sort(torch.cat((s_index, p_index)))[0] # torch.sort returns a 'torch.return_types.sort' object has 2 items: values, indices\n",
    "#         print(\"size of sent_indexes: \" + str(sent_indexes.size()))\n",
    "#         print(\"sent_indexes: \", sent_indexes)\n",
    "        sp_sent_output = sequence_output[:,sent_indexes,:]\n",
    "#         print(\"size of sp_sent_output: \" + str(sp_sent_output.size()))      \n",
    "        \n",
    "        sp_sent_output_t = self.dense_sp_sent(sp_sent_output)\n",
    "#         print(\"size of sp_sent_output_t after dense: \" + str(sp_sent_output_t.size()))      \n",
    "        # Non-linearity\n",
    "        sp_sent_output_t = torch.tanh(sp_sent_output_t) \n",
    "#         print(\"size of sp_sent_output_t after tanh: \" + str(sp_sent_output_t.size()))        \n",
    "        sp_sent_output_t = self.linear_sp_sent(sp_sent_output_t)\n",
    "#         print(\"size of sp_sent_output_t: \" + str(sp_sent_output_t.size()))       \n",
    " \n",
    "        sp_sent_output_aux = torch.zeros(sp_sent_output_t.shape, dtype=torch.float, device=sp_sent_output_t.device) \n",
    "#         print(\"size of sp_sent_output_aux: \" + str(sp_sent_output_aux.size()))  \n",
    "        predict_support_sent = torch.cat([sp_sent_output_aux, sp_sent_output_t], dim=-1).contiguous()\n",
    "#         print(\"size of predict_support_sent: \" + str(predict_support_sent.size()))  \n",
    "        \n",
    "        outputs = (start_logits, end_logits, type_logits, sp_para_output_t, sp_sent_output_t)  \n",
    "        #outputs = (torch.sigmoid(start_logits), torch.sigmoid(end_logits), torch.sigmoid(type_logits), torch.sigmoid(sp_para_output_t), torch.sigmoid(sp_sent_output_t))  \n",
    "        answer_loss, type_loss, sp_para_loss, sp_sent_loss  = self.loss_computation(start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)\n",
    "#         print(\"answer_loss: \" + str(answer_loss))\n",
    "#         print(\"type_loss: \" + str(type_loss))\n",
    "#         print(\"sp_para_loss: \" + str(sp_para_loss))\n",
    "#         print(\"sp_sent_loss: \" + str(sp_sent_loss))\n",
    "        outputs = (answer_loss, type_loss, sp_para_loss, sp_sent_loss,) + outputs    \n",
    "        return outputs\n",
    "    \n",
    "    def loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent):\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "\n",
    "            if not self.args.regular_softmax_loss:\n",
    "                # loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\n",
    "                # NOTE: this returns sum of losses, not mean, so loss won't be normalized across different batch sizes\n",
    "                # but batch size is always 1, so this is not a problem\n",
    "                start_loss = self.or_softmax_cross_entropy_loss_one_doc(start_logits, start_positions, ignore_index=-1)\n",
    "#                 print(\"start_positions: \" + str(start_positions)) \n",
    "#                 print(\"start_loss: \" + str(start_loss)) \n",
    "                \n",
    "#                 # for debug: check is there any impact if remove -1s from start_positions, and turns out no impact at all\n",
    "#                 start_positions_debug = start_positions[:, torch.where(start_positions!=-1)[1]]\n",
    "#                 start_loss_debug = self.or_softmax_cross_entropy_loss_one_doc(start_logits, start_positions_debug, ignore_index=-1)\n",
    "#                 print(\"start_positions_debug: \" + str(start_positions_debug)) \n",
    "#                 print(\"start_loss_debug: \" + str(start_loss_debug)) \n",
    "                \n",
    "                end_loss = self.or_softmax_cross_entropy_loss_one_doc(end_logits, end_positions, ignore_index=-1)\n",
    "#                 print(\"end_positions: \" + str(end_positions)) \n",
    "#                 print(\"end_loss: \" + str(end_loss)) \n",
    "                \n",
    "#                 # for debug: check is there any impact if remove -1s from \n",
    "#                 end_positions_debug = end_positions[:, torch.where(end_positions!=-1)[1]]\n",
    "#                 end_loss_debug = self.or_softmax_cross_entropy_loss_one_doc(end_logits, end_positions_debug, ignore_index=-1)\n",
    "#                 print(\"end_positions_debug: \" + str(end_positions_debug)) \n",
    "#                 print(\"end_loss_debug: \" + str(end_loss_debug)) \n",
    "\n",
    "                type_loss = self.or_softmax_cross_entropy_loss_one_doc(type_logits, q_type.unsqueeze(0), ignore_index=-1)\n",
    "\n",
    "#                 binary_loss = torch.nn.BCELoss()\n",
    "# #                 print(\"sp_para_output_t.squeeze().type(): \", sp_para_output_t.squeeze().type())\n",
    "# #                 print(\"sp_para.to(dtype=torch.half, device=sp_para.device).type(): \", sp_para.to(dtype=torch.half, device=sp_para.device).type())\n",
    "#                 sp_para_loss = binary_loss(sp_para_output_t.squeeze(), sp_para.squeeze().to(dtype=torch.half, device=sp_para.device))\n",
    "#                 sp_sent_loss = binary_loss(sp_sent_output_t.squeeze(), sp_sent.squeeze().to(dtype=torch.half, device=sp_sent.device))\n",
    "                \n",
    "#                 sp_para_loss = torch.tensor([0.0], device = predict_support_para.device )\n",
    "# #                 print(\"predict_support_para.squeeze(): \", predict_support_para.squeeze())\n",
    "# #                 print(\"sp_para.squeeze(): \", sp_para.squeeze())\n",
    "#                 for para_predict, para_gold in zip(predict_support_para.squeeze(), sp_para.squeeze()):\n",
    "# #                     print(\"para_predict.unsqueeze(0): \", para_predict.unsqueeze(0))\n",
    "# #                     print(\" para_gold.unsqueeze(0): \",  para_gold.unsqueeze(0))\n",
    "\n",
    "                # only one example per batch, instead treating each example as a row, after squeeze, each para / sentence is a row\n",
    "                sp_para_loss = self.or_softmax_cross_entropy_loss_one_doc(predict_support_para.squeeze(), sp_para.squeeze().unsqueeze(-1), ignore_index=-1)\n",
    "                sp_sent_loss = self.or_softmax_cross_entropy_loss_one_doc(predict_support_sent.squeeze(), sp_sent.squeeze().unsqueeze(-1), ignore_index=-1)\n",
    "        \n",
    "            else:\n",
    "                loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "                start_positions = start_positions[:, 0:1]   # only use the top1 start_position considering only one appearance of the answer string\n",
    "                end_positions = end_positions[:, 0:1]\n",
    "                start_loss = loss_fct(start_logits, start_positions[:, 0])\n",
    "                end_loss = loss_fct(end_logits, end_positions[:, 0])\n",
    "                type_loss = loss_fct(type_logits, q_type)  \n",
    "                \n",
    "                nll_average = torch.nn.CrossEntropyLoss(size_average=True, ignore_index=-1)\n",
    "#                 print(\"predict_support_para.view(-1, 2).size()\", predict_support_para.view(-1, 2).size())\n",
    "#                 print(\"sp_para.view(-1).size()\", sp_para.view(-1).size())\n",
    "                sp_para_loss = nll_average(predict_support_para.view(-1, 2), sp_para.view(-1))\n",
    "                sp_sent_loss = nll_average(predict_support_sent.view(-1, 2), sp_sent.view(-1))\n",
    " \n",
    "                \n",
    "            answer_loss = (start_loss + end_loss) / 2 \n",
    "        return answer_loss, type_loss, sp_para_loss, sp_sent_loss  \n",
    "\n",
    "#     %%add_to hotpotqa    \n",
    "    def _get_special_index(self, input_ids, special_token):\n",
    "        assert(input_ids.size(0)==1)\n",
    "        token_indices =  torch.nonzero(input_ids == self.tokenizer.convert_tokens_to_ids(special_token))\n",
    "        ### FOR DEBUG ###\n",
    "        # input_ids = torch.tensor([[0.6, 0.0, 0.6, 0.0]]) \n",
    "        # token_indices =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "        return token_indices[:,1]    \n",
    "\n",
    "    def or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1):\n",
    "        \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "        assert logits.ndim == 2\n",
    "        assert target.ndim == 2\n",
    "        assert logits.size(0) == target.size(0) \n",
    "        \n",
    "        # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "        # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "        # target are indexes of tokens, padded with ignore_index=-1\n",
    "        # logits are scores (one for each label) for each token\n",
    "#         print(\"or_softmax_cross_entropy_loss_one_doc\" ) \n",
    "#         print(\"size of logits: \" + str(logits.size()))                    # torch.Size([1, 746]), 746 is number of all tokens \n",
    "#         print(\"size of target: \" + str(target.size()))                    # torch.Size([1, 64]),  -1 padded\n",
    "#         print(\"target: \" + str(target)) \n",
    "\n",
    "        # compute a target mask\n",
    "        target_mask = target == ignore_index\n",
    "        # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "        masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "#         print(\"masked_target: \" + str(masked_target))     \n",
    "        # gather logits\n",
    "        gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    "#         print(\"size of gathered_logits: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"gathered_logits: \" + str(gathered_logits)) \n",
    "        # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "        gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    "#         print(\"gathered_logits after -inf: \" + str(gathered_logits))      # tensor([[0.4382,   -inf,   -inf,   -inf,   -inf,...]])\n",
    "        \n",
    "        # each batch is one example\n",
    "        gathered_logits = gathered_logits.view(1, -1)\n",
    "        logits = logits.view(1, -1)\n",
    "#         print(\"size of gathered_logits after view: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"size of logits after view: \" + str(logits.size()))                    # torch.Size([1, 746])　　\n",
    "\n",
    "        # numerator = log(sum(exp(gathered logits)))\n",
    "        log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_score: \" + str(log_score)) \n",
    "        # denominator = log(sum(exp(logits)))\n",
    "        log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_norm: \" + str(log_norm)) \n",
    "        \n",
    "        # compute the loss\n",
    "        loss = -(log_score - log_norm)\n",
    "        loss = torch.sigmoid(loss)     # to normalize different losses\n",
    "#         print(\"loss: \" + str(loss)) \n",
    "\n",
    "        # some of the examples might have a loss of `inf` when `target` is all `ignore_index`: when computing start_loss and end_loss for question with the gold answer of yes/no \n",
    "        # replace -inf with 0\n",
    "        loss = loss[~torch.isinf(loss)].sum()\n",
    "#         print(\"final loss: \" + str(loss)) \n",
    "        return loss \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xdisk/msurdeanu/fanluo/miniconda3/envs/hotpotqa/lib/python3.6/site-packages/ipykernel_launcher.py:195: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "# input_ids = torch.tensor([[-1, 5, -1, 2]])\n",
    "# input_ids.size(0)\n",
    "# token_indices =  torch.nonzero(input_ids == torch.tensor(-1))[:,1]\n",
    "# # token_indices\n",
    "# # token_indices.item()\n",
    "# # indices =  torch.LongTensor([[2],[0,2]])\n",
    "\n",
    "# # torch.gather(input_ids, 1, token_indices.unsqueeze(0))\n",
    "# # p_index = token_indices.view(input_ids.size(0), -1)[:,1::2]   \n",
    "# # attention_mask = torch.ones(input_ids.shape, dtype=torch.long) \n",
    "# # attention_mask[:,token_indices] = 2\n",
    "# # attention_mask\n",
    "# p_index = torch.tensor([1, 3, 4])\n",
    "# s_index = torch.tensor([1,3,6])\n",
    "# torch.sort(torch.cat((s_index, p_index)))[0]\n",
    "# attention_mask.view(-1)[ p_index.view(-1), :].view(attention_mask.size(0), -1)\n",
    "# # for pi in p_index[0]:\n",
    "# #     attention_mask[:, pi] = 2\n",
    "# # attention_mask\n",
    "# # s_index = torch.tensor([[1,3]])\n",
    "# # torch.sort(torch.cat((p_index, s_index), -1), -1)\n",
    "\n",
    "# sequence_output  = torch.tensor([[[-1, 5, -1, 2],\n",
    "#                                  [-2, 27, 2, 9],\n",
    "#                                  [3, 6, 1, 65],\n",
    "#                                  [52, 36, 13, 2],\n",
    "#                                  [73, 26, 1, 7]\n",
    "#                                 ]])\n",
    "\n",
    "# sp_para_output_t   = torch.tensor([[[-1],\n",
    "#                                  [-2 ],\n",
    "#                                  [3],\n",
    "#                                  [52],\n",
    "#                                  [73]\n",
    "#                                 ]])\n",
    "# torch.zeros(sp_para_output_t.shape, dtype=torch.float) \n",
    "\n",
    "# print(\"size of sequence_output: \" + str(sequence_output.size()))\n",
    "# # print(\"size of p_index.unsqueeze(0).unsqueeze(-1): \" + str(p_index.unsqueeze(0).size()))\n",
    "# sequence_output[:,p_index,:]\n",
    "# b = torch.tensor([0, 1, 2, 3])\n",
    "# p_index.unsqueeze(-1) * b\n",
    "\n",
    "# input_ids = torch.tensor([[0.2, 0.0, 0.6, 0.6], [0.2, 0.6, 0.0, 0.0]]) \n",
    "# # input_ids.tolist()\n",
    "# p_index =  torch.nonzero(input_ids == torch.tensor(0.2))\n",
    "# print(p_index)\n",
    "# s_index =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "# print(s_index)\n",
    "\n",
    "# sp_sent = torch.tensor([[0, 1, 1, 0]])\n",
    "# torch.where(sp_sent.squeeze())[0]\n",
    "# cat_index = torch.tensor([])\n",
    "# cat_index = torch.cat((cat_index, ids[0][1]))\n",
    "# print(ids)\n",
    "# print(cat_index)\n",
    "# p_index[p_index[:,0] == 0]\n",
    "\n",
    "# cat_index[cat_index[:,0].argsort()]\n",
    "\n",
    "# sorted(torch.cat((p_index, s_index)), key = lambda x: x[0])\n",
    "# torch.sort(torch.cat((p_index, s_index)), 0)[0]\n",
    "# for cor in token_indices:\n",
    "#     attention_mask[cor[0].item()][cor[1].item()] = 2\n",
    "# attention_mask \n",
    "# input_ids = torch.tensor([[-1, 5, -6, 2]])\n",
    "# print(input_ids.size())\n",
    "# input_ids.topk(k=2, dim=-1).indices\n",
    "\n",
    "# predict_type = torch.tensor([[-0.0925, -0.0999, -0.1671]])\n",
    "# p_type = torch.argmax(predict_type, dim=1).item()\n",
    "# p_type_score = torch.max(predict_type, dim=1)[0].item()\n",
    "# print(\"predict_type: \", predict_type)\n",
    "# print(\"p_type: \", p_type)\n",
    "# print(\"p_type_score: \", p_type_score)\n",
    "    \n",
    "# a = torch.tensor([[0.9213,  1.0887, -0.8858, -1.7683]])\n",
    "# a.view(-1).size() \n",
    "# print(torch.sigmoid(a))\n",
    "# a = torch.tensor([ 9.213,  1.0887, -0.8858, 7683])\n",
    "# print(torch.sigmoid(a))\n",
    "\n",
    "# a = torch.tensor([[[1],[2],[4],[-1],[-1]]])\n",
    "# a= a.squeeze(-1)\n",
    "# a.size() \n",
    "# a[:, torch.where(a!=-1)[1]]\n",
    "# m = torch.nn.Sigmoid()\n",
    "# print(\"m: \", m)\n",
    "# loss = torch.nn.BCELoss()\n",
    "# # input = torch.randn(3, requires_grad=True)\n",
    "# # print(\"input: \", input)\n",
    "# # target = torch.empty(3).random_(2)\n",
    "# # print(\"target: \", target)\n",
    "# # output = loss(m(input), target)\n",
    "# # print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([1.0293, -0.1585,  1.1408], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# print(\"Sigmoid(input): \", m(input))\n",
    "# target = torch.tensor([0., 1., 0.])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# input = torch.tensor([[1.0293, -0.1585,  1.1408]], requires_grad=True)\n",
    "# print(\"input: \", input)\n",
    "# target = torch.tensor([[0., 1., 0.]])\n",
    "# print(\"target: \", target)\n",
    "# output = loss(m(input), target)\n",
    "# print(\"output: \", output)\n",
    "\n",
    "# 1.1761 * 3\n",
    "\n",
    "# def or_softmax_cross_entropy_loss_one_doc(logits, target, ignore_index=-1, dim=-1):\n",
    "#         \"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"\n",
    "#         assert logits.ndim == 2\n",
    "#         assert target.ndim == 2\n",
    "#         assert logits.size(0) == target.size(0)\n",
    "         \n",
    "        \n",
    "#         # with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target, considing only one correct target \n",
    "#         # here, the numerator is the sum of a few potential targets, where some of them is the correct answer, considing more correct targets\n",
    "\n",
    "#         # target are indexes of tokens, padded with ignore_index=-1\n",
    "#         # logits are scores (one for each label) for each token\n",
    "#         print(\"or_softmax_cross_entropy_loss_one_doc\" ) \n",
    "#         print(\"size of logits: \" + str(logits.size()))                    # torch.Size([1, 746]), 746 is number of all tokens \n",
    "#         print(\"size of target: \" + str(target.size()))                    # torch.Size([1, 64]),  -1 padded\n",
    "#         print(\"target: \" + str(target)) \n",
    "\n",
    "#         # compute a target mask\n",
    "#         target_mask = target == ignore_index\n",
    "#         # replaces ignore_index with 0, so `gather` will select logit at index 0 for the masked targets\n",
    "#         masked_target = target * (1 - target_mask.long())                 # replace all -1 in target with 0， tensor([[447,   0,   0,   0, ...]])\n",
    "#         print(\"masked_target: \" + str(masked_target))     \n",
    "#         # gather logits\n",
    "#         gathered_logits = logits.gather(dim=dim, index=masked_target)     # tensor([[0.4382, 0.2340, 0.2340, 0.2340 ... ]]), padding logits are all replaced by logits[0] \n",
    "#         print(\"size of gathered_logits: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"gathered_logits: \" + str(gathered_logits)) \n",
    "#         # Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0\n",
    "#         gathered_logits[target_mask] = float('-inf')                      # padding logits are all replaced by -inf\n",
    "#         print(\"gathered_logits after -inf: \" + str(gathered_logits))      # tensor([[0.4382,   -inf,   -inf,   -inf,   -inf,...]])\n",
    "        \n",
    "#         # each batch is one example\n",
    "#         gathered_logits = gathered_logits.view(1, -1)\n",
    "#         logits = logits.view(1, -1)\n",
    "#         print(\"size of gathered_logits after view: \" + str(gathered_logits.size()))  # torch.Size([1, 64])\n",
    "#         print(\"size of logits after view: \" + str(logits.size()))                    # torch.Size([1, 746])　　\n",
    "\n",
    "#         # numerator = log(sum(exp(gathered logits)))\n",
    "#         log_score = torch.logsumexp(gathered_logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_score: \" + str(log_score)) \n",
    "#         # denominator = log(sum(exp(logits)))\n",
    "#         log_norm = torch.logsumexp(logits, dim=dim, keepdim=False)\n",
    "#         print(\"log_norm: \" + str(log_norm)) \n",
    "        \n",
    "#         # compute the loss\n",
    "#         loss = -(log_score - log_norm)\n",
    "#         print(\"loss: \" + str(loss)) \n",
    "\n",
    "#         # some of the examples might have a loss of `inf` when `target` is all `ignore_index`. remove those from the loss before computing the sum.\n",
    "#         loss = loss[~torch.isinf(loss)].sum()\n",
    "#         print(\"final loss: \" + str(loss)) \n",
    "#         return loss \n",
    "\n",
    "# input = torch.tensor([[ 0,  0.0780],\n",
    "#         [0, 0.9253 ],\n",
    "#         [0, 0.0987]])\n",
    "# target = torch.tensor([0,1,0])\n",
    "# target.size(0) < 1\n",
    "# input = torch.tensor([[ 1.1879,  1.0780,  0.5312],\n",
    "#         [-0.3499, -1.9253, -1.5725],\n",
    "#         [-0.6578, -0.0987,  1.1570]])\n",
    "# target=torch.tensor([0,1,2])\n",
    "# predict_support_para.view(-1, 2), sp_para.view(-1)\n",
    "# or_softmax_cross_entropy_loss_one_doc(input, target.unsqueeze(-1))\n",
    "# soft_input = torch.nn.Softmax(dim=-1)\n",
    "# log_soft_input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss() \n",
    "# loss(log_soft_input, target)\n",
    "# input = torch.log(soft_input(input))\n",
    "# loss=torch.nn.NLLLoss()\n",
    "# loss(input,target)\n",
    "\n",
    "# loss =torch.nn.CrossEntropyLoss()\n",
    "# loss(input,target) \n",
    "\n",
    "# sp_sent_logits =torch.tensor([[[0.0988],\n",
    "#          [0.0319],\n",
    "#          [0.0314]]])\n",
    "# sp_sent_logits.squeeze()\n",
    "\n",
    "input_ids = torch.tensor([[0.6, 0.0, 0.6, 0.0]]) \n",
    "token_indices =  torch.nonzero(input_ids == torch.tensor(0.6))\n",
    "token_indices[:,1][0].item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug: check loaded dataset by DataLoader\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# num_new_tokens = tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<p>\", \"<q>\", \"</q>\"]})\n",
    "# # # print(tokenizer.all_special_tokens)    \n",
    "# # # print(tokenizer.all_special_ids)     \n",
    "# # # tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "# # # tokenizer.sep_token\n",
    "\n",
    "# # # all_doc_tokens = []\n",
    "# # # orig_to_tok_index = []\n",
    "# # # tok_to_orig_index = []\n",
    "# # # for (i, token) in enumerate([\"<s>\", \"da\", \"tell\", \"<p>\", \"say\"]):\n",
    "# # #     orig_to_tok_index.append(len(all_doc_tokens))\n",
    "# # #     sub_tokens = tokenizer.tokenize(f'. {token}')[1:] if i > 0 else tokenizer.tokenize(token)\n",
    "# # #     for sub_token in sub_tokens:\n",
    "# # #         tok_to_orig_index.append(i)\n",
    "# # #         all_doc_tokens.append(sub_token)\n",
    "# # # all_doc_tokens\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# dataset = hotpotqaDataset(file_path= args.train_dataset, tokenizer=tokenizer,\n",
    "#                           max_seq_len= args.max_seq_len, max_doc_len= args.max_doc_len,\n",
    "#                           doc_stride= args.doc_stride,\n",
    "#                           max_num_answers= args.max_num_answers,\n",
    "#                           max_question_len= args.max_question_len,\n",
    "#                           ignore_seq_with_no_answers= args.ignore_seq_with_no_answers)\n",
    "# print(len(dataset))\n",
    "\n",
    "# # # dl = DataLoader(dataset, batch_size=1, shuffle=None,\n",
    "# # #                     num_workers=args.num_workers, sampler=None,\n",
    "# # #                     collate_fn=hotpotqaDataset.collate_one_doc_and_lists)\n",
    "\n",
    "# example = dataset[3]  \n",
    "# [input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids] = example\n",
    " \n",
    "\n",
    "# print(input_ids[0][:20].tolist())\n",
    "# print(input_mask) \n",
    "# print(segment_ids) \n",
    "# print(subword_starts) \n",
    "# print(subword_ends)\n",
    "# print(q_type)\n",
    "# print(sp_sent) \n",
    "# print(sp_para) \n",
    "# print(qids)\n",
    "# print(tokenizer.convert_ids_to_tokens(input_ids[0][667:669+1].tolist()))\n",
    "# 0.0033 * 90447 \n",
    "# 28*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### configure_ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%add_to hotpotqa\n",
    " # A hook to overwrite to define your own DDP(DistributedDataParallel) implementation init. \n",
    " # The only requirement is that: \n",
    " # 1. On a validation batch the call goes to model.validation_step.\n",
    " # 2. On a training batch the call goes to model.training_step.\n",
    " # 3. On a testing batch, the call goes to model.test_step\n",
    " def configure_ddp(self, model, device_ids):\n",
    "    model = LightningDistributedDataParallel(\n",
    "        model,\n",
    "        device_ids=device_ids,\n",
    "        find_unused_parameters=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **configure_optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def configure_optimizers(self):\n",
    "    # Set up optimizers and (optionally) learning rate schedulers\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < self.args.warmup:\n",
    "            return float(current_step) / float(max(1, self.args.warmup))\n",
    "        return max(0.0, float(self.args.steps - current_step) / float(max(1, self.args.steps - self.args.warmup)))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=self.args.lr)\n",
    "\n",
    "    self.scheduler = LambdaLR(optimizer, lr_lambda, last_epoch=-1)  # scheduler is not saved in the checkpoint, but global_step is, which is enough to restart\n",
    "    self.scheduler.step(self.global_step)\n",
    "\n",
    "    return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optimizer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# A hook to do a lot of non-standard training tricks such as learning-rate warm-up\n",
    "def optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None):\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    self.scheduler.step(self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **training_step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# A hook\n",
    "def on_epoch_start(self):\n",
    "    print(\"Start epoch \", self.current_epoch)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def training_step(self, batch, batch_nb):\n",
    "    # do the forward pass and calculate the loss for a batch \n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch \n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss  = output[:4]\n",
    "    loss  = answer_loss +  type_loss + sp_para_loss + sp_sent_loss\n",
    "#     print(\"returned loss: \", loss)\n",
    "#     print(\"self.trainer.optimizers[0].param_groups[0]['lr']: \", self.trainer.optimizers[0].param_groups[0]['lr'])\n",
    "    lr = loss.new_zeros(1) + self.trainer.optimizers[0].param_groups[0]['lr']  # loss.new_zeros(1) is tensor([0.]), converting 'lr' to tensor' by adding it. \n",
    "#     print(\"loss: \", loss)\n",
    "    print(\"lr: \", lr)    # lr will increading over time\n",
    "    tensorboard_logs = {'train_answer_loss': answer_loss, 'train_type_loss': type_loss, 'train_sp_para_loss': sp_para_loss, 'train_sp_sent_loss': sp_sent_loss, \n",
    "                        'lr': lr,\n",
    "                        'input_size': input_ids.numel(),\n",
    "                        'mem': torch.cuda.memory_allocated(input_ids.device) / 1024 ** 3}\n",
    "    return {'loss': loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# When the validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, model goes back to training mode and gradients are enabled.\n",
    "def validation_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch\n",
    "    print(\"validation_step\")\n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    answer_loss, type_loss, sp_para_loss, sp_sent_loss, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output = output \n",
    "    loss = answer_loss +  type_loss + sp_para_loss + sp_sent_loss\n",
    "#     print(\"loss: \" + str(loss))\n",
    "\n",
    "    answers_pred, sp_sent_pred, sp_para_pred = self.decode(input_ids, start_logits, end_logits, type_logits, sp_para_output, sp_sent_output)\n",
    "    print(\"answers_pred: \" + str(answers_pred))\n",
    "    \n",
    "    # answers_pred only contains the top one predicted answer['text', 'score']\n",
    "#     answers_pred = sorted(answers_pred, key=lambda x: x['score'], reverse=True)[0:1] # each batch is one document\n",
    "#     print(\"answers_pred after sorted: \" + str(answers_pred))\n",
    "    if(len(answers_pred) != 1):\n",
    "        print(\"len(answers_pred) != 1\")\n",
    "        assert(len(answers_pred) == 1)\n",
    "    answers_pred = answers_pred[0]\n",
    "\n",
    "    answer_score = answers_pred['score']  # (start_logit + end_logit + p_type_score) / 3\n",
    "    print(\"answer_score: \" + str(answer_score))\n",
    "    \n",
    "    print(\"answer_text: \" + str(answers_pred['text'])) \n",
    "\n",
    "    if(q_type == 1):\n",
    "        answer_gold = 'yes'\n",
    "    elif(q_type == 2):\n",
    "        answer_gold = 'no' \n",
    "    else:\n",
    "        # even though there can be multiple gold start_postion (subword_start) and end_position(subword_end), the corresponing answer string are same\n",
    "        answer_gold_token_ids = input_ids[0, subword_starts[0][0]: subword_ends[0][0] + 1]\n",
    "        print(\"answer_gold_token_ids: \" + str(answer_gold_token_ids))\n",
    "        answer_gold_tokens = self.tokenizer.convert_ids_to_tokens(answer_gold_token_ids.tolist())\n",
    "        print(\"answer_gold_tokens: \" + str(answer_gold_tokens))\n",
    "        answer_gold = self.tokenizer.convert_tokens_to_string(answer_gold_tokens)\n",
    "    print(\"answer_gold: \" + str(answer_gold))\n",
    " \n",
    "    f1, prec, recall = self.f1_score(answers_pred['text'], answer_gold)\n",
    "    em = self.exact_match_score(answers_pred['text'], answer_gold) \n",
    "    print(\"f1: \" + str(f1))\n",
    "    print(\"prec: \" + str(prec))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"em: \" + str(em)) \n",
    "\n",
    "    if(len(sp_sent_pred) > 0):\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = self.sp_metrics(sp_sent_pred, torch.where(sp_sent.squeeze())[0].tolist())\n",
    "#         print(\"sp_sent_em: \" + str(sp_sent_em))\n",
    "#         print(\"sp_sent_precision: \" + str(sp_sent_precision))\n",
    "#         print(\"sp_sent_recall: \" + str(sp_sent_recall))    \n",
    "#         print(\"sp_sent_f1: \" + str(sp_sent_f1))    \n",
    "        \n",
    "        joint_prec = prec * sp_sent_precision\n",
    "        joint_recall = recall * sp_sent_recall\n",
    "        if joint_prec + joint_recall > 0:\n",
    "            joint_f1 = 2 * joint_prec * joint_recall / (joint_prec + joint_recall)\n",
    "        else:\n",
    "            joint_f1 = 0.\n",
    "        joint_em = em * sp_sent_em \n",
    "\n",
    "    else:\n",
    "        sp_sent_em, sp_sent_precision, sp_sent_recall, sp_sent_f1 = 0, 0, 0, 0\n",
    "        joint_em, joint_f1, joint_prec, joint_recall = 0, 0, 0, 0\n",
    "         \n",
    "\n",
    "    return {'qids': [qids], 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss,\n",
    "            'answer_score': [answer_score], 'f1': [f1], 'prec':[prec], 'recall':[recall], 'em': [em],\n",
    "            'sp_em': [sp_sent_em], 'sp_f1': [sp_sent_f1], 'sp_prec': [sp_sent_precision], 'sp_recall': [sp_sent_recall],\n",
    "            'joint_em': [joint_em], 'joint_f1': [joint_f1], 'joint_prec': [joint_prec], 'joint_recall': [joint_recall]}\n",
    "#     return {'qids': [qids], 'vloss': loss, 'answer_loss': answer_loss, 'type_loss': type_loss, 'sp_para_loss': sp_para_loss, 'sp_sent_loss': sp_sent_loss,\n",
    "#                 'answer_score': answer_score, 'f1': f1, 'prec':prec, 'recall':recall, 'em': em,\n",
    "#                 'sp_em': sp_sent_em, 'sp_f1': sp_sent_f1, 'sp_prec': sp_sent_precision, 'sp_recall': sp_sent_recall,\n",
    "#                 'joint_em': joint_em, 'joint_f1': joint_f1, 'joint_prec': joint_prec, 'joint_recall': joint_recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits):\n",
    "    print(\"decode\")\n",
    "    \n",
    "    question_end_index = self._get_special_index(input_ids, \"</q>\")\n",
    "#     print(\"question_end_index: \", question_end_index)\n",
    "    \n",
    "    # one example per batch\n",
    "    start_logits = start_logits.squeeze()\n",
    "    end_logits = end_logits.squeeze()\n",
    "#     print(\"start_logits: \", start_logits)\n",
    "#     print(\"end_logits: \", end_logits)\n",
    "    start_logits_indices = start_logits.topk(k=self.args.n_best_size, dim=-1).indices\n",
    "#     print(\"start_logits_indices: \", start_logits_indices)\n",
    "    end_logits_indices = end_logits.topk(k=self.args.n_best_size, dim=-1).indices \n",
    "    if(len(start_logits_indices.size()) > 1):\n",
    "        print(\"len(start_logits_indices.size()): \", len(start_logits_indices.size()))\n",
    "        assert(\"len(start_logits_indices.size()) > 1\")\n",
    "    p_type = torch.argmax(type_logits, dim=1).item()\n",
    "    p_type_score = torch.max(type_logits, dim=1)[0] \n",
    "#     print(\"type_logits: \", type_logits)\n",
    "#     print(\"p_type: \", p_type)\n",
    "#     print(\"p_type_score: \", p_type_score)\n",
    "    \n",
    "    answers = []\n",
    "    if p_type == 0:\n",
    "        potential_answers = []\n",
    "        for start_logit_index in start_logits_indices: \n",
    "            for end_logit_index in end_logits_indices: \n",
    "                if start_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if end_logit_index <= question_end_index.item():\n",
    "                    continue\n",
    "                if start_logit_index > end_logit_index:\n",
    "                    continue\n",
    "                answer_len = end_logit_index - start_logit_index + 1\n",
    "                if answer_len > self.args.max_answer_length:\n",
    "                    continue\n",
    "                potential_answers.append({'start': start_logit_index, 'end': end_logit_index,\n",
    "                                          'start_logit': start_logits[start_logit_index],  # single logit score for start position at start_logit_index\n",
    "                                          'end_logit': end_logits[end_logit_index]})    \n",
    "        sorted_answers = sorted(potential_answers, key=lambda x: (x['start_logit'] + x['end_logit']), reverse=True) \n",
    "#         print(\"sorted_answers: \" + str(sorted_answers))\n",
    "        if len(sorted_answers) == 0:\n",
    "            answers.append({'text': 'NoAnswerFound', 'score': -1000000})\n",
    "        else:\n",
    "            answer = sorted_answers[0]\n",
    "            answer_token_ids = input_ids[0, answer['start']: answer['end'] + 1]\n",
    "            answer_tokens = self.tokenizer.convert_ids_to_tokens(answer_token_ids.tolist())\n",
    "            text = self.tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "#             score = (answer['start_logit'] + answer['end_logit'] + p_type_score) / 3\n",
    "            score = (torch.sigmoid(answer['start_logit']) + torch.sigmoid(answer['end_logit']) + torch.sigmoid(p_type_score)) / 3\n",
    "            answers.append({'text': text, 'score': score})\n",
    "            print(\"answers: \" + str(answers))\n",
    "    elif p_type == 1: \n",
    "        answers.append({'text': 'yes', 'score': p_type_score})\n",
    "    elif p_type == 2:\n",
    "        answers.append({'text': 'no', 'score': p_type_score})\n",
    "    else:\n",
    "        assert False \n",
    "\n",
    "    p_index = self._get_special_index(input_ids, \"<p>\")\n",
    "#     print(\"p_index: \" + str(p_index))\n",
    "    s_index = self._get_special_index(input_ids, \"<s>\")\n",
    "#     print(\"s_index: \" + str(s_index))\n",
    "    sent_indexes = torch.sort(torch.cat((s_index, p_index)))[0]\n",
    "    \n",
    "    s_to_p_map = []\n",
    "    for s in sent_indexes:\n",
    "        s_to_p = torch.where(torch.le(p_index, s))[0][-1]     # last p_index smaller or equal to s\n",
    "        s_to_p_map.append(s_to_p.item()) \n",
    "#     print(\"s_to_p_map: \" + str(s_to_p_map))\n",
    "    \n",
    "#     print(\"sp_para_logits\", sp_para_logits)\n",
    "#     print(\"sp_sent_logits\", sp_sent_logits)\n",
    "\n",
    "#     print(\"sp_para_logits.squeeze().size(0): \", sp_para_logits.squeeze().size(0))\n",
    "#     print(\"sp_sent_logits.squeeze().size(0): \", sp_sent_logits.squeeze().size(0))\n",
    "    sp_para_top2 = sp_para_logits.squeeze().topk(k=2).indices\n",
    "    if(sp_sent_logits.squeeze().size(0) > 12):\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=12).indices\n",
    "    else:\n",
    "        sp_sent_top12 = sp_sent_logits.squeeze().topk(k=sp_sent_logits.squeeze().size(0)).indices\n",
    "#     print(\"sp_para_top2\", sp_para_top2)\n",
    "#     print(\"sp_sent_top12\", sp_sent_top12)\n",
    "    \n",
    "    sp_sent_pred = set()\n",
    "    sp_para_pred = set()\n",
    "    for sp_sent in sp_sent_top12:\n",
    "        sp_sent_to_para = s_to_p_map[sp_sent.item()]\n",
    "        if sp_sent_to_para in sp_para_top2:\n",
    "            sp_sent_pred.add(sp_sent.item())\n",
    "            sp_para_pred.add(sp_sent_to_para) \n",
    "#     print(\"sp_sent_pred: \" + str(sp_sent_pred))\n",
    "#     print(\"sp_para_pred: \" + str(sp_para_pred))\n",
    "    return (answers, sp_sent_pred, sp_para_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def normalize_answer(self, s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(self, prediction, ground_truth):\n",
    "    normalized_prediction = self.normalize_answer(prediction)\n",
    "    normalized_ground_truth = self.normalize_answer(ground_truth)\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "    \n",
    "    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def exact_match_score(self, prediction, ground_truth):\n",
    "    return int(self.normalize_answer(prediction) == self.normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def sp_metrics(self, prediction, gold):\n",
    "#     print(\"prediction: \", prediction)\n",
    "#     print(\"gold: \", gold)\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for e in prediction:\n",
    "        if e in gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "#             print(\"e: \", e)\n",
    "#             print(\"gold: \", gold)\n",
    "#             print(\"e not in gold!!!\")\n",
    "    for e in gold:\n",
    "        if e not in prediction:\n",
    "            fn += 1\n",
    "#             print(\"e: \", e)\n",
    "#             print(\"prediction: \", prediction)\n",
    "#             print(\"e not in prediction!!!\")\n",
    "    prec = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "#     print(\"sp prec: \", prec)\n",
    "#     print(\"sp recall: \", recall)\n",
    "#     print(\"sp f1: \", f1)\n",
    "#     print(\"sp em: \", em)\n",
    "    return em, prec, recall, f1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "# If a validation_step is not defined, this won't be called. Called at the end of the validation loop with the outputs of validation_step.\n",
    "def validation_end(self, outputs):\n",
    "    print(\"validation_end\")\n",
    "    avg_loss = torch.stack([x['vloss'] for x in outputs]).mean()  \n",
    "    avg_answer_loss = torch.stack([x['answer_loss'] for x in outputs]).mean()  \n",
    "    avg_type_loss = torch.stack([x['type_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_para_loss = torch.stack([x['sp_para_loss'] for x in outputs]).mean()  \n",
    "    avg_sp_sent_loss = torch.stack([x['sp_sent_loss'] for x in outputs]).mean()  \n",
    "        \n",
    "    string_qids = [item for sublist in outputs for item in sublist['qids']]\n",
    "    int_qids = [self.val_dataloader_object.dataset.val_qid_string_to_int_map[qid] for qid in string_qids]\n",
    "    answer_scores = [item for sublist in outputs for item in sublist['answer_score']] #torch.stack([x['answer_score'] for x in outputs]).mean() # \n",
    "    f1_scores = [item for sublist in outputs for item in sublist['f1']] #torch.stack([x['f1'] for x in outputs]).mean()  #\n",
    "    em_scores = [item for sublist in outputs for item in sublist['em']] #torch.stack([x['em'] for x in outputs]).mean()  #\n",
    "    prec_scores = [item for sublist in outputs for item in sublist['prec']] #torch.stack([x['prec'] for x in outputs]).mean()  #\n",
    "    recall_scores = [item for sublist in outputs for item in sublist['recall']]  #torch.stack([x['recall'] for x in outputs]).mean()  #\n",
    "    \n",
    "    sp_sent_f1_scores = [item for sublist in outputs for item in sublist['sp_f1']] #torch.stack([x['sp_f1'] for x in outputs]).mean() #\n",
    "    sp_sent_em_scores = [item for sublist in outputs for item in sublist['sp_em']] #torch.stack([x['sp_em'] for x in outputs]).mean() #\n",
    "    sp_sent_prec_scores = [item for sublist in outputs for item in sublist['sp_prec']] #torch.stack([x['sp_prec'] for x in outputs]).mean() #\n",
    "    sp_sent_recall_scores = [item for sublist in outputs for item in sublist['sp_recall']]  #torch.stack([x['sp_recall'] for x in outputs]).mean() #\n",
    "     \n",
    "    joint_f1_scores = [item for sublist in outputs for item in sublist['joint_f1']] #torch.stack([x['joint_f1'] for x in outputs]).mean() #\n",
    "    joint_em_scores = [item for sublist in outputs for item in sublist['joint_em']] #torch.stack([x['joint_em'] for x in outputs]).mean() #\n",
    "    joint_prec_scores = [item for sublist in outputs for item in sublist['joint_prec']] #torch.stack([x['joint_prec'] for x in outputs]).mean() #\n",
    "    joint_recall_scores = [item for sublist in outputs for item in sublist['joint_recall']] #torch.stack([x['joint_recall'] for x in outputs]).mean() #     \n",
    "\n",
    "    print(f'before sync --> sizes: {len(int_qids)}, {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "    if self.trainer.use_ddp:\n",
    "        torch.distributed.all_reduce(avg_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_answer_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_answer_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_type_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_type_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_para_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_para_loss /= self.trainer.world_size \n",
    "        torch.distributed.all_reduce(avg_sp_sent_loss, op=torch.distributed.ReduceOp.SUM)\n",
    "        avg_sp_sent_loss /= self.trainer.world_size \n",
    "\n",
    "        int_qids = self.sync_list_across_gpus(int_qids, avg_loss.device, torch.int)\n",
    "        answer_scores = self.sync_list_across_gpus(answer_scores, avg_loss.device, torch.float)\n",
    "        f1_scores = self.sync_list_across_gpus(f1_scores, avg_loss.device, torch.float)\n",
    "        em_scores = self.sync_list_across_gpus(em_scores, avg_loss.device, torch.float)\n",
    "        prec_scores = self.sync_list_across_gpus(prec_scores, avg_loss.device, torch.float)\n",
    "        recall_scores = self.sync_list_across_gpus(recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        sp_sent_f1_scores = self.sync_list_across_gpus(sp_sent_f1_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_em_scores = self.sync_list_across_gpus(sp_sent_em_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_prec_scores = self.sync_list_across_gpus(sp_sent_prec_scores, avg_loss.device, torch.float)\n",
    "        sp_sent_recall_scores = self.sync_list_across_gpus(sp_sent_recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        joint_f1_scores = self.sync_list_across_gpus(joint_f1_scores, avg_loss.device, torch.float)\n",
    "        joint_em_scores = self.sync_list_across_gpus(joint_em_scores, avg_loss.device, torch.float)\n",
    "        joint_prec_scores = self.sync_list_across_gpus(joint_prec_scores, avg_loss.device, torch.float)\n",
    "        joint_recall_scores = self.sync_list_across_gpus(joint_recall_scores, avg_loss.device, torch.float)\n",
    "        \n",
    "        \n",
    "    print(f'after sync --> sizes: {len(int_qids)}, {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}')\n",
    "    print(\"answer_scores: \", answer_scores)\n",
    "    print(\"f1_scores: \", f1_scores)\n",
    "    print(\"em_scores: \", em_scores)\n",
    "    \n",
    "    print(\"avg_loss: \", avg_loss, end = '\\t') \n",
    "    print(\"avg_answer_loss: \", avg_answer_loss, end = '\\t') \n",
    "    print(\"avg_type_loss: \", avg_type_loss, end = '\\t') \n",
    "    print(\"avg_sp_para_loss: \", avg_sp_para_loss, end = '\\t') \n",
    "    print(\"avg_sp_sent_loss: \", avg_sp_sent_loss, end = '\\t')  \n",
    "        \n",
    "    avg_val_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    print(\"len(f1_scores): \", len(f1_scores))\n",
    "    print(\"avg_val_f1: \", avg_val_f1)\n",
    "    avg_val_em = sum(em_scores) / len(em_scores)\n",
    "#     print(\"len(em_scores): \", len(em_scores))\n",
    "    print(\"avg_val_em: \", avg_val_em)\n",
    "    avg_val_prec = sum(prec_scores) / len(prec_scores)\n",
    "#     print(\"len(prec_scores): \", len(prec_scores))\n",
    "    print(\"avg_val_prec: \", avg_val_prec)\n",
    "    avg_val_recall = sum(recall_scores) / len(recall_scores) \n",
    "#     print(\"len(recall_scores): \", len(recall_scores))\n",
    "    print(\"avg_val_recall: \", avg_val_recall)\n",
    "    \n",
    "    avg_val_sp_sent_f1 = sum(sp_sent_f1_scores) / len(sp_sent_f1_scores)\n",
    "    print(\"avg_val_sp_sent_f1: \", avg_val_sp_sent_f1)\n",
    "    avg_val_sp_sent_em = sum(sp_sent_em_scores) / len(sp_sent_em_scores)\n",
    "    print(\"avg_val_sp_sent_em: \", avg_val_sp_sent_em)\n",
    "    avg_val_sp_sent_prec = sum(sp_sent_prec_scores) / len(sp_sent_prec_scores)\n",
    "    print(\"avg_val_sp_sent_prec: \", avg_val_sp_sent_prec)\n",
    "    avg_val_sp_sent_recall = sum(sp_sent_recall_scores) / len(sp_sent_recall_scores) \n",
    "    print(\"avg_val_sp_sent_recall: \", avg_val_sp_sent_recall)\n",
    "        \n",
    "    avg_val_joint_f1 = sum(joint_f1_scores) / len(joint_f1_scores)\n",
    "    print(\"avg_val_joint_f1: \", avg_val_joint_f1)\n",
    "    avg_val_joint_em = sum(joint_em_scores) / len(joint_em_scores)\n",
    "    print(\"avg_val_joint_em: \", avg_val_joint_em)\n",
    "    avg_val_joint_prec = sum(joint_prec_scores) / len(joint_prec_scores)\n",
    "    print(\"avg_val_joint_prec: \", avg_val_joint_prec)\n",
    "    avg_val_joint_recall = sum(joint_recall_scores) / len(joint_recall_scores) \n",
    "    print(\"avg_val_joint_recall: \", avg_val_joint_recall)\n",
    "     \n",
    "    \n",
    "    \n",
    "#     print(\"avg_loss: \", avg_loss)\n",
    "    \n",
    "    logs = {'avg_val_loss': avg_loss, 'avg_val_answer_loss': avg_answer_loss, 'avg_val_type_loss': avg_type_loss, 'avg_val_sp_para_loss': avg_sp_para_loss, 'avg_val_sp_sent_loss': avg_sp_sent_loss, \n",
    "            'avg_val_f1': avg_val_f1, 'avg_val_em': avg_val_em,  'avg_val_prec': avg_val_prec, 'avg_val_recall': avg_val_recall,\n",
    "            'avg_val_sp_sent_f1': avg_val_sp_sent_f1, 'avg_val_sp_sent_em': avg_val_sp_sent_em,  'avg_val_sp_sent_prec': avg_val_sp_sent_prec, 'avg_val_sp_sent_recall': avg_val_sp_sent_recall,\n",
    "            'avg_val_joint_f1': avg_val_joint_f1, 'avg_val_joint_em': avg_val_joint_em,  'avg_val_joint_prec': avg_val_joint_prec, 'avg_val_joint_recall': avg_val_joint_recall\n",
    "           }\n",
    "\n",
    "    return {'avg_val_loss': avg_loss, 'log': logs}\n",
    "\n",
    "#     answer_scores =  torch.stack([x['answer_score'] for x in outputs]).mean() # \n",
    "#     f1_scores =  torch.stack([x['f1'] for x in outputs]).mean()  #\n",
    "#     em_scores =  torch.stack([x['em'] for x in outputs]).mean()  #\n",
    "#     prec_scores =  torch.stack([x['prec'] for x in outputs]).mean()  #\n",
    "#     recall_scores =  torch.stack([x['recall'] for x in outputs]).mean()  #\n",
    "    \n",
    "#     sp_sent_f1_scores =  torch.stack([x['sp_f1'] for x in outputs]).mean() #\n",
    "#     sp_sent_em_scores =  torch.stack([x['sp_em'] for x in outputs]).mean() #\n",
    "#     sp_sent_prec_scores =  torch.stack([x['sp_prec'] for x in outputs]).mean() #\n",
    "#     sp_sent_recall_scores =  torch.stack([x['sp_recall'] for x in outputs]).mean() #\n",
    "     \n",
    "#     joint_f1_scores =  torch.stack([x['joint_f1'] for x in outputs]).mean() #\n",
    "#     joint_em_scores =  torch.stack([x['joint_em'] for x in outputs]).mean() #\n",
    "#     joint_prec_scores =  torch.stack([x['joint_prec'] for x in outputs]).mean() #\n",
    "#     joint_recall_scores = torch.stack([x['joint_recall'] for x in outputs]).mean() #     \n",
    "\n",
    "#     return {'avg_val_loss': avg_loss}\n",
    "\n",
    "def sync_list_across_gpus(self, l, device, dtype):\n",
    "    l_tensor = torch.tensor(l, device=device, dtype=dtype)\n",
    "    gather_l_tensor = [torch.ones_like(l_tensor) for _ in range(self.trainer.world_size)]\n",
    "    torch.distributed.all_gather(gather_l_tensor, l_tensor)\n",
    "    return torch.cat(gather_l_tensor).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_step(self, batch, batch_nb):\n",
    "    input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para, qids = batch\n",
    "    output = self.forward(input_ids, input_mask, segment_ids, subword_starts, subword_ends, q_type, sp_sent, sp_para)\n",
    "    loss, start_logits, end_logits = output[:3]\n",
    "    answers = self.decode(input_ids, start_logits, end_logits)\n",
    "\n",
    "    # each batch is one document\n",
    "    answers = sorted(answers, key=lambda x: x['score'], reverse=True)[0:1]\n",
    "    qids = [qids]\n",
    "    assert len(answers) == len(qids)\n",
    "    return {'qids': qids, 'answers': answers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "def test_end(self, outputs):\n",
    "    qids = [item for sublist in outputs for item in sublist['qids']]\n",
    "    answers = [item for sublist in outputs for item in sublist['answers']]\n",
    "\n",
    "    qa_with_duplicates = defaultdict(list)\n",
    "    for qid, answer in zip(qids, answers):\n",
    "        qa_with_duplicates[qid].append({'answer_score': answer['score'], 'answer_text': answer['text'], })\n",
    "\n",
    "    qid_to_answer_text = {}\n",
    "    for qid, answer_metrics in qa_with_duplicates.items():\n",
    "        top_answer = sorted(answer_metrics, key=lambda x: x['answer_score'], reverse=True)[0]\n",
    "        qid_to_answer_text[qid] = top_answer['answer_text']\n",
    "\n",
    "    with open('predictions.json', 'w') as f:\n",
    "        json.dump(qid_to_answer_text, f)\n",
    "\n",
    "    return {'count': len(qid_to_answer_text)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add_model_specific_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to hotpotqa\n",
    "@staticmethod\n",
    "def add_model_specific_args(parser, root_dir):\n",
    "    parser.add_argument(\"--save_dir\", type=str, default='jupyter-hotpotqa')\n",
    "    parser.add_argument(\"--save_prefix\", type=str, required=True)\n",
    "    parser.add_argument(\"--train_dataset\", type=str, required=False, help=\"Path to the training squad-format\")\n",
    "    parser.add_argument(\"--dev_dataset\", type=str, required=True, help=\"Path to the dev squad-format\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2, help=\"Batch size\")\n",
    "    parser.add_argument(\"--gpus\", type=str, default='0',\n",
    "                        help=\"Comma separated list of gpus. Default is gpu 0. To use CPU, use --gpus \"\" \")\n",
    "    parser.add_argument(\"--warmup\", type=int, default=1000, help=\"Number of warmup steps\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.00005, help=\"Maximum learning rate\")\n",
    "    parser.add_argument(\"--val_every\", type=float, default=1.0, help=\"How often within one training epoch to check the validation set.\")\n",
    "    parser.add_argument(\"--val_percent_check\", default=1.00, type=float, help='Percent of validation data used')\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=4, help=\"Number of data loader workers\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=1234, help=\"Seed\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=6, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=4096,\n",
    "                        help=\"Maximum length of seq passed to the transformer model\")\n",
    "    parser.add_argument(\"--max_doc_len\", type=int, default=4096,\n",
    "                        help=\"Maximum number of wordpieces of the input document\")\n",
    "    parser.add_argument(\"--max_num_answers\", type=int, default=64,\n",
    "                        help=\"Maximum number of answer spans per document (64 => 94%)\")\n",
    "    parser.add_argument(\"--max_question_len\", type=int, default=55,\n",
    "                        help=\"Maximum length of the question\")\n",
    "    parser.add_argument(\"--doc_stride\", type=int, default=-1,\n",
    "                        help=\"Overlap between document chunks. Use -1 to only use the first chunk\")\n",
    "    parser.add_argument(\"--ignore_seq_with_no_answers\", action='store_true',\n",
    "                        help=\"each example should have at least one answer. Default is False\")\n",
    "    parser.add_argument(\"--disable_checkpointing\", action='store_true', help=\"No logging or checkpointing\")\n",
    "    parser.add_argument(\"--n_best_size\", type=int, default=20,\n",
    "                        help=\"Number of answer candidates. Used at decoding time\")\n",
    "    parser.add_argument(\"--max_answer_length\", type=int, default=30,\n",
    "                        help=\"maximum num of wordpieces/answer. Used at decoding time\")\n",
    "    parser.add_argument(\"--regular_softmax_loss\", action='store_true', help=\"IF true, use regular softmax. Default is using ORed softmax loss\")\n",
    "    parser.add_argument(\"--test\", action='store_true', help=\"Test only, no training\")\n",
    "    parser.add_argument(\"--model_path\", type=str,\n",
    "                        help=\"Path to the checkpoint directory\")\n",
    "    parser.add_argument(\"--no_progress_bar\", action='store_true', help=\"no progress bar. Good for printing\")\n",
    "    parser.add_argument(\"--attention_mode\", type=str, choices=['tvm', 'sliding_chunks'],\n",
    "                        default='sliding_chunks', help='Which implementation of selfattention to use')\n",
    "    parser.add_argument(\"--fp32\", action='store_true', help=\"default is fp16. Use --fp32 to switch to fp32\")\n",
    "    parser.add_argument('--train_percent', type=float, default=1.0)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### class info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_apply',\n",
       " '_call_impl',\n",
       " '_forward_unimplemented',\n",
       " '_get_name',\n",
       " '_get_special_index',\n",
       " '_load_from_state_dict',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " 'add_model_specific_args',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'configure_apex',\n",
       " 'configure_ddp',\n",
       " 'configure_optimizers',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'decode',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'exact_match_score',\n",
       " 'extra_repr',\n",
       " 'f1_score',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'grad_norm',\n",
       " 'half',\n",
       " 'init_ddp_connection',\n",
       " 'load_from_checkpoint',\n",
       " 'load_from_metrics',\n",
       " 'load_model',\n",
       " 'load_state_dict',\n",
       " 'loss_computation',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'normalize_answer',\n",
       " 'on_after_backward',\n",
       " 'on_batch_end',\n",
       " 'on_batch_start',\n",
       " 'on_before_zero_grad',\n",
       " 'on_epoch_end',\n",
       " 'on_epoch_start',\n",
       " 'on_hpc_load',\n",
       " 'on_hpc_save',\n",
       " 'on_load_checkpoint',\n",
       " 'on_post_performance_check',\n",
       " 'on_pre_performance_check',\n",
       " 'on_sanity_check_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_train_end',\n",
       " 'on_train_start',\n",
       " 'optimizer_step',\n",
       " 'or_softmax_cross_entropy_loss_one_doc',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'sp_metrics',\n",
       " 'state_dict',\n",
       " 'summarize',\n",
       " 'sync_list_across_gpus',\n",
       " 'tbptt_split_batch',\n",
       " 'test_dataloader',\n",
       " 'test_end',\n",
       " 'test_step',\n",
       " 'tng_dataloader',\n",
       " 'to',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'training_end',\n",
       " 'training_step',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'val_dataloader',\n",
       " 'validation_end',\n",
       " 'validation_step',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T_destination', ~T_destination),\n",
       " ('__abstractmethods__', frozenset({'configure_optimizers', 'training_step'})),\n",
       " ('__annotations__',\n",
       "  {'dump_patches': bool,\n",
       "   '_version': int,\n",
       "   'training': bool,\n",
       "   'forward': typing.Callable[..., typing.Any],\n",
       "   '__call__': typing.Callable[..., typing.Any]}),\n",
       " ('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__class__', abc.ABCMeta),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dict__',\n",
       "  mappingproxy({'__module__': '__main__',\n",
       "                '__init__': <function __main__.hotpotqa.__init__(self, args)>,\n",
       "                'load_model': <function __main__.hotpotqa.load_model(self)>,\n",
       "                'train_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>,\n",
       "                'val_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>,\n",
       "                'test_dataloader': <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>,\n",
       "                'forward': <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>,\n",
       "                'loss_computation': <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>,\n",
       "                '_get_special_index': <function __main__.hotpotqa._get_special_index(self, input_ids, special_token)>,\n",
       "                'or_softmax_cross_entropy_loss_one_doc': <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>,\n",
       "                '__doc__': None,\n",
       "                '__abstractmethods__': frozenset({'configure_optimizers',\n",
       "                           'training_step'}),\n",
       "                '_abc_registry': <_weakrefset.WeakSet at 0x7f0165f233c8>,\n",
       "                '_abc_cache': <_weakrefset.WeakSet at 0x7f0165f23470>,\n",
       "                '_abc_negative_cache': <_weakrefset.WeakSet at 0x7f0165f23550>,\n",
       "                '_abc_negative_cache_version': 228,\n",
       "                'configure_ddp': <function __main__.configure_ddp(self, model, device_ids)>,\n",
       "                'configure_optimizers': <function __main__.configure_optimizers(self)>,\n",
       "                'optimizer_step': <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>,\n",
       "                'on_epoch_start': <function __main__.on_epoch_start(self)>,\n",
       "                'training_step': <function __main__.training_step(self, batch, batch_nb)>,\n",
       "                'validation_step': <function __main__.validation_step(self, batch, batch_nb)>,\n",
       "                'decode': <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>,\n",
       "                'normalize_answer': <function __main__.normalize_answer(self, s)>,\n",
       "                'f1_score': <function __main__.f1_score(self, prediction, ground_truth)>,\n",
       "                'exact_match_score': <function __main__.exact_match_score(self, prediction, ground_truth)>,\n",
       "                'sp_metrics': <function __main__.sp_metrics(self, prediction, gold)>,\n",
       "                'validation_end': <function __main__.validation_end(self, outputs)>,\n",
       "                'sync_list_across_gpus': <function __main__.sync_list_across_gpus(self, l, device, dtype)>,\n",
       "                'test_step': <function __main__.test_step(self, batch, batch_nb)>,\n",
       "                'test_end': <function __main__.test_end(self, outputs)>,\n",
       "                'add_model_specific_args': <staticmethod at 0x7f0165f6b518>})),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__doc__', None),\n",
       " ('__eq__', <slot wrapper '__eq__' of 'object' objects>),\n",
       " ('__format__', <method '__format__' of 'object' objects>),\n",
       " ('__ge__', <slot wrapper '__ge__' of 'object' objects>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__getattribute__', <slot wrapper '__getattribute__' of 'object' objects>),\n",
       " ('__gt__', <slot wrapper '__gt__' of 'object' objects>),\n",
       " ('__hash__', <slot wrapper '__hash__' of 'object' objects>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__init_subclass__', <function hotpotqa.__init_subclass__>),\n",
       " ('__le__', <slot wrapper '__le__' of 'object' objects>),\n",
       " ('__lt__', <slot wrapper '__lt__' of 'object' objects>),\n",
       " ('__module__', '__main__'),\n",
       " ('__ne__', <slot wrapper '__ne__' of 'object' objects>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <method '__reduce__' of 'object' objects>),\n",
       " ('__reduce_ex__', <method '__reduce_ex__' of 'object' objects>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('__sizeof__', <method '__sizeof__' of 'object' objects>),\n",
       " ('__str__', <slot wrapper '__str__' of 'object' objects>),\n",
       " ('__subclasshook__', <function hotpotqa.__subclasshook__>),\n",
       " ('__weakref__', <attribute '__weakref__' of 'ABC' objects>),\n",
       " ('_abc_cache', <_weakrefset.WeakSet at 0x7f0165f23470>),\n",
       " ('_abc_negative_cache', <_weakrefset.WeakSet at 0x7f0165f23550>),\n",
       " ('_abc_negative_cache_version', 228),\n",
       " ('_abc_registry', <_weakrefset.WeakSet at 0x7f0165f233c8>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_token)>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('_version', 1),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, use_amp, loss, optimizer)>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp, model, optimizers, amp_level)>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu', <function torch.nn.modules.module.Module.cpu(self:~T) -> ~T>),\n",
       " ('cuda',\n",
       "  <function torch.nn.modules.module.Module.cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('double', <function torch.nn.modules.module.Module.double(self:~T) -> ~T>),\n",
       " ('dump_patches', False),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float', <function torch.nn.modules.module.Module.float(self:~T) -> ~T>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self)>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type)>),\n",
       " ('half', <function torch.nn.modules.module.Module.half(self:~T) -> ~T>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, proc_rank, world_size)>),\n",
       " ('load_from_checkpoint',\n",
       "  <bound method LightningModule.load_from_checkpoint of <class '__main__.hotpotqa'>>),\n",
       " ('load_from_metrics',\n",
       "  <bound method LightningModule.load_from_metrics of <class '__main__.hotpotqa'>>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('normalize_answer', <function __main__.normalize_answer(self, s)>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self)>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self)>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch)>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer)>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self)>),\n",
       " ('on_epoch_start', <function __main__.on_epoch_start(self)>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint)>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint)>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint)>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self)>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self)>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint)>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self)>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self)>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode)>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch, split_size)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('to', <function torch.nn.modules.module.Module.to(self, *args, **kwargs)>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_nb)>),\n",
       " ('type',\n",
       "  <function torch.nn.modules.module.Module.type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self)>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "getmembers(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__call__',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('__delattr__',\n",
       "  <function torch.nn.modules.module.Module.__delattr__(self, name)>),\n",
       " ('__dir__', <function torch.nn.modules.module.Module.__dir__(self)>),\n",
       " ('__getattr__',\n",
       "  <function torch.nn.modules.module.Module.__getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]>),\n",
       " ('__init__', <function __main__.hotpotqa.__init__(self, args)>),\n",
       " ('__repr__', <function torch.nn.modules.module.Module.__repr__(self)>),\n",
       " ('__setattr__',\n",
       "  <function torch.nn.modules.module.Module.__setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None>),\n",
       " ('__setstate__',\n",
       "  <function torch.nn.modules.module.Module.__setstate__(self, state)>),\n",
       " ('_apply', <function torch.nn.modules.module.Module._apply(self, fn)>),\n",
       " ('_call_impl',\n",
       "  <function torch.nn.modules.module.Module._call_impl(self, *input, **kwargs)>),\n",
       " ('_forward_unimplemented',\n",
       "  <function torch.nn.modules.module.Module._forward_unimplemented(self, *input:Any) -> None>),\n",
       " ('_get_name', <function torch.nn.modules.module.Module._get_name(self)>),\n",
       " ('_get_special_index',\n",
       "  <function __main__.hotpotqa._get_special_index(self, input_ids, special_token)>),\n",
       " ('_load_from_state_dict',\n",
       "  <function torch.nn.modules.module.Module._load_from_state_dict(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)>),\n",
       " ('_named_members',\n",
       "  <function torch.nn.modules.module.Module._named_members(self, get_members_fn, prefix='', recurse=True)>),\n",
       " ('_register_load_state_dict_pre_hook',\n",
       "  <function torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self, hook)>),\n",
       " ('_register_state_dict_hook',\n",
       "  <function torch.nn.modules.module.Module._register_state_dict_hook(self, hook)>),\n",
       " ('_replicate_for_data_parallel',\n",
       "  <function torch.nn.modules.module.Module._replicate_for_data_parallel(self)>),\n",
       " ('_save_to_state_dict',\n",
       "  <function torch.nn.modules.module.Module._save_to_state_dict(self, destination, prefix, keep_vars)>),\n",
       " ('_slow_forward',\n",
       "  <function torch.nn.modules.module.Module._slow_forward(self, *input, **kwargs)>),\n",
       " ('add_model_specific_args',\n",
       "  <function __main__.add_model_specific_args(parser, root_dir)>),\n",
       " ('add_module',\n",
       "  <function torch.nn.modules.module.Module.add_module(self, name:str, module:'Module') -> None>),\n",
       " ('apply',\n",
       "  <function torch.nn.modules.module.Module.apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T>),\n",
       " ('backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.backward(self, use_amp, loss, optimizer)>),\n",
       " ('bfloat16',\n",
       "  <function torch.nn.modules.module.Module.bfloat16(self:~T) -> ~T>),\n",
       " ('buffers',\n",
       "  <function torch.nn.modules.module.Module.buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]>),\n",
       " ('children',\n",
       "  <function torch.nn.modules.module.Module.children(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('configure_apex',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.configure_apex(self, amp, model, optimizers, amp_level)>),\n",
       " ('configure_ddp', <function __main__.configure_ddp(self, model, device_ids)>),\n",
       " ('configure_optimizers', <function __main__.configure_optimizers(self)>),\n",
       " ('cpu', <function torch.nn.modules.module.Module.cpu(self:~T) -> ~T>),\n",
       " ('cuda',\n",
       "  <function torch.nn.modules.module.Module.cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T>),\n",
       " ('decode',\n",
       "  <function __main__.decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)>),\n",
       " ('double', <function torch.nn.modules.module.Module.double(self:~T) -> ~T>),\n",
       " ('eval', <function torch.nn.modules.module.Module.eval(self:~T) -> ~T>),\n",
       " ('exact_match_score',\n",
       "  <function __main__.exact_match_score(self, prediction, ground_truth)>),\n",
       " ('extra_repr',\n",
       "  <function torch.nn.modules.module.Module.extra_repr(self) -> str>),\n",
       " ('f1_score', <function __main__.f1_score(self, prediction, ground_truth)>),\n",
       " ('float', <function torch.nn.modules.module.Module.float(self:~T) -> ~T>),\n",
       " ('forward',\n",
       "  <function __main__.hotpotqa.forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)>),\n",
       " ('freeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.freeze(self)>),\n",
       " ('grad_norm',\n",
       "  <function pytorch_lightning.core.grads.GradInformation.grad_norm(self, norm_type)>),\n",
       " ('half', <function torch.nn.modules.module.Module.half(self:~T) -> ~T>),\n",
       " ('init_ddp_connection',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.init_ddp_connection(self, proc_rank, world_size)>),\n",
       " ('load_model', <function __main__.hotpotqa.load_model(self)>),\n",
       " ('load_state_dict',\n",
       "  <function torch.nn.modules.module.Module.load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)>),\n",
       " ('loss_computation',\n",
       "  <function __main__.hotpotqa.loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)>),\n",
       " ('modules',\n",
       "  <function torch.nn.modules.module.Module.modules(self) -> Iterator[_ForwardRef('Module')]>),\n",
       " ('named_buffers',\n",
       "  <function torch.nn.modules.module.Module.named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('named_children',\n",
       "  <function torch.nn.modules.module.Module.named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]>),\n",
       " ('named_modules',\n",
       "  <function torch.nn.modules.module.Module.named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')>),\n",
       " ('named_parameters',\n",
       "  <function torch.nn.modules.module.Module.named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]>),\n",
       " ('normalize_answer', <function __main__.normalize_answer(self, s)>),\n",
       " ('on_after_backward',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_after_backward(self)>),\n",
       " ('on_batch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_end(self)>),\n",
       " ('on_batch_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_batch_start(self, batch)>),\n",
       " ('on_before_zero_grad',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_before_zero_grad(self, optimizer)>),\n",
       " ('on_epoch_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_epoch_end(self)>),\n",
       " ('on_epoch_start', <function __main__.on_epoch_start(self)>),\n",
       " ('on_hpc_load',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_load(self, checkpoint)>),\n",
       " ('on_hpc_save',\n",
       "  <function pytorch_lightning.core.saving.ModelIO.on_hpc_save(self, checkpoint)>),\n",
       " ('on_load_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_load_checkpoint(self, checkpoint)>),\n",
       " ('on_post_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_post_performance_check(self)>),\n",
       " ('on_pre_performance_check',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_pre_performance_check(self)>),\n",
       " ('on_sanity_check_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_sanity_check_start(self)>),\n",
       " ('on_save_checkpoint',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.on_save_checkpoint(self, checkpoint)>),\n",
       " ('on_train_end',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_end(self)>),\n",
       " ('on_train_start',\n",
       "  <function pytorch_lightning.core.hooks.ModelHooks.on_train_start(self)>),\n",
       " ('optimizer_step',\n",
       "  <function __main__.optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)>),\n",
       " ('or_softmax_cross_entropy_loss_one_doc',\n",
       "  <function __main__.hotpotqa.or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)>),\n",
       " ('parameters',\n",
       "  <function torch.nn.modules.module.Module.parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]>),\n",
       " ('register_backward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_buffer',\n",
       "  <function torch.nn.modules.module.Module.register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None>),\n",
       " ('register_forward_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_forward_pre_hook',\n",
       "  <function torch.nn.modules.module.Module.register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle>),\n",
       " ('register_parameter',\n",
       "  <function torch.nn.modules.module.Module.register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None>),\n",
       " ('requires_grad_',\n",
       "  <function torch.nn.modules.module.Module.requires_grad_(self:~T, requires_grad:bool=True) -> ~T>),\n",
       " ('share_memory',\n",
       "  <function torch.nn.modules.module.Module.share_memory(self:~T) -> ~T>),\n",
       " ('sp_metrics', <function __main__.sp_metrics(self, prediction, gold)>),\n",
       " ('state_dict',\n",
       "  <function torch.nn.modules.module.Module.state_dict(self, destination=None, prefix='', keep_vars=False)>),\n",
       " ('summarize',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.summarize(self, mode)>),\n",
       " ('sync_list_across_gpus',\n",
       "  <function __main__.sync_list_across_gpus(self, l, device, dtype)>),\n",
       " ('tbptt_split_batch',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.tbptt_split_batch(self, batch, split_size)>),\n",
       " ('test_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('test_end', <function __main__.test_end(self, outputs)>),\n",
       " ('test_step', <function __main__.test_step(self, batch, batch_nb)>),\n",
       " ('tng_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('to', <function torch.nn.modules.module.Module.to(self, *args, **kwargs)>),\n",
       " ('train',\n",
       "  <function torch.nn.modules.module.Module.train(self:~T, mode:bool=True) -> ~T>),\n",
       " ('train_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('training_end',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.training_end(self, *args, **kwargs)>),\n",
       " ('training_step', <function __main__.training_step(self, batch, batch_nb)>),\n",
       " ('type',\n",
       "  <function torch.nn.modules.module.Module.type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T>),\n",
       " ('unfreeze',\n",
       "  <function pytorch_lightning.core.lightning.LightningModule.unfreeze(self)>),\n",
       " ('val_dataloader',\n",
       "  <function pytorch_lightning.core.decorators.data_loader.<locals>._get_data_loader(self)>),\n",
       " ('validation_end', <function __main__.validation_end(self, outputs)>),\n",
       " ('validation_step',\n",
       "  <function __main__.validation_step(self, batch, batch_nb)>),\n",
       " ('zero_grad',\n",
       "  <function torch.nn.modules.module.Module.zero_grad(self) -> None>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions_list = [o for o in getmembers(hotpotqa) if isfunction(o[1])]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.hotpotqa,\n",
       " pytorch_lightning.core.lightning.LightningModule,\n",
       " abc.ABC,\n",
       " pytorch_lightning.core.grads.GradInformation,\n",
       " pytorch_lightning.core.saving.ModelIO,\n",
       " pytorch_lightning.core.hooks.ModelHooks,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmro(hotpotqa)  # a hierarchy of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class hotpotqa in module __main__:\n",
      "\n",
      "class hotpotqa(pytorch_lightning.core.lightning.LightningModule)\n",
      " |  Helper class that provides a standard way to create an ABC using\n",
      " |  inheritance.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      hotpotqa\n",
      " |      pytorch_lightning.core.lightning.LightningModule\n",
      " |      abc.ABC\n",
      " |      pytorch_lightning.core.grads.GradInformation\n",
      " |      pytorch_lightning.core.saving.ModelIO\n",
      " |      pytorch_lightning.core.hooks.ModelHooks\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, args)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  configure_ddp(self, model, device_ids)\n",
      " |  \n",
      " |  configure_optimizers(self)\n",
      " |  \n",
      " |  decode(self, input_ids, start_logits, end_logits, type_logits, sp_para_logits, sp_sent_logits)\n",
      " |  \n",
      " |  exact_match_score(self, prediction, ground_truth)\n",
      " |  \n",
      " |  f1_score(self, prediction, ground_truth)\n",
      " |  \n",
      " |  forward(self, input_ids, attention_mask, segment_ids, start_positions, end_positions, q_type, sp_sent, sp_para)\n",
      " |      Same as torch.nn.Module.forward(), however in Lightning you want this to define\n",
      " |      the  operations you want to use for prediction (ie: on a server or as a feature extractor).\n",
      " |      \n",
      " |      Normally you'd call self.forward() from your training_step() method. This makes it easy to write a complex\n",
      " |      system for training with the outputs you'd want in a prediction setting.\n",
      " |      \n",
      " |      Args:\n",
      " |          x (tensor): Whatever  you decide to define in the forward method\n",
      " |      \n",
      " |      Return:\n",
      " |          Predicted output\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # example if we were using this model as a feature extractor\n",
      " |          def forward(self, x):\n",
      " |              feature_maps = self.convnet(x)\n",
      " |              return feature_maps\n",
      " |      \n",
      " |          def training_step(self, batch, batch_idx):\n",
      " |              x, y = batch\n",
      " |              feature_maps = self.forward(x)\n",
      " |              logits = self.classifier(feature_maps)\n",
      " |      \n",
      " |              # ...\n",
      " |              return loss\n",
      " |      \n",
      " |          # splitting it this way allows model to be used a feature extractor\n",
      " |          model = MyModelAbove()\n",
      " |      \n",
      " |          inputs = server.get_request()\n",
      " |          results = model(inputs)\n",
      " |          server.write_results(results)\n",
      " |      \n",
      " |          # -------------\n",
      " |          # This is in stark contrast to torch.nn.Module where normally you would have this:\n",
      " |          def forward(self, batch):\n",
      " |              x, y = batch\n",
      " |              feature_maps = self.convnet(x)\n",
      " |              logits = self.classifier(feature_maps)\n",
      " |              return logits\n",
      " |  \n",
      " |  load_model(self)\n",
      " |  \n",
      " |  loss_computation(self, start_positions, end_positions, start_logits, end_logits, q_type, type_logits, sp_para, predict_support_para, sp_sent, predict_support_sent)\n",
      " |  \n",
      " |  normalize_answer(self, s)\n",
      " |  \n",
      " |  on_epoch_start(self)\n",
      " |  \n",
      " |  optimizer_step(self, current_epoch, batch_nb, optimizer, optimizer_i, second_order_closure=None)\n",
      " |  \n",
      " |  or_softmax_cross_entropy_loss_one_doc(self, logits, target, ignore_index=-1, dim=-1)\n",
      " |      loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\n",
      " |  \n",
      " |  sp_metrics(self, prediction, gold)\n",
      " |  \n",
      " |  sync_list_across_gpus(self, l, device, dtype)\n",
      " |  \n",
      " |  test_dataloader = _get_data_loader(self)\n",
      " |  \n",
      " |  test_end(self, outputs)\n",
      " |  \n",
      " |  test_step(self, batch, batch_nb)\n",
      " |  \n",
      " |  train_dataloader = _get_data_loader(self)\n",
      " |  \n",
      " |  training_step(self, batch, batch_nb)\n",
      " |  \n",
      " |  val_dataloader = _get_data_loader(self)\n",
      " |  \n",
      " |  validation_end(self, outputs)\n",
      " |  \n",
      " |  validation_step(self, batch, batch_nb)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  add_model_specific_args(parser, root_dir)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'configure_optimizers', 'training_ste...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pytorch_lightning.core.lightning.LightningModule:\n",
      " |  \n",
      " |  configure_apex(self, amp, model, optimizers, amp_level)\n",
      " |      Override to init AMP your own way\n",
      " |      Must return a model and list of optimizers\n",
      " |      \n",
      " |      Args:\n",
      " |          amp (object): pointer to amp library object\n",
      " |          model (LightningModule): pointer to current lightningModule\n",
      " |          optimizers (list): list of optimizers passed in configure_optimizers()\n",
      " |          amp_level (str): AMP mode chosen ('O1', 'O2', etc...)\n",
      " |      \n",
      " |      Return:\n",
      " |          Apex wrapped model and optimizers\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Default implementation used by Trainer.\n",
      " |          def configure_apex(self, amp, model, optimizers, amp_level):\n",
      " |              model, optimizers = amp.initialize(\n",
      " |                  model, optimizers, opt_level=amp_level,\n",
      " |              )\n",
      " |      \n",
      " |              return model, optimizers\n",
      " |  \n",
      " |  freeze(self)\n",
      " |      Freeze all params for inference\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          model = MyLightningModule(...)\n",
      " |          model.freeze()\n",
      " |  \n",
      " |  init_ddp_connection(self, proc_rank, world_size)\n",
      " |      Override to define your custom way of setting up a distributed environment.\n",
      " |      \n",
      " |      Lightning's implementation uses env:// init by default and sets the first node as root.\n",
      " |      \n",
      " |      Args:\n",
      " |          proc_rank (int): The current process rank within the node.\n",
      " |          world_size (int): Number of GPUs being use across all nodes. (num_nodes*nb_gpu_nodes).\n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def init_ddp_connection(self):\n",
      " |              # use slurm job id for the port number\n",
      " |              # guarantees unique ports across jobs from same grid search\n",
      " |              try:\n",
      " |                  # use the last 4 numbers in the job id as the id\n",
      " |                  default_port = os.environ['SLURM_JOB_ID']\n",
      " |                  default_port = default_port[-4:]\n",
      " |      \n",
      " |                  # all ports should be in the 10k+ range\n",
      " |                  default_port = int(default_port) + 15000\n",
      " |      \n",
      " |              except Exception as e:\n",
      " |                  default_port = 12910\n",
      " |      \n",
      " |              # if user gave a port number, use that one instead\n",
      " |              try:\n",
      " |                  default_port = os.environ['MASTER_PORT']\n",
      " |              except Exception:\n",
      " |                  os.environ['MASTER_PORT'] = str(default_port)\n",
      " |      \n",
      " |              # figure out the root node addr\n",
      " |              try:\n",
      " |                  root_node = os.environ['SLURM_NODELIST'].split(' ')[0]\n",
      " |              except Exception:\n",
      " |                  root_node = '127.0.0.2'\n",
      " |      \n",
      " |              root_node = self.trainer.resolve_root_node_address(root_node)\n",
      " |              os.environ['MASTER_ADDR'] = root_node\n",
      " |              dist.init_process_group(\n",
      " |                  'nccl',\n",
      " |                  rank=self.proc_rank,\n",
      " |                  world_size=self.world_size\n",
      " |              )\n",
      " |  \n",
      " |  on_load_checkpoint(self, checkpoint)\n",
      " |      Called by lightning to restore your model.\n",
      " |      If you saved something with **on_save_checkpoint** this is your chance to restore this.\n",
      " |      \n",
      " |      Args:\n",
      " |          checkpoint (dict): Loaded checkpoint\n",
      " |      \n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def on_load_checkpoint(self, checkpoint):\n",
      " |              # 99% of the time you don't need to implement this method\n",
      " |              self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']\n",
      " |      \n",
      " |      .. note:: Lighting auto-restores global step, epoch, and all training state including amp scaling.\n",
      " |          No need for you to restore anything regarding training.\n",
      " |  \n",
      " |  on_save_checkpoint(self, checkpoint)\n",
      " |      Called by lightning when saving a  checkpoint  to give you a chance to store anything else you\n",
      " |      might want to  save\n",
      " |      \n",
      " |      Args:\n",
      " |          checkpoint (dic): Checkpoint to be saved\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def on_save_checkpoint(self, checkpoint):\n",
      " |              # 99% of use cases you don't need to implement this method\n",
      " |              checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object\n",
      " |      \n",
      " |      .. note:: Lighting saves all aspects of training (epoch, global step, etc...) including amp scaling. No need\n",
      " |          for you to store anything about training.\n",
      " |  \n",
      " |  summarize(self, mode)\n",
      " |  \n",
      " |  tbptt_split_batch(self, batch, split_size)\n",
      " |      When using truncated backpropagation through time, each batch must be split along the time dimension.\n",
      " |      Lightning handles this by default, but  for custom behavior override this function.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch (torch.nn.Tensor): Current batch\n",
      " |          split_size (int): How big the split  is\n",
      " |      \n",
      " |      Return:\n",
      " |          list of batch splits. Each split will be passed to forward_step to enable truncated\n",
      " |          back propagation through time. The default implementation splits root level Tensors and\n",
      " |          Sequences at dim=1 (i.e. time dim). It assumes that each time dim is the same length.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def tbptt_split_batch(self, batch, split_size):\n",
      " |            splits = []\n",
      " |            for t in range(0, time_dims[0], split_size):\n",
      " |                batch_split = []\n",
      " |                for i, x in enumerate(batch):\n",
      " |                    if isinstance(x, torch.Tensor):\n",
      " |                        split_x = x[:, t:t + split_size]\n",
      " |                    elif isinstance(x, collections.Sequence):\n",
      " |                        split_x = [None] * len(x)\n",
      " |                        for batch_idx in range(len(x)):\n",
      " |                            split_x[batch_idx] = x[batch_idx][t:t + split_size]\n",
      " |      \n",
      " |                    batch_split.append(split_x)\n",
      " |      \n",
      " |                splits.append(batch_split)\n",
      " |      \n",
      " |            return splits\n",
      " |      \n",
      " |      .. note:: Called in the training loop after on_batch_start if `truncated_bptt_steps > 0`.\n",
      " |          Each returned batch split is passed separately to training_step(...).\n",
      " |  \n",
      " |  tng_dataloader = _get_data_loader(self)\n",
      " |  \n",
      " |  training_end(self, *args, **kwargs)\n",
      " |      return loss, dict with metrics for tqdm\n",
      " |      \n",
      " |      :param outputs: What you return in `training_step`.\n",
      " |      :return dict: dictionary with loss key and optional log, progress keys:\n",
      " |          - loss -> tensor scalar [REQUIRED]\n",
      " |          - progress_bar -> Dict for progress bar display. Must have only tensors\n",
      " |          - log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)\n",
      " |      \n",
      " |      In certain cases (dp, ddp2), you might want to use all outputs of every process to do something.\n",
      " |      For instance, if using negative samples, you could run a batch via dp and use ALL the outputs\n",
      " |      for a single softmax across the full batch (ie: the denominator would use the full batch).\n",
      " |      \n",
      " |      In this case you should define training_end to perform those calculations.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # WITHOUT training_end\n",
      " |          # if used in DP or DDP2, this batch is 1/num_gpus large\n",
      " |          def training_step(self, batch, batch_idx):\n",
      " |              # batch is 1/num_gpus big\n",
      " |              x, y = batch\n",
      " |      \n",
      " |              out = self.forward(x)\n",
      " |              loss = self.softmax(out)\n",
      " |              loss = nce_loss(loss)\n",
      " |              return {'loss': loss}\n",
      " |      \n",
      " |          # --------------\n",
      " |          # with training_end to do softmax over the full batch\n",
      " |          def training_step(self, batch, batch_idx):\n",
      " |              # batch is 1/num_gpus big\n",
      " |              x, y = batch\n",
      " |      \n",
      " |              out = self.forward(x)\n",
      " |              return {'out': out}\n",
      " |      \n",
      " |          def training_end(self, outputs):\n",
      " |              # this out is now the full size of the batch\n",
      " |              out = outputs['out']\n",
      " |      \n",
      " |              # this softmax now uses the full batch size\n",
      " |              loss = self.softmax(out)\n",
      " |              loss = nce_loss(loss)\n",
      " |              return {'loss': loss}\n",
      " |      \n",
      " |      If you define multiple optimizers, this step will also be called with an additional `optimizer_idx` param.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Multiple optimizers (ie: GANs)\n",
      " |          def training_step(self, batch, batch_idx, optimizer_idx):\n",
      " |              if optimizer_idx == 0:\n",
      " |                  # do training_step with encoder\n",
      " |              if optimizer_idx == 1:\n",
      " |                  # do training_step with decoder\n",
      " |      \n",
      " |      If you add truncated back propagation through time you will also get an additional argument\n",
      " |       with the hidden states of the previous step.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Truncated back-propagation through time\n",
      " |          def training_step(self, batch, batch_idx, hiddens):\n",
      " |              # hiddens are the hiddens from the previous truncated backprop step\n",
      " |      \n",
      " |      You can also return a -1 instead of a dict to stop the current loop. This is useful if you want to\n",
      " |      break out of the current training epoch early.\n",
      " |  \n",
      " |  unfreeze(self)\n",
      " |      Unfreeze all params for inference.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          model = MyLightningModule(...)\n",
      " |          model.unfreeze()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pytorch_lightning.core.lightning.LightningModule:\n",
      " |  \n",
      " |  load_from_checkpoint(checkpoint_path, map_location=None) from abc.ABCMeta\n",
      " |      Primary way of loading model from a checkpoint. When Lightning saves a checkpoint\n",
      " |      it  stores  the hyperparameters in the checkpoint if you initialized your  LightningModule\n",
      " |      with an argument  called `hparams` which is a Namespace or dictionary of hyperparameters\n",
      " |      \n",
      " |          Example\n",
      " |          -------\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              # --------------\n",
      " |              # Case 1\n",
      " |              # when using Namespace (output of using Argparse to parse command line arguments)\n",
      " |              from argparse import Namespace\n",
      " |              hparams = Namespace(**{'learning_rate': 0.1})\n",
      " |      \n",
      " |              model = MyModel(hparams)\n",
      " |      \n",
      " |              class MyModel(pl.LightningModule):\n",
      " |                  def __init__(self, hparams):\n",
      " |                      self.learning_rate = hparams.learning_rate\n",
      " |      \n",
      " |              # --------------\n",
      " |              # Case 2\n",
      " |              # when using a dict\n",
      " |              model = MyModel({'learning_rate': 0.1})\n",
      " |      \n",
      " |              class MyModel(pl.LightningModule):\n",
      " |                  def __init__(self, hparams):\n",
      " |                      self.learning_rate = hparams['learning_rate']\n",
      " |      \n",
      " |      Args:\n",
      " |          checkpoint_path (str): Path to checkpoint.\n",
      " |          map_location (dic): If your checkpoint saved from a GPU model and you now load on CPUs\n",
      " |              or a different number of GPUs, use this to map to the new setup.\n",
      " |      \n",
      " |      Return:\n",
      " |          LightningModule with loaded weights.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # load weights without mapping\n",
      " |          MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')\n",
      " |      \n",
      " |          # load weights mapping all weights from GPU 1 to GPU 0\n",
      " |          map_location = {'cuda:1':'cuda:0'}\n",
      " |          MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt', map_location=map_location)\n",
      " |  \n",
      " |  load_from_metrics(weights_path, tags_csv, map_location=None) from abc.ABCMeta\n",
      " |      You should use `load_from_checkpoint` instead!\n",
      " |      However, if your .ckpt weights don't have the hyperparameters saved, use this method  to pass\n",
      " |      in a .csv with the hparams you'd like to use. These will  be converted  into a argparse.Namespace\n",
      " |      and passed into  your LightningModule for use.\n",
      " |      \n",
      " |      Args:\n",
      " |      \n",
      " |          weights_path (str): Path to a PyTorch checkpoint\n",
      " |          tags_csv (str): Path to a .csv with two columns (key, value) as in this\n",
      " |              Example::\n",
      " |                  key,value\n",
      " |                  drop_prob,0.2\n",
      " |                  batch_size,32\n",
      " |      \n",
      " |          map_location (dict): A dictionary mapping saved weight GPU devices to new\n",
      " |              GPU devices (example: {'cuda:1':'cuda:0'})\n",
      " |      Return:\n",
      " |          LightningModule with loaded weights\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          pretrained_model = MyLightningModule.load_from_metrics(\n",
      " |              weights_path='/path/to/pytorch_checkpoint.ckpt',\n",
      " |              tags_csv='/path/to/hparams_file.csv',\n",
      " |              on_gpu=True,\n",
      " |              map_location=None\n",
      " |          )\n",
      " |      \n",
      " |          # predict\n",
      " |          pretrained_model.eval()\n",
      " |          pretrained_model.freeze()\n",
      " |          y_hat = pretrained_model(x)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from abc.ABC:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pytorch_lightning.core.grads.GradInformation:\n",
      " |  \n",
      " |  grad_norm(self, norm_type)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pytorch_lightning.core.saving.ModelIO:\n",
      " |  \n",
      " |  on_hpc_load(self, checkpoint)\n",
      " |      Hook to do whatever you need right before Slurm manager loads the model\n",
      " |      :return:\n",
      " |  \n",
      " |  on_hpc_save(self, checkpoint)\n",
      " |      Hook to do whatever you need right before Slurm manager saves the model\n",
      " |      :return:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pytorch_lightning.core.hooks.ModelHooks:\n",
      " |  \n",
      " |  backward(self, use_amp, loss, optimizer)\n",
      " |      Override backward with your own implementation if you need to\n",
      " |      \n",
      " |      :param use_amp: Whether amp was requested or not\n",
      " |      :param loss: Loss is already scaled by accumulated grads\n",
      " |      :param optimizer: Current optimizer being used\n",
      " |      :return:\n",
      " |      \n",
      " |      Called to perform backward step.\n",
      " |      Feel free to override as needed.\n",
      " |      \n",
      " |      The loss passed in has already been scaled for accumulated gradients if requested.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def backward(self, use_amp, loss, optimizer):\n",
      " |              if use_amp:\n",
      " |                  with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
      " |                      scaled_loss.backward()\n",
      " |              else:\n",
      " |                  loss.backward()\n",
      " |  \n",
      " |  on_after_backward(self)\n",
      " |      Called after loss.backward() and before optimizers do anything.\n",
      " |      \n",
      " |      :return:\n",
      " |      \n",
      " |      Called in the training loop after model.backward()\n",
      " |      This is the ideal place to inspect or log gradient information\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def on_after_backward(self):\n",
      " |              # example to inspect gradient information in tensorboard\n",
      " |              if self.trainer.global_step % 25 == 0:  # don't make the tf file huge\n",
      " |                  params = self.state_dict()\n",
      " |                  for k, v in params.items():\n",
      " |                      grads = v\n",
      " |                      name = k\n",
      " |                      self.logger.experiment.add_histogram(tag=name, values=grads,\n",
      " |                                                           global_step=self.trainer.global_step)\n",
      " |  \n",
      " |  on_batch_end(self)\n",
      " |      Called in the training loop after the batch.\n",
      " |  \n",
      " |  on_batch_start(self, batch)\n",
      " |      Called in the training loop before anything happens for that batch.\n",
      " |      \n",
      " |      :param batch:\n",
      " |      :return:\n",
      " |  \n",
      " |  on_before_zero_grad(self, optimizer)\n",
      " |      Called after optimizer.step() and before optimizer.zero_grad()\n",
      " |      \n",
      " |      Called in the training loop after taking an optimizer step and before zeroing grads.\n",
      " |      Good place to inspect weight information with weights updated.\n",
      " |      \n",
      " |      for optimizer in optimizers::\n",
      " |      \n",
      " |          optimizer.step()\n",
      " |          model.on_before_zero_grad(optimizer) # < ---- called here\n",
      " |          optimizer.zero_grad\n",
      " |      \n",
      " |      :param optimizer:\n",
      " |      :return:\n",
      " |  \n",
      " |  on_epoch_end(self)\n",
      " |      Called in the training loop at the very end of the epoch.\n",
      " |  \n",
      " |  on_post_performance_check(self)\n",
      " |      Called at the very end of the validation loop.\n",
      " |  \n",
      " |  on_pre_performance_check(self)\n",
      " |      Called at the very beginning of the validation loop.\n",
      " |  \n",
      " |  on_sanity_check_start(self)\n",
      " |      Called before starting evaluate\n",
      " |      .. warning:: will be deprecated.\n",
      " |      :return:\n",
      " |  \n",
      " |  on_train_end(self)\n",
      " |      Called at the end of training before logger experiment is closed\n",
      " |      :return:\n",
      " |  \n",
      " |  on_train_start(self)\n",
      " |      Called at the beginning of training before sanity check\n",
      " |      :return:\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name:str, module:'Module') -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self:~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[_ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self:~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self:~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self:~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self:~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self:~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[_ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self:~T, requires_grad:bool=True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self:~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self:~T, mode:bool=True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self) -> None\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |      Type variable.\n",
      " |      \n",
      " |      Usage::\n",
      " |      \n",
      " |        T = TypeVar('T')  # Can be anything\n",
      " |        A = TypeVar('A', str, bytes)  # Must be str or bytes\n",
      " |      \n",
      " |      Type variables exist primarily for the benefit of static type\n",
      " |      checkers.  They serve as the parameters for generic types as well\n",
      " |      as for generic function definitions.  See class Generic for more\n",
      " |      information on generic types.  Generic functions work as follows:\n",
      " |      \n",
      " |        def repeat(x: T, n: int) -> List[T]:\n",
      " |            '''Return a list containing n references to x.'''\n",
      " |            return [x]*n\n",
      " |      \n",
      " |        def longest(x: A, y: A) -> A:\n",
      " |            '''Return the longest of two strings.'''\n",
      " |            return x if len(x) >= len(y) else y\n",
      " |      \n",
      " |      The latter example's signature is essentially the overloading\n",
      " |      of (str, str) -> str and (bytes, bytes) -> bytes.  Also note\n",
      " |      that if the arguments are instances of some subclass of str,\n",
      " |      the return type is still plain str.\n",
      " |      \n",
      " |      At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.\n",
      " |      \n",
      " |      Type variables defined with covariant=True or contravariant=True\n",
      " |      can be used do declare covariant or contravariant generic types.\n",
      " |      See PEP 484 for more details. By default generic types are invariant\n",
      " |      in all type variables.\n",
      " |      \n",
      " |      Type variables can be introspected. e.g.:\n",
      " |      \n",
      " |        T.__name__ == 'T'\n",
      " |        T.__constraints__ == ()\n",
      " |        T.__covariant__ == False\n",
      " |        T.__contravariant__ = False\n",
      " |        A.__constraints__ == (str, bytes)\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_ver...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function configure_optimizers in module __main__:\n",
      "\n",
      "configure_optimizers(self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hotpotqa.configure_optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# code, line_no = inspect.getsourcelines(hotpotqa.training_step)\n",
    "# print(''.join(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/u32/fanluo/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/u32/fanluo/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:transformers.tokenization_utils_base:Assigning ['<cls>', '<p>', '<q>', '</q>'] to the additional_special_tokens key of the tokenizer\n",
      "INFO:transformers.tokenization_utils:Adding <cls> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding <p> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding <q> to the vocabulary\n",
      "INFO:transformers.tokenization_utils:Adding </q> to the vocabulary\n",
      "INFO:transformers.configuration_utils:loading configuration file longformer-base-4096/config.json\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"attention_dilation\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"attention_mode\": \"tvm\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"autoregressive\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file longformer-base-4096/pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing Longformer.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of Longformer were initialized from the model checkpoint at longformer-base-4096.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use Longformer for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with config:\n",
      "RobertaConfig {\n",
      "  \"attention_dilation\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"attention_mode\": \"tvm\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256,\n",
      "    256\n",
      "  ],\n",
      "  \"autoregressive\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hotpotqa(\n",
       "  (model): Longformer(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50269, 768)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dense_type): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_type): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dense_sp_sent): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_sp_sent): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dense_sp_para): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_sp_para): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    hotpotqa.__abstractmethods__=set()   # without this, got an error \"Can't instantiate abstract class hotpotqa with abstract methods\" if these two abstract methods are not implemented in the same cell where class hotpotqa defined \n",
    "    model = hotpotqa(args)\n",
    "    model.to('cuda')    # this is necessary to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger = TestTubeLogger( # The TestTubeLogger adds a nicer folder structure to manage experiments and snapshots all hyperparameters you pass to a LightningModule.\n",
    "        save_dir=args.save_dir,\n",
    "        name=args.save_prefix,\n",
    "        version=0  # always use version=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:224: UserWarning: Checkpoint directory jupyter-hotpotqa/hotpotqa-longformer/checkpoints exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  f\"Checkpoint directory {filepath} exists and is not empty with save_top_k != 0.\"\n"
     ]
    }
   ],
   "source": [
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(args.save_dir, args.save_prefix, \"checkpoints\"),\n",
    "        save_top_k=5,\n",
    "        verbose=True,\n",
    "        monitor='avg_val_f1',\n",
    "        mode='max',\n",
    "        prefix=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_size:  16\n",
      "num_devices:  1\n",
      ">>>>>>> #steps: 48.0, #epochs: 6, batch_size: 2 <<<<<<<\n"
     ]
    }
   ],
   "source": [
    "    args.gpus = [int(x) for x in args.gpus.split(',')] if args.gpus is not \"\" else None\n",
    "    train_set_size = 16 * args.train_percent # 90447 * args.train_percent   # hardcode dataset size. Needed to compute number of steps for the lr scheduler\n",
    "    print(\"train_set_size: \", train_set_size)\n",
    "    num_devices = len(args.gpus) #1 or len(args.gpus)\n",
    "    print(\"num_devices: \", num_devices)\n",
    "    args.steps = args.epochs * train_set_size / (args.batch_size * num_devices)\n",
    "    print(f'>>>>>>> #train_set_size: {train_set_size}, #steps: {args.steps}, #epochs: {args.epochs}, batch_size: {args.batch_size * num_devices} <<<<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To install apex ### \n",
    "#     !git clone https://github.com/NVIDIA/apex\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/apex/\")\n",
    "#     !module load cuda101/neuralnet/7/7.6.4  \n",
    "#     !module load cuda10.1/toolkit/10.1.243 \n",
    "#     !conda install -c conda-forge cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf201901 cudatoolkit-dev --yes\n",
    "#     !conda install -c conda-forge/label/cf202003 cudatoolkit-dev --yes\n",
    "#     !which nvcc\n",
    "#     !python -m pip install -v --no-cache-dir ./\n",
    "#     os.chdir(\"/xdisk/msurdeanu/fanluo/hotpotQA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:using 16bit precision\n"
     ]
    }
   ],
   "source": [
    "    trainer = pl.Trainer(gpus=args.gpus, distributed_backend='ddp' if args.gpus and (len(args.gpus) > 1) else None,\n",
    "                         track_grad_norm=-1, max_epochs=args.epochs, early_stop_callback=None,\n",
    "                         accumulate_grad_batches=args.batch_size,\n",
    "                         train_percent_check = args.train_percent,\n",
    "#                          val_check_interval=args.val_every,\n",
    "                         val_percent_check=args.val_percent_check,\n",
    "                         test_percent_check=args.val_percent_check,\n",
    "                         logger=logger if not args.disable_checkpointing else False,\n",
    "                         checkpoint_callback=checkpoint_callback if not args.disable_checkpointing else False,\n",
    "                         show_progress_bar=args.no_progress_bar,\n",
    "                         use_amp=not args.fp32, amp_level='O1',\n",
    "                         check_val_every_n_epoch=args.epochs\n",
    "                         )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "INFO:root:\n",
      "                                       Name               Type Params\n",
      "0                                     model         Longformer  148 M\n",
      "1                          model.embeddings  RobertaEmbeddings   41 M\n",
      "2          model.embeddings.word_embeddings          Embedding   38 M\n",
      "3      model.embeddings.position_embeddings          Embedding    3 M\n",
      "4    model.embeddings.token_type_embeddings          Embedding  768  \n",
      "..                                      ...                ...    ...\n",
      "242                             linear_type             Linear    2 K\n",
      "243                           dense_sp_sent             Linear  590 K\n",
      "244                          linear_sp_sent             Linear  769  \n",
      "245                           dense_sp_para             Linear  590 K\n",
      "246                          linear_sp_para             Linear  769  \n",
      "\n",
      "[247 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
      "reading file: small.json\n",
      "['</s>', '<s>', '<cls>', '</q>', '<pad>', '</s>', '<mask>', '<q>', '<p>', '<s>', '<unk>']\n",
      "[2, 0, 50265, 50268, 1, 2, 50264, 50267, 50266, 0, 3]\n",
      "reading file: small_dev.json\n",
      "['</s>', '<s>', '<cls>', '</q>', '<pad>', '</s>', '<mask>', '<q>', '<p>', '<s>', '<unk>']\n",
      "[2, 0, 50265, 50268, 1, 2, 50264, 50267, 50266, 0, 3]\n",
      "reading file: small_dev.json\n",
      "['</s>', '<s>', '<cls>', '</q>', '<pad>', '</s>', '<mask>', '<q>', '<p>', '<s>', '<unk>']\n",
      "[2, 0, 50265, 50268, 1, 2, 50264, 50267, 50266, 0, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:model and trainer restored from checkpoint: jupyter-hotpotqa/hotpotqa-longformer/checkpoints/_ckpt_epoch_5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  How old is the female main protagonist of Catching Fire?\n",
      "orig_answer_text:  16-year-old\n",
      "question text:  Which band was founded first, Hole, the rock band that Courtney Love was a frontwoman of, or The Wolfhounds?\n",
      "orig_answer_text:  The Wolfhounds\n",
      "question text:  Which  American politician did Donahue replaced \n",
      "orig_answer_text:  Kelli Ward\n",
      "orig_answer_text:  Kelli Ward\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'How', 'Ġold', 'Ġis', 'Ġthe', 'Ġfemale', 'Ġmain', 'Ġprotagonist', 'Ġof', 'ĠC', 'atching', 'ĠFire', '?', '</q>', '<p>', 'ĠC', 'atching', 'ĠFire', 'Ġis', 'Ġa', 'Ġ2009', 'Ġscience', 'Ġfiction', 'Ġyoung', 'Ġadult', 'Ġnovel', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġnovelist', 'ĠSuzanne', 'ĠCollins', ',', 'Ġthe', 'Ġsecond', 'Ġbook', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', 'Ġtrilogy', '\".', 'Ġ', '<s>', 'ĠAs', 'Ġthe', 'Ġsequel', 'Ġto', 'Ġthe', 'Ġ2008', 'Ġbest', 'seller', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\",', 'Ġit', 'Ġcontinues', 'Ġthe', 'Ġstory', 'Ġof', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', 'Ġand', 'Ġthe', 'Ġpost', '-', 'ap', 'ocalyptic', 'Ġnation', 'Ġof', 'ĠPan', 'em', '.', 'Ġ', '<s>', 'ĠFollowing', 'Ġthe', 'Ġevents', 'Ġof', 'Ġthe', 'Ġprevious', 'Ġnovel', ',', 'Ġa', 'Ġrebellion', 'Ġagainst', 'Ġthe', 'Ġoppressive', 'ĠCapitol', 'Ġhas', 'Ġbegun', ',', 'Ġand', 'ĠKat', 'n', 'iss', 'Ġand', 'Ġfellow', 'Ġtribute', 'ĠPe', 'eta', 'ĠMell', 'ark', 'Ġare', 'Ġforced', 'Ġto', 'Ġreturn', 'Ġto', 'Ġthe', 'Ġarena', 'Ġin', 'Ġa', 'Ġspecial', 'Ġedition', 'Ġof', 'Ġthe', 'ĠHunger', 'ĠGames', '.', '<p>', 'ĠOil', 'Ġwell', 'Ġfires', 'Ġare', 'Ġoil', 'Ġor', 'Ġgas', 'Ġwells', 'Ġthat', 'Ġhave', 'Ġcaught', 'Ġon', 'Ġfire', 'Ġand', 'Ġburn', '.', 'Ġ', '<s>', 'ĠOil', 'Ġwell', 'Ġfires', 'Ġcan', 'Ġbe', 'Ġthe', 'Ġresult', 'Ġof', 'Ġhuman', 'Ġactions', ',', 'Ġsuch', 'Ġas', 'Ġaccidents', 'Ġor', 'Ġarson', ',', 'Ġor', 'Ġnatural', 'Ġevents', ',', 'Ġsuch', 'Ġas', 'Ġlightning', '.', 'Ġ', '<s>', 'ĠThey', 'Ġcan', 'Ġexist', 'Ġon', 'Ġa', 'Ġsmall', 'Ġscale', ',', 'Ġsuch', 'Ġas', 'Ġan', 'Ġoil', 'Ġfield', 'Ġspill', 'Ġcatching', 'Ġfire', ',', 'Ġor', 'Ġon', 'Ġa', 'Ġhuge', 'Ġscale', ',', 'Ġas', 'Ġin', 'Ġge', 'ys', 'er', '-', 'like', 'Ġjets', 'Ġof', 'Ġflames', 'Ġfrom', 'Ġignited', 'Ġhigh', 'Ġpressure', 'Ġwells', '.', 'Ġ', '<s>', 'ĠA', 'Ġfrequent', 'Ġcause', 'Ġof', 'Ġa', 'Ġwell', 'Ġfire', 'Ġis', 'Ġa', 'Ġhigh', '-', 'pressure', 'Ġblow', 'out', 'Ġduring', 'Ġdrilling', 'Ġoperations', '.', '<p>', 'ĠHO', ':', 'ĠFoot', 'prints', 'Ġin', 'Ġthe', 'ĠSand', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġby', 'ĠMak', 'ura', 'Ġthat', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠJune', 'Ġ23', ',', 'Ġ2006', 'Ġfor', 'Ġthe', 'ĠPC', 'Ġas', 'Ġa', 'ĠDVD', ';', 'Ġa', 'Ġversion', 'Ġplayable', 'Ġon', 'Ġthe', 'ĠPlayStation', 'Ġ2', 'Ġunder', 'Ġthe', 'Ġtitle', 'Ġ\"', 'HO', 'Ġ+', '\"', 'Ġfollowed', 'Ġon', 'ĠApril', 'Ġ24', ',', 'Ġ2008', 'Ġwith', 'Ġadult', 'Ġcontent', 'Ġremoved', ',', 'Ġbut', 'Ġin', 'Ġits', 'Ġplace', 'Ġwill', 'Ġbe', 'Ġadditional', 'Ġscenarios', 'Ġand', 'Ġgraphics', 'Ġnot', 'Ġseen', 'Ġin', 'Ġthe', 'Ġoriginal', 'Ġrelease', '.', 'Ġ', '<s>', 'Ġ\"', 'HO', '\"', 'Ġis', 'ĠMak', 'ura', \"'s\", 'Ġfirst', 'Ġgame', ';', 'Ġa', 'Ġsequel', 'Ġnamed', 'Ġ\"', 'Root', 'ĠAfter', 'Ġand', 'ĠAnother', '\"', 'Ġwas', 'Ġlater', 'Ġproduced', 'Ġin', 'ĠOctober', 'Ġ2007', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'HO', '\"', 'Ġfollows', 'Ġa', 'Ġplot', 'Ġline', 'Ġthat', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġthree', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThere', 'Ġare', 'Ġtwo', 'Ġmodes', 'Ġof', 'Ġgameplay', ',', 'Ġthe', 'ĠBlind', 'ness', 'ĠEffect', 'Ġand', 'ĠNormal', 'ĠEffect', ',', 'Ġwhere', 'Ġthe', 'Ġformer', 'Ġplays', 'Ġon', 'Ġthe', 'Ġfact', 'Ġthat', 'Ġthe', 'Ġprotagonist', 'Ġis', 'Ġblind', ',', 'Ġand', 'Ġthe', 'Ġlatter', 'Ġmode', 'Ġremoves', 'Ġthe', 'Ġadded', 'Ġelement', 'Ġof', 'Ġgameplay', 'Ġthe', 'ĠBlind', 'ness', 'ĠEffect', 'Ġhas', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġis', 'Ġbroken', 'Ġinto', 'Ġthree', 'Ġparts', ':', 'Ġthe', 'Ġoriginal', 'Ġintroduction', 'Ġand', 'Ġmeeting', ',', 'Ġfollowing', 'Ġby', 'Ġa', 'Ġseparation', 'Ġand', 'Ġreunion', ',', 'Ġand', 'Ġfinally', 'Ġending', 'Ġwith', 'Ġthe', 'Ġprotagonist', 'Ġchoosing', 'Ġone', 'Ġof', 'Ġthe', 'Ġgirls', 'Ġand', 'Ġspending', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġgame', 'Ġwith', 'Ġher', '.', '<p>', 'ĠTo', 'ĠHeart', 'Ġ2', 'Ġ(', 'ãĥĪ', 'ãĤ', '¥', 'ãĥı', 'ãĥ¼ãĥ', 'Ī', 'ï', '¼', 'Ĵ', 'Ġ,', 'ĠTu', 'ĠH', 'Äģ', 'to', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġstyl', 'ized', 'Ġas', 'ĠTo', 'Heart', '2', ',', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġromance', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠLeaf', 'Ġand', 'Ġpublished', 'Ġby', 'ĠAqua', 'plus', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġfirst', 'Ġreleased', 'Ġfor', 'Ġthe', 'ĠPlayStation', 'Ġ2', 'Ġon', 'ĠDecember', 'Ġ28', ',', 'Ġ2004', 'Ġas', 'Ġan', 'Ġall', '-', 'ages', 'Ġtitle', ',', 'Ġand', 'Ġwas', 'Ġfollowed', 'Ġby', 'Ġan', 'Ġadult', 'Ġversion', 'Ġplayable', 'Ġon', 'ĠMicrosoft', 'ĠWindows', 'Ġand', 'Ġsubsequent', 'Ġall', '-', 'ages', 'Ġversions', 'Ġfor', 'Ġthe', 'ĠPlayStation', 'ĠPortable', 'Ġand', 'ĠPlayStation', 'Ġ3', '.', 'Ġ', '<s>', 'ĠThis', 'Ġdev', 'iated', 'Ġfrom', 'Ġthe', 'Ġrelease', 'Ġhistory', 'Ġof', 'Ġthe', 'Ġgame', \"'s\", 'Ġpredecessor', ',', 'Ġ\"', 'To', 'ĠHeart', '\",', 'Ġwhich', 'Ġwas', 'Ġoriginally', 'Ġreleased', 'Ġwith', 'Ġadult', 'Ġcontent', 'Ġprior', 'Ġto', 'Ġreceiving', 'Ġversions', 'Ġwith', 'Ġsuch', 'Ġcontent', 'Ġremoved', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'To', 'ĠHeart', 'Ġ2', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwith', 'Ġmultiple', 'Ġendings', ',', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġand', 'Ġcourses', 'Ġof', 'Ġinteraction', 'Ġbased', 'Ġon', 'Ġthe', 'Ġplayer', \"'s\", 'Ġdecisions', '.', 'Ġ', '<s>', 'ĠIts', 'Ġstory', 'Ġcenters', 'Ġon', 'Ġthe', 'Ġmale', 'Ġprotagonist', 'ĠT', 'aka', 'aki', 'ĠK', 'oun', 'o', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', '<p>', 'ĠThe', 'ĠHunger', 'ĠGames', 'Ġis', 'Ġa', 'Ġ2008', 'Ġdystopian', 'Ġnovel', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġwriter', 'ĠSuzanne', 'ĠCollins', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġwritten', 'Ġin', 'Ġthe', 'Ġvoice', 'Ġof', 'Ġ16', '-', 'year', '-', 'old', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', ',', 'Ġwho', 'Ġlives', 'Ġin', 'Ġthe', 'Ġfuture', ',', 'Ġpost', '-', 'ap', 'ocalyptic', 'Ġnation', 'Ġof', 'ĠPan', 'em', 'Ġin', 'ĠNorth', 'ĠAmerica', '.', 'Ġ', '<s>', 'ĠThe', 'ĠCapitol', ',', 'Ġa', 'Ġhighly', 'Ġadvanced', 'Ġmet', 'ropolis', ',', 'Ġexercises', 'Ġpolitical', 'Ġcontrol', 'Ġover', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġnation', '.', 'Ġ', '<s>', 'ĠThe', 'ĠHunger', 'ĠGames', 'Ġis', 'Ġan', 'Ġannual', 'Ġevent', 'Ġin', 'Ġwhich', 'Ġone', 'Ġboy', 'Ġand', 'Ġone', 'Ġgirl', 'Ġaged', 'Ġ12', 'âĢĵ', '18', 'Ġfrom', 'Ġeach', 'Ġof', 'Ġthe', 'Ġtwelve', 'Ġdistricts', 'Ġsurrounding', 'Ġthe', 'ĠCapitol', 'Ġare', 'Ġselected', 'Ġby', 'Ġlottery', 'Ġto', 'Ġcompete', 'Ġin', 'Ġa', 'Ġtelevised', 'Ġbattle', 'Ġto', 'Ġthe', 'Ġdeath', '.', '<p>', 'ĠMoon', 'Ġ(', 'sty', 'led', 'Ġas', 'ĠMoon', '.)', 'Ġ', '<s>', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠTactics', ',', 'Ġa', 'Ġbrand', 'Ġof', 'ĠNext', 'on', ',', 'Ġreleased', 'Ġon', 'ĠNovember', 'Ġ21', ',', 'Ġ1997', 'Ġplayable', 'Ġon', 'ĠWindows', 'ĠPCs', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġdescribed', 'Ġby', 'Ġthe', 'Ġdevelopment', 'Ġteam', 'Ġas', 'Ġa', 'Ġ\"', 'Re', 'aching', 'Ġthe', 'ĠHeart', 'ĠAVG', '\"', 'Ġ(', 'å¿', 'ĥ', 'ãģ«', 'å', '±', 'Ĭ', 'ãģı', 'AV', 'G', 'Ġ,', 'ĠKok', 'oro', 'Ġni', 'ĠT', 'od', 'oku', 'ĠAVG', 'Ġ)', 'Ġ.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġfollows', 'Ġthe', 'Ġprotagonist', 'ĠIk', 'umi', 'ĠAm', 'as', 'awa', ',', 'Ġa', 'Ġgirl', 'Ġwho', 'Ġjoins', 'Ġan', 'Ġorganization', 'Ġcalled', 'ĠFargo', 'Ġin', 'Ġthe', 'Ġhopes', 'Ġof', 'Ġdiscovering', 'Ġwhy', 'Ġand', 'Ġhow', 'Ġher', 'Ġmother', 'Ġdied', ',', 'Ġwho', 'Ġwas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'Ġsame', 'Ġgroup', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'Moon', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġthree', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġranked', 'Ġtwice', 'Ġin', 'Ġthe', 'Ġnational', 'Ġtop', 'Ġ50', 'Ġfor', 'Ġbest', '-', 'selling', 'ĠPC', 'Ġgames', 'Ġsold', 'Ġin', 'ĠJapan', '.', '<p>', 'ĠD', 'Åį', 'sei', 'Ġ(', 'åĲ', 'Į', 'æ', '£', '²', 'Ġ,', 'Ġlit', '.', 'Ġ\"', 'Ġ', '<s>', 'ĠCoh', 'ab', 'itation', '\")', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġsocial', 'Ġsimulation', 'Ġgame', 'Ġdeveloped', 'Ġby', 'ĠTactics', ',', 'Ġa', 'Ġbrand', 'Ġof', 'ĠNext', 'on', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠMay', 'Ġ23', ',', 'Ġ1997', 'Ġfor', 'ĠWindows', 'ĠPCs', ',', 'Ġthe', 'Ġsame', 'Ġday', 'Ġas', 'Ġ\"', 'To', 'ĠHeart', '\"', 'Ġby', 'ĠLeaf', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'D', 'Åį', 'sei', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġsole', 'Ġfemale', 'Ġmain', 'Ġcharacter', 'ĠMan', 'ami', 'ĠMin', 'ase', '.', 'Ġ', '<s>', 'ĠThe', 'Ġplayer', 'Ġassumes', 'Ġthe', 'Ġrole', 'Ġof', 'Ġprotagonist', 'ĠMas', 'aki', 'ĠYam', 'ada', 'Ġwho', 'Ġis', 'Ġliving', 'Ġwith', 'ĠMan', 'ami', 'Ġshortly', 'Ġafter', 'Ġthey', 'Ġhave', 'Ġgraduated', 'Ġfrom', 'Ġhigh', 'Ġschool', '.', 'Ġ', '<s>', 'ĠMas', 'aki', 'Ġearns', 'Ġmoney', 'Ġat', 'Ġa', 'Ġjob', ',', 'Ġand', 'Ġwhen', 'Ġhe', 'Ġreturns', 'Ġhome', 'Ġwill', 'Ġhave', 'Ġsex', 'Ġwith', 'ĠMan', 'ami', 'Ġoften', ';', 'Ġthis', 'Ġprocess', 'Ġof', 'Ġwork', 'Ġin', 'Ġthe', 'Ġday', ',', 'Ġand', 'Ġsex', 'Ġat', 'Ġnight', 'Ġrepeats', 'Ġmany', 'Ġtimes', 'Ġthroughout', 'Ġgameplay', '.', '<p>', 'ĠThe', 'ĠHunger', 'ĠGames', ':', 'ĠC', 'atching', 'ĠFire', 'Ġis', 'Ġa', 'Ġ2013', 'ĠAmerican', 'Ġdystopian', 'Ġscience', 'Ġfiction', 'Ġadventure', 'Ġfilm', 'Ġbased', 'Ġon', 'ĠSuzanne', 'ĠCollins', \"'\", 'Ġdystopian', 'Ġnovel', ',', 'Ġ\"', 'C', 'atching', 'ĠFire', '\"', 'Ġ(', '2009', '),', 'Ġthe', 'Ġsecond', 'Ġinstallment', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġtrilogy', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġis', 'Ġthe', 'Ġsequel', 'Ġto', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġ(', '2012', ')', 'Ġand', 'Ġthe', 'Ġsecond', 'Ġinstallment', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġfilm', 'Ġseries', ',', 'Ġproduced', 'Ġby', 'ĠNina', 'ĠJacob', 'son', 'Ġand', 'ĠJon', 'ĠKil', 'ik', ',', 'Ġand', 'Ġdistributed', 'Ġby', 'ĠLions', 'gate', '.', 'Ġ', '<s>', 'ĠFrancis', 'ĠLawrence', 'Ġdirected', 'Ġthe', 'Ġfilm', ',', 'Ġwith', 'Ġa', 'Ġscreenplay', 'Ġby', 'ĠSimon', 'ĠBeau', 'f', 'oy', 'Ġand', 'ĠMichael', 'ĠAr', 'nd', 't', '.', 'Ġ', '<s>', 'ĠAdding', 'Ġto', 'Ġthe', 'Ġexisting', 'Ġcast', ',', 'Ġthe', 'Ġsupporting', 'Ġcast', 'Ġwas', 'Ġfilled', 'Ġout', 'Ġwith', 'ĠPhilip', 'ĠSeymour', 'ĠHoffman', ',', 'ĠJeffrey', 'ĠWright', ',', 'ĠJ', 'ena', 'ĠMalone', ',', 'ĠSam', 'ĠCl', 'af', 'lin', ',', 'ĠLynn', 'ĠCohen', ',', 'ĠAmanda', 'ĠPl', 'ummer', ',', 'ĠAlan', 'ĠR', 'itch', 'son', ',', 'Ġand', 'ĠMeta', 'ĠGold', 'ing', '.', 'Ġ', '<s>', 'ĠFil', 'ming', 'Ġbegan', 'Ġon', 'ĠSeptember', 'Ġ10', ',', 'Ġ2012', ',', 'Ġin', 'ĠAtlanta', ',', 'ĠGeorgia', ',', 'Ġbefore', 'Ġmoving', 'Ġto', 'ĠHawaii', '.', 'Ġ', '<s>', 'ĠThe', 'Ġplot', 'Ġof', 'Ġ\"', 'C', 'atching', 'ĠFire', '\"', 'Ġtakes', 'Ġplace', 'Ġa', 'Ġfew', 'Ġmonths', 'Ġafter', 'Ġthe', 'Ġprevious', 'Ġinstallment', ';', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', 'Ġand', 'Ġfellow', 'ĠDistrict', 'Ġ12', 'Ġtribute', 'ĠPe', 'eta', 'ĠMell', 'ark', 'Ġhave', 'Ġreturned', 'Ġhome', 'Ġsafely', 'Ġafter', 'Ġwinning', 'Ġthe', 'Ġ74', 'th', 'ĠAnnual', 'ĠHunger', 'ĠGames', '.', 'Ġ', '<s>', 'ĠThroughout', 'Ġthe', 'Ġstory', ',', 'ĠKat', 'n', 'iss', 'Ġsenses', 'Ġthat', 'Ġa', 'Ġrebellion', 'Ġagainst', 'Ġthe', 'Ġoppressive', 'ĠCapitol', 'Ġis', 'Ġsimmer', 'ing', 'Ġthroughout', 'Ġthe', 'Ġdistricts', '.', '<p>', 'ĠTens', 'hin', 'ĠRan', 'man', ':', 'ĠLucky', 'Ġor', 'ĠUn', 'l', 'ucky', '!?', 'Ġ', '<s>', 'Ġ(', 'å¤©', 'ç¥ŀ', 'ä¹', '±', 'æ', '¼', '«', 'Ġ-', 'L', 'UCK', 'Y', 'Ġor', 'ĠUN', 'L', 'UCK', 'Y', '!?', 'Ġ', '<s>', 'Ġ-', 'Ġ)', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠY', 'uz', 'us', 'oft', ',', 'Ġand', 'Ġreleased', 'Ġfor', 'Ġthe', 'ĠPC', 'Ġon', 'ĠMay', 'Ġ29', ',', 'Ġ2009', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġlater', 'Ġported', 'Ġto', 'Ġthe', 'ĠPlayStation', 'ĠPortable', 'Ġconsole', 'Ġby', 'ĠRussell', 'Ġon', 'ĠMarch', 'Ġ25', ',', 'Ġ2010', ',', 'Ġunder', 'Ġthe', 'Ġtitle', 'Ġ\"', 'T', 'ens', 'hin', 'ĠRan', 'man', 'Ġ-', 'ĠHappy', 'ĠGo', 'ĠLucky', '!!\"', 'Ġ', '<s>', 'Ġ.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'T', 'ens', 'hin', 'ĠRan', 'man', '\"', 'Ġfollows', 'Ġa', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfour', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġrevolves', 'Ġaround', 'ĠHar', 'uki', 'ĠCh', 'it', 'ose', ',', 'Ġthe', 'Ġvery', 'Ġunfortunate', 'Ġprotagonist', ',', 'Ġand', 'Ġolder', 'Ġbrother', 'Ġof', 'ĠSana', 'ĠCh', 'it', 'ose', '.', 'Ġ', '<s>', 'ĠOne', 'Ġday', ',', 'Ġhe', 'Ġreceives', 'Ġa', 'Ġparcel', 'Ġcontaining', 'Ġsomething', 'Ġhe', 'Ġwould', 'Ġnever', 'Ġhave', 'Ġthought', '.', '<p>', 'ĠHello', ',', 'ĠGood', '-', 'bye', 'Ġ(', 'ãĥı', 'ãĥŃ', 'ãĥ¼', 'ãĤ°', 'ãĥĥãĥī', 'ãĥĲ', 'ãĤ¤', 'Ġ,', 'ĠHar', 'Åį', 'ĠG', 'udd', 'ob', 'ai', 'Ġ)', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġand', 'Ġpublished', 'Ġby', 'ĠLump', 'Ġof', 'ĠSugar', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠDecember', 'Ġ17', ',', 'Ġ2010', 'Ġfor', 'ĠWindows', 'Ġas', 'ĠLump', 'Ġof', 'ĠSugar', \"'s\", 'Ġsixth', 'Ġtitle', '.', 'Ġ', '<s>', 'ĠA', 'Ġtrial', 'Ġedition', 'Ġwas', 'Ġreleased', 'Ġin', 'ĠOctober', 'Ġ2010', 'Ġrated', 'Ġfor', 'Ġall', 'Ġages', '.', 'Ġ', '<s>', 'ĠThe', 'Ġprimary', 'Ġfocus', 'Ġof', 'Ġthe', 'Ġgame', 'Ġis', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfour', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġresolves', 'Ġaround', 'Ġthe', 'Ġprotagonist', ',', 'ĠK', 'aito', 'ĠTou', 'bu', ',', 'Ġwho', 'Ġis', 'Ġactually', 'Ġa', 'Ġsecret', 'Ġagent', 'Ġwith', 'Ġthe', 'Ġability', 'Ġto', 'Ġexperience', 'Ġtime', 'Ġloops', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  New Faces of 1952 is a musical revue with songs and comedy skits, it helped jump start the career of which young performer, and American actress?\n",
      "orig_answer_text:  Carol Lawrence\n",
      "orig_answer_text:  Carol Lawrence\n",
      "decode\n",
      "answers: [{'text': ' the second book in \"The Hunger Games trilogy\".', 'score': tensor([0.6943], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' the second book in \"The Hunger Games trilogy\".', 'score': tensor([0.6943], device='cuda:0')}]\n",
      "answer_score: tensor([0.6943], device='cuda:0')\n",
      "answer_text:  the second book in \"The Hunger Games trilogy\".\n",
      "answer_gold_token_ids: tensor([545,  12, 180,  12, 279], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ16', '-', 'year', '-', 'old']\n",
      "answer_gold:  16-year-old\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġband', 'Ġwas', 'Ġfounded', 'Ġfirst', ',', 'ĠHole', ',', 'Ġthe', 'Ġrock', 'Ġband', 'Ġthat', 'ĠCourtney', 'ĠLove', 'Ġwas', 'Ġa', 'Ġfront', 'woman', 'Ġof', ',', 'Ġor', 'ĠThe', 'ĠWolf', 'h', 'ounds', '?', '</q>', '<p>', 'ĠNobody', \"'s\", 'ĠDaughter', 'Ġis', 'Ġthe', 'Ġfourth', 'Ġand', 'Ġfinal', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġreleased', 'Ġworldwide', 'Ġon', 'ĠApril', 'Ġ27', ',', 'Ġ2010', ',', 'Ġthrough', 'ĠMercury', 'ĠRecords', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġoriginally', 'Ġconceived', 'Ġby', 'ĠHole', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġas', 'Ġa', 'Ġsolo', 'Ġproject', 'Ġtitled', 'Ġ\"', 'How', 'ĠDirty', 'ĠGirls', 'ĠGet', 'ĠClean', '\",', 'Ġfollowing', 'Ġher', 'Ġpoorly', 'Ġreceived', 'Ġsolo', 'Ġdebut', 'Ġ\"', 'America', \"'s\", 'ĠSweet', 'heart', '\"', 'Ġ(', '2004', ').', 'Ġ', '<s>', 'ĠMuch', 'Ġof', 'Ġthe', 'Ġmaterial', 'Ġfeatured', 'Ġon', 'Ġ\"', 'Nobody', \"'s\", 'ĠDaughter', '\"', 'Ġoriginated', 'Ġfrom', 'Ġstudio', 'Ġsessions', 'Ġfor', 'Ġ\"', 'How', 'ĠDirty', 'ĠGirls', 'ĠGet', 'ĠClean', '\",', 'Ġwhich', 'Ġhad', 'Ġbeen', 'Ġconceived', 'Ġin', 'Ġ2006', 'Ġafter', 'Ġa', 'Ġmultitude', 'Ġof', 'Ġlegal', 'Ġissues', ',', 'Ġdrug', 'Ġaddiction', ',', 'Ġand', 'Ġrehabilitation', 'Ġsentences', 'Ġhad', 'Ġleft', 'ĠLove', 'Ġ\"', 'su', 'icidal', '\".', 'Ġ', '<s>', 'ĠLove', 'Ġfinanced', 'Ġthe', 'Ġmaking', 'Ġof', 'Ġthe', 'Ġrecord', 'Ġherself', ',', 'Ġwhich', 'Ġcost', 'Ġnearly', 'Ġtwo', 'Ġmillion', 'Ġdollars', '.', '<p>', 'ĠCourtney', 'ĠLove', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġmusician', 'Ġand', 'Ġactress', 'Ġwho', 'Ġbegan', 'Ġher', 'Ġprofessional', 'Ġcareer', 'Ġin', 'Ġfilm', 'Ġin', 'Ġ1986', 'Ġwith', 'Ġa', 'Ġsupporting', 'Ġrole', 'Ġin', 'ĠAlex', 'ĠCox', \"'s\", 'Ġ\"', 'S', 'id', 'Ġand', 'ĠNancy', '\"', 'Ġ(', '1986', ');', 'Ġshe', 'Ġhad', 'Ġprior', 'Ġstudied', 'Ġfilm', 'Ġwith', 'Ġexperimental', 'Ġdirector', 'ĠGeorge', 'ĠK', 'uch', 'ar', 'Ġat', 'Ġthe', 'ĠSan', 'ĠFrancisco', 'ĠArt', 'ĠInstitute', 'Ġin', 'Ġ1984', ',', 'Ġand', 'Ġappeared', 'Ġin', 'Ġone', 'Ġof', 'ĠK', 'uch', 'ar', \"'s\", 'Ġshort', 'Ġfilms', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġpursuing', 'Ġmusic', 'Ġand', 'Ġhaving', 'Ġa', 'Ġsuccessful', 'Ġcareer', 'Ġas', 'Ġthe', 'Ġfront', 'woman', 'Ġof', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'ĠLove', 'Ġalso', 'Ġhad', 'Ġintermittent', 'Ġroles', 'Ġin', 'Ġfilms', ',', 'Ġmost', 'Ġnotably', 'Ġreceiving', 'Ġcritical', 'Ġattention', 'Ġfor', 'Ġher', 'Ġperformance', 'Ġas', 'ĠAl', 'the', 'a', 'ĠFly', 'nt', 'Ġin', 'ĠMilo', 'Å¡', 'ĠForm', 'an', \"'s\", 'Ġ1996', 'Ġbi', 'opic', 'Ġ\"', 'The', 'ĠPeople', 'Ġvs', '.', 'ĠLarry', 'ĠFly', 'nt', '\",', 'Ġwhich', 'Ġearned', 'Ġher', 'Ġa', 'ĠGolden', 'ĠGlobe', 'ĠNom', 'ination', 'Ġfor', 'ĠBest', 'ĠActress', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġawards', 'Ġfrom', 'Ġthe', 'ĠBoston', ',', 'ĠChicago', ',', 'ĠNew', 'ĠYork', ',', 'Ġand', 'ĠLos', 'ĠAngeles', 'Ġfilm', 'Ġcritics', 'Ġassociations', '.', 'Ġ', '<s>', 'ĠLove', 'Ġlater', 'Ġappeared', 'Ġamong', 'Ġan', 'Ġensemble', 'Ġcast', 'Ġin', 'Ġ\"', '200', 'ĠCig', 'arettes', '\"', 'Ġ(', '1998', '),', 'Ġas', 'Ġwell', 'Ġas', 'Ġin', 'Ġa', 'Ġleading', 'Ġrole', 'Ġin', 'Ġ\"', 'Man', 'Ġon', 'Ġthe', 'ĠMoon', '\"', 'Ġ(', '1999', ')', 'Ġalongside', 'ĠJim', 'ĠCar', 'rey', ',', 'Ġfor', 'Ġwhich', 'Ġshe', 'Ġreceived', 'Ġcritical', 'Ġrecognition', '.', 'Ġ', '<s>', 'ĠShe', 'Ġlater', 'Ġappeared', 'Ġin', 'Ġseveral', 'Ġindependent', 'Ġfilms', 'Ġand', 'Ġshort', 'Ġsubjects', 'Ġas', 'Ġwell', 'Ġas', 'Ġthe', 'Ġthriller', 'Ġ\"', 'Tra', 'pped', '\"', 'Ġ(', '2002', ')', 'Ġalongside', 'ĠCharl', 'ize', 'ĠTher', 'on', 'Ġand', 'ĠKevin', 'ĠBacon', ',', 'Ġand', 'Ġ\"', 'Jul', 'ie', 'ĠJohnson', '\"', 'Ġ(', '2001', '),', 'Ġfor', 'Ġwhich', 'Ġshe', 'Ġreceived', 'Ġan', 'Ġaward', 'Ġfor', 'ĠBest', 'ĠActress', 'Ġat', 'ĠLos', 'ĠAngeles', \"'\", 'Ġgay', 'Ġand', 'Ġlesbian', 'ĠOut', 'fest', 'Ġfilm', 'Ġfestival', '.', '<p>', 'ĠPatricia', 'ĠTheresa', 'ĠSc', 'hem', 'el', 'Ġ(', 'born', 'ĠApril', 'Ġ24', ',', 'Ġ1967', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġdrummer', 'Ġand', 'Ġmusician', 'Ġwho', 'Ġrose', 'Ġto', 'Ġprominence', 'Ġas', 'Ġthe', 'Ġdrummer', 'Ġof', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', 'Ġfrom', 'Ġ1992', 'Ġuntil', 'Ġ1998', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1998', ',', 'ĠSc', 'hem', 'el', 'Ġleft', 'ĠHole', ',', 'Ġand', 'Ġin', 'Ġthe', 'Ġearly', 'Ġ2000', 's', 'Ġreunited', 'Ġwith', 'ĠHole', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġduring', 'Ġher', 'Ġsolo', 'Ġcareer', ',', 'Ġand', 'Ġlater', 'Ġdrum', 'med', 'Ġfor', 'ĠJuliet', 'te', 'Ġand', 'Ġthe', 'ĠL', 'icks', '.', 'Ġ', '<s>', 'ĠAs', 'Ġof', 'Ġ2010', ',', 'ĠSc', 'hem', 'el', 'Ġcontinues', 'Ġto', 'Ġplay', 'Ġmusic', 'Ġand', 'Ġgives', 'Ġdrum', 'Ġlessons', ',', 'Ġin', 'Ġaddition', 'Ġto', 'Ġowning', 'Ġa', 'Ġdog', 'Ġday', 'care', '/', 'boarding', 'Ġbusiness', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2013', ',', 'ĠSc', 'hem', 'el', 'Ġjoined', 'Ġthe', 'Ġindie', 'Ġrock', 'Ġgroup', 'ĠUps', 'et', ',', 'Ġformed', 'Ġby', 'ĠAli', 'ĠK', 'oe', 'hler', ',', 'Ġpreviously', 'Ġof', 'ĠViv', 'ian', 'ĠGirls', 'Ġand', 'ĠBest', 'ĠCoast', '.', 'Ġ', '<s>', 'ĠShe', 'Ġalso', 'Ġformed', 'Ġa', 'Ġrock', 'Ġand', 'Ġroll', 'Ġband', 'Ġwith', 'Ġher', 'Ġbrother', ',', 'ĠLarry', 'ĠSc', 'hem', 'el', ',', 'Ġcalled', 'ĠDeath', 'ĠValley', 'ĠGirls', '.', '<p>', 'Ġ\"', 'Beaut', 'iful', 'ĠSon', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġcollectively', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', ',', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', 'Ġand', 'Ġdrummer', 'ĠPatty', 'ĠSc', 'hem', 'el', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġfourth', 'Ġsingle', 'Ġin', 'ĠApril', 'Ġ1993', 'Ġon', 'Ġthe', 'ĠEuropean', 'Ġlabel', 'ĠCity', 'ĠSl', 'ang', '.', 'Ġ', '<s>', 'ĠTo', 'Ġcoincide', 'Ġwith', 'Ġthe', 'Ġsong', \"'s\", 'Ġlyrics', ',', 'ĠLove', 'Ġused', 'Ġa', 'Ġphotograph', 'Ġof', 'Ġher', 'Ġhusband', ',', 'ĠKurt', 'ĠCob', 'ain', ',', 'Ġat', 'Ġage', 'Ġ7', 'Ġas', 'Ġthe', 'Ġsingle', \"'s\", 'Ġartwork', '.', '<p>', 'ĠThe', 'ĠWolf', 'h', 'ounds', 'Ġare', 'Ġan', 'Ġindie', 'Ġpop', '/', 'no', 'ise', 'Ġpop', 'Ġband', 'Ġformed', 'Ġin', 'ĠRom', 'ford', ',', 'ĠUK', 'Ġin', 'Ġ1985', 'Ġby', 'ĠDave', 'ĠCall', 'ahan', ',', 'ĠPaul', 'ĠClark', ',', 'ĠAndy', 'ĠGold', 'ing', ',', 'ĠAndy', 'ĠBolton', 'Ġand', 'ĠFrank', 'ĠSt', 'eb', 'bing', ',', 'Ġand', 'Ġoriginally', 'Ġactive', 'Ġuntil', 'Ġ1990', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġreformed', 'Ġin', 'Ġ2005', 'Ġand', 'Ġcontinues', 'Ġto', 'Ġwrite', ',', 'Ġrecord', 'Ġand', 'Ġplay', 'Ġlive', ',', 'Ġreleasing', 'Ġnew', 'Ġalbums', 'Ġin', 'Ġ2014', 'Ġand', 'Ġ2016', '.', '<p>', 'ĠLive', 'ĠThrough', 'ĠThis', 'Ġis', 'Ġthe', 'Ġsecond', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġby', 'ĠD', 'GC', 'ĠRecords', 'Ġon', 'ĠApril', 'Ġ12', ',', 'Ġ1994', ',', 'Ġjust', 'Ġone', 'Ġweek', 'Ġafter', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', \"'s\", 'Ġhusband', ',', 'ĠKurt', 'ĠCob', 'ain', ',', 'Ġdied', 'Ġin', 'Ġtheir', 'Ġhome', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'ĠHole', \"'s\", 'Ġonly', 'Ġalbum', 'Ġto', 'Ġfeature', 'Ġbass', 'ist', 'ĠKristen', 'ĠPf', 'aff', 'Ġbefore', 'Ġher', 'Ġdeath', 'Ġin', 'ĠJune', 'Ġ1994', '.', 'Ġ', '<s>', 'ĠRecorded', 'Ġin', 'ĠOctober', 'Ġ1993', ',', 'Ġthe', 'Ġalbum', 'Ġmarked', 'Ġa', 'Ġdivergence', 'Ġfrom', 'Ġthe', 'Ġband', \"'s\", 'Ġunp', 'ol', 'ished', 'Ġhardcore', 'Ġaesthetics', 'Ġto', 'Ġmore', 'Ġrefined', 'Ġmelodies', 'Ġand', 'Ġsong', 'Ġstructure', ',', 'Ġand', 'Ġfeatures', 'Ġproduction', 'Ġby', 'ĠSean', 'ĠSl', 'ade', 'Ġand', 'ĠPaul', 'ĠQ', '.', 'ĠK', 'old', 'erie', ',', 'Ġwith', 'Ġmixing', 'Ġby', 'ĠScott', 'ĠL', 'itt', 'Ġand', 'ĠJ', 'ĠM', 'asc', 'is', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', \"'s\", 'Ġlyrics', 'Ġand', 'Ġpackaging', 'Ġreflect', 'ĠLove', \"'s\", 'Ġpre', 'occup', 'ation', 'Ġwith', 'Ġbeauty', ',', 'Ġand', 'Ġits', 'Ġsongs', 'Ġcontain', 'Ġrepeated', 'Ġmotif', 's', 'Ġof', 'Ġmilk', ',', 'Ġmother', 'hood', ',', 'Ġanti', '-', 'el', 'itism', ',', 'Ġand', 'Ġviolence', 'Ġagainst', 'Ġwomen', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', \"'s\", 'Ġtitle', 'Ġis', 'Ġderived', 'Ġfrom', 'Ġa', 'Ġquote', 'Ġin', 'Ġ\"', 'G', 'one', 'Ġwith', 'Ġthe', 'ĠWind', '\".', '<p>', 'Ġ\"', 'Tur', 'pent', 'ine', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'Ġvocal', 'ist', 'Ġand', 'Ġrhythm', 'Ġguitarist', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġone', 'Ġof', 'Ġthe', 'Ġband', \"'s\", 'Ġfirst', 'Ġcompositions', 'Ġand', 'Ġremained', 'Ġunre', 'leased', 'Ġfor', 'Ġseven', 'Ġyears', 'Ġbefore', 'Ġbeing', 'Ġreleased', 'Ġon', 'Ġthe', 'Ġband', \"'s\", 'Ġsecond', 'ĠEP', ',', 'Ġ\"', 'The', 'ĠFirst', 'ĠSession', '\"', 'Ġon', 'ĠAugust', 'Ġ26', ',', 'Ġ1997', '.', 'Ġ', '<s>', 'ĠAlthough', 'Ġnot', 'Ġas', 'Ġwell', 'Ġknown', 'Ġas', 'ĠHole', \"'s\", 'Ġlater', 'Ġsongs', ',', 'Ġ\"', 'Tur', 'pent', 'ine', '\"', 'Ġis', 'Ġa', 'Ġnotable', 'Ġsong', 'Ġfor', 'Ġthe', 'Ġband', 'Ġas', 'Ġit', 'Ġis', 'Ġoften', 'Ġcited', 'Ġas', 'Ġ\"', 'the', 'Ġfirst', 'ĠHole', 'Ġsong', '.\"', '<p>', 'Ġ\"', 'Miss', 'ĠWorld', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġfifth', 'Ġsingle', 'Ġand', 'Ġthe', 'Ġfirst', 'Ġfrom', 'Ġtheir', 'Ġsecond', 'Ġstudio', 'Ġalbum', ',', 'Ġ\"', 'Live', 'ĠThrough', 'ĠThis', '\",', 'Ġin', 'ĠMarch', 'Ġ1994', '.', '<p>', 'Ġ\"', 'So', 'fter', ',', 'ĠSoft', 'est', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġeighth', 'Ġsingle', 'Ġand', 'Ġfourth', 'Ġand', 'Ġfinal', 'Ġsingle', 'Ġfrom', 'Ġtheir', 'Ġsecond', 'Ġstudio', 'Ġalbum', ',', 'Ġ\"', 'Live', 'ĠThrough', 'ĠThis', '\",', 'Ġin', 'ĠDecember', 'Ġ1995', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsingle', 'Ġwas', 'Ġreleased', 'Ġjust', 'Ġas', 'Ġthe', 'Ġband', 'Ġfinished', 'Ġtheir', 'Ġextensive', 'Ġtouring', 'Ġin', 'Ġ1995', '.', '<p>', 'ĠCourtney', 'ĠMichelle', 'ĠLove', 'Ġ(', 'born', 'ĠCourtney', 'ĠMichelle', 'ĠHarrison', ';', 'ĠJuly', 'Ġ9', ',', 'Ġ1964', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġsinger', ',', 'Ġsong', 'writer', ',', 'Ġactress', ',', 'Ġand', 'Ġvisual', 'Ġartist', '.', 'Ġ', '<s>', 'ĠProl', 'ific', 'Ġin', 'Ġthe', 'Ġpunk', 'Ġand', 'Ġgrun', 'ge', 'Ġscenes', 'Ġof', 'Ġthe', 'Ġ1990', 's', ',', 'ĠLove', 'Ġhas', 'Ġenjoyed', 'Ġa', 'Ġcareer', 'Ġthat', 'Ġspans', 'Ġfour', 'Ġdecades', '.', 'Ġ', '<s>', 'ĠShe', 'Ġrose', 'Ġto', 'Ġprominence', 'Ġas', 'Ġthe', 'Ġfront', 'woman', 'Ġof', 'Ġthe', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwhich', 'Ġshe', 'Ġformed', 'Ġin', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠLove', 'Ġhas', 'Ġdrawn', 'Ġpublic', 'Ġattention', 'Ġfor', 'Ġher', 'Ġunin', 'hibited', 'Ġlive', 'Ġperformances', 'Ġand', 'Ġconfront', 'ational', 'Ġlyrics', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġher', 'Ġhighly', 'Ġpublicized', 'Ġpersonal', 'Ġlife', 'Ġfollowing', 'Ġher', 'Ġmarriage', 'Ġto', 'ĠKurt', 'ĠCob', 'ain', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Who is the director of the 2003 film which has scenes in it filmed at the Quality Cafe in Los Angeles?\n",
      "orig_answer_text:  Todd Phillips\n",
      "decode\n",
      "answers: [{'text': ' by American alternative rock band Hole, written by frontwoman Courtney Love and lead guitarist Eric Erlandson. <s> The song was released as the', 'score': tensor([0.6816], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' by American alternative rock band Hole, written by frontwoman Courtney Love and lead guitarist Eric Erlandson. <s> The song was released as the', 'score': tensor([0.6816], device='cuda:0')}]\n",
      "answer_score: tensor([0.6816], device='cuda:0')\n",
      "answer_text:  by American alternative rock band Hole, written by frontwoman Courtney Love and lead guitarist Eric Erlandson. <s> The song was released as the\n",
      "answer_gold_token_ids: tensor([   20,  7602,   298, 12363], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠThe', 'ĠWolf', 'h', 'ounds']\n",
      "answer_gold:  The Wolfhounds\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġ', 'ĠAmerican', 'Ġpolitician', 'Ġdid', 'ĠDon', 'ah', 'ue', 'Ġreplaced', 'Ġ', '</q>', '<p>', 'ĠMike', 'ĠDmit', 'rich', 'Ġ(', 'born', 'Ġ1936', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'ĠNatural', 'ĠResource', 'ĠConsult', 'ant', 'Ġfrom', 'ĠUtah', '.', 'Ġ', '<s>', 'ĠA', 'ĠDemocrat', ',', 'Ġhe', 'Ġserved', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠUtah', 'ĠState', 'ĠSenate', ',', 'Ġrepresenting', 'Ġthe', 'Ġstate', \"'s\", 'Ġ27', 'th', 'Ġsenate', 'Ġdistrict', 'Ġin', 'ĠPrice', '.', 'Ġ', '<s>', 'ĠDmit', 'rich', 'Ġserved', 'Ġas', 'Ġthe', 'ĠMinority', 'ĠLeader', 'Ġin', 'Ġthe', 'ĠUtah', 'ĠSenate', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġbeing', 'Ġelected', 'Ġto', 'Ġthe', 'ĠUtah', 'ĠSenate', 'ĠDmit', 'rich', 'Ġserved', 'Ġin', 'Ġthe', 'ĠState', 'ĠHouse', 'Ġfrom', 'Ġ1969', 'Ġto', 'Ġ1992', '.', 'Ġ', '<s>', 'ĠHe', 'Ġretired', 'Ġprior', 'Ġto', 'Ġthe', 'Ġ2008', 'Ġelections', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠDavid', 'ĠP', '.', 'ĠH', 'ink', 'ins', '.', '<p>', 'ĠMaurice', 'ĠA', '.', 'ĠDon', 'ah', 'ue', 'Ġ(', 'September', 'Ġ21', ',', 'Ġ1918', 'ĠâĢĵ', 'ĠJanuary', 'Ġ13', ',', 'Ġ1999', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġas', 'ĠPresident', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠSenate', 'Ġfrom', 'Ġ1964', 'Ġto', 'Ġ1971', '.', '<p>', 'ĠJohn', 'ĠHenry', 'ĠH', 'oe', 'ven', 'ĠIII', 'Ġ(', 'born', 'ĠMarch', 'Ġ13', ',', 'Ġ1957', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'Ġthe', 'Ġsenior', 'ĠUnited', 'ĠStates', 'ĠSenator', 'Ġfrom', 'ĠNorth', 'ĠDakota', ',', 'Ġin', 'Ġoffice', 'Ġsince', 'Ġ2011', '.', 'Ġ', '<s>', 'ĠA', 'Ġmember', 'Ġof', 'Ġthe', 'ĠNorth', 'ĠDakota', 'ĠRepublican', 'ĠParty', ',', 'Ġhe', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġthe', 'Ġ31', 'st', 'ĠGovernor', 'Ġof', 'ĠNorth', 'ĠDakota', 'Ġfrom', 'ĠDecember', 'Ġ2000', 'Ġto', 'ĠDecember', 'Ġ2010', '.', 'Ġ', '<s>', 'ĠH', 'oe', 'ven', 'Ġwas', 'Ġelected', 'Ġto', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠSenate', 'Ġin', 'Ġthe', 'ĠNovember', 'Ġ2', ',', 'Ġ2010', 'Ġgeneral', 'Ġelection', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreplaced', 'Ġjunior', 'ĠSenator', 'ĠByron', 'ĠL', '.', 'ĠD', 'organ', ',', 'Ġwho', 'Ġchose', 'Ġnot', 'Ġto', 'Ġseek', 'Ġre', '-', 'election', '.', 'Ġ', '<s>', 'ĠH', 'oe', 'ven', 'Ġbecame', 'Ġthe', 'Ġsenior', 'ĠSenator', 'Ġin', 'Ġ2013', 'Ġafter', 'ĠKent', 'ĠConrad', 'Ġretired', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠHeidi', 'ĠHe', 'it', 'kamp', ',', 'Ġwho', 'Ġwas', 'Ġonce', 'ĠH', 'oe', 'ven', \"'s\", 'Ġopponent', 'Ġfor', 'Ġthe', 'ĠGovernor', \"'s\", 'Ġoffice', '.', '<p>', 'ĠAnne', 'Ġde', 'Ġla', 'ĠBlanc', 'het', 'ai', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġfrom', 'Ġthe', 'Ġstate', 'Ġof', 'ĠVermont', '.', 'Ġ', '<s>', 'ĠShe', 'Ġhas', 'Ġserved', 'Ġas', 'Ġa', 'ĠRepublican', 'Ġmember', 'Ġof', 'Ġthe', 'ĠVermont', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġsince', 'Ġ2003', ',', 'Ġrepresenting', 'Ġthe', 'ĠWashington', '-', '2', 'Ġdistrict', ',', 'Ġwhich', 'Ġincludes', 'Ġthe', 'ĠWashington', 'ĠCounty', 'Ġtowns', 'Ġof', 'ĠBerlin', 'Ġand', 'ĠNorth', 'field', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġalso', 'Ġeditor', 'Ġof', 'Ġ\"', 'Counter', 'point', '\",', 'Ġa', 'Ġquarterly', 'Ġmental', 'Ġhealth', 'Ġpublication', 'Ġdistributed', 'Ġfor', 'Ġfree', 'Ġthroughout', 'ĠVermont', '.', '<p>', 'ĠSue', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġwas', 'Ġappointed', 'Ġin', 'Ġ2016', 'Ġto', 'Ġserve', 'Ġin', 'Ġthe', 'ĠArizona', 'ĠState', 'ĠSenate', 'Ġrepresenting', 'Ġthe', 'Ġfifth', 'Ġlegislative', 'Ġdistrict', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠRepublican', 'ĠParty', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġreplaced', 'ĠK', 'elli', 'ĠWard', 'Ġwho', 'Ġresigned', 'Ġto', 'Ġrun', 'Ġfor', 'Ġthe', 'ĠUnited', 'ĠStates', 'ĠSenate', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġdid', 'Ġnot', 'Ġrun', 'Ġfor', 'Ġre', '-', 'election', 'Ġin', 'Ġ2016', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠSonny', 'ĠBor', 'rell', 'i', '.', '<p>', 'ĠFrank', 'ĠJ', '.', 'ĠDon', 'ah', 'ue', 'Ġ(', '18', '81', 'âĢĵ', '1979', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġas', 'Ġthe', 'ĠMassachusetts', 'ĠSecretary', 'Ġof', 'Ġthe', 'ĠCommonwealth', ',', 'ĠChairman', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠDemocratic', 'ĠState', 'ĠCommittee', ',', 'Ġand', 'Ġas', 'Ġan', 'ĠAssociate', 'ĠJustice', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠSuperior', 'ĠCourt', '.', '<p>', 'ĠCharles', 'ĠW', '.', 'ĠHar', 'low', 'Ġ(', 'born', 'ĠMay', 'Ġ25', ',', 'Ġ1942', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġfrom', 'ĠMaine', '.', 'Ġ', '<s>', 'ĠHar', 'low', 'Ġserved', 'Ġon', 'Ġthe', 'ĠPortland', ',', 'ĠMaine', 'ĠCity', 'ĠCouncil', 'Ġfrom', 'Ġ1990', 'Ġto', 'Ġ1999', ',', 'Ġincluding', 'Ġa', 'Ġterm', 'Ġas', 'Ġceremonial', 'Ġmayor', 'Ġfrom', 'Ġ1992', 'Ġto', 'Ġ1993', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2004', ',', 'ĠHar', 'low', 'Ġwas', 'Ġelected', 'Ġas', 'Ġa', 'ĠDemocrat', 'Ġto', 'Ġthe', 'ĠMaine', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġfrom', 'ĠDistrict', 'Ġ116', '.', 'Ġ', '<s>', 'ĠHe', 'Ġserved', 'Ġuntil', 'Ġ2010', ',', 'Ġwhen', 'Ġhe', 'Ġwas', 'Ġreplaced', 'Ġby', 'Ġhis', 'Ġdaughter', ',', 'ĠDenise', 'ĠHar', 'low', '.', '<p>', 'ĠK', 'elli', 'ĠWard', 'Ġ(\"', 'n', 'Ã©e', '\"', 'ĠKaz', 'nos', 'ki', ';', 'Ġborn', 'ĠJanuary', 'Ġ25', ',', 'Ġ1969', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'Ġoste', 'opathic', 'Ġphysician', '.', 'Ġ', '<s>', 'ĠA', 'Ġmember', 'Ġof', 'Ġthe', 'ĠRepublican', 'ĠParty', ',', 'ĠWard', 'Ġwas', 'Ġelected', 'Ġin', 'Ġ2012', 'Ġto', 'Ġserve', 'Ġin', 'Ġthe', 'ĠArizona', 'ĠState', 'ĠSenate', 'Ġrepresenting', 'Ġthe', 'Ġfifth', 'Ġlegislative', 'Ġdistrict', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġun', 'opp', 'osed', 'Ġfor', 'Ġelection', 'Ġin', 'Ġ2014', '.', 'Ġ', '<s>', 'ĠWhile', 'Ġserving', 'Ġin', 'Ġoffice', ',', 'Ġshe', 'Ġcontinued', 'Ġto', 'Ġpractice', 'Ġmedicine', 'Ġin', 'Ġthe', 'Ġemergency', 'Ġdepartments', 'Ġin', 'ĠLake', 'ĠHav', 'asu', 'ĠCity', 'Ġand', 'ĠKing', 'man', ',', 'ĠArizona', '.', '<p>', 'ĠDaniel', 'ĠM', '.', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġserving', 'Ġin', 'Ġthe', 'ĠMassachusetts', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġsince', 'ĠSeptember', 'Ġ2013', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'ĠWorcester', 'Ġresident', 'Ġand', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠDemocratic', 'ĠParty', '.', '<p>', 'ĠWarren', 'ĠT', '.', 'ĠFur', 'ut', 'ani', 'Ġ(', 'born', 'ĠOctober', 'Ġ16', ',', 'Ġ1947', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġin', 'Ġthe', 'ĠCalifornia', 'ĠState', 'ĠAssembly', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'ĠDemocrat', 'Ġand', 'Ġa', 'Ġfourth', '-', 'generation', 'ĠJapanese', 'ĠAmerican', '.', 'Ġ', '<s>', 'ĠFur', 'ut', 'ani', 'Ġwas', 'Ġelected', 'Ġin', 'Ġa', 'Ġspecial', 'Ġelection', 'Ġin', 'Ġ2008', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreplaced', 'ĠLaura', 'ĠRichardson', 'Ġas', 'Ġthe', 'Ġmember', 'Ġof', 'Ġthe', 'ĠUS', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġfrom', 'ĠCalifornia', \"'s\", 'Ġ37', 'th', 'Ġdistrict', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġbeing', 'Ġelected', ',', 'Ġhe', 'Ġserved', 'Ġon', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠUnified', 'ĠSchool', 'ĠDistrict', 'Ġand', 'Ġthen', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCommunity', 'ĠCollege', 'ĠDistrict', 'ĠBoard', 'Ġof', 'ĠTrust', 'ees', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġthe', 'Ġfirst', 'ĠAsian', 'ĠPacific', 'ĠAmerican', 'Ġever', 'Ġelected', 'Ġto', 'Ġthe', 'ĠLA', 'USD', 'Ġin', 'Ġ1987', 'Ġand', 'Ġbecame', 'Ġthe', 'Ġboard', \"'s\", 'Ġpresident', 'Ġin', 'Ġ1991', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Chang Ucchin was born in korea during a time that ended with the conclusion of what? \n",
      "orig_answer_text:  World War II\n",
      "orig_answer_text:  World War II\n",
      "orig_answer_text:  World War II\n",
      "answers: [{'text': ' While serving in office, she continued to practice medicine in the emergency departments in Lake Havasu City and Kingman, Arizona.', 'score': tensor([0.6718], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' While serving in office, she continued to practice medicine in the emergency departments in Lake Havasu City and Kingman, Arizona.', 'score': tensor([0.6718], device='cuda:0')}]\n",
      "answer_score: tensor([0.6718], device='cuda:0')\n",
      "answer_text:  While serving in office, she continued to practice medicine in the emergency departments in Lake Havasu City and Kingman, Arizona.\n",
      "answer_gold_token_ids: tensor([  229, 13750,  5986], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠK', 'elli', 'ĠWard']\n",
      "answer_gold:  Kelli Ward\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', 'Ġis', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġwith', 'Ġsongs', 'Ġand', 'Ġcomedy', 'Ġsk', 'its', ',', 'Ġit', 'Ġhelped', 'Ġjump', 'Ġstart', 'Ġthe', 'Ġcareer', 'Ġof', 'Ġwhich', 'Ġyoung', 'Ġperformer', ',', 'Ġand', 'ĠAmerican', 'Ġactress', '?', '</q>', '<p>', 'Ġ\"', 'Gu', 'ess', 'ĠWho', 'ĠI', 'ĠSaw', 'ĠToday', '\"', 'Ġis', 'Ġa', 'Ġpopular', 'Ġjazz', 'Ġsong', 'Ġwritten', 'Ġby', 'ĠMurray', 'ĠGrand', 'Ġwith', 'Ġlyrics', 'Ġby', 'ĠEl', 'isse', 'ĠBoyd', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġoriginally', 'Ġcomposed', 'Ġfor', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠBroadway', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\"', 'Ġin', 'Ġwhich', 'Ġit', 'Ġwas', 'Ġsung', 'Ġby', 'ĠJune', 'ĠCarroll', '.', '<p>', 'ĠPaul', 'ĠDavid', 'ĠNass', 'au', 'Ġ(', 'January', 'Ġ30', ',', 'Ġ1930', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', 'ĠâĢĵ', 'ĠMarch', 'Ġ9', ',', 'Ġ2013', 'Ġin', 'ĠPalm', 'ĠBeach', 'ĠGardens', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġcomposer', 'Ġand', 'Ġlyric', 'ist', 'Ġfor', 'Ġthe', 'Ġstage', '.', 'Ġ', '<s>', 'ĠHe', 'Ġcontributed', 'Ġsongs', 'Ġto', 'Ġthe', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1956', '\",', 'Ġand', 'Ġwrote', 'Ġboth', 'Ġthe', 'Ġmusic', 'Ġand', 'Ġlyric', 'Ġto', 'Ġthe', 'ĠBroadway', 'Ġshows', 'Ġ\"', 'Happy', 'ĠTown', '\"', 'Ġ(', '1959', '),', 'Ġ\"', 'A', 'ĠJoy', 'ful', 'ĠNoise', '\"', 'Ġ(', '1966', '),', 'Ġand', 'Ġ\"', 'The', 'ĠEducation', 'Ġof', 'ĠH', '*', 'Y', '*', 'M', '*', 'A', '*', 'N', 'ĠK', '*', 'A', '*', 'P', '*', 'L', '*', 'A', '*', 'N', '\"', 'Ġ(', '1968', ').', 'Ġ', '<s>', 'ĠHe', 'Ġmarried', 'ĠChloe', 'ĠAnderson', 'Ġon', 'ĠDecember', 'Ġ23', ',', 'Ġ1953', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcouple', 'Ġhad', 'Ġtwo', 'Ġchildren', ':', 'ĠRobert', 'Ġand', 'ĠJulie', '.', '<p>', 'ĠNew', 'ĠFaces', 'Ġof', 'Ġ1952', 'Ġis', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġwith', 'Ġsongs', 'Ġand', 'Ġcomedy', 'Ġsk', 'its', '.', 'Ġ', '<s>', 'ĠIt', 'Ġran', 'Ġon', 'ĠBroadway', 'Ġfor', 'Ġnearly', 'Ġa', 'Ġyear', 'Ġin', 'Ġ1952', 'Ġand', 'Ġwas', 'Ġthen', 'Ġmade', 'Ġinto', 'Ġa', 'Ġmotion', 'Ġpicture', 'Ġin', 'Ġ1954', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhelped', 'Ġjump', 'Ġstart', 'Ġthe', 'Ġcareers', 'Ġof', 'Ġseveral', 'Ġyoung', 'Ġperformers', 'Ġincluding', 'ĠPaul', 'ĠLynd', 'e', ',', 'ĠAlice', 'ĠGhost', 'ley', ',', 'ĠEarth', 'a', 'ĠKitt', ',', 'ĠRobert', 'ĠCl', 'ary', ',', 'ĠCarol', 'ĠLawrence', ',', 'ĠRon', 'ny', 'ĠGraham', ',', 'Ġperformer', '/', 'writer', 'ĠMel', 'ĠBrooks', 'Ġ(', 'as', 'ĠMelvin', 'ĠBrooks', '),', 'Ġand', 'Ġlyric', 'ist', 'ĠSheldon', 'ĠH', 'arn', 'ick', '.', '<p>', 'ĠCarol', 'ĠLawrence', 'Ġ(', 'born', 'ĠSeptember', 'Ġ5', ',', 'Ġ1932', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactress', ',', 'Ġmost', 'Ġoften', 'Ġassociated', 'Ġwith', 'Ġmusical', 'Ġtheatre', ',', 'Ġbut', 'Ġwho', 'Ġhas', 'Ġalso', 'Ġappeared', 'Ġextensively', 'Ġon', 'Ġtelevision', '.', '<p>', 'Ġ\"', 'Mon', 'oton', 'ous', '\"', 'Ġis', 'Ġa', 'Ġpopular', 'Ġsong', 'Ġwritten', 'Ġby', 'ĠJune', 'ĠCarroll', 'Ġand', 'ĠArthur', 'ĠS', 'iegel', 'Ġfor', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠBroadway', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġwritten', 'Ġbased', 'Ġon', 'Ġthe', 'Ġexperiences', 'Ġof', 'Ġits', 'Ġsinger', 'ĠEarth', 'a', 'ĠKitt', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġperformed', ',', 'Ġat', 'Ġthe', 'Ġinsistence', 'Ġof', 'ĠKitt', ',', 'Ġon', 'Ġthree', 'Ġcha', 'ise', 'Ġlong', 'ues', 'Ġ(', 'K', 'itt', 'Ġtried', 'Ġoriginally', 'Ġfor', 'Ġsix', 'Ġand', 'Ġwas', 'Ġgiven', 'Ġthree', 'Ġin', 'Ġcompromise', '),', 'Ġcrawling', 'Ġcat', '-', 'like', 'Ġfrom', 'Ġone', 'Ġto', 'Ġthe', 'Ġother', ',', 'Ġdemonstrating', 'Ġher', 'Ġflexibility', 'Ġand', 'Ġher', 'Ġdance', 'Ġtraining', 'Ġfrom', 'Ġthe', 'ĠKatherine', 'ĠDunham', 'ĠCompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġalso', 'Ġincludes', 'Ġreferences', 'Ġto', 'Ġmany', 'Ġwell', '-', 'known', 'Ġpeople', 'Ġof', 'Ġthe', 'Ġ1950', 's', '.', 'Ġ', '<s>', 'ĠPeople', 'Ġreferenced', 'Ġin', 'Ġthe', 'Ġsong', 'Ġinclude', ':', '<p>', 'ĠHow', 'Ġto', 'ĠEat', 'ĠLike', 'Ġa', 'ĠChild', 'ĠâĢĵ', 'ĠAnd', 'ĠOther', 'ĠLessons', 'Ġin', 'ĠNot', 'ĠBeing', 'Ġa', 'ĠG', 'rown', '-', 'up', 'Ġis', 'Ġan', 'Ġoriginal', 'Ġmusical', 'Ġcomedy', 'Ġtelevision', 'Ġspecial', 'Ġthat', 'Ġaired', 'Ġon', 'ĠNBC', 'Ġon', 'ĠSeptember', 'Ġ22', ',', 'Ġ1981', '.', 'Ġ', '<s>', 'ĠBased', 'Ġon', 'ĠDel', 'ia', 'ĠE', 'ph', 'ron', \"'s\", 'Ġbest', '-', 'selling', 'Ġbook', 'Ġof', 'Ġthe', 'Ġsame', 'Ġname', ',', 'Ġand', 'Ġadapted', 'Ġfor', 'Ġtelevision', 'Ġby', 'ĠJudith', 'ĠK', 'ahan', 'Ġwith', 'Ġmusic', 'Ġand', 'Ġlyrics', 'Ġby', 'ĠJohn', 'ĠFor', 'ster', ',', 'Ġthe', 'Ġone', '-', 'hour', 'Ġspecial', ',', 'Ġthrough', 'Ġa', 'Ġseries', 'Ġof', 'Ġcomedy', 'Ġsk', 'its', 'Ġand', 'Ġsongs', ',', 'Ġlamp', 'oons', 'Ġthe', 'Ġadult', 'Ġworld', 'Ġthrough', 'Ġthe', 'Ġeyes', 'Ġof', 'Ġchildren', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmusical', 'Ġvariety', 'Ġstars', 'ĠDick', 'ĠVan', 'ĠDy', 'ke', 'Ġas', 'Ġthe', 'Ġresident', 'Ġ\"', 'grown', '-', 'up', '\"', 'Ġalongside', 'Ġ15', 'Ġchildren', 'Ġ(', '8', 'Ġboys', 'Ġand', 'Ġ7', 'Ġgirls', ')', 'Ġranging', 'Ġin', 'Ġage', 'Ġfrom', 'Ġ7', 'Ġto', 'Ġ13', '.', 'Ġ', '<s>', 'ĠSeveral', 'Ġof', 'Ġthe', 'Ġspecial', \"'s\", 'Ġyoung', 'Ġperformers', 'Ġwould', 'Ġsubsequently', 'Ġgo', 'Ġon', 'Ġto', 'Ġachieve', 'Ġchild', 'Ġst', 'ard', 'om', 'Ġin', 'Ġtheir', 'Ġown', 'Ġright', ',', 'Ġmost', 'Ġnotably', 'ĠCorey', 'ĠFeldman', ',', 'ĠBilly', 'ĠJacob', 'y', 'Ġand', 'ĠGeorg', 'ĠOld', 'en', '.', '<p>', 'ĠNew', 'ĠFaces', 'Ġis', 'Ġa', 'Ġ1954', 'ĠAmerican', 'Ġfilm', 'Ġadaptation', 'Ġof', 'Ġthe', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\"', 'Ġdirected', 'Ġby', 'ĠHarry', 'ĠHor', 'ner', 'Ġand', 'Ġsketches', 'Ġdirected', 'Ġby', 'ĠJohn', 'ĠBe', 'al', '.', 'Ġ', '<s>', 'ĠFil', 'med', 'Ġin', 'ĠCinem', 'asc', 'ope', 'Ġand', 'ĠEast', 'man', 'color', 'Ġit', 'Ġwas', 'Ġreleased', 'Ġby', 'ĠTw', 'ent', 'ieth', 'ĠCentury', 'ĠFox', 'Ġon', 'ĠMarch', 'Ġ6', ',', 'Ġ1954', '.', '<p>', 'ĠMary', 'ĠBe', 'go', 'Ã±a', 'Ġ(', 'born', 'Ġ1929', 'Ġin', 'ĠBil', 'b', 'ao', ',', 'ĠSpain', ')', 'Ġwas', 'Ġthe', 'Ġstage', 'Ġname', 'Ġof', 'ĠMar', 'ÃŃa', 'ĠBr', 'ag', 'as', 'ĠBe', 'go', 'Ã±a', 'Ġwho', 'Ġwas', 'Ġa', 'ĠSpanish', 'Ġv', 'ed', 'ette', 'Ġand', 'Ġactress', '.', 'Ġ', '<s>', 'ĠShe', 'Ġstarted', 'Ġdancing', 'Ġat', 'Ġage', 'Ġ7', 'Ġand', 'Ġperformed', 'Ġin', 'Ġvenues', 'Ġin', 'ĠMadrid', 'Ġwhile', 'Ġshe', 'Ġwas', 'Ġstudying', 'Ġat', 'Ġthe', 'ĠAcad', 'emies', 'Ġof', 'ĠQu', 'i', 'rog', 'a', ',', 'ĠO', 'mp', 'ÃŃn', 'Ġand', 'ĠMon', 'real', '.', 'Ġ', '<s>', 'ĠThen', 'Ġshe', 'Ġstudied', 'Ġwith', 'ĠAntonio', 'ĠB', 'aut', 'ista', 'Ġand', 'ĠSach', 'a', 'ĠG', 'oud', 'ine', 'Ġin', 'ĠBarcelona', '.', 'Ġ', '<s>', 'ĠShe', 'Ġdebuted', 'Ġin', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġat', 'Ġthe', 'Ġage', 'Ġof', 'Ġfourteen', 'Ġand', 'Ġduring', 'ĠSpanish', 'ĠCivil', 'ĠWar', 'Ġ(', 'from', 'Ġ1936', 'Ġto', 'Ġ1939', ')', 'Ġwas', 'Ġpart', 'Ġof', 'Ġthe', 'ĠC', 'NT', 'ĠUnion', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1943', ',', 'ĠBe', 'go', 'Ã±a', 'Ġworked', 'Ġin', 'ĠValencia', 'Ġin', 'ĠJuan', 'ita', 'ĠRe', 'ina', \"'s\", 'Ġacting', 'Ġtrou', 'pe', ',', 'Ġbut', 'Ġreturned', 'Ġto', 'ĠMadrid', 'Ġto', 'Ġdebut', 'Ġin', 'Ġthe', 'ĠTe', 'atro', 'ĠCalder', 'Ã³n', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1945', 'Ġshe', 'Ġappeared', 'Ġin', 'Ġthe', 'Ġrev', 'ue', 'Ġ\"', 'Dan', 'ub', 'io', 'ĠAz', 'ul', '\"', 'Ġ(', 'Blue', 'ĠDan', 'ube', ')', 'Ġwith', 'ĠMan', 'olo', 'ĠCar', 'ac', 'ol', 'Ġand', 'ĠL', 'ola', 'ĠFlores', 'Ġand', 'Ġthe', 'Ġfollowing', 'Ġyear', 'Ġwas', 'Ġthe', 'Ġprincipal', 'Ġv', 'ed', 'ette', 'Ġin', 'Ġthe', 'Ġrev', 'ue', 'Ġ\"', 'De', 'Ġla', 'ĠTier', 'ra', 'Ġa', 'ĠVenus', '\"', 'Ġ(', 'From', 'Ġthe', 'ĠEarth', 'Ġto', 'ĠVenus', ').', 'Ġ', '<s>', 'ĠFor', 'Ġthe', 'Ġnext', 'Ġseveral', 'Ġyears', 'Ġshe', 'Ġperformed', 'Ġin', 'Ġvariety', 'Ġshows', 'Ġwith', 'Ġvarious', 'Ġacting', 'Ġt', 'roup', 'es', ',', 'Ġsuch', 'Ġas', 'Ġ\"', 'T', 'res', 'Ġd', 'ÃŃ', 'as', 'Ġpara', 'Ġqu', 'erer', 'te', '\"', 'Ġ(', '1945', '),', 'Ġ\"', 'Â', '¡', 'R', 'Ã³', 'b', 'ame', 'Ġest', 'a', 'Ġn', 'oche', '!\"', 'Ġ', '<s>', 'Ġ(', '19', '47', '),', 'Ġ\"', 'A', 'ĠLa', 'ĠHab', 'ana', 'Ġme', 'Ġvoy', '\"', 'Ġ(', '19', '48', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ1951', ',', 'Ġshe', 'Ġdid', 'Ġa', 'Ġseason', 'Ġin', 'Ġthe', 'ĠUS', 'Ġand', 'Ġthen', 'Ġreturned', 'Ġto', 'ĠSpain', 'Ġappearing', 'Ġin', 'Ġ\"', 'Â', '¡', 'A', 'Ġv', 'iv', 'ir', 'Ġdel', 'Ġcu', 'ento', '!\"', 'Ġ', '<s>', 'Ġ(', '19', '52', ')', 'Ġand', 'Ġ\"', 'Los', 'Ġl', 'ÃŃ', 'os', 'Ġde', 'ĠEl', 'ÃŃ', 'as', '\"', 'Ġ(', '19', '54', ').', 'Ġ', '<s>', 'ĠBe', 'go', 'Ã±a', 'Ġthen', 'Ġformed', 'Ġher', 'Ġown', 'Ġcompany', ',', 'Ġwhich', 'Ġbetween', 'Ġ1953', 'Ġand', 'Ġ1960', 'Ġperformed', 'Ġten', 'Ġdifferent', 'Ġplays', '.', 'Ġ', '<s>', 'ĠAs', 'Ġher', 'Ġcareer', 'Ġdeclined', 'Ġin', 'Ġrev', 'ue', 'Ġstyle', 'Ġshows', ',', 'Ġshe', 'Ġbegan', 'Ġperforming', 'Ġin', 'Ġcomedy', 'Ġtheater', ',', 'Ġfilm', ',', 'Ġand', 'Ġtelevision', '.', '<p>', 'ĠLeonard', 'ĠS', 'ill', 'man', 'Ġ(', 'May', 'Ġ9', ',', 'Ġ1908', 'Ġ-', 'ĠJanuary', 'Ġ23', ',', 'Ġ1982', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'ĠBroadway', 'Ġproducer', '.', 'Ġ', '<s>', 'ĠBorn', 'Ġin', 'ĠDetroit', ',', 'ĠMichigan', 'Ġon', 'ĠMay', 'Ġ9', ',', 'Ġ1908', ',', 'Ġhe', 'Ġwas', 'Ġthe', 'Ġbrother', 'Ġof', 'ĠJune', 'ĠCarroll', ',', 'Ġthe', 'Ġbrother', '-', 'in', '-', 'law', 'Ġof', 'ĠSidney', 'ĠCarroll', 'Ġand', 'Ġthe', 'Ġuncle', 'Ġof', 'ĠSteve', 'ĠReich', 'Ġand', 'ĠJonathan', 'ĠCarroll', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġperhaps', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġseries', 'Ġof', 'Ġmusical', 'Ġrev', 'ues', ',', 'Ġ\"', 'Leon', 'ard', 'ĠS', 'ill', 'man', \"'s\", 'ĠNew', 'ĠFaces', '\",', 'Ġwhich', 'Ġintroduced', 'Ġmany', 'Ġmajor', 'Ġstars', 'Ġto', 'ĠBroadway', 'Ġaudiences', ',', 'Ġsuch', 'Ġas', 'ĠEarth', 'a', 'ĠKitt', ',', 'ĠIn', 'ga', 'ĠSw', 'enson', ',', 'ĠPaul', 'ĠLynd', 'e', 'Ġand', 'ĠMaggie', 'ĠSmith', '.', 'Ġ', '<s>', 'ĠVers', 'ions', 'Ġof', 'Ġ\"', 'New', 'ĠFaces', '\"', 'Ġwere', 'Ġproduced', 'Ġin', 'Ġ1934', ',', 'Ġ1936', 'Ġ(', 'made', 'Ġinto', 'Ġthe', 'Ġfilm', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1937', '\"),', 'Ġ1943', ',', 'Ġ1952', 'Ġ(', 'made', 'Ġinto', 'Ġthe', 'Ġfilm', 'Ġ\"', 'New', 'ĠFaces', '\"),', 'Ġ1956', ',', 'Ġ1962', 'Ġand', 'Ġ1968', '.', 'Ġ', '<s>', 'ĠThe', 'Ġvery', 'Ġfirst', 'Ġ\"', 'New', 'ĠFaces', '\"', 'Ġin', 'Ġ1934', 'Ġincluded', 'Ġactors', 'ĠHenry', 'ĠF', 'onda', ',', 'ĠIm', 'ogene', 'ĠCoca', 'Ġand', 'ĠFrances', 'ĠDew', 'ey', 'ĠWorm', 'ser', '.', '<p>', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠNew', 'ĠFaces', 'Ġof', 'Ġ1968', 'Ġis', 'Ġa', 'Ġ1968', 'Ġmusical', 'Ġrev', 'ue', 'Ġproduced', 'Ġby', 'ĠLeonard', 'ĠS', 'ill', 'man', '.', 'Ġ', '<s>', 'ĠThe', 'Ġoriginal', 'Ġproduction', 'Ġincluded', 'ĠMad', 'eline', 'ĠKahn', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  American politician Joe Heck ran unsuccessfully against Democrat Catherine Cortez Masto, a woman who previously served as the 32nd Attorney General of where?\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "answers: [{'text': ' other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the', 'score': tensor([0.6689], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the', 'score': tensor([0.6689], device='cuda:0')}]\n",
      "answer_score: tensor([0.6689], device='cuda:0')\n",
      "answer_text:  other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the\n",
      "answer_gold_token_ids: tensor([9347, 6226,    6], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠCarol', 'ĠLawrence', ',']\n",
      "answer_gold:  Carol Lawrence,\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Who', 'Ġis', 'Ġthe', 'Ġdirector', 'Ġof', 'Ġthe', 'Ġ2003', 'Ġfilm', 'Ġwhich', 'Ġhas', 'Ġscenes', 'Ġin', 'Ġit', 'Ġfilmed', 'Ġat', 'Ġthe', 'ĠQuality', 'ĠCafe', 'Ġin', 'ĠLos', 'ĠAngeles', '?', '</q>', '<p>', 'ĠThe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwas', 'Ġstarted', 'Ġin', 'Ġ18', '85', '.', 'Ġ', '<s>', 'ĠOriginally', ',', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwas', 'Ġsplit', 'Ġinto', 'Ġfive', 'Ġindividual', 'Ġunions', 'Ġof', 'Ġb', 'akers', ',', 'Ġcigar', 'Ġmakers', ',', 'Ġprinters', ',', 'Ġtail', 'ors', ',', 'Ġand', 'Ġcar', 'pent', 'ers', '.', 'Ġ', '<s>', 'ĠNow', 'Ġthey', 'Ġrepresent', 'Ġover', 'Ġ300', 'Ġunions', ',', 'Ġabout', 'Ġ800', ',', '000', 'Ġpeople', ',', 'Ġthroughout', 'ĠLos', 'ĠAngeles', 'ĠCounty', ',', 'Ġmaking', 'Ġit', 'Ġthe', 'Ġsecond', 'Ġlargest', 'Ġin', 'Ġthe', 'Ġcountry', '.', 'Ġ', '<s>', 'ĠâĢ', 'ľ', 'A', 'Ġsurvey', 'Ġpublished', 'Ġin', 'ĠDecember', 'Ġ2003', 'Ġshowed', 'Ġthat', 'Ġthe', 'Ġthree', 'Ġlargest', 'Ġunions', 'Ġin', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwere', 'ĠSE', 'IU', 'Ġ4', '34', 'B', 'Ġ(', 'with', 'Ġseventy', '-', 'four', 'Ġthousand', 'Ġhome', 'care', 'Ġand', 'Ġnursing', 'Ġhome', 'Ġworkers', '),', 'ĠSE', 'IU', 'Ġ399', 'Ġwith', 'Ġforty', '-', 'five', 'Ġthousand', 'Ġhealth', 'Ġcare', 'Ġand', 'Ġother', 'Ġemployees', ',', 'Ġand', 'Ġthe', 'ĠUnited', 'ĠTeachers', 'Ġof', 'ĠLos', 'ĠAngeles', 'Ġ(', 'with', 'Ġthirty', 'Ġthousand', 'Ġteachers', 'Ġfrom', 'Ġthe', 'ĠAmerican', 'ĠFederation', 'Ġand', 'Ġthe', 'ĠNational', 'ĠEducation', 'ĠAssociation', ').', 'âĢ', 'Ŀ', 'Ġ', '<s>', 'ĠThey', 'Ġhave', 'Ġhelped', 'Ġmake', 'ĠLos', 'ĠAngeles', 'Ġa', 'Ġunion', 'Ġcity', '.', 'Ġ', '<s>', 'ĠTheir', 'Ġmission', 'Ġis', 'Ġto', 'ĠâĢ', 'ľ', 'Ġpromote', 'Ġa', 'Ġvoice', 'Ġfor', 'Ġworkers', 'Ġthrough', 'Ġorganizing', 'Ġthemselves', 'Ġinto', 'Ġunions', ',', 'Ġbuilding', 'Ġstrong', 'Ġcoal', 'itions', 'Ġof', 'Ġlabor', ',', 'Ġcommunity', ',', 'Ġfaith', ',', 'Ġand', 'Ġresponsible', 'Ġbusinesses', ',', 'Ġengaging', 'Ġin', 'Ġboth', 'Ġorganizing', 'Ġand', 'Ġpolitical', 'Ġcampaigns', ',', 'Ġelecting', 'Ġpro', '-', 'union', 'Ġand', 'Ġpro', '-', 'worker', 'Ġcandidates', 'Ġand', 'Ġadvancing', 'Ġpublic', 'Ġpolicies', 'Ġthat', 'Ġsupport', 'Ġworkers', ',', 'Ġfamilies', 'Ġand', 'Ġlocal', 'Ġcommunities', '.', 'âĢ', 'Ŀ', 'Ġ', '<s>', 'ĠThey', 'Ġalso', 'Ġencourage', 'Ġpeople', 'Ġto', 'Ġhelp', 'Ġmake', 'Ġchange', 'Ġby', 'Ġvoting', '.', 'Ġ', '<s>', 'ĠThe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'Ġlabor', 'Ġis', 'Ġa', 'Ġmajor', 'Ġfocal', 'Ġpoint', 'Ġfor', 'Ġnew', 'ĠAmerican', 'Ġlabor', 'Ġmovement', '.', 'Ġ', '<s>', 'ĠRecently', ',', 'Ġthe', 'Ġimpressive', 'Ġprogression', 'Ġof', 'ĠLos', 'ĠAngeles', 'Ġbecoming', 'Ġa', 'Ġunion', 'Ġcity', 'Ġhas', 'Ġbecome', 'Ġa', 'Ġstand', 'Ġout', 'Ġmodel', 'Ġfor', 'Ġother', 'Ġnon', '-', 'union', 'Ġcities', 'Ġbecause', 'Ġof', 'ĠLos', 'ĠAngeles', 'âĢ', 'Ļ', 'Ġanti', '-', 'union', 'Ġhistory', '.', 'Ġ', '<s>', 'ĠLos', 'ĠAngeles', 'Ġcombines', 'Ġthe', 'Ġeconomic', 'Ġdevelopment', 'Ġactivism', 'Ġand', 'Ġthe', 'Ġrefined', 'Ġpolitical', 'Ġwork', 'Ġof', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', '.', '<p>', 'ĠThe', 'ĠGood', 'ĠLife', 'ĠCafe', 'Ġwas', 'Ġa', 'Ġhealth', 'Ġfood', 'Ġmarket', 'Ġand', 'Ġcafe', 'Ġin', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', ',', 'Ġknown', 'Ġfor', 'Ġits', 'Ġopen', 'Ġmic', 'Ġnights', 'Ġthat', 'Ġhelped', 'Ġthe', 'Ġ1990', 's', 'ĠLos', 'ĠAngeles', 'Ġalternative', 'Ġhip', 'Ġhop', 'Ġmovement', 'Ġflourish', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2008', ',', 'Ġdirector', 'ĠAv', 'a', 'ĠDu', 'V', 'ern', 'ay', ',', 'Ġwho', 'Ġhad', 'Ġperformed', 'Ġat', 'Ġthe', 'Ġcafe', 'Ġwith', 'Ġthe', 'ĠFigures', 'Ġof', 'ĠSpeech', 'Ġhip', 'Ġhop', 'Ġgroup', ',', 'Ġreleased', 'Ġa', 'Ġdocumentary', 'Ġabout', 'Ġthe', 'Ġcafe', ',', 'Ġ\"', 'This', 'ĠIs', 'ĠThe', 'ĠLife', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġfeatured', 'Ġa', 'Ġnumber', 'Ġof', 'Ġhip', 'Ġhop', 'Ġartists', 'Ġdiscussing', 'Ġthe', 'Ġimportance', 'Ġof', 'Ġthe', 'ĠGood', 'ĠLife', 'ĠCafe', 'Ġto', 'Ġthemselves', 'Ġand', 'Ġthe', 'Ġhip', 'Ġhop', 'Ġscene', '.', 'Ġ', '<s>', 'ĠThe', 'ĠCafe', 'Ġwas', 'Ġopen', 'Ġfrom', 'Ġ1989', 'Ġto', 'Ġ1999', '.', '<p>', 'ĠAustin', 'ĠYoung', 'Ġ(', 'born', 'ĠApril', 'Ġ12', ',', 'Ġ1966', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġphotographer', ',', 'Ġfilm', 'Ġmaker', 'Ġand', 'Ġnew', 'Ġmedia', 'Ġartist', 'Ġcurrently', 'Ġbased', 'Ġin', 'ĠLos', 'ĠAngeles', '.', 'Ġ', '<s>', 'ĠHis', 'Ġwork', 'Ġhas', 'Ġcreated', 'Ġan', 'Ġen', 'cycl', 'oped', 'ic', 'Ġdocumentation', 'Ġof', 'Ġsub', 'Ġand', 'Ġtrans', 'Ġculture', 'Ġin', 'ĠNew', 'ĠYork', ',', 'ĠLos', 'ĠAngeles', 'Ġand', 'ĠSan', 'ĠFrancisco', '.', 'Ġ', '<s>', 'ĠYoung', \"'s\", 'Ġphotographs', 'Ġhave', 'Ġbeen', 'Ġfeatured', 'Ġin', 'Ġmajor', 'Ġpublications', 'Ġsuch', 'Ġas', 'ĠInterview', 'Ġmagazine', ',', 'ĠOK', ',', 'Ġand', 'ĠFl', 'aunt', 'Ġand', 'Ġhave', 'Ġbeen', 'Ġshown', 'Ġin', 'Ġsolo', 'Ġexhibitions', 'Ġand', 'Ġprojects', 'Ġat', 'ĠL', 'AC', 'MA', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠMachine', 'ĠProject', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠHammer', 'ĠMuseum', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠBerkeley', 'ĠArt', 'ĠMuseum', 'Ġ(', 'Ber', 'keley', ',', 'ĠCalifornia', ');', 'Ġand', 'Ġas', 'Ġwell', 'Ġas', 'Ġgroups', 'Ġshows', 'Ġat', 'ĠLos', 'ĠAngeles', 'ĠContemporary', 'ĠEx', 'hib', 'itions', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', ')', 'Ġand', 'ĠStephen', 'ĠCohen', 'ĠGallery', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', ').', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', 'Ġto', 'Ġphotography', 'Ġand', 'Ġfilm', 'Ġmaking', ',', 'ĠYoung', 'Ġis', 'Ġco', '-', 'founder', 'Ġof', 'ĠFallen', 'ĠFruit', ',', 'Ġan', 'Ġart', 'Ġcollective', 'Ġwho', 'Ġuse', 'Ġfruit', 'Ġas', 'Ġa', 'Ġcommon', 'Ġdenomin', 'ator', 'Ġfor', 'Ġpublic', 'Ġengagement', 'Ġand', 'Ġcollaboration', '.', '<p>', 'ĠOld', 'ĠSchool', 'Ġis', 'Ġa', 'Ġ2003', 'ĠAmerican', 'Ġcomedy', 'Ġfilm', 'Ġreleased', 'Ġby', 'ĠDream', 'Works', 'ĠPictures', 'Ġand', 'ĠThe', 'ĠMonte', 'c', 'ito', 'ĠPicture', 'ĠCompany', 'Ġand', 'Ġdirected', 'Ġby', 'ĠTodd', 'ĠPhillips', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠCourt', 'ĠCr', 'and', 'all', ',', 'Ġand', 'Ġthe', 'Ġfilm', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠPhillips', 'Ġand', 'ĠScot', 'ĠArmstrong', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġstars', 'ĠLuke', 'ĠWilson', ',', 'ĠVince', 'ĠVaughn', ',', 'Ġand', 'ĠWill', 'ĠFer', 'rell', 'Ġas', 'Ġthree', 'Ġdepressed', 'Ġthirty', '-', 's', 'omet', 'h', 'ings', 'Ġwho', 'Ġseek', 'Ġto', 'Ġre', '-', 'live', 'Ġtheir', 'Ġcollege', 'Ġdays', 'Ġby', 'Ġstarting', 'Ġa', 'Ġfraternity', ',', 'Ġand', 'Ġthe', 'Ġtrib', 'ulations', 'Ġthey', 'Ġencounter', 'Ġin', 'Ġdoing', 'Ġso', '.', 'Ġ', '<s>', 'ĠSince', 'Ġits', 'Ġrelease', 'Ġit', 'Ġhas', 'Ġgained', 'Ġa', 'Ġmassive', 'Ġcult', 'Ġfollowing', ',', 'Ġsince', 'Ġa', 'Ġlot', 'Ġof', 'Ġminor', 'Ġcharacters', 'Ġin', 'Ġthe', 'Ġfilm', 'Ġwent', 'Ġon', 'Ġto', 'Ġhave', 'Ġhuge', 'Ġcareers', 'Ġsuch', 'Ġas', 'ĠSimon', 'ĠHel', 'berg', ',', 'ĠE', 'lish', 'a', 'ĠC', 'uth', 'bert', ',', 'ĠRob', 'ĠCord', 'dry', 'Ġand', 'ĠArt', 'ie', 'ĠLange', '.', '<p>', 'ĠStephen', 'ĠNicholas', 'Ġ(', 'born', 'Ġ23', 'ĠAugust', 'Ġ1978', ')', 'Ġalso', 'Ġknown', 'Ġas', 'ĠStephen', 'ĠCharles', 'ĠNicholas', 'Ġis', 'Ġan', 'Ġactor', 'Ġand', 'Ġpresenter', 'Ġfrom', 'ĠDon', 'caster', ',', 'ĠSouth', 'ĠYorkshire', ',', 'ĠEngland', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġcurrently', 'Ġlives', 'Ġin', 'ĠSheffield', ',', 'Ġhis', 'Ġfirst', 'Ġrole', 'Ġwas', 'Ġon', 'ĠSky', 'ĠOne', \"'s\", 'ĠDream', 'ĠTeam', ',', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠScott', 'ĠWard', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġthere', ',', 'Ġhe', 'Ġfilmed', 'Ġthe', 'Ġfirst', 'Ġin', 'Ġthe', 'Ġtrilogy', 'ĠGoal', '!', 'Ġ', '<s>', 'Ġ(', 'In', 'Ġwhich', 'Ġhe', 'Ġplayed', 'Ġa', 'ĠNewcastle', 'ĠUnited', 'ĠRes', 'erves', 'Ġplayer', ').', 'Ġ', '<s>', 'ĠFollowing', 'Ġthis', ',', 'Ġhe', 'Ġmoved', 'Ġto', 'ĠLos', 'ĠAngeles', ',', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠSmith', 'Ġin', 'Ġthe', 'Ġfeature', 'Ġfilm', 'ĠFut', 'ba', 'al', ':', 'ĠThe', 'ĠPrice', 'Ġof', 'ĠDreams', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġthen', 'Ġreturned', 'Ġto', 'Ġthe', 'ĠUK', 'Ġto', 'Ġmake', 'Ġa', 'ĠB', 'ollywood', 'Ġfilm', 'Ġcalled', 'ĠDh', 'ana', 'ĠDh', 'ana', 'ĠGoal', 'Ġwith', 'ĠJohn', 'ĠAbraham', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġthen', 'Ġexperienced', 'Ġhis', 'Ġfirst', 'Ġopportunity', 'Ġin', 'Ġreality', 'ĠTV', 'Ġwith', 'Ġthe', 'Ġshow', 'ĠPremier', 'ĠLeague', 'ĠAll', 'ĠStars', 'Ġfor', 'ĠSky', 'ĠOne', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġplaying', 'Ġa', 'Ġfootballer', ',', 'Ġhe', 'Ġwas', 'Ġon', '-', 'hand', 'Ġto', 'Ġpresent', 'Ġcelebrity', 'Ġgossip', 'Ġand', 'Ġpitch', 'Ġside', 'Ġreports', '.', 'Ġ', '<s>', 'ĠHe', 'Ġthen', 'Ġappeared', 'Ġin', 'ĠCelebrity', 'ĠMost', 'ĠHaunted', 'Ġand', 'ĠDate', 'Ġthe', 'ĠEnemy', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġthere', 'Ġhe', 'Ġthen', 'Ġwent', 'Ġon', 'Ġto', 'Ġstar', 'Ġin', 'ĠGoal', 'Ġ3', 'Ġwhere', 'Ġhe', 'Ġnot', 'Ġonly', 'Ġacted', 'Ġin', 'Ġthe', 'Ġfilm', 'Ġhe', 'Ġalso', 'Ġbecame', 'Ġthe', 'Ġfootball', 'Ġchore', 'ographer', 'Ġand', 'Ġchore', 'ographed', 'Ġall', 'Ġthe', 'Ġfootball', 'Ġscenes', 'Ġin', 'Ġthe', 'Ġfilm', '.', 'Ġ', '<s>', 'ĠNicholas', 'Ġthen', 'Ġstarred', 'Ġin', 'Ġthe', 'Ġfilm', 'ĠDam', 'ned', 'ĠUnited', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠWelsh', 'Ġinternational', 'ĠAlan', 'ĠDur', 'ban', ',', 'Ġthe', 'Ġfilm', 'Ġwas', 'Ġfilmed', 'Ġin', 'ĠChester', 'field', 'Ġand', 'ĠLeeds', 'Ġand', 'Ġwas', 'Ġdirected', 'Ġby', 'ĠOscar', 'Ġwinner', 'ĠTom', 'ĠHo', 'oper', 'Ġand', 'Ġalso', 'Ġstarred', 'ĠOscar', 'Ġnominated', 'ĠMichael', 'ĠSheen', '.', 'Ġ', '<s>', 'ĠStephens', 'Ġnext', 'Ġproduction', 'Ġwas', 'Ġthe', 'Ġfeature', 'Ġfilm', 'Ġcalled', \"Ġ'\", 'No', 'ĠWay', 'ĠBack', 'ĠNow', \"'\", 'about', 'Ġthe', 'Ġnotorious', 'ĠManchester', 'Ġdistrict', 'Ġof', 'ĠMoss', 'ĠSide', ',', 'Ġwhere', 'ĠStephen', 'Ġplayed', 'Ġthe', 'Ġlead', 'Ġactor', 'ĠStuart', 'ĠGavin', ',', 'The', 'Ġfeature', 'Ġis', 'Ġroughly', 'Ġbased', 'Ġon', 'Ġthe', 'Ġnotorious', 'ĠGo', 'och', 'Ġgang', 'Ġthat', 'Ġterror', 'ised', 'ĠManchester', 'Ġthroughout', 'Ġthe', 'Ġyears', '.', 'Ġ', '<s>', 'ĠThe', 'Ġnext', 'Ġmove', 'Ġfor', 'ĠStephen', 'Ġwas', 'Ġp', 'antom', 'ime', 'Ġwhere', 'Ġhe', 'Ġwas', 'Ġpart', 'Ġof', 'Ġthe', 'Ġproduction', 'ĠAl', 'addin', 'Ġover', 'Ġthe', 'ĠChristmas', 'Ġperiod', 'Ġof', 'Ġ2015', 'Ġin', 'ĠDon', 'caster', 'Ġplaying', 'ĠAb', 'an', 'aza', 'Ġthe', 'Ġmain', 'Ġvillain', 'Ġwhich', 'Ġhe', 'Ġdid', 'Ġuntil', 'ĠJanuary', 'Ġ7', ',', 'Ġ2016', '!', 'Ġ', '<s>', 'Ġ.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġrecently', 'Ġbeen', 'Ġcast', 'Ġin', 'Ġthe', 'Ġup', '-', 'and', '-', 'coming', 'ĠFeature', 'ĠFilm', \"Ġ'\", 'White', 'blade', \"'\", 'Ġwhere', 'Ġhe', 'Ġwill', 'Ġplay', 'ĠThur', 'stan', 'Ġthe', 'Ġhead', 'ĠWar', 'lord', 'ĠWhite', 'blade', 'Ġis', 'Ġcurrently', 'Ġin', 'Ġproduction', 'Ġand', 'ĠStephen', 'Ġis', 'Ġshooting', 'Ġhis', 'Ġscenes', 'Ġin', 'ĠAugust', 'Ġ2016', '.', 'Ġ', '<s>', 'ĠIn', 'ĠSeptember', 'Ġ2016', 'ĠStephen', 'Ġwill', 'Ġbe', 'Ġpresenting', 'Ġthe', 'ĠSky', 'ĠTV', 'Ġshow', \"Ġ'\", 'Brit', 'z', 'Ġgo', 'ĠB', 'ollywood', \"'\", 'Ġthe', 'Ġshow', 'Ġconsists', 'Ġof', 'Ġa', 'Ġgroup', 'Ġof', 'ĠCeleb', 'rities', 'Ġbeing', 'Ġdressed', 'Ġby', 'ĠThe', 'Ġbest', 'ĠIndian', 'Ġdesigners', ',', 'ĠStephen', 'Ġis', 'Ġthe', 'Ġmain', 'Ġpresenter', 'Ġof', 'Ġthe', 'Ġshow', 'Ġwhich', 'Ġwill', 'Ġbe', 'Ġscreened', 'Ġlive', 'ĠSeptember', 'Ġ2', ',', 'Ġ2016', '.', '<p>', 'ĠCompos', 'er', 'ĠJohn', 'ĠMiner', 'Ġmay', 'Ġbe', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġrock', 'Ġopera', 'ĠHeaven', 's', 'ĠCafe', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠFl', 'aming', 'o', 'ĠTheater', 'Ġin', 'ĠLas', 'ĠVegas', 'Ġ1996', ',', 'Ġthe', 'ĠCharleston', 'ĠPer', 'forming', 'ĠArts', 'ĠCenter', 'Ġin', 'Ġ1997', ',', 'Ġand', 'Ġlater', 'Ġat', 'ĠIns', 'ur', 'go', 'ĠTheater', 'Ġin', 'ĠLos', 'ĠAngeles', 'Ġin', 'Ġ2004', '.', 'Ġ', '<s>', 'ĠMiner', 'Ġformed', 'Ġthe', 'Ġprogressive', 'Ġrock', 'Ġgroup', 'ĠArt', 'ĠRock', 'ĠCircus', 'Ġto', 'Ġperform', 'Ġthe', 'Ġmusic', 'Ġwith', 'Ġa', 'Ġlive', 'Ġband', 'Ġon', 'Ġstage', 'Ġalongside', 'Ġthe', 'Ġsingers', 'Ġand', 'Ġactors', '.', 'Ġ', '<s>', 'ĠInvestor', 'ĠMike', 'ĠLewis', 'Ġwas', 'Ġinstrumental', 'Ġin', 'Ġfinancing', 'Ġand', 'Ġstaging', 'ĠHeaven', 's', 'ĠCafe', '.', 'Ġ', '<s>', 'ĠThe', 'ĠT', 'ribut', 'ary', 'ĠMusic', 'ĠLabel', 'Ġreleased', 'Ġa', 'Ġlive', 'ĠCD', 'Ġof', 'ĠHeaven', 's', 'ĠCafe', 'Ġto', 'Ġthe', 'Ġprogressive', 'Ġrock', 'Ġcommunity', 'Ġin', 'Ġ2000', '.', '<p>', 'ĠQuality', 'ĠCafe', 'Ġis', 'Ġthe', 'Ġname', 'Ġof', 'Ġtwo', 'Ġdifferent', 'Ġformer', 'Ġlocations', 'Ġin', 'ĠDowntown', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', '.', '<p>', 'ĠQuality', 'ĠCafe', 'Ġwas', 'Ġa', 'Ġhistorical', 'Ġrestaurant', 'Ġand', 'Ġjazz', 'Ġclub', 'Ġlocated', 'Ġat', 'Ġ11', '43', 'ĠEast', 'Ġ12', 'th', 'ĠStreet', 'Ġnear', 'Ġthe', 'Ġcorner', 'Ġof', 'ĠCentral', 'ĠAvenue', 'Ġin', 'ĠDowntown', 'ĠLos', 'ĠAngeles', '.', 'Ġ', '<s>', 'ĠQuality', 'ĠFour', ',', 'Ġa', 'Ġjazz', 'Ġquart', 'et', 'Ġfounded', 'Ġby', 'Ġsax', 'ophon', 'ist', 'ĠPaul', 'ĠHoward', 'Ġand', 'Ġfeaturing', 'Ġyoung', 'Ġvib', 'raph', 'on', 'ist', 'ĠLionel', 'ĠHampton', ',', 'Ġwas', 'Ġformed', 'Ġin', 'Ġ1924', 'Ġto', 'Ġplay', 'Ġat', 'ĠQuality', 'ĠCafe', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġsoon', 'Ġbecame', 'ĠQuality', 'ĠQuint', 'et', 'Ġand', 'Ġthen', 'ĠQuality', 'ĠS', 'eren', 'ades', ',', 'Ġand', 'Ġwas', 'Ġdisbanded', 'Ġafter', 'Ġa', 'Ġtour', 'Ġwith', 'ĠHazel', 'ĠMyers', 'Ġlater', 'Ġin', 'Ġthe', 'Ġsame', 'Ġyear', '.', 'Ġ', '<s>', 'ĠOn', 'ĠJune', 'Ġ7', ',', 'Ġ1924', ',', 'Ġthe', 'Ġvenue', 'Ġchanged', 'Ġits', 'Ġname', 'Ġto', 'ĠHum', 'ming', 'ĠBird', 'ĠCafe', 'Ġand', 'Ġbecame', 'Ġ\"', 'one', 'Ġof', 'Ġthe', 'Ġhottest', 'Ġnightclub', 's', 'Ġin', 'Ġthe', 'Ġarea', '\"', 'Ġunder', 'Ġthis', 'Ġname', '.', '<p>', 'ĠFil', 'and', 'ia', 'Ġis', 'Ġa', 'Ġtown', 'Ġand', 'Ġmunicipality', 'Ġin', 'Ġthe', 'Ġnorthern', 'Ġpart', 'Ġof', 'Ġthe', 'Ġdepartment', 'Ġof', 'ĠQu', 'ind', 'ÃŃ', 'o', ',', 'ĠColombia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġlocated', 'Ġon', 'Ġthe', 'Ġwest', 'Ġside', 'Ġof', 'ĠCord', 'iller', 'a', 'ĠCentral', 'Ġof', 'Ġthe', 'ĠAnd', 'es', 'Ġmountain', 'Ġrange', 'Ġrunning', 'Ġthrough', 'Ġcentral', 'ĠColombia', ',', 'Ġ26', 'Âł', 'km', 'Ġnorth', 'Ġof', 'Ġthe', 'Ġdepartment', 'al', 'Ġcapital', 'ĠArmenia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġnorthern', 'most', 'Ġof', 'Ġtwelve', 'Ġmunicipalities', 'Ġthat', 'Ġform', 'ĠQu', 'ind', 'ÃŃ', 'o', ',', 'Ġthe', 'Ġsecond', 'Ġsmallest', 'Ġdepartment', 'Ġof', 'ĠColombia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhouses', 'Ġa', 'Ġsmall', 'Ġcommunity', 'Ġeconomically', 'Ġsupported', 'Ġby', 'Ġagriculture', 'Ġand', 'Ġtourism', '.', 'Ġ', '<s>', 'ĠAlthough', 'Ġcoffee', 'Ġis', 'Ġthe', 'Ġmajor', 'Ġagricultural', 'Ġproduct', ',', 'Ġthe', 'Ġmunicipality', \"'s\", 'Ġdiverse', 'Ġecosystem', 'Ġmakes', 'Ġit', 'Ġperfect', 'Ġfor', 'Ġthe', 'Ġproduction', 'Ġof', 'Ġnumerous', 'Ġfruits', 'Ġand', 'Ġvegetables', '.', 'Ġ', '<s>', 'ĠThe', 'Ġpopulation', 'Ġis', 'Ġevenly', 'Ġsplit', 'Ġbetween', 'Ġthe', 'Ġurban', 'Ġand', 'Ġrural', 'Ġareas', ',', 'Ġwith', 'Ġan', 'Ġurban', 'Ġpopulation', 'Ġin', 'Ġthe', 'Ġtown', 'Ġof', 'ĠFil', 'and', 'ia', 'Ġitself', 'Ġof', 'Ġnearly', 'Ġ7000', 'Ġinhabitants', 'Ġand', 'Ġa', 'Ġpopulation', 'Ġof', 'Ġaround', 'Ġ6', '500', 'Ġin', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġmunicipality', '.', 'Ġ', '<s>', 'ĠMost', 'Ġof', 'Ġthe', 'Ġpopulation', 'Ġis', 'Ġclassified', 'Ġas', 'Ġm', 'est', 'izo', 'Ġ(', '63', ',', '2', '%)', 'Ġand', 'Ġthe', 'Ġmost', 'Ġcommon', 'Ġreligion', 'Ġis', 'ĠRoman', 'ĠCatholic', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtown', \"'s\", 'Ġarchitecture', ',', 'Ġlandscapes', 'Ġand', 'Ġthe', 'Ġsoc', 'iability', 'Ġof', 'Ġthe', 'Ġlocals', 'Ġmakes', 'ĠFil', 'and', 'ia', 'Ġone', 'Ġof', 'Ġthe', 'Ġmost', 'Ġbeautiful', 'Ġand', 'Ġattractive', 'Ġtowns', 'Ġin', 'Ġthe', 'Ġdepartment', 'Ġof', 'ĠQu', 'ind', 'io', 'Ġand', 'Ġthe', 'Ġnation', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtown', \"'s\", 'Ġbest', '-', 'known', 'Ġtourist', 'Ġattractions', 'Ġare', 'Ġits', 'Ġ\"', 'mir', 'ador', '\"', 'Ġ(', 'view', 'ing', 'Ġtower', ')', 'Ġwith', 'Ġits', 'Ġextensive', 'Ġviews', 'Ġover', 'Ġthe', 'ĠC', 'au', 'ca', 'ĠRiver', 'Ġvalley', 'Ġto', 'Ġthe', 'Ġwest', 'Ġand', 'Ġthe', 'ĠPar', 'que', 'ĠN', 'ac', 'ional', 'ĠNatural', 'Ġlos', 'ĠNev', 'ados', 'Ġto', 'Ġthe', 'Ġeast', 'Ġ(', 'it', 'Ġis', 'Ġalso', 'Ġpossible', 'Ġto', 'Ġsee', 'Ġboth', 'ĠArmenia', 'Ġand', 'ĠPere', 'ira', 'Ġfrom', 'Ġthe', 'Ġtop', 'Ġof', 'Ġthe', 'Ġtower', '),', 'Ġand', 'Ġthe', 'Ġcafe', 'Ġin', 'Ġthe', 'Ġmain', 'Ġsquare', 'Ġwhere', 'Ġscenes', 'Ġfrom', 'Ġthe', 'Ġpopular', 'ĠColombian', 'Ġtel', 'eno', 'vel', 'a', 'Ġ\"', 'C', 'afe', ',', 'Ġcon', 'Ġaroma', 'Ġde', 'Ġm', 'uj', 'er', '\"', 'Ġwere', 'Ġfilmed', '.', '<p>', 'ĠThe', 'ĠQuality', 'ĠCafe', 'Ġ(', 'also', 'Ġknown', 'Ġas', 'ĠQuality', 'ĠD', 'iner', ')', 'Ġis', 'Ġa', 'Ġnow', '-', 'def', 'unct', 'Ġdiner', 'Ġat', 'Ġ12', '36', 'ĠWest', 'Ġ7', 'th', 'ĠStreet', 'Ġin', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrestaurant', 'Ġceased', 'Ġto', 'Ġfunction', 'Ġas', 'Ġa', 'Ġdiner', 'Ġin', 'Ġlate', 'Ġ2006', 'Ġbut', 'Ġhas', 'Ġappeared', 'Ġas', 'Ġa', 'Ġlocation', 'Ġfeatured', 'Ġin', 'Ġa', 'Ġnumber', 'Ġof', 'ĠHollywood', 'Ġfilms', ',', 'Ġincluding', 'Ġ\"', 'Training', 'ĠDay', '\",', 'Ġ\"', 'Old', 'ĠSchool', '\",', 'Ġ\"', 'Se', '7', 'en', '\",', 'Ġ\"', 'Ghost', 'ĠWorld', '\",', 'Ġ\"', 'G', 'one', 'Ġin', 'Ġ60', 'ĠSeconds', '\",', 'Ġ\"', 'The', 'ĠStep', 'father', '\",', 'Ġ\"', 'What', \"'s\", 'ĠLove', 'ĠGot', 'Ġto', 'ĠDo', 'Ġwith', 'ĠIt', '\",', 'Ġ\"', 'Sex', 'Ġand', 'ĠDeath', 'Ġ101', '\",', 'Ġand', 'Ġ\"', 'C', 'atch', 'ĠMe', 'ĠIf', 'ĠYou', 'ĠCan', '.\"', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġalso', 'Ġfeatured', 'Ġin', 'ĠSeason', 'Ġ1', 'Ġof', 'Ġthe', 'Ġ2007', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Mad', 'ĠMen', ',\"', 'Ġin', 'Ġthe', 'Ġepisode', 'Ġ\"', '5', 'G', '\".']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers: [{'text': ' started in 1885. <s> Originally, the Los Angeles', 'score': tensor([0.6802], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' started in 1885. <s> Originally, the Los Angeles', 'score': tensor([0.6802], device='cuda:0')}]\n",
      "answer_score: tensor([0.6802], device='cuda:0')\n",
      "answer_text:  started in 1885. <s> Originally, the Los Angeles\n",
      "answer_gold_token_ids: tensor([6540, 7431,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠTodd', 'ĠPhillips', '.']\n",
      "answer_gold:  Todd Phillips.\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_end\n",
      "before sync --> sizes: 5, 5, 5, 5\n",
      "after sync --> sizes: 5, 5, 5, 5\n",
      "answer_scores:  [tensor([0.6943], device='cuda:0'), tensor([0.6816], device='cuda:0'), tensor([0.6718], device='cuda:0'), tensor([0.6689], device='cuda:0'), tensor([0.6802], device='cuda:0')]\n",
      "f1_scores:  [0, 0, 0, 0, 0]\n",
      "em_scores:  [0, 0, 0, 0, 0]\n",
      "avg_loss:  tensor(2.7772, device='cuda:0')\tavg_answer_loss:  tensor(0.9990, device='cuda:0')\tavg_type_loss:  tensor(0.6461, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5766, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.5555, device='cuda:0')\tlen(f1_scores):  5\n",
      "avg_val_f1:  0.0\n",
      "avg_val_em:  0.0\n",
      "avg_val_prec:  0.0\n",
      "avg_val_recall:  0.0\n",
      "avg_val_sp_sent_f1:  0.06666666666666667\n",
      "avg_val_sp_sent_em:  0.0\n",
      "avg_val_sp_sent_prec:  0.05\n",
      "avg_val_sp_sent_recall:  0.1\n",
      "avg_val_joint_f1:  0.0\n",
      "avg_val_joint_em:  0.0\n",
      "avg_val_joint_prec:  0.0\n",
      "avg_val_joint_recall:  0.0\n",
      "Start epoch  5\n",
      "question text:  The Dutch-Belgian television series that \"House of Anubis\" was based on first aired in what year?\n",
      "orig_answer_text:  2006\n",
      "question text:  Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\n",
      "orig_answer_text:  Jonathan Stark\n",
      "question text:  Gunmen from Laredo starred which narrator of \"Frontier\"?\n",
      "orig_answer_text:  Walter Darwin Coy\n",
      "input:  ['<cls>', '<q>', 'The', 'ĠDutch', '-', 'Bel', 'gian', 'Ġtelevision', 'Ġseries', 'Ġthat', 'Ġ\"', 'House', 'Ġof', 'ĠAn', 'ubis', '\"', 'Ġwas', 'Ġbased', 'Ġon', 'Ġfirst', 'Ġaired', 'Ġin', 'Ġwhat', 'Ġyear', '?', '</q>', '<p>', 'ĠHouse', 'Ġof', 'ĠAn', 'ubis', 'Ġis', 'Ġa', 'Ġmystery', 'Ġtelevision', 'Ġseries', 'Ġdeveloped', 'Ġfor', 'ĠNickel', 'ode', 'on', 'Ġbased', 'Ġon', 'Ġthe', 'ĠDutch', '-', 'Bel', 'gian', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'H', 'et', 'ĠHu', 'is', 'ĠAn', 'ubis', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġseries', 'Ġwas', 'Ġcreated', 'Ġby', 'ĠHans', 'ĠBour', 'lon', 'Ġand', 'ĠG', 'ert', 'ĠVer', 'h', 'ul', 'st', 'Ġand', 'Ġpremiered', 'Ġon', 'ĠNickel', 'ode', 'on', 'Ġon', 'Ġ1', 'ĠJanuary', 'Ġ2011', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġand', 'Ġon', 'Ġ25', 'ĠFebruary', 'Ġ2011', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠKingdom', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', 'Ġis', 'Ġthe', 'Ġfirst', 'Ġseries', 'Ġfrom', 'Ġthe', 'Ġnetwork', 'Ġto', 'Ġbe', 'Ġfilmed', 'Ġoutside', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġand', 'Ġthe', 'Ġfirst', 'Ġtel', 'eno', 'vel', 'a', '-', 'format', 'Ġseries', 'Ġfor', 'Ġthe', 'Ġnetwork', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġaired', 'Ġfrom', 'Ġ1', 'ĠJanuary', 'Ġ2011', 'Ġto', 'Ġ17', 'ĠJune', 'Ġ2013', '.', '<p>', 'ĠBat', 'ib', 'ot', 'Ġwas', 'Ġa', 'ĠPhilippine', 'Ġchildren', \"'s\", 'Ġtelevision', 'Ġseries', 'Ġproduced', 'Ġby', 'ĠP', 'CTV', 'Ġand', 'Ġbased', 'Ġon', 'Ġ\"', 'S', 'esame', 'ĠStreet', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġfirst', 'Ġaired', 'Ġin', 'Ġ1984', 'Ġon', 'ĠR', 'PN', 'Ġas', 'Ġ\"', 'S', 'esame', '!\"', 'Ġ', '<s>', 'Ġand', 'Ġwas', 'Ġco', '-', 'produced', 'Ġby', 'ĠChildren', \"'s\", 'ĠTelevision', 'ĠWorkshop', 'Ġ(\"', 'now', 'Ġknown', 'Ġas', '\"', 'ĠS', 'esame', 'ĠWorkshop', ')', 'Ġbut', 'Ġthe', 'Ġpartnership', 'Ġbroke', 'Ġup', '.', 'Ġ', '<s>', 'Ġ\"', 'S', 'esame', '!\"', 'Ġ', '<s>', 'Ġlater', 'Ġaired', 'Ġas', 'Ġ\"', 'Bat', 'ib', 'ot', '\"', 'Ġin', 'Ġ1985', ',', 'Ġa', 'Ġfull', 'ĠFilipino', 'Ġlanguage', 'Ġseries', '.', 'Ġ', '<s>', 'ĠIt', 'Ġaired', 'Ġuntil', 'Ġ1998', 'Ġand', 'Ġwas', 'Ġaired', 'Ġin', 'Ġat', 'Ġleast', 'Ġfour', 'Ġtelevision', 'Ġnetworks', '.', 'Ġ', '<s>', 'ĠTV', '5', 'Ġlater', 'Ġrevived', 'Ġthe', 'Ġshow', 'Ġand', 'Ġaired', 'Ġit', 'Ġfrom', 'Ġ2010', 'âĢĵ', '2013', '.', 'Ġ', '<s>', 'ĠA', 'Ġmobile', 'Ġapp', 'Ġbased', 'Ġon', 'Ġthe', 'Ġseries', 'Ġwas', 'Ġreleased', 'Ġin', 'Ġ2015', '.', '<p>', 'ĠWolf', 'blood', 'Ġis', 'Ġa', 'ĠBritish', 'âĢĵ', 'German', 'Ġfantasy', 'Ġteen', 'Ġdrama', 'Ġtelevision', 'Ġseries', 'Ġtargeted', 'Ġat', 'Ġa', 'Ġyoung', 'Ġadult', 'Ġaudience', '.', 'Ġ', '<s>', 'ĠCreated', 'Ġby', 'ĠDebbie', 'ĠMoon', ',', 'Ġit', 'Ġis', 'Ġa', 'Ġco', '-', 'production', 'Ġbetween', 'ĠCB', 'BC', 'Ġand', 'ĠZ', 'DF', '/', 'Z', 'DF', 'E', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtelevision', 'Ġseries', 'Ġrevolves', 'Ġaround', 'Ġthe', 'Ġlife', 'Ġof', 'Ġthe', 'Ġspecies', 'Ġknown', 'Ġas', 'Ġwolf', 'blood', 's', '.', 'Ġ', '<s>', 'ĠThey', 'Ġare', 'Ġcreatures', 'Ġthat', 'Ġhave', 'Ġenhanced', 'Ġsenses', 'Ġand', 'Ġlook', 'Ġlike', 'Ġhumans', 'Ġbut', 'Ġat', 'Ġcan', 'Ġturn', 'Ġat', 'Ġwill', 'Ġinto', 'Ġwolves', '.', 'Ġ', '<s>', 'ĠTheir', 'Ġtransformation', 'Ġis', 'Ġuncontrolled', 'Ġduring', 'Ġa', 'Ġfull', 'Ġmoon', ',', 'Ġand', 'Ġthey', 'Ġare', 'Ġat', 'Ġtheir', 'Ġweakest', 'Ġduring', 'Ġ\"', 'the', 'Ġdark', 'Ġof', 'Ġthe', 'Ġmoon', '\",', 'Ġat', 'Ġa', 'Ġnew', 'Ġmoon', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtelevision', 'Ġseries', 'Ġfocuses', 'Ġon', 'Ġtheir', 'Ġdaily', 'Ġlife', 'Ġand', 'Ġthe', 'Ġchallenges', 'Ġthat', 'Ġthey', 'Ġface', 'Ġto', 'Ġhide', 'Ġtheir', 'Ġsecret', '.', 'Ġ', '<s>', 'ĠEach', 'Ġseries', 'Ġhas', 'Ġnew', 'Ġcharacters', 'Ġand', 'Ġconcepts', 'Ġand', 'Ġoverall', 'Ġthe', 'Ġtelevision', 'Ġseries', 'Ġhas', 'Ġan', 'Ġinteresting', 'Ġstoryline', '.', 'Ġ', '<s>', 'ĠTo', 'Ġdate', ',', 'Ġfive', 'Ġcomplete', 'Ġseries', 'Ġhave', 'Ġaired', '.', 'Ġ', '<s>', 'ĠSeries', 'Ġ1', 'Ġfirst', 'Ġaired', 'Ġon', 'Ġ10', 'ĠSeptember', 'Ġ2012', 'Ġand', 'Ġconcluded', 'Ġon', 'Ġ22', 'ĠOctober', 'Ġ2012', 'Ġand', 'Ġconsisted', 'Ġof', 'Ġ13', 'Ġepisodes', '.', 'Ġ', '<s>', 'ĠSeries', 'Ġ2', 'Ġfirst', 'Ġaired', 'Ġon', 'Ġ9', 'ĠSeptember', 'Ġ2013', 'Ġand', 'Ġconcluded', 'Ġon', 'Ġ21', 'ĠOctober', 'Ġ2013', 'Ġand', 'Ġagain', 'Ġconsisted', 'Ġof', 'Ġ13', 'Ġepisodes', '.', 'Ġ', '<s>', 'ĠSeries', 'Ġ3', 'Ġfirst', 'Ġaired', 'Ġon', 'Ġ15', 'ĠSeptember', 'Ġ2014', 'Ġand', 'Ġconcluded', 'Ġon', 'Ġ27', 'ĠOctober', 'Ġ2014', 'Ġand', 'Ġalso', 'Ġconsisted', 'Ġof', 'Ġ13', 'Ġepisodes', '.', 'Ġ', '<s>', 'ĠSeries', 'Ġ4', 'Ġfirst', 'Ġaired', 'Ġon', 'Ġ8', 'ĠMarch', 'Ġ2016', 'Ġand', 'Ġconcluded', 'Ġon', 'Ġ13', 'ĠApril', 'Ġ2016', 'Ġand', 'Ġthis', 'Ġtime', 'Ġconsisted', 'Ġof', 'Ġ12', 'Ġepisodes', '.', 'Ġ', '<s>', 'ĠA', 'Ġfifth', 'Ġseason', 'Ġwas', 'Ġannounced', 'Ġon', 'Ġ6', 'ĠJune', 'Ġ2016', 'Ġand', 'Ġbegan', 'Ġairing', 'Ġon', 'Ġ27', 'ĠFebruary', 'Ġ2017', 'Ġand', 'Ġconcluded', 'Ġon', 'Ġ1', 'ĠMay', 'Ġ2017', 'Ġwith', 'Ġ10', 'Ġepisodes', '.', '<p>', 'ĠThis', 'Ġarticle', 'Ġis', 'Ġan', 'Ġepisode', 'Ġlist', 'Ġfor', 'Ġ\"', 'House', 'Ġof', 'ĠAn', 'ubis', '\",', 'Ġa', 'Ġmystery', '/', 'com', 'edy', '-', 'd', 'rama', 'Ġtelevision', 'Ġseries', 'Ġbroadcast', 'Ġon', 'ĠNickel', 'ode', 'on', '.', '<p>', 'ĠMaj', 'is', 'uka', 'ĠG', 'aku', 'en', 'Ġ(', 'ãĥŀ', 'ãĤ¸', 'ãģĻ', 'ãģĭ', 'åŃ', '¦', 'åľ', 'Ĵ', 'Ġ)', 'Ġ(', 'lit', '.', 'Ġ', '<s>', 'Ġ\"', 'M', 'aj', 'is', 'uka', 'ĠAcademy', '\")', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġtelevision', 'Ġdrama', 'Ġseries', 'Ġfirst', 'Ġaired', 'Ġon', 'ĠTV', 'ĠTokyo', 'Ġstarring', 'ĠAK', 'B', '48', '.', 'Ġ', '<s>', 'ĠA', 'Ġsecond', 'Ġseason', 'ĠMaj', 'is', 'uka', 'ĠG', 'aku', 'en', 'Ġ2', 'Ġwas', 'Ġaired', 'Ġthe', 'Ġfollowing', 'Ġyear', ',', 'Ġthe', 'Ġ3', 'rd', 'ĠSeason', 'Ġwas', 'Ġaired', 'Ġon', 'ĠJuly', 'Ġ13', ',', 'Ġ2012', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2015', ',', 'Ġthe', 'Ġseries', 'Ġmoved', 'Ġto', 'ĠN', 'TV', 'Ġand', 'Ġthe', 'Ġ4', 'th', 'ĠSeason', 'Ġwas', 'Ġaired', 'Ġon', 'ĠJanuary', 'Ġ19', ',', 'Ġ2015', '.', 'Ġ', '<s>', 'ĠOn', 'Ġthe', 'Ġsame', 'Ġyear', ',', 'Ġa', 'Ġ5', 'th', 'ĠSeason', 'Ġwas', 'Ġannounced', 'Ġand', 'Ġfor', 'Ġthe', 'Ġfirst', 'Ġtime', 'Ġwill', 'Ġbe', 'Ġaired', 'Ġexclusively', 'Ġon', 'Ġinternet', ',', 'Ġby', 'Ġthe', 'Ġstreaming', 'Ġsite', 'ĠHulu', 'Ġ(', 'only', 'Ġin', 'ĠUSA', 'Ġ&', 'ĠJapan', '),', 'Ġbecause', 'ĠN', 'TV', 'Ġwill', 'Ġbroadcast', 'Ġonly', 'Ġthe', 'Ġfirst', 'Ġtwo', 'Ġepisodes', 'Ġ(', 'August', 'Ġ24', '),', 'Ġdue', 'Ġto', 'Ġvarious', 'Ġscenes', 'Ġof', 'Ġviolence', ',', 'Ġwhich', 'Ġdoes', 'Ġnot', 'Ġjustify', 'Ġfull', 'Ġseason', 'Ġshowing', 'Ġon', 'ĠTV', ',', 'Ġbecause', 'Ġthere', 'Ġmay', 'Ġbe', 'Ġmany', 'Ġproblems', '.', 'Ġ', '<s>', 'ĠA', 'Ġspecial', 'Ġspin', '-', 'off', 'Ġfrom', 'Ġthe', 'Ġ4', 'th', 'Ġand', 'Ġ5', 'th', 'Ġseason', 'Ġof', 'Ġthe', 'Ġseries', 'Ġtitled', 'Ġ\"', 'M', 'aj', 'is', 'uka', 'ĠG', 'aku', 'en', 'Ġ0', ':', 'ĠKis', 'ar', 'az', 'u', 'ĠR', 'ant', 'Åį', 'hen', '\"', 'Ġ(', 'ãĥŀ', 'ãĤ¸', 'ãģĻ', 'ãģĭ', 'åŃ', '¦', 'åľ', 'Ĵ', '0', 'Ġæľ', '¨', 'æ', 'Ľ', '´', 'æ', '´', '¥', 'ä¹', '±', 'éĹĺ', 'ç·', '¨', 'Ġ)', 'Ġ(', 'lit', '.', 'Ġ', '<s>', 'Ġ\"', 'M', 'aj', 'is', 'uka', 'ĠAcademy', 'Ġ0', ':', 'ĠThe', 'Ġstory', 'Ġof', 'Ġthe', 'ĠBrawl', 'Ġat', 'ĠKis', 'ar', 'az', 'u', '\")', 'Ġwhich', 'Ġfirst', 'Ġto', 'Ġfeature', 'ĠHK', 'T', '48', 'Ġas', 'Ġthe', 'Ġmain', 'Ġcast', 'Ġand', 'Ġfirst', 'Ġto', 'Ġhave', 'Ġa', 'Ġcollaboration', 'Ġwith', 'Ġthe', 'Ġrock', 'Ġgroup', 'ĠK', 'ish', 'idan', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġaired', 'Ġon', 'ĠNovember', 'Ġ28', ',', 'Ġ2015', 'Ġon', 'ĠN', 'TV', 'Ġat', 'Ġ25', ':', '05', 'ĠJ', 'ST', 'Ġand', 'Ġrun', 'Ġfor', 'Ġhalf', 'Ġan', 'Ġhour', '.', '<p>', 'Ġ\"', 'Grad', 'uation', 'ĠDay', '\"', 'Ġis', 'Ġthe', 'Ġseason', 'Ġfinale', 'Ġof', 'Ġthe', 'ĠWB', 'ĠTelevision', 'ĠNetwork', \"'s\", 'Ġthird', 'Ġseason', 'Ġof', 'Ġthe', 'Ġdrama', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'B', 'uffy', 'Ġthe', 'ĠVampire', 'ĠSlayer', '\",', 'Ġconsisting', 'Ġof', 'Ġthe', 'Ġtwenty', '-', 'first', 'Ġand', 'Ġtwenty', '-', 'second', 'Ġepisodes', '.', 'Ġ', '<s>', 'ĠThey', 'Ġwere', 'Ġwritten', 'Ġand', 'Ġdirected', 'Ġby', 'Ġseries', 'Ġcreator', 'ĠJ', 'oss', 'ĠWhedon', '.', 'Ġ', '<s>', 'Ġ\"', 'Part', 'Ġ1', '\"', 'Ġfirst', 'Ġaired', 'Ġon', 'ĠMay', 'Ġ18', ',', 'Ġ1999', 'Ġand', 'Ġ\"', 'Part', 'Ġ2', '\"', 'Ġfirst', 'Ġaired', 'Ġon', 'ĠJuly', 'Ġ13', ',', 'Ġ1999', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsecond', 'Ġpart', 'Ġwas', 'Ġto', 'Ġoriginally', 'Ġbe', 'Ġaired', 'Ġon', 'ĠMay', 'Ġ25', ',', 'Ġ1999', ',', 'Ġbut', 'Ġwas', 'Ġpostponed', 'Ġdue', 'Ġto', 'Ġthe', 'Ġepisode', \"'s\", 'Ġcontent', 'Ġand', 'Ġthe', 'Ġoccurrence', 'Ġof', 'Ġthe', 'ĠColumb', 'ine', 'ĠHigh', 'ĠSchool', 'Ġshootings', 'Ġone', 'Ġmonth', 'Ġprior', '.', '<p>', 'ĠFish', 'ĠPolice', 'Ġis', 'Ġan', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġfrom', 'ĠHanna', '-', 'Bar', 'ber', 'a', 'Ġbased', 'Ġon', 'Ġthe', 'Ġcomic', 'Ġbook', 'Ġseries', 'Ġcreated', 'Ġby', 'ĠSteve', 'ĠMon', 'c', 'use', '.', 'Ġ', '<s>', 'ĠIt', 'Ġfirst', 'Ġaired', 'Ġon', 'ĠCBS', 'Ġin', 'Ġ1992', ',', 'Ġlasting', 'Ġsix', 'Ġepisodes', 'Ġover', 'Ġone', 'Ġseason', '.', 'Ġ', '<s>', 'ĠIn', 'ĠFebruary', 'Ġof', 'Ġthat', 'Ġyear', ',', 'Ġthree', 'Ġepisodes', 'Ġaired', ',', 'Ġthen', 'Ġthe', 'Ġshow', 'Ġwas', 'Ġax', 'ed', 'Ġafter', 'Ġfalling', 'Ġin', 'Ġthe', 'Ġtelevision', 'Ġratings', '.', 'Ġ', '<s>', 'ĠThe', 'Ġremaining', 'Ġthree', 'Ġepisodes', 'Ġnever', 'Ġaired', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġbut', 'Ġthe', 'Ġentire', 'Ġseries', 'Ġran', 'Ġin', 'ĠEuropean', 'Ġsynd', 'ication', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġhad', 'Ġa', 'Ġdecidedly', 'Ġmore', 'Ġmature', 'Ġtone', 'Ġthan', 'Ġmost', 'Ġother', 'Ġanimated', 'ĠHanna', '-', 'Bar', 'bara', 'Ġshows', '.', 'Ġ', '<s>', 'ĠEp', 'isodes', 'Ġoften', 'Ġcontained', 'Ġinn', 'u', 'endo', 'Ġand', 'Ġcases', 'Ġof', 'Ġmild', 'Ġprof', 'anity', '.', '<p>', 'ĠNath', 'alia', 'ĠNor', 'ah', 'ĠRamos', 'ĠCohen', 'Ġ(', 'born', 'ĠJuly', 'Ġ3', ',', 'Ġ1992', ')', 'Ġis', 'Ġa', 'ĠSpanish', '-', 'Australian', 'Ġactress', ',', 'Ġwho', 'Ġalso', 'Ġholds', 'ĠU', '.', 'S', '.', 'Ġcitizenship', '.', 'Ġ', '<s>', 'ĠRamos', 'Ġis', 'Ġknown', 'Ġfor', 'Ġher', 'Ġportray', 'als', 'Ġof', 'ĠYas', 'min', 'Ġin', 'Ġthe', 'Ġ2007', 'Ġfilm', 'Ġ\"', '\",', 'ĠJill', 'Ġin', 'Ġthe', 'Ġ2013', 'Ġfilm', 'Ġ\"', 'The', 'ĠDam', 'ned', '\",', 'Ġand', 'Ġlead', 'Ġcharacter', 'ĠNina', 'ĠMartin', 'Ġin', 'Ġthe', 'Ġ2011', 'ĠNickel', 'ode', 'on', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'House', 'Ġof', 'ĠAn', 'ubis', '\".', '<p>', 'ĠH', 'et', 'ĠHu', 'is', 'ĠAn', 'ubis', 'Ġ(\"', 'The', 'ĠHouse', 'Ġof', 'ĠAn', 'ubis', '\")', 'Ġis', 'Ġa', 'ĠBelgian', '-', 'Dutch', 'Ġchildren', \"'s\", 'Ġtelevision', 'Ġdrama', 'Ġcreated', 'Ġby', 'ĠStudio', 'Ġ100', 'Ġand', 'ĠNickel', 'ode', 'on', ',', 'Ġairing', 'Ġin', 'Ġthe', 'ĠNetherlands', 'Ġand', 'ĠF', 'landers', '.', 'Ġ', '<s>', 'ĠIt', 'Ġfirst', 'Ġaired', 'Ġin', 'ĠSeptember', 'Ġ2006', 'Ġand', 'Ġthe', 'Ġlast', 'Ġepisode', 'Ġwas', 'Ġbroadcast', 'Ġon', 'ĠDecember', 'Ġ4', ',', 'Ġ2009', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġwas', 'Ġa', 'Ġhuge', 'Ġsuccess', 'Ġin', 'Ġthe', 'ĠBen', 'el', 'ux', ',', 'Ġdespite', 'Ġthe', 'Ġshow', \"'s\", 'Ġlow', 'Ġbudget', 'Ġfor', 'Ġthe', 'Ġfirst', 'Ġtwo', 'Ġseasons', '.', '<p>', 'ĠDas', 'ĠH', 'aus', 'ĠAn', 'ubis', 'Ġis', 'Ġa', 'Ġtelevision', 'Ġprogram', 'Ġproduced', 'Ġjointly', 'Ġby', 'ĠBelgian', 'Ġbroadcaster', 'ĠStudio', 'Ġ100', 'Ġand', 'ĠNickel', 'ode', 'on', 'Ġand', 'Ġthe', 'Ġfirst', 'Ġremake', 'Ġof', 'ĠH', 'et', 'ĠHu', 'is', 'ĠAn', 'ubis', 'Ġaired', 'Ġin', 'ĠThe', 'ĠNetherlands', 'Ġand', 'ĠBelgium', '.', 'Ġ', '<s>', 'ĠAnother', 'ĠEnglish', 'Ġremake', 'Ġcalled', 'ĠHouse', 'Ġof', 'ĠAn', 'ubis', 'Ġaired', 'Ġin', 'Ġ2011', '.', 'Ġ', '<s>', 'ĠWith', 'Ġa', 'Ġseven', '-', 'figure', 'Ġproduction', 'Ġbudget', ',', 'Ġit', 'Ġis', 'Ġone', 'Ġof', 'ĠNickel', 'ode', 'on', \"'s\", 'Ġlargest', 'Ġin', '-', 'house', 'Ġproductions', ',', 'Ġand', 'Ġthe', 'Ġfirst', 'ĠGerman', 'Ġdaily', 'Ġsoap', 'Ġopera', 'Ġspecifically', 'Ġaimed', 'Ġat', 'Ġolder', 'Ġchildren', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġ29', 'ĠSeptember', 'Ġ2009', 'Ġto', 'Ġ4', 'ĠMay', 'Ġ2012', ',', 'Ġthe', 'Ġshow', 'Ġhad', 'Ġbeen', 'Ġrunning', 'Ġboth', 'Ġon', 'Ġchildren', \"'s\", 'Ġchannel', 'ĠNick', 'Ġ(', 'daily', 'Ġat', 'Ġ7', ':', '40', 'pm', ',', 'Ġand', 'Ġrepeated', 'Ġin', 'Ġthe', 'Ġafternoon', 'Ġand', 'Ġat', 'Ġweekends', '),', 'Ġand', 'Ġseason', 'Ġ1', 'Ġon', 'Ġmusic', 'Ġchannel', 'ĠV', 'IV', 'A', '.']\n",
      "lr:  tensor([4.7500e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Which genus of moth in the world's seventh-largest country contains only one species?\n",
      "orig_answer_text:  Crambidae\n",
      "orig_answer_text:  Crambidae\n",
      "orig_answer_text:  Crambidae\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġtennis', 'Ġplayer', 'Ġwon', 'Ġmore', 'ĠGrand', 'ĠSlam', 'Ġtitles', ',', 'ĠHenri', 'ĠL', 'ec', 'onte', 'Ġor', 'ĠJonathan', 'ĠStark', '?', '</q>', '<p>', 'ĠLi', 'ĠNa', 'Ġ(', ';', 'Ġ;', 'Ġborn', 'Ġ26', 'ĠFebruary', 'Ġ1982', ')', 'Ġis', 'Ġa', 'Ġretired', 'ĠChinese', 'Ġprofessional', 'Ġtennis', 'Ġplayer', ',', 'Ġwho', 'Ġachieved', 'Ġa', 'Ġcareer', '-', 'high', 'ĠW', 'TA', '-', 'ranking', 'Ġof', 'Ġworld', 'ĠNo', '.', 'Ġ2', 'Ġon', 'Ġ17', 'ĠFebruary', 'Ġ2014', '.', 'Ġ', '<s>', 'ĠOver', 'Ġthe', 'Ġcourse', 'Ġof', 'Ġher', 'Ġcareer', ',', 'ĠLi', 'Ġwon', 'Ġseven', 'ĠW', 'TA', 'Ġsingles', 'Ġtitles', 'Ġand', 'Ġtwo', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġtitles', 'Ġat', 'Ġthe', 'Ġ2011', 'ĠFrench', 'ĠOpen', 'Ġand', 'Ġ2014', 'ĠAustralian', 'ĠOpen', '.', 'Ġ', '<s>', 'ĠLi', \"'s\", 'Ġrise', 'Ġto', 'Ġprominence', 'Ġcame', 'Ġafter', 'Ġthose', 'Ġvictories', ',', 'Ġwhich', 'Ġmade', 'Ġher', 'Ġthe', 'Ġfirst', 'Ġand', 'Ġonly', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġchampion', 'Ġfrom', 'ĠEast', 'ĠAsia', 'Ġand', 'ĠAsia', 'Ġas', 'Ġa', 'Ġwhole', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġthis', ',', 'Ġshe', 'Ġhad', 'Ġalready', 'Ġbecome', 'Ġthe', 'Ġfirst', 'Ġplayer', 'Ġrepresenting', 'Ġan', 'ĠEast', 'ĠAsian', 'Ġand', 'ĠAsian', 'Ġcountry', 'Ġto', 'Ġappear', 'Ġin', 'Ġa', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġfinal', ',', 'Ġa', 'Ġmilestone', 'Ġshe', 'Ġachieved', 'Ġat', 'Ġthe', 'Ġ2011', 'ĠAustralian', 'ĠOpen', '.', 'Ġ', '<s>', 'ĠLi', 'Ġwas', 'Ġalso', 'Ġthe', 'Ġrunner', '-', 'up', 'Ġat', 'Ġthe', 'Ġ2013', 'ĠAustralian', 'ĠOpen', 'Ġand', 'Ġ2013', 'ĠW', 'TA', 'ĠTour', 'ĠChampionships', ',', 'Ġa', 'Ġthree', '-', 'time', 'Ġquarter', 'final', 'ist', 'Ġat', 'ĠWim', 'bledon', 'Ġand', 'Ġa', 'Ġsemif', 'inal', 'ist', 'Ġat', 'Ġthe', 'Ġ2008', 'ĠBeijing', 'ĠOlympic', 'ĠGames', 'Ġand', 'Ġ2013', 'ĠUS', 'ĠOpen', '.', 'Ġ', '<s>', 'ĠAmong', 'Ġher', 'Ġother', 'Ġmost', 'Ġnotable', 'Ġaccol', 'ades', ',', 'Ġshe', 'Ġwas', 'Ġthe', 'Ġfirst', 'ĠChinese', 'Ġplayer', 'Ġto', 'Ġwin', 'Ġa', 'ĠW', 'TA', 'Ġtour', 'Ġtitle', 'Ġat', 'Ġthe', 'ĠGuang', 'zhou', 'ĠInternational', 'ĠWomen', \"'s\", 'ĠOpen', 'Ġin', 'Ġ2004', ',', 'Ġthe', 'Ġfirst', 'Ġto', 'Ġreach', 'Ġa', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġquarter', 'final', 'Ġat', 'Ġthe', 'Ġ2006', 'ĠWim', 'bledon', 'ĠChampionships', ',', 'Ġand', 'Ġthe', 'Ġfirst', 'Ġto', 'Ġbreak', 'Ġinto', 'Ġthe', 'Ġworld', \"'s\", 'Ġtop', 'Ġ10', '.', 'Ġ', '<s>', 'ĠHer', 'Ġfeats', 'Ġhave', 'Ġsparked', 'Ġa', 'Ġmajor', 'Ġpopulation', 'Ġgrowth', 'Ġof', 'Ġtennis', 'Ġplayers', 'Ġin', 'ĠEast', 'ĠAsia', ',', 'Ġearning', 'Ġher', 'Ġthe', 'Ġreputation', 'Ġas', 'Ġthe', 'Ġregion', \"'s\", 'Ġtennis', 'Ġpioneer', 'Ġand', 'Ġtrail', 'bl', 'azer', '.', '<p>', 'ĠThe', 'ĠWilliams', 'Ġsisters', 'Ġare', 'Ġtwo', 'Ġprofessional', 'ĠAmerican', 'Ġtennis', 'Ġplayers', ':', 'ĠVenus', 'ĠWilliams', 'Ġ(', 'b', '.', 'Ġ1980', '),', 'Ġa', 'Ġseven', '-', 'time', 'ĠGrand', 'ĠSlam', 'Ġtitle', 'Ġwinner', 'Ġ(', 'sing', 'les', '),', 'Ġand', 'ĠSere', 'na', 'ĠWilliams', 'Ġ(', 'b', '.', 'Ġ1981', '),', 'Ġtwenty', '-', 'three', '-', 'time', 'ĠGrand', 'ĠSlam', 'Ġtitle', 'Ġwinner', 'Ġ(', 'sing', 'les', '),', 'Ġboth', 'Ġof', 'Ġwhom', 'Ġwere', 'Ġcoached', 'Ġfrom', 'Ġan', 'Ġearly', 'Ġage', 'Ġby', 'Ġtheir', 'Ġparents', 'ĠRichard', 'ĠWilliams', 'Ġand', 'ĠOr', 'ac', 'ene', 'ĠPrice', '.', 'Ġ', '<s>', 'ĠThere', 'Ġis', 'Ġa', 'Ġnoted', 'Ġprofessional', 'Ġrivalry', 'Ġbetween', 'Ġthem', 'ĠâĢĵ', 'Ġbetween', 'Ġthe', 'Ġ2001', 'ĠUS', 'ĠOpen', 'Ġand', 'Ġthe', 'Ġ2017', 'ĠAustralian', 'ĠOpen', 'Ġtournaments', ',', 'Ġthey', 'Ġmet', 'Ġin', 'Ġnine', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġfinals', '.', 'Ġ', '<s>', 'ĠThey', 'Ġbecame', 'Ġthe', 'Ġfirst', 'Ġtwo', 'Ġplayers', ',', 'Ġfemale', 'Ġor', 'Ġmale', ',', 'Ġto', 'Ġplay', 'Ġin', 'Ġ4', 'Ġconsecutive', 'Ġgrand', 'Ġslam', 'Ġsingles', 'Ġfinals', 'Ġfrom', 'Ġthe', 'Ġ2002', 'ĠFrench', 'ĠOpen', 'Ġto', 'Ġthe', 'Ġ2003', 'ĠAustralian', 'ĠOpen', ';', 'ĠSere', 'na', 'Ġfamously', 'Ġwon', 'Ġall', 'Ġ4', 'Ġto', 'Ġcomplete', 'Ġthe', 'Ġfirst', 'Ġof', 'Ġtwo', 'Ġ\"', 'S', 'ere', 'na', 'ĠSlam', 's', '\".', 'Ġ', '<s>', 'ĠBetween', 'Ġ2000', 'Ġand', 'Ġ2016', ',', 'Ġa', 'Ġ17', '-', 'year', 'Ġspan', ',', 'Ġthey', 'Ġcollectively', 'Ġwon', 'Ġ12', 'ĠWim', 'bledon', 'Ġsingles', 'Ġtitles', 'Ġ(', 'Ven', 'us', 'Ġwon', 'Ġ5', 'Ġand', 'ĠSere', 'na', 'Ġwon', 'Ġ7', ').', 'Ġ', '<s>', 'ĠBy', 'Ġwinning', 'Ġthe', 'Ġ2001', 'ĠAustralian', 'ĠOpen', 'Ġwomen', \"'s\", 'Ġdoubles', 'Ġtitle', ',', 'Ġthey', 'Ġbecame', 'Ġthe', 'Ġ5', 'th', 'Ġpair', 'Ġto', 'Ġcomplete', 'Ġthe', 'ĠCareer', 'ĠDou', 'bles', 'ĠGrand', 'ĠSlam', 'Ġand', 'Ġthe', 'Ġonly', 'Ġpair', 'Ġto', 'Ġcomplete', 'Ġthe', 'ĠCareer', 'ĠDou', 'bles', 'ĠGolden', 'ĠSlam', '.', 'Ġ', '<s>', 'ĠAt', 'Ġthe', 'Ġtime', ',', 'ĠVenus', 'Ġand', 'ĠSere', 'na', 'Ġwere', 'Ġonly', 'Ġ20', 'Ġand', 'Ġ19', 'Ġyears', 'Ġold', ',', 'Ġrespectively', '.', 'Ġ', '<s>', 'ĠSince', 'Ġthen', 'Ġthey', 'Ġhave', 'Ġgone', 'Ġon', 'Ġto', 'Ġadd', 'Ġanother', 'Ġtwo', 'ĠOlympic', 'Ġgold', 'Ġmedals', 'Ġin', 'Ġthe', 'Ġ2008', 'ĠBeijing', 'ĠOlympics', 'Ġand', 'Ġthe', 'Ġ2012', 'ĠLondon', 'ĠOlympics', '.', 'Ġ', '<s>', 'ĠNearly', 'Ġa', 'Ġdecade', 'Ġlater', ',', 'Ġthe', 'Ġduo', 'Ġwould', 'Ġgo', 'Ġon', 'Ġto', 'Ġwin', 'Ġ4', 'Ġconsecutive', 'Ġgrand', 'Ġslam', 'Ġdoubles', 'Ġtitles', 'Ġfrom', 'Ġ2009', 'ĠWim', 'bledon', 'Ġthrough', 'Ġ2010', 'ĠRoland', 'ĠGar', 'ros', ',', 'Ġwhich', 'Ġwould', 'Ġcatapult', 'Ġthem', 'Ġto', 'Ġco', '-', 'No', '.', 'Ġ', '<s>', 'Ġ1', 'Ġdoubles', 'Ġplayers', 'Ġon', 'Ġ7', 'ĠJune', 'Ġ2010', '.', 'Ġ', '<s>', 'ĠTwo', 'Ġweeks', 'Ġlater', ',', 'Ġon', 'Ġ21', 'ĠJune', 'Ġ2010', ',', 'ĠSere', 'na', 'Ġwould', 'Ġhold', 'Ġthe', 'ĠNo', '.', 'Ġ1', 'Ġsingles', 'Ġranking', 'Ġand', 'ĠVenus', 'Ġwould', 'Ġbe', 'Ġright', 'Ġbehind', 'Ġher', 'Ġat', 'ĠNo', '.', 'Ġ2', 'Ġin', 'Ġsingles', '.', 'Ġ', '<s>', 'ĠTheir', 'Ġmost', 'Ġrecent', 'Ġgrand', 'Ġslam', 'Ġdoubles', 'Ġtitles', 'Ġcame', 'Ġat', 'Ġthe', 'Ġ2012', 'ĠWim', 'bledon', 'Ġ&', 'Ġ2016', 'ĠWim', 'bledon', 'Ġevents', '.', 'Ġ', '<s>', 'ĠThey', 'Ġremain', 'Ġvery', 'Ġclose', ',', 'Ġoften', 'Ġwatching', 'Ġeach', 'Ġother', \"'s\", 'Ġmatches', 'Ġin', 'Ġsupport', ',', 'Ġeven', 'Ġafter', 'Ġone', 'Ġof', 'Ġthem', 'Ġhas', 'Ġbeen', 'Ġknocked', 'Ġout', 'Ġof', 'Ġa', 'Ġtournament', '.', '<p>', 'ĠHenri', 'ĠL', 'ec', 'onte', 'Ġ(', 'born', 'Ġ4', 'ĠJuly', 'Ġ1963', ')', 'Ġis', 'Ġa', 'Ġformer', 'ĠFrench', 'Ġprofessional', 'Ġtennis', 'Ġplayer', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreached', 'Ġthe', 'Ġmen', \"'s\", 'Ġsingles', 'Ġfinal', 'Ġat', 'Ġthe', 'ĠFrench', 'ĠOpen', 'Ġin', 'Ġ1988', ',', 'Ġwon', 'Ġthe', 'ĠFrench', 'ĠOpen', 'Ġmen', \"'s\", 'Ġdoubles', 'Ġtitle', 'Ġin', 'Ġ1984', ',', 'Ġand', 'Ġhelped', 'ĠFrance', 'Ġwin', 'Ġthe', 'ĠDavis', 'ĠCup', 'Ġin', 'Ġ1991', '.', 'Ġ', '<s>', 'ĠL', 'ec', 'onte', \"'s\", 'Ġcareer', '-', 'high', 'Ġsingles', 'Ġranking', 'Ġwas', 'Ġworld', 'ĠNo', '.', 'Ġ5', '.', '<p>', 'ĠStefan', 'ie', 'ĠMaria', 'Ġ\"', 'Ste', 'ff', 'i', '\"', 'ĠGra', 'f', 'Ġ(', ']', 'Ġ;', 'Ġborn', 'Ġ14', 'ĠJune', 'Ġ1969', ')', 'Ġis', 'Ġa', 'ĠGerman', 'Ġformer', 'Ġtennis', 'Ġplayer', ',', 'Ġwho', 'Ġwas', 'Ġranked', 'Ġworld', 'ĠNo', '.', 'Ġ1', 'Ġduring', 'Ġher', 'Ġcareer', '.', 'Ġ', '<s>', 'ĠGra', 'f', 'Ġwon', 'Ġ22', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġtitles', '.', 'Ġ', '<s>', 'ĠHer', 'Ġ22', 'Ġsingles', 'Ġtitles', 'Ġput', 'Ġher', 'Ġsecond', 'Ġon', 'Ġthe', 'Ġlist', 'Ġof', 'ĠMajor', 'Ġwins', 'Ġin', 'Ġthe', 'Ġfemale', 'Ġcompetition', 'Ġsince', 'Ġthe', 'Ġintroduction', 'Ġof', 'Ġthe', 'ĠOpen', 'ĠEra', 'Ġin', 'Ġ1968', 'Ġand', 'Ġis', 'Ġthird', 'Ġall', '-', 'time', 'Ġbehind', 'ĠMargaret', 'ĠCourt', 'Ġ(', '24', ')', 'Ġand', 'ĠSere', 'na', 'ĠWilliams', 'Ġ(', '23', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ1988', ',', 'Ġshe', 'Ġbecame', 'Ġthe', 'Ġfirst', 'Ġand', 'Ġonly', 'Ġtennis', 'Ġplayer', 'Ġ(', 'male', 'Ġor', 'Ġfemale', ')', 'Ġto', 'Ġachieve', 'Ġthe', 'ĠGolden', 'ĠSlam', 'Ġby', 'Ġwinning', 'Ġall', 'Ġfour', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġtitles', 'Ġand', 'Ġthe', 'ĠOlympic', 'Ġgold', 'Ġmedal', 'Ġin', 'Ġthe', 'Ġsame', 'Ġcalendar', 'Ġyear', '.', 'Ġ', '<s>', 'ĠFurthermore', ',', 'Ġshe', 'Ġis', 'Ġthe', 'Ġonly', 'Ġtennis', 'Ġplayer', 'Ġto', 'Ġhave', 'Ġwon', 'Ġeach', 'ĠGrand', 'ĠSlam', 'Ġevent', 'Ġat', 'Ġleast', 'Ġfour', 'Ġtimes', '.', '<p>', 'ĠThe', 'Ġ1986', 'ĠGerman', 'ĠOpen', 'Ġ(', 'also', 'Ġknown', 'Ġas', 'Ġthe', 'Ġ1986', 'ĠE', 'bel', 'ĠGerman', 'ĠOpen', ')', 'Ġwas', 'Ġa', 'Ġmen', \"'s\", 'Ġtennis', 'Ġtournament', 'Ġof', 'Ġthe', 'Ġ1986', 'ĠNab', 'isco', 'ĠGrand', 'ĠPrix', 'Ġand', 'Ġplayed', 'Ġon', 'Ġoutdoor', 'Ġred', 'Ġclay', 'Ġcourts', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġthe', 'Ġ77', 'th', 'Ġedition', 'Ġof', 'Ġthe', 'Ġevent', '.', 'Ġ', '<s>', 'ĠIt', 'Ġtook', 'Ġplace', 'Ġat', 'Ġthe', 'ĠAm', 'ĠRot', 'hen', 'baum', 'Ġin', 'ĠHamburg', ',', 'ĠWest', 'ĠGermany', ',', 'Ġfrom', 'Ġ15', 'ĠSeptember', 'Ġthrough', 'Ġ21', 'ĠSeptember', 'Ġ1986', '.', 'Ġ', '<s>', 'ĠHenri', 'ĠL', 'ec', 'onte', 'Ġwon', 'Ġthe', 'Ġsingles', 'Ġtitle', '.', 'Ġ', '<s>', 'ĠFourth', '-', 'se', 'eded', 'ĠHenri', 'ĠL', 'ec', 'onte', 'Ġwon', 'Ġthe', 'Ġsingles', 'Ġtitle', '.', '<p>', 'ĠJonathan', 'ĠStark', 'Ġ(', 'born', 'ĠApril', 'Ġ3', ',', 'Ġ1971', ')', 'Ġis', 'Ġa', 'Ġformer', 'Ġprofessional', 'Ġtennis', 'Ġplayer', 'Ġfrom', 'Ġthe', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠDuring', 'Ġhis', 'Ġcareer', 'Ġhe', 'Ġwon', 'Ġtwo', 'ĠGrand', 'ĠSlam', 'Ġdoubles', 'Ġtitles', 'Ġ(', 'the', 'Ġ1994', 'ĠFrench', 'ĠOpen', 'ĠMen', \"'s\", 'ĠDou', 'bles', 'Ġand', 'Ġthe', 'Ġ1995', 'ĠWim', 'bledon', 'ĠChampionships', 'ĠMixed', 'ĠDou', 'bles', ').', 'Ġ', '<s>', 'ĠStark', 'Ġreached', 'Ġthe', 'ĠWorld', 'ĠNo', '.', 'Ġ1', 'Ġdoubles', 'Ġranking', 'Ġin', 'Ġ1994', '.', '<p>', 'ĠPam', 'ĠTee', 'gu', 'arden', 'Ġ(', 'born', 'ĠApril', 'Ġ17', ',', 'Ġ1951', ')', 'Ġis', 'Ġa', 'Ġformer', 'ĠAmerican', 'Ġprofessional', 'Ġtennis', 'Ġplayer', 'Ġin', 'Ġthe', 'Ġ1970', 's', 'Ġand', 'Ġ1980', 's', ',', 'Ġranked', 'Ġin', 'Ġthe', 'Ġtop', 'Ġ20', 'Ġfrom', 'Ġ1970', 'âĢĵ', '1975', ',', 'Ġaccording', 'Ġto', 'Ġ\"', 'John', 'ĠD', 'olan', \"'s\", 'ĠWomen', \"'s\", 'ĠTennis', 'ĠUltimate', 'ĠGuide', '\",', 'Ġprior', 'Ġto', 'Ġcomputer', 'Ġrankings', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwon', 'Ġtwo', 'ĠGrand', 'ĠSlam', 'ĠDou', 'bles', 'ĠTit', 'les', 'Ġand', 'Ġwas', 'Ġa', 'Ġquarter', 'Ġfinal', 'ist', 'Ġin', 'Ġsingles', 'Ġat', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠOpen', 'Ġand', 'ĠThe', 'ĠFrench', 'ĠOpen', '.', 'Ġ', '<s>', 'ĠHer', 'Ġfather', 'ĠJerry', ',', 'Ġa', 'Ġwell', 'Ġknown', 'Ġcoach', ',', 'Ġhelped', 'ĠMargaret', 'ĠCourt', 'Ġwin', 'Ġthe', 'Ġcoveted', 'ĠGrand', 'ĠSlam', 'Ġ(', 'all', 'Ġfour', 'ĠGrand', 'ĠSlam', 'Ġtitles', 'Ġin', 'Ġone', 'Ġyear', ')', 'Ġin', 'Ġ1970', 'Ġand', 'ĠVirginia', 'ĠWade', 'Ġto', 'Ġher', 'Ġ1977', 'ĠWim', 'bledon', 'Ġtriumph', '.', 'Ġ', '<s>', 'ĠTee', 'gu', 'arden', 'Ġwas', 'Ġvoted', 'Ġthe', 'Ġ\"', 'Most', 'ĠWatch', 'able', 'ĠPlayer', '\"', 'Ġbased', 'Ġon', 'Ġplay', 'Ġand', 'Ġappearance', 'Ġby', 'Ġa', 'Ġgroup', 'Ġof', 'ĠMadison', 'ĠAvenue', 'Ġadvertising', 'Ġexecutives', 'Ġor', 'Ġ\"', 'Mad', 'ĠMen', '\"', 'Ġwhile', 'Ġplaying', 'Ġat', 'Ġthe', 'ĠUS', 'ĠOpen', '.', 'Ġ', '<s>', 'ĠTee', 'gu', 'arden', 'Ġplayed', 'Ġin', 'Ġ19', 'Ġconsecutive', 'ĠUS', 'ĠOp', 'ens', ',', 'Ġholding', 'Ġthe', 'Ġrecord', 'Ġuntil', 'ĠChris', 'ĠE', 'vert', 'Ġplayed', 'Ġin', 'Ġ20', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwore', 'Ġthe', 'Ġfirst', 'Ġall', 'Ġblack', 'Ġoutfit', 'Ġin', 'Ġthe', 'Ġhistory', 'Ġof', 'Ġtennis', 'Ġin', 'Ġ1975', 'Ġat', 'ĠThe', 'ĠBrid', 'gest', 'one', 'ĠDou', 'bles', 'ĠChampionships', 'Ġin', 'ĠTokyo', ',', 'Ġstarting', 'Ġa', 'Ġtrend', 'Ġthat', 'Ġis', 'Ġstill', 'Ġpopular', 'Ġtoday', '.', 'Ġ', '<s>', 'ĠTee', 'gu', 'arden', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġwoman', 'Ġtennis', 'Ġplayer', 'Ġsigned', 'Ġby', 'ĠNike', '.', 'Ġ', '<s>', 'ĠShe', 'Ġplayed', 'Ġon', 'Ġthe', 'Ġvictorious', 'ĠLos', 'ĠAngeles', 'ĠStr', 'ings', 'ĠTeam', 'ĠTennis', 'Ġteam', 'Ġin', 'Ġ1981', 'Ġand', 'Ġwon', 'Ġthe', 'ĠTeam', 'ĠTennis', 'ĠMixed', 'ĠDou', 'bles', 'ĠDivision', 'Ġwith', 'ĠTom', 'ĠG', 'ull', 'i', 'kson', 'Ġin', 'Ġ1977', ';', 'Ġthey', 'Ġwere', 'Ġalso', 'Ġrunners', '-', 'up', 'Ġin', 'Ġthe', 'Ġleague', 'Ġthat', 'Ġyear', '.', '<p>', 'ĠKenneth', 'ĠRobert', 'ĠRose', 'wall', 'Ġ{', \"'\", '1', \"':\", 'Ġ\",', \"Ġ'\", '2', \"':\", 'Ġ\",', \"Ġ'\", '3', \"':\", \"Ġ'\", 'AM', ',', 'ĠMB', 'E', \"',\", \"Ġ'\", '4', \"':\", 'Ġ\"', '}', 'Ġ(', 'born', 'Ġ2', 'ĠNovember', 'Ġ1934', ')', 'Ġis', 'Ġa', 'Ġformer', 'Ġworld', 'Ġtop', '-', 'ranking', 'Ġamateur', 'Ġand', 'Ġprofessional', 'Ġtennis', 'Ġplayer', 'Ġfrom', 'ĠAustralia', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwon', 'Ġa', 'Ġrecord', 'Ġ23', 'Ġtennis', 'ĠMaj', 'ors', 'Ġincluding', 'Ġ8', 'ĠGrand', 'ĠSlam', 'Ġsingles', 'Ġtitles', 'Ġand', 'Ġbefore', 'Ġthe', 'ĠOpen', 'ĠEra', 'Ġa', 'Ġrecord', 'Ġ15', 'ĠPro', 'ĠSlam', 'Ġtitles', 'Ġand', 'Ġa', 'Ġrecord', 'Ġ35', 'ĠMajor', 'Ġfinals', 'Ġoverall', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwon', 'Ġthe', 'ĠPro', 'ĠGrand', 'ĠSlam', 'Ġin', 'Ġ1963', '.', 'Ġ', '<s>', 'ĠRose', 'wall', 'Ġwon', 'Ġ9', 'Ġslams', 'Ġin', 'Ġdoubles', 'Ġwith', 'Ġa', 'Ġcareer', 'Ġdouble', 'Ġgrand', 'Ġslam', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġconsidered', 'Ġto', 'Ġbe', 'Ġone', 'Ġof', 'Ġthe', 'Ġgreatest', 'Ġtennis', 'Ġplayers', 'Ġof', 'Ġall', 'Ġtime', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhad', 'Ġa', 'Ġrenowned', 'Ġback', 'hand', 'Ġand', 'Ġenjoyed', 'Ġa', 'Ġlong', 'Ġcareer', 'Ġat', 'Ġthe', 'Ġhighest', 'Ġlevels', 'Ġfrom', 'Ġthe', 'Ġearly', 'Ġ1950', 's', 'Ġto', 'Ġthe', 'Ġearly', 'Ġ1970', 's', '.', 'Ġ', '<s>', 'ĠRose', 'wall', 'Ġwas', 'Ġone', 'Ġof', 'Ġthe', 'Ġtwo', 'Ġbest', 'Ġmale', 'Ġplayers', 'Ġfor', 'Ġabout', 'Ġnine', 'Ġyears', 'Ġand', 'Ġwas', 'Ġthe', 'ĠWorld', 'ĠNo', '.', 'Ġ1', 'Ġplayer', 'Ġfor', 'Ġa', 'Ġnumber', 'Ġof', 'Ġyears', 'Ġin', 'Ġthe', 'Ġearly', 'Ġ1960', 's', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġranked', 'Ġamong', 'Ġthe', 'Ġtop', 'Ġ20', 'Ġplayers', ',', 'Ġamateur', 'Ġor', 'Ġprofessional', ',', 'Ġevery', 'Ġyear', 'Ġfrom', 'Ġ1952', 'Ġthrough', 'Ġ1977', '.', 'Ġ', '<s>', 'ĠRose', 'wall', 'Ġis', 'Ġthe', 'Ġonly', 'Ġplayer', 'Ġto', 'Ġhave', 'Ġsimultaneously', 'Ġheld', 'ĠPro', 'ĠGrand', 'ĠSlam', 'Ġtitles', 'Ġon', 'Ġthree', 'Ġdifferent', 'Ġsurfaces', 'Ġ(', '19', '62', 'âĢĵ', '1963', ').', 'Ġ', '<s>', 'ĠAt', 'Ġthe', 'Ġ1971', 'ĠAustralian', 'ĠOpen', 'Ġhe', 'Ġbecame', 'Ġthe', 'Ġfirst', 'Ġmale', 'Ġplayer', 'Ġduring', 'Ġthe', 'Ġopen', 'Ġera', 'Ġto', 'Ġwin', 'Ġa', 'ĠGrand', 'ĠSlam', 'Ġtournament', 'Ġwithout', 'Ġdropping', 'Ġa', 'Ġset', '.', '<p>', 'ĠSere', 'na', 'ĠWilliams', \"'s\", 'Ġ2009', 'Ġtennis', 'Ġseason', 'Ġofficially', 'Ġbegan', 'Ġat', 'Ġthe', 'Ġ2009', 'ĠMed', 'ib', 'ank', 'ĠInternational', 'ĠSydney', '.', 'Ġ', '<s>', 'ĠWilliams', 'Ġfinished', 'Ġthe', 'Ġyear', 'Ġranked', 'Ġworld', 'Ġno', '.', 'Ġ1', 'Ġfor', 'Ġthe', 'Ġsecond', 'Ġtime', 'Ġin', 'Ġher', 'Ġcareer', ',', 'Ġhaving', 'Ġplayed', 'Ġin', 'Ġ16', 'Ġtournaments', ',', 'Ġmore', 'Ġthan', 'Ġany', 'Ġother', 'Ġyear', '.', 'Ġ', '<s>', 'ĠShe', 'Ġalso', 'Ġbroke', 'Ġthe', 'Ġrecord', 'Ġpreviously', 'Ġset', 'Ġby', 'ĠJust', 'ine', 'ĠHen', 'in', 'Ġfor', 'Ġthe', 'Ġmost', 'Ġprize', 'Ġmoney', 'Ġearned', 'Ġby', 'Ġa', 'Ġfemale', 'Ġtennis', 'Ġplayer', 'Ġin', 'Ġone', 'Ġyear', ',', 'Ġwith', 'ĠWilliams', 'Ġearning', 'Ġ$', '6', ',', '545', ',', '586', '.', 'Ġ', '<s>', 'ĠIn', 'Ġdoubles', ',', 'Ġshe', 'Ġfinished', 'Ġthe', 'Ġyear', 'Ġranked', 'Ġworld', 'Ġno', '.', 'Ġ3', ',', 'Ġdespite', 'Ġplaying', 'Ġonly', 'Ġsix', 'Ġtournaments', 'Ġas', 'Ġa', 'Ġpair', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwon', 'Ġfive', 'ĠGrand', 'ĠSlam', 'Ġtitles', ',', 'Ġputting', 'Ġher', 'Ġtotal', 'ĠGrand', 'ĠSlam', 'Ġtitles', 'Ġat', 'Ġ23', '.', '<p>', 'ĠLar', 'isa', 'ĠSav', 'chenko', '-', 'Neil', 'and', 'Ġ(', 'n', 'Ã©e', 'ĠSav', 'chenko', ';', 'Ġborn', 'Ġ21', 'ĠJuly', 'Ġ1966', ')', 'Ġis', 'Ġa', 'Ġformer', 'Ġprofessional', 'Ġtennis', 'Ġplayer', 'Ġwho', 'Ġrepresented', 'Ġthe', 'ĠSoviet', 'ĠUnion', 'Ġand', 'ĠLatvia', '.', 'Ġ', '<s>', 'ĠA', 'Ġformer', 'Ġworld', 'Ġnumber', 'Ġone', 'Ġranked', 'Ġdoubles', 'Ġplayer', ',', 'ĠNeil', 'and', 'Ġwon', 'Ġtwo', 'Ġwomen', \"'s\", 'Ġdoubles', 'ĠGrand', 'ĠSlam', 'Ġtitles', 'Ġand', 'Ġfour', 'Ġmixed', 'Ġdoubles', 'ĠGrand', 'ĠSlam', 'Ġtitles', '.', 'Ġ', '<s>', 'ĠShe', 'Ġalso', 'Ġwon', 'Ġtwo', 'Ġsingles', 'Ġtitles', 'Ġand', 'Ġsixty', '-', 'five', 'Ġdoubles', 'Ġtitles', '.']\n",
      "lr:  tensor([4.7500e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "orig_answer_text:  6.213 km long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u32/fanluo/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  ['<cls>', '<q>', 'Gun', 'men', 'Ġfrom', 'ĠL', 'ared', 'o', 'Ġstarred', 'Ġwhich', 'Ġnarrator', 'Ġof', 'Ġ\"', 'Front', 'ier', '\"?', '</q>', '<p>', 'ĠLouis', 'ĠStevens', 'Ġ(', 'December', 'Ġ25', ',', 'Ġ1896', 'ĠâĢĵ', 'ĠSeptember', 'Ġ29', ',', 'Ġ1963', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġscreen', 'writer', 'Ġof', 'Ġthe', 'Ġsilent', 'Ġand', 'Ġsound', 'Ġfilm', 'Ġeras', '.', 'Ġ', '<s>', 'ĠBorn', 'Ġon', 'ĠChristmas', 'ĠDay', 'Ġ1896', 'Ġin', 'ĠR', 'iga', ',', 'ĠLatvia', ',', 'ĠStevens', 'Ġentered', 'Ġthe', 'Ġfilm', 'Ġindustry', 'Ġin', 'Ġ1920', 'Ġwhen', 'Ġhe', 'Ġco', '-', 'wrote', 'Ġthe', 'Ġsilent', 'Ġfilm', 'Ġ\"', 'A', 'ĠWorld', 'Ġof', 'ĠF', 'olly', '\",', 'Ġwith', 'ĠJane', 'ĠGro', 'gan', '.', 'Ġ', '<s>', 'ĠIn', 'Ġhis', 'Ġover', 'Ġ30', '-', 'year', 'Ġcareer', 'Ġhe', 'Ġworked', 'Ġon', 'Ġover', 'Ġ40', 'Ġscreen', 'plays', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġseveral', 'Ġfilm', 'Ġshorts', 'Ġand', 'Ġtwo', 'Ġtelevision', 'Ġseries', '.', 'Ġ', '<s>', 'ĠAmong', 'Ġhis', 'Ġmore', 'Ġnotable', 'Ġfilms', 'Ġwere', ':', 'Ġcontributing', 'Ġto', 'Ġthe', 'Ġscript', 'Ġof', 'Ġthe', 'Ġ1931', 'Ġversion', 'Ġof', 'Ġ\"', 'Dr', 'ac', 'ula', '\",', 'Ġstarring', 'ĠBel', 'a', 'ĠLug', 'osi', ';', 'Ġco', '-', 'writing', 'Ġthe', 'Ġstory', 'Ġfor', 'ĠWhat', 'ĠPrice', 'ĠHollywood', '?', 'Ġ', '<s>', 'Ġ(', '19', '32', ');', 'Ġthe', 'Ġscreenplay', 'Ġfor', 'Ġthe', 'Ġ1940', 'Ġwestern', ',', 'Ġ\"', 'Colorado', '\",', 'Ġdirected', 'Ġby', 'ĠJoseph', 'ĠKane', ',', 'Ġand', 'Ġstarring', 'ĠRoy', 'ĠRogers', ';', 'Ġthe', 'Ġstory', 'Ġfor', 'Ġ\"', 'Stre', 'ets', 'Ġof', 'ĠL', 'ared', 'o', '\"', 'Ġ(', '19', '49', '),', 'Ġstarring', 'ĠWilliam', 'ĠHolden', ',', 'ĠMac', 'donald', 'ĠCarey', 'Ġand', 'ĠWilliam', 'ĠB', 'endix', ';', 'Ġ1951', \"'s\", 'Ġ\"', 'The', 'ĠC', 'imar', 'ron', 'ĠKid', '\",', 'Ġstarring', 'ĠAud', 'ie', 'ĠMurphy', ';', 'Ġand', 'Ġ\"', 'Hor', 'izons', 'ĠWest', '\"', 'Ġ(', '19', '52', '),', 'Ġstarring', 'ĠRobert', 'ĠRyan', ',', 'ĠJulie', 'ĠAdams', ',', 'Ġand', 'ĠRock', 'ĠHudson', '.', 'Ġ', '<s>', 'ĠStevens', \"'\", 'Ġfinal', 'Ġscreenplay', 'Ġwas', 'Ġfor', 'Ġ\"', 'F', 'lam', 'ing', 'ĠFrontier', '\"', 'Ġin', 'Ġ1958', ',', 'Ġalthough', 'Ġhe', 'Ġdid', 'Ġsome', 'Ġwork', 'Ġon', 'Ġadditional', 'Ġdialogue', 'Ġfor', 'Ġthe', 'Ġ1959', 'Ġfilm', ',', 'Ġ\"', 'Des', 'ert', 'ĠDes', 'per', 'adoes', '\".', 'Ġ', '<s>', 'ĠStevens', 'Ġalso', 'Ġwrote', 'Ġseveral', 'Ġtelevision', 'Ġepisodes', ',', 'Ġone', 'Ġfor', 'Ġ\"', 'Che', 'y', 'enne', '\",', 'Ġand', 'Ġtwo', 'Ġfor', 'Ġ\"', 'Haw', 'keye', 'Ġand', 'Ġthe', 'ĠLast', 'Ġof', 'Ġthe', 'ĠMoh', 'icans', '\",', 'Ġall', 'Ġin', 'Ġ1957', '.', '<p>', 'ĠThe', 'ĠLone', 'ĠGun', 'men', 'Ġare', 'Ġa', 'Ġtrio', 'Ġof', 'Ġfictional', 'Ġcharacters', ',', 'ĠRichard', 'Ġ\"', 'R', 'ingo', '\"', 'ĠLang', 'ly', ',', 'ĠMelvin', 'ĠFro', 'h', 'ike', 'Ġand', 'ĠJohn', 'ĠFitzgerald', 'ĠBy', 'ers', ',', 'Ġwho', 'Ġappeared', 'Ġin', 'Ġrecurring', 'Ġroles', 'Ġon', 'Ġthe', 'ĠAmerican', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠX', '-', 'Files', '\",', 'Ġand', 'Ġwho', 'Ġstarred', 'Ġin', 'Ġthe', 'Ġshort', '-', 'lived', 'Ġspin', '-', 'off', ',', 'Ġ\"', 'The', 'ĠLone', 'ĠGun', 'men', '\".', 'Ġ', '<s>', 'ĠTheir', 'Ġname', 'Ġwas', 'Ġderived', 'Ġfrom', 'Ġthe', 'ĠWarren', 'ĠCommission', \"'s\", 'Ġconclusion', 'Ġthat', 'ĠLee', 'ĠHarvey', 'ĠOswald', 'Ġwas', 'Ġsolely', 'Ġresponsible', 'Ġfor', 'Ġthe', 'Ġassassination', 'Ġof', 'ĠJohn', 'ĠF', '.', 'ĠKennedy', '.', '<p>', 'ĠHerm', 'and', 'ad', 'Ġde', 'ĠPist', 'oler', 'os', 'ĠLatinos', 'Ġ(', 'H', 'PL', ',', 'Ġa', '.', 'k', '.', 'a', '.', 'ĠPist', 'oler', 'os', 'ĠLatinos', 'Ġor', 'ĠCu', 'et', 'es', ')', 'Ġis', 'Ġa', 'ĠLatino', 'Ġprison', 'Ġgang', 'Ġfounded', 'Ġby', 'ĠCh', 'ino', 'ĠAv', 'itia', 'Ġin', 'ĠTexas', 'Ġduring', 'Ġthe', 'Ġearly', 'Ġ1980', 's', '.', 'Ġ', '<s>', 'ĠThe', 'ĠEnglish', 'Ġtranslation', 'Ġof', 'Ġthe', 'Ġgang', \"'s\", 'Ġname', 'Ġis', 'Ġ\"', 'Brother', 'hood', 'Ġof', 'ĠLatin', 'ĠGun', 'men', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġoperates', 'Ġin', 'Ġall', 'ĠTexas', 'Ġprisons', 'Ġand', 'Ġon', 'Ġthe', 'Ġstreets', 'Ġin', 'Ġmany', 'Ġcommunities', 'Ġin', 'ĠTexas', ',', 'Ġparticularly', 'Ġin', 'ĠL', 'ared', 'o', '.', 'Ġ', '<s>', 'ĠH', 'PL', 'Ġis', 'Ġactive', 'Ġthroughout', 'ĠMexico', 'Ġwith', 'Ġits', 'Ġlargest', 'Ġcontingent', 'Ġin', 'ĠN', 'ue', 'vo', 'ĠL', 'ared', 'o', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgang', 'Ġis', 'Ġstructured', 'Ġand', 'Ġis', 'Ġestimated', 'Ġto', 'Ġhave', 'Ġ1', ',', '000', 'Ġmembers', '.', 'Ġ', '<s>', 'ĠMembers', 'Ġmaintain', 'Ġclose', 'Ġties', 'Ġto', 'Ġseveral', 'ĠMexican', 'Ġdrug', 'Ġtrafficking', 'Ġorganizations', 'Ġand', 'Ġare', 'Ġinvolved', 'Ġin', 'Ġthe', 'Ġtrafficking', 'Ġof', 'Ġlarge', 'Ġquantities', 'Ġof', 'Ġcocaine', 'Ġand', 'Ġmarijuana', 'Ġfrom', 'ĠMexico', 'Ġinto', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġfor', 'Ġdistribution', '.', '<p>', 'ĠPir', 'an', 'ha', ',', 'Ġalso', 'Ġknown', 'Ġas', 'ĠPir', 'an', 'ha', ',', 'ĠPir', 'an', 'ha', 'Ġor', 'ĠCarib', 'e', ',', 'Ġis', 'Ġa', 'Ġ1972', 'Ġadventure', 'Ġfilm', 'Ġshot', 'Ġin', 'ĠVenezuela', 'Ġstarring', 'ĠWilliam', 'ĠSmith', 'Ġand', 'ĠPeter', 'ĠBrown', 'Ġwho', 'Ġhad', 'Ġpreviously', 'Ġstarred', 'Ġtogether', 'Ġin', 'Ġthe', 'Ġ\"', 'L', 'ared', 'o', '\"', 'ĠWestern', 'ĠTV', 'Ġseries', 'Ġand', 'ĠAh', 'na', 'ĠCap', 'ri', '.', '<p>', 'ĠGun', 'men', 'Ġfrom', 'ĠL', 'ared', 'o', 'Ġis', 'Ġa', 'Ġ1959', 'ĠAmerican', 'Ġwestern', 'Ġfilm', 'Ġproduced', 'Ġand', 'Ġdirected', 'Ġby', 'ĠWallace', 'ĠMacDonald', ',', 'Ġwhich', 'Ġstars', 'ĠRobert', 'ĠKn', 'app', ',', 'ĠMa', 'ureen', 'ĠH', 'ing', 'ert', ',', 'Ġand', 'ĠWalter', 'ĠCoy', '.', '<p>', 'ĠShe', 'em', 'anto', 'Ġhe', 'era', 'Ġ(', 'The', 'ĠFrontier', 'ĠDiamond', ')', 'Ġis', 'Ġa', 'Ġdetective', 'Ġno', 've', 'lla', 'Ġwritten', 'Ġin', 'ĠBeng', 'ali', 'Ġby', 'ĠShar', 'ad', 'indu', 'ĠBand', 'y', 'op', 'ad', 'hy', 'ay', 'Ġfeaturing', 'Ġthe', 'Ġsle', 'uth', 'ĠBy', 'om', 'k', 'esh', 'ĠBak', 'shi', 'Ġand', 'ĠAj', 'it', 'ĠBand', 'y', 'op', 'ad', 'hy', 'ay', '.', 'Ġ', '<s>', 'ĠWritten', 'Ġin', 'Ġ1934', ',', 'Ġit', 'Ġis', 'Ġthe', 'Ġthird', 'Ġsuch', 'Ġwork', 'Ġof', 'Ġfiction', 'Ġfeaturing', 'ĠBy', 'om', 'k', 'esh', 'Ġand', 'Ġis', 'Ġwritten', 'Ġin', 'Ġfirst', '-', 'person', 'Ġnarrative', ',', 'Ġas', 'Ġexperienced', 'Ġby', 'ĠBy', 'om', 'k', 'esh', \"'s\", 'Ġfriend', ',', 'Ġassociate', ',', 'Ġand', 'Ġnarrator', ',', 'ĠAj', 'it', 'ĠBand', 'y', 'op', 'ad', 'hy', 'ay', '.', '<p>', 'ĠFrontier', 'ĠTexas', '!', 'Ġ', '<s>', 'Ġis', 'Ġa', 'Ġ14', '000', 'Ġsq', 'ft', 'Ġmuseum', 'Ġof', 'Ġthe', 'ĠAmerican', 'ĠWest', 'Ġin', 'Ġdowntown', 'ĠAb', 'il', 'ene', ',', 'Ġthe', 'Ġseat', 'Ġof', 'ĠTaylor', 'ĠCounty', 'Ġin', 'ĠWest', 'ĠTexas', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmuseum', 'Ġserves', 'Ġas', 'Ġa', 'Ġvisitors', 'Ġinformation', 'Ġcenter', 'Ġfor', 'Ġthe', 'ĠTexas', 'ĠF', 'orts', 'ĠTrail', ',', 'Ġone', 'Ġof', 'Ġten', 'ĠTexas', 'ĠHistorical', 'ĠCommission', 'Ġdriving', 'Ġregions', '.', 'Ġ', '<s>', 'ĠOp', 'ened', 'Ġin', 'Ġ2004', 'Ġat', 'Ġ625', 'ĠNorth', 'ĠFirst', 'ĠStreet', 'Ġon', 'Ġ6', '.', '4', 'Ġacre', 'Ġnear', 'Ġthe', 'ĠTexas', 'Ġand', 'ĠPacific', 'ĠRailway', 'Ġtracks', ',', 'Ġthe', 'Ġmuseum', 'Ġfocuses', 'Ġon', 'Ġsettlers', 'Ġand', 'Ġlifestyles', 'Ġin', 'Ġthe', 'ĠOld', 'ĠWest', '.', 'Ġ', '<s>', 'ĠEx', 'hib', 'its', 'Ġdisplay', 'Ġattacks', 'Ġby', 'ĠIndians', 'Ġand', 'Ġwolves', ',', 'Ġstamp', 'eding', 'Ġbuffalo', ',', 'Ġa', 'Ġcard', 'Ġgame', 'Ġshootout', ',', 'Ġand', 'Ġa', 'Ġpra', 'irie', 'Ġthunder', 'storm', '.', 'Ġ', '<s>', 'ĠVisitors', 'Ġsee', 'Ġdepictions', 'Ġof', 'Ġbuffalo', 'Ġhunters', ',', 'ĠCom', 'anche', 'Ġwarriors', ',', 'Ġexplorers', ',', 'Ġand', 'Ġpioneers', 'Ġin', 'Ġthe', 'Ġtheatre', 'Ġcalled', 'Ġthe', 'Ġ\"', 'Cent', 'ury', 'Ġof', 'ĠAdventure', '\",', 'Ġ17', '80', '-', '18', '80', '.', 'Ġ', '<s>', 'ĠThe', 'Ġnarrator', 'Ġin', 'Ġthe', 'Ġtheater', 'Ġis', 'Ġactor', '-', 'artist', 'ĠBuck', 'ĠTaylor', 'Ġfrom', 'ĠFort', 'ĠWorth', '.', '<p>', 'ĠWalter', 'ĠDarwin', 'ĠCoy', 'Ġ(', 'January', 'Ġ31', ',', 'Ġ1909', 'ĠâĢĵ', 'ĠDecember', 'Ġ11', ',', 'Ġ1974', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġstage', ',', 'Ġradio', ',', 'Ġfilm', ',', 'Ġand', ',', 'Ġprincipally', ',', 'Ġtelevision', 'Ġactor', ',', 'Ġoriginally', 'Ġfrom', 'ĠGreat', 'ĠFalls', ',', 'ĠMontana', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġnarr', 'ating', 'Ġthe', 'ĠNBC', 'Ġwestern', 'Ġanthology', 'Ġseries', ',', 'Ġ\"', 'Front', 'ier', '\",', 'Ġwhich', 'Ġaired', 'Ġearly', 'ĠSunday', 'Ġevenings', 'Ġin', 'Ġthe', 'Ġ1955', 'âĢĵ', '19', '56', 'Ġseason', '.', '<p>', 'ĠMax', 'ĠMc', 'Lean', 'Ġis', 'Ġthe', 'Ġfounder', 'Ġand', 'Ġartistic', 'Ġdirector', 'Ġof', 'ĠFellowship', 'Ġfor', 'ĠPer', 'forming', 'ĠArts', ',', 'Ġa', 'ĠNew', 'ĠYork', 'ĠCity', '-', 'based', 'Ġproducer', 'Ġof', 'Ġlive', 'Ġtheater', 'Ġfrom', 'Ġa', 'ĠChristian', 'Ġworldview', '.', 'Ġ', '<s>', 'ĠMc', 'Lean', 'Ġconceived', ',', 'Ġadapted', ',', 'Ġproduced', 'Ġand', 'Ġstarred', 'Ġin', 'Ġ\"', 'The', 'ĠScrew', 't', 'ape', 'ĠLetters', '\",', 'Ġa', 'Ġplay', 'Ġbased', 'Ġon', 'Ġthe', 'Ġbook', 'Ġby', 'ĠOxford', 'Ġand', 'ĠCambridge', 'Ġscholar', ',', 'Ġauthor', 'Ġand', 'Ġfantasy', 'Ġwriter', 'ĠC', '.', 'S', '.', 'ĠLewis', '.', 'Ġ', '<s>', 'ĠHis', 'Ġstage', 'Ġadaptation', 'Ġof', 'ĠLewis', 'âĢ', 'Ļ', 'Ġ\"', 'The', 'ĠGreat', 'ĠDiv', 'orce', '\"', 'Ġlaunched', 'Ġits', 'Ġnational', 'Ġtour', 'Ġin', 'Ġlate', 'Ġ2013', '.', 'Ġ', '<s>', 'ĠMc', 'Lean', 'Ġadapted', ',', 'Ġco', '-', 'directed', 'Ġand', 'Ġstarred', 'Ġin', 'Ġ\"', 'C', '.', 'S', '.', 'ĠLewis', 'ĠOn', 'stage', ':', 'ĠThe', 'ĠMost', 'ĠRel', 'uct', 'ant', 'ĠConvert', '\",', 'Ġand', 'Ġco', '-', 'wrote', 'Ġand', 'Ġproduced', 'Ġ\"', 'Martin', 'ĠLuther', 'Ġon', 'ĠTrial', '\".', 'Ġ', '<s>', 'ĠMc', 'Lean', 'Ġalso', 'Ġis', 'Ġthe', 'Ġnarrator', 'Ġof', 'ĠThe', 'ĠList', 'ener', \"'s\", 'ĠBible', '.', '<p>', 'ĠBruce', 'ĠHar', 'wood', 'Ġ(', 'born', 'ĠApril', 'Ġ29', ',', 'Ġ1963', ')', 'Ġis', 'Ġa', 'ĠCanadian', 'Ġcharacter', 'Ġactor', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġrole', 'Ġof', 'ĠJohn', 'ĠFitzgerald', 'ĠBy', 'ers', ',', 'Ġone', 'Ġof', 'ĠThe', 'ĠLone', 'ĠGun', 'men', 'Ġon', 'Ġthe', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠX', '-', 'Files', '\".', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', 'Ġto', 'Ġ\"', 'The', 'ĠX', '-', 'Files', '\",', 'ĠHar', 'wood', 'Ġportrayed', 'ĠBy', 'ers', 'Ġin', 'Ġthe', 'Ġspin', '-', 'off', 'Ġseries', 'Ġ\"', 'The', 'ĠLone', 'ĠGun', 'men', '\",', 'Ġwhich', 'Ġaired', 'Ġthirteen', 'Ġepisodes', 'Ġin', 'Ġ2001', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġalso', 'Ġplayed', 'Ġother', 'Ġroles', 'Ġwith', 'Ġa', 'Ġstrong', 'Ġsimilarity', 'Ġto', 'ĠBy', 'ers', ',', 'Ġsuch', 'Ġas', 'ĠWillis', ',', 'Ġa', 'Ġtechnician', 'Ġfrom', 'Ġthe', 'ĠPhoenix', 'ĠFoundation', 'Ġin', 'Ġ\"', 'Mac', 'Gy', 'ver', '\",', 'Ġand', 'Ġgovernment', '-', 'scient', 'ist', '-', 'turned', '-', 'cons', 'piracy', '-', 'the', 'or', 'ist', 'ĠDr', '.', 'ĠAvery', 'ĠStrong', 'Ġin', 'Ġ\"', 'The', 'ĠOuter', 'ĠLimits', '\".', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġa', 'Ġfounding', 'Ġmember', 'Ġof', 'Ġthe', 'ĠVancouver', 'Ġsummer', 'ĠShakespeare', 'Ġfestival', ',', 'ĠBard', 'Ġon', 'Ġthe', 'ĠBeach', '.', 'Ġ', '<s>', 'ĠHe', 'Ġalso', 'Ġstarred', 'Ġin', 'Ġthe', 'Ġ1988', 'Ġmovie', 'Ġ\"', 'Earth', 'ĠStar', 'ĠVoyager', '\".']\n",
      "lr:  tensor([4.8000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Fast Cars, Danger, Fire and Knives includes guest appearances from which hip hop record executive?\n",
      "orig_answer_text:  Jaime Meline\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġgenus', 'Ġof', 'Ġmoth', 'Ġin', 'Ġthe', 'Ġworld', \"'s\", 'Ġseventh', '-', 'largest', 'Ġcountry', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', '?', '</q>', '<p>', 'ĠIndia', ',', 'Ġofficially', 'Ġthe', 'ĠRepublic', 'Ġof', 'ĠIndia', 'Ġ(\"', 'B', 'h', 'Äģ', 'rat', 'ĠGa', 'á¹', 'ĩ', 'ar', 'Äģ', 'j', 'ya', '\"),', 'Ġis', 'Ġa', 'Ġcountry', 'Ġin', 'ĠSouth', 'ĠAsia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġseventh', '-', 'largest', 'Ġcountry', 'Ġby', 'Ġarea', ',', 'Ġthe', 'Ġsecond', '-', 'most', 'Ġpopulous', 'Ġcountry', 'Ġ(', 'with', 'Ġover', 'Ġ1', '.', '2', 'Ġbillion', 'Ġpeople', '),', 'Ġand', 'Ġthe', 'Ġmost', 'Ġpopulous', 'Ġdemocracy', 'Ġin', 'Ġthe', 'Ġworld', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġbounded', 'Ġby', 'Ġthe', 'ĠIndian', 'ĠOcean', 'Ġon', 'Ġthe', 'Ġsouth', ',', 'Ġthe', 'ĠArabian', 'ĠSea', 'Ġon', 'Ġthe', 'Ġsouthwest', ',', 'Ġand', 'Ġthe', 'ĠBay', 'Ġof', 'ĠBengal', 'Ġon', 'Ġthe', 'Ġsoutheast', '.', 'Ġ', '<s>', 'ĠIt', 'Ġshares', 'Ġland', 'Ġborders', 'Ġwith', 'ĠPakistan', 'Ġto', 'Ġthe', 'Ġwest', ';', 'ĠChina', ',', 'ĠNepal', ',', 'Ġand', 'ĠBh', 'utan', 'Ġto', 'Ġthe', 'Ġnortheast', ';', 'Ġand', 'ĠMyanmar', 'Ġ(', 'Bur', 'ma', ')', 'Ġand', 'ĠBangladesh', 'Ġto', 'Ġthe', 'Ġeast', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'ĠIndian', 'ĠOcean', ',', 'ĠIndia', 'Ġis', 'Ġin', 'Ġthe', 'Ġvicinity', 'Ġof', 'ĠSri', 'ĠLanka', 'Ġand', 'Ġthe', 'ĠMald', 'ives', '.', 'Ġ', '<s>', 'ĠIndia', \"'s\", 'ĠAnd', 'aman', 'Ġand', 'ĠNic', 'obar', 'ĠIslands', 'Ġshare', 'Ġa', 'Ġmaritime', 'Ġborder', 'Ġwith', 'ĠThailand', 'Ġand', 'ĠIndonesia', '.', '<p>', 'ĠIndia', 'Ġis', 'Ġa', 'Ġcountry', 'Ġin', 'ĠSouth', 'ĠAsia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġseventh', '-', 'largest', 'Ġcountry', 'Ġby', 'Ġarea', ',', 'Ġthe', 'Ġsecond', '-', 'most', 'Ġpopulous', 'Ġcountry', 'Ġ(', 'with', 'Ġover', 'Ġ1', '.', '2', 'Ġbillion', 'Ġpeople', '),', 'Ġand', 'Ġthe', 'Ġmost', 'Ġpopulous', 'Ġdemocracy', 'Ġin', 'Ġthe', 'Ġworld', '.', '<p>', 'ĠE', 'ut', 'rap', 'ela', 'Ġis', 'Ġa', 'Ġgenus', 'Ġof', 'Ġmoth', 'Ġin', 'Ġthe', 'ĠGe', 'omet', 'rid', 'ae', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠE', 'ut', 'rap', 'ela', 'Ġcle', 'mat', 'aria', ',', 'Ġthe', 'Ġcurve', '-', 't', 'oot', 'hed', 'Ġge', 'ometer', 'Ġmoth', 'Ġor', 'Ġpur', 'pl', 'ish', '-', 'brown', 'Ġlo', 'oper', ',', 'Ġwhich', 'Ġis', 'Ġfound', 'Ġin', 'ĠNorth', 'ĠAmerica', ',', 'Ġwhere', 'Ġit', 'Ġhas', 'Ġbeen', 'Ġrecorded', 'Ġfrom', 'ĠNova', 'ĠScotia', 'Ġto', 'ĠFlorida', ',', 'Ġwest', 'Ġto', 'ĠTexas', 'Ġand', 'Ġnorth', 'Ġto', 'ĠSaskatchewan', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhabitat', 'Ġconsists', 'Ġof', 'Ġdec', 'id', 'uous', 'Ġand', 'Ġmixed', 'Ġwood', 'lands', '.', '<p>', 'ĠIndia', 'Ġlies', 'Ġon', 'Ġthe', 'ĠIndian', 'ĠPlate', ',', 'Ġthe', 'Ġnorthern', 'Ġportion', 'Ġof', 'Ġthe', 'ĠIndo', '-', 'Australian', 'ĠPlate', ',', 'Ġwhose', 'Ġcontinental', 'Ġcrust', 'Ġforms', 'Ġthe', 'ĠIndian', 'Ġsub', 'cont', 'inent', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcountry', 'Ġis', 'Ġsituated', 'Ġnorth', 'Ġof', 'Ġthe', 'Ġequ', 'ator', 'Ġbetween', 'Ġ8', 'Â°', '4', \"'\", 'Ġto', 'Ġ37', 'Â°', '6', \"'\", 'Ġnorth', 'Ġlatitude', 'Ġand', 'Ġ68', 'Â°', '7', \"'\", 'Ġto', 'Ġ97', 'Â°', '25', \"'\", 'Ġeast', 'Ġlong', 'itude', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġseventh', '-', 'largest', 'Ġcountry', 'Ġin', 'Ġthe', 'Ġworld', ',', 'Ġwith', 'Ġa', 'Ġtotal', 'Ġarea', 'Ġof', 'Ġ3', '287', '263', 'Ġkm', '2', 'Ġ.', 'Ġ', '<s>', 'ĠIndia', 'Ġmeasures', 'Ġ32', '14', 'Ġkm', 'Ġfrom', 'Ġnorth', 'Ġto', 'Ġsouth', 'Ġand', 'Ġ29', '33', 'Ġkm', 'Ġfrom', 'Ġeast', 'Ġto', 'Ġwest', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhas', 'Ġa', 'Ġland', 'Ġfrontier', 'Ġof', 'Ġ15', '200', 'Ġkm', 'Ġand', 'Ġa', 'Ġcoastline', 'Ġof', 'Ġ75', '16', '.', '6', 'Ġkm', 'Ġ.', '<p>', 'ĠYosh', 'iy', 'as', 'ua', 'Ġis', 'Ġa', 'Ġgrass', 'Ġmoth', 'Ġgenus', 'Ġ(', 'family', 'ĠC', 'ram', 'bid', 'ae', ')', 'Ġof', 'Ġsub', 'family', 'ĠMus', 'ot', 'im', 'ina', 'e', '.', 'Ġ', '<s>', 'ĠSome', 'Ġauthors', 'Ġhave', 'Ġplaced', 'Ġit', 'Ġin', 'Ġthe', 'Ġsn', 'out', 'Ġmoth', 'Ġfamily', 'Ġ(', 'Py', 'ral', 'idae', '),', 'Ġwhere', 'Ġall', 'Ġgrass', 'Ġm', 'oths', 'Ġwere', 'Ġonce', 'Ġalso', 'Ġincluded', ',', 'Ġbut', 'Ġthis', 'Ġseems', 'Ġto', 'Ġbe', 'Ġin', 'Ġerror', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgenus', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠYosh', 'iy', 'as', 'ua', 'Ġy', 'as', 'ud', 'ai', ',', 'Ġwhich', 'Ġis', 'Ġfound', 'Ġin', 'ĠJapan', ',', 'Ġwhere', 'Ġit', 'Ġhas', 'Ġbeen', 'Ġrecorded', 'Ġfrom', 'Ġthe', 'ĠRyu', 'ky', 'u', 'ĠIslands', '.', '<p>', 'ĠNep', 'ita', 'Ġis', 'Ġa', 'Ġgenus', 'Ġof', 'Ġmoth', 'Ġin', 'Ġthe', 'Ġfamily', 'ĠAr', 'ct', 'i', 'idae', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgenus', 'Ġconsists', 'Ġof', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠNep', 'ita', 'Ġconf', 'ert', 'a', ',', 'Ġwhich', 'Ġcan', 'Ġbe', 'Ġfound', 'Ġin', 'ĠIndia', 'Ġand', 'ĠSri', 'ĠLanka', '.', 'Ġ', '<s>', 'ĠThe', 'Ġspecies', 'Ġcommonly', 'Ġcalled', 'Ġfoot', 'man', 'Ġmoth', '.', '<p>', 'ĠP', 'are', 'ct', 'rop', 'is', 'Ġis', 'Ġa', 'Ġgenus', 'Ġin', 'Ġthe', 'Ġge', 'ometer', 'Ġmoth', 'Ġfamily', 'Ġ(', 'Ge', 'omet', 'rid', 'ae', ').', 'Ġ', '<s>', 'ĠA', 'Ġsmall', 'ĠOld', 'ĠWorld', 'Ġgenus', ',', 'Ġit', 'Ġcontains', 'Ġonly', 'Ġa', 'Ġgood', 'Ġdozen', 'Ġspecies', 'Ġaltogether', ',', 'Ġthough', 'Ġnew', 'Ġones', 'Ġare', 'Ġstill', 'Ġbeing', 'Ġdiscovered', '.', 'Ġ', '<s>', 'ĠOnly', 'Ġone', 'Ġspecies', 'Ġ(\"', 'P', '.', 'Ġsimilar', 'ia', '\")', 'Ġis', 'Ġfound', 'Ġin', 'ĠEurope', ';', 'Ġmost', 'Ġothers', 'Ġlive', 'Ġin', 'ĠAsia', 'Ġthough', 'Ġsome', 'Ġoccur', 'Ġin', 'ĠAfrica', '.', '<p>', 'ĠInd', 'ogram', 'm', 'odes', 'Ġis', 'Ġa', 'Ġgenus', 'Ġof', 'Ġm', 'oths', 'Ġof', 'Ġthe', 'ĠC', 'ram', 'bid', 'ae', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠInd', 'ogram', 'm', 'odes', 'Ġp', 'ect', 'inic', 'orn', 'alis', ',', 'Ġwhich', 'Ġis', 'Ġfound', 'Ġin', 'ĠIndia', '.', '<p>', 'ĠE', 'um', 'ac', 'aria', 'Ġis', 'Ġa', 'Ġgenus', 'Ġof', 'Ġmoth', 'Ġin', 'Ġthe', 'Ġfamily', 'ĠGe', 'omet', 'rid', 'ae', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠE', 'um', 'ac', 'aria', 'Ġmad', 'op', 'ata', ',', 'Ġthe', 'Ġbrown', '-', 'b', 'ordered', 'Ġge', 'ometer', 'Ġmoth', ',', 'Ġwhich', 'Ġis', 'Ġfound', 'Ġin', 'ĠNorth', 'ĠAmerica', ',', 'Ġwhere', 'Ġit', 'Ġhas', 'Ġbeen', 'Ġrecorded', 'Ġfrom', 'ĠBritish', 'ĠColumbia', ',', 'Ġnorthern', 'ĠWashington', ',', 'Ġsouthern', 'ĠSaskatchewan', ',', 'Ġfrom', 'ĠMaine', 'Ġto', 'ĠFlorida', ',', 'ĠSouth', 'ĠDakota', ',', 'ĠNorth', 'ĠDakota', ',', 'ĠNebraska', ',', 'ĠWyoming', ',', 'ĠIdaho', ',', 'ĠColorado', 'Ġand', 'ĠNew', 'ĠMexico', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhabitat', 'Ġconsists', 'Ġof', 'Ġor', 'ch', 'ards', 'Ġand', 'Ġshr', 'ub', 'lands', '.', '<p>', 'ĠN', 'ymph', 'ul', 'ie', 'lla', 'Ġis', 'Ġa', 'Ġgenus', 'Ġof', 'Ġmoth', 'Ġof', 'Ġthe', 'ĠC', 'ram', 'bid', 'ae', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontains', 'Ġonly', 'Ġone', 'Ġspecies', ',', 'ĠN', 'ymph', 'ul', 'ie', 'lla', 'Ġda', 'ec', 'ke', 'alis', ',', 'Ġthe', 'ĠChina', 'ĠMark', 'ĠM', 'oth', ',', 'Ġwhich', 'Ġis', 'Ġfound', 'Ġfrom', 'ĠNew', 'ĠJersey', 'Ġsouth', 'Ġto', 'ĠFlorida', 'Ġand', 'Ġwest', 'Ġto', 'ĠColorado', '.']\n",
      "lr:  tensor([4.8000e-06], device='cuda:0')\n",
      "question text:  In which American football game was Malcolm Smith named Most Valuable player?\n",
      "orig_answer_text:  Super Bowl XLVIII\n",
      "orig_answer_text:  Super Bowl XLVIII\n",
      "input:  ['<cls>', '<q>', 'What', 'Ġis', 'Ġthe', 'Ġlength', 'Ġof', 'Ġthe', 'Ġtrack', 'Ġwhere', 'Ġthe', 'Ġ2013', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġwas', 'Ġstaged', '?', '</q>', '<p>', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', 'Ġis', 'Ġa', 'Ġmotor', 'Ġracing', 'Ġtrack', 'Ġlocated', 'Ġin', 'ĠBath', 'urst', ',', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġsituated', 'Ġon', 'Ġa', 'Ġhill', 'Ġwith', 'Ġthe', 'Ġdual', 'Ġofficial', 'Ġnames', 'Ġof', 'ĠMount', 'ĠPan', 'orama', 'Ġand', 'ĠWah', 'lu', 'u', 'Ġand', 'Ġis', 'Ġbest', 'Ġknown', 'Ġas', 'Ġthe', 'Ġhome', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ1000', 'Ġmotor', 'Ġrace', 'Ġheld', 'Ġeach', 'ĠOctober', ',', 'Ġand', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġevent', 'Ġheld', 'Ġeach', 'ĠFebruary', '.', 'Ġ', '<s>', 'ĠThe', 'Ġ6', '.', '213', 'Ġkm', 'Ġlong', 'Ġtrack', 'Ġis', 'Ġtechnically', 'Ġa', 'Ġstreet', 'Ġcircuit', ',', 'Ġand', 'Ġis', 'Ġa', 'Ġpublic', 'Ġroad', ',', 'Ġwith', 'Ġnormal', 'Ġspeed', 'Ġrestrictions', ',', 'Ġwhen', 'Ġno', 'Ġracing', 'Ġevents', 'Ġare', 'Ġbeing', 'Ġrun', ',', 'Ġand', 'Ġthere', 'Ġare', 'Ġmany', 'Ġresidences', 'Ġwhich', 'Ġcan', 'Ġonly', 'Ġbe', 'Ġaccessed', 'Ġfrom', 'Ġthe', 'Ġcircuit', '.', '<p>', 'ĠThe', 'Ġ2016', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġseason', 'Ġof', 'Ġthe', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġfeatured', 'Ġthree', 'Ġrounds', 'Âł', 'âĢĶ', 'Ġafter', 'Ġthe', 'Ġcancellation', 'Ġof', 'Ġthe', 'Ġ6', 'ĠHours', 'Ġof', 'Ġthe', 'ĠAmericas', 'Ġ-', 'Ġstarting', 'Ġwith', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġon', 'Ġ7', 'ĠFebruary', 'Ġand', 'Ġthe', 'Ġseason', 'Ġconcluded', 'Ġwith', 'Ġthe', 'ĠSep', 'ang', 'Ġ12', 'ĠHours', 'Ġon', 'Ġ10', 'ĠDecember', '.', '<p>', 'ĠThe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġ(', 'currently', 'Ġknown', 'Ġas', 'Ġthe', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġfor', 'Ġsponsorship', 'Ġreasons', ')', 'Ġis', 'Ġan', 'Ġendurance', 'Ġrace', 'Ġfor', 'ĠGT', 'Ġand', 'Ġproduction', 'Ġcars', 'Ġheld', 'Ġat', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġin', 'ĠBath', 'urst', ',', 'ĠAustralia', 'Ġin', 'ĠFebruary', 'Ġeach', 'Ġyear', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrace', 'Ġwas', 'Ġfirst', 'Ġheld', 'Ġin', 'Ġ1991', 'Ġfor', 'ĠSeries', 'ĠProduction', 'Ġcars', 'Ġand', 'Ġmoved', 'Ġto', 'ĠSydney', \"'s\", 'ĠEastern', 'ĠCreek', 'ĠRac', 'eway', 'Ġin', 'Ġ1995', 'Ġbefore', 'Ġbeing', 'Ġdiscontinued', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrace', 'Ġwas', 'Ġrevived', 'Ġin', 'Ġ2007', ',', 'Ġagain', 'Ġfor', 'Ġproduction', 'Ġcars', ',', 'Ġbefore', 'Ġadding', 'Ġa', 'Ġnew', 'Ġclass', 'Ġfor', 'ĠGT', '3', 'Ġand', 'Ġother', 'ĠGT', 'Ġcars', 'Ġin', 'Ġ2011', '.', 'Ġ', '<s>', 'ĠThis', 'Ġhas', 'Ġled', 'Ġto', 'Ġunprecedented', 'Ġdomestic', 'Ġand', 'Ġinternational', 'Ġexposure', 'Ġfor', 'Ġthe', 'Ġevent', '.', 'Ġ', '<s>', 'ĠIn', 'Ġall', ',', 'Ġsixteen', 'Ġraces', 'Ġhave', 'Ġtaken', 'Ġplace', ';', 'Ġfifteen', 'Ġat', 'ĠMount', 'ĠPan', 'orama', 'Ġand', 'Ġone', 'Ġat', 'ĠEastern', 'ĠCreek', 'ĠRac', 'eway', '.', '<p>', 'ĠThe', 'Ġ2018', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', 'Ġwill', 'Ġbe', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġof', 'Ġthe', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġwill', 'Ġfeature', 'Ġfour', 'Ġrounds', ',', 'Ġstarting', 'Ġwith', 'Ġthe', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġon', 'Ġ4', 'ĠFebruary', ',', 'Ġand', 'Ġconcluding', 'Ġwith', 'Ġthe', 'ĠCalifornia', 'Ġ8', 'ĠHours', 'Ġon', 'Ġ21', 'ĠOctober', '.', '<p>', 'ĠThe', 'Ġ2016', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġwas', 'Ġan', 'Ġendurance', 'Ġrace', 'Ġfor', 'Ġa', 'Ġvariety', 'Ġof', 'ĠGT', 'Ġand', 'Ġtouring', 'Ġcar', 'Ġclasses', ',', 'Ġincluding', ':', 'ĠGT', '3', 'Ġcars', ',', 'ĠGT', '4', 'Ġcars', 'Ġand', 'ĠGroup', 'Ġ3', 'E', 'ĠSeries', 'ĠProduction', 'ĠCars', '.', 'Ġ', '<s>', 'ĠThe', 'Ġevent', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġnear', 'ĠBath', 'urst', ',', 'Ġin', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', 'Ġon', 'Ġ7', 'ĠFebruary', 'Ġ2016', ',', 'Ġwas', 'Ġthe', 'Ġfour', 'teenth', 'Ġrunning', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġalso', 'Ġthe', 'Ġopening', 'Ġround', 'Ġof', 'Ġthe', 'Ġ2016', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', 'ĠSeries', '.', '<p>', 'ĠThe', 'Ġ2017', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', 'Ġwill', 'Ġbe', 'Ġthe', 'Ġsecond', 'Ġseason', 'Ġof', 'Ġthe', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġfeatures', 'Ġfour', 'Ġrounds', ',', 'Ġstarting', 'Ġwith', 'Ġthe', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġon', 'Ġ5', 'ĠFebruary', ',', 'Ġand', 'Ġconcluding', 'Ġwith', 'Ġthe', 'ĠSep', 'ang', 'Ġ12', 'ĠHours', 'Ġon', 'Ġ10', 'ĠDecember', '.', 'Ġ', '<s>', 'ĠLaure', 'ns', 'ĠVan', 'th', 'oor', 'Ġis', 'Ġthe', 'Ġdefending', 'Ġdrivers', \"'\", 'Ġchampion', 'Ġand', 'ĠAudi', 'Ġis', 'Ġthe', 'Ġdefending', 'Ġmanufacturers', \"'\", 'Ġchampion', '.', '<p>', 'ĠThe', 'Ġ2013', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġwas', 'Ġan', 'Ġendurance', 'Ġrace', 'Ġfor', 'Ġa', 'Ġvariety', 'Ġof', 'ĠGT', 'Ġand', 'Ġtouring', 'Ġcar', 'Ġclasses', ',', 'Ġincluding', ':', 'ĠGT', '3', 'Ġcars', ',', 'ĠGT', '4', 'Ġcars', ',', 'ĠGroup', 'Ġ3', 'E', 'ĠSeries', 'ĠProduction', 'ĠCars', 'Ġand', 'ĠDubai', 'Ġ24', 'ĠHour', 'Ġcars', '.', 'Ġ', '<s>', 'ĠThe', 'Ġevent', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġnear', 'ĠBath', 'urst', ',', 'Ġin', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', 'Ġon', 'Ġ10', 'ĠFebruary', 'Ġ2013', ',', 'Ġwas', 'Ġthe', 'Ġele', 'venth', 'Ġrunning', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrace', 'Ġalso', 'Ġincorporated', 'Ġthe', 'Ġopening', 'Ġround', 'Ġof', 'Ġthe', 'Ġ2013', 'ĠAustralian', 'ĠGT', 'ĠChampionship', '.', 'Ġ', '<s>', 'ĠThe', 'ĠAustralian', 'ĠGT', 'ĠChampionship', 'Ġwas', 'Ġto', 'Ġcompete', 'Ġas', 'Ġthe', 'Ġfirst', 'Ġhour', 'Ġonly', 'Ġand', 'Ġcars', 'Ġwere', 'Ġpermitted', 'Ġto', 'Ġenter', 'Ġfor', 'Ġonly', 'Ġthat', 'Ġhour', 'Ġor', 'Ġto', 'Ġcross', '-', 'enter', 'Ġfor', 'Ġboth', 'Ġthe', 'Ġfirst', 'Ġhour', 'Ġand', 'Ġcontinue', 'Ġfor', 'Ġthe', 'Ġendurance', 'Ġrace', '.', '<p>', 'ĠThe', 'Ġ2015', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġwas', 'Ġan', 'Ġendurance', 'Ġrace', 'Ġfor', 'Ġa', 'Ġvariety', 'Ġof', 'ĠGT', 'Ġand', 'Ġtouring', 'Ġcar', 'Ġclasses', ',', 'Ġincluding', ':', 'ĠGT', '3', 'Ġcars', ',', 'ĠGT', '4', 'Ġcars', 'Ġand', 'ĠGroup', 'Ġ3', 'E', 'ĠSeries', 'ĠProduction', 'ĠCars', '.', 'Ġ', '<s>', 'ĠThe', 'Ġevent', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġnear', 'ĠBath', 'urst', ',', 'Ġin', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', 'Ġon', 'Ġ8', 'ĠFebruary', 'Ġ2015', ',', 'Ġwas', 'Ġthe', 'Ġth', 'ir', 'teenth', 'Ġrunning', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', '.', '<p>', 'ĠThe', 'Ġ2017', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġendurance', 'Ġrace', 'Ġfor', 'ĠGT', 'Ġand', 'Ġtouring', 'Ġcar', 'Ġclasses', ',', 'ĠGT', '3', 'Ġand', 'ĠGT', '4', 'Ġcars', 'Ġwas', 'Ġstaged', 'Ġon', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġnear', 'ĠBath', 'urst', ',', 'Ġin', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', 'Ġ5', 'ĠFebruary', 'Ġ2017', '.', 'Ġ', '<s>', 'ĠThe', 'Ġ15', 'th', 'Ġrunning', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġconstituted', 'Ġthe', 'Ġopening', 'Ġround', 'Ġof', 'Ġthe', 'Ġ2017', 'ĠInter', 'continental', 'ĠGT', 'ĠChallenge', 'ĠSeries', '.', 'Ġ', '<s>', 'ĠFor', 'Ġthe', 'Ġfirst', 'Ġtime', ',', 'Ġthe', 'Ġwinners', 'Ġof', 'Ġthe', 'Ġrace', 'Ġwere', 'Ġawarded', 'Ġthe', 'ĠAustralian', 'ĠTour', 'ist', 'ĠTrophy', '.', '<p>', 'ĠThe', 'Ġ2014', 'ĠLiqu', 'i', 'ĠM', 'oly', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', 'Ġwas', 'Ġan', 'Ġendurance', 'Ġrace', 'Ġfor', 'Ġa', 'Ġvariety', 'Ġof', 'ĠGT', 'Ġand', 'Ġtouring', 'Ġcar', 'Ġclasses', ',', 'Ġincluding', ':', 'ĠGT', '3', 'Ġcars', ',', 'ĠGT', '4', 'Ġcars', 'Ġand', 'ĠGroup', 'Ġ3', 'E', 'ĠSeries', 'ĠProduction', 'ĠCars', '.', 'Ġ', '<s>', 'ĠThe', 'Ġevent', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠMount', 'ĠPan', 'orama', 'ĠCircuit', ',', 'Ġnear', 'ĠBath', 'urst', ',', 'Ġin', 'ĠNew', 'ĠSouth', 'ĠWales', ',', 'ĠAustralia', 'Ġon', 'Ġ9', 'ĠFebruary', 'Ġ2014', ',', 'Ġwas', 'Ġthe', 'Ġtw', 'elfth', 'Ġrunning', 'Ġof', 'Ġthe', 'ĠBath', 'urst', 'Ġ12', 'ĠHour', '.']\n",
      "lr:  tensor([4.9000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  The 1988 American comedy film, The Great Outdoors, starred a four-time Academy Award nominee, who received a star on the Hollywood Walk of Fame in what year?\n",
      "orig_answer_text:  2006\n",
      "orig_answer_text:  2006\n",
      "input:  ['<cls>', '<q>', 'Fast', 'ĠCars', ',', 'ĠDanger', ',', 'ĠFire', 'Ġand', 'ĠKn', 'ives', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġfrom', 'Ġwhich', 'Ġhip', 'Ġhop', 'Ġrecord', 'Ġexecutive', '?', '</q>', '<p>', 'ĠLights', 'ĠOut', 'ĠParis', 'Ġis', 'Ġthe', 'Ġfirst', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġartist', 'ĠSims', ',', 'Ġa', 'Ġmember', 'Ġof', 'ĠMinneapolis', 'Ġindie', 'Ġhip', 'Ġhop', 'Ġcollective', 'ĠDoom', 'tree', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'ĠJuly', 'Ġ28', ',', 'Ġ2005', 'Ġon', 'ĠDoom', 'tree', 'ĠRecords', 'Ġand', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠP', '.', 'O', '.', 'S', ',', 'ĠCrescent', 'ĠMoon', ',', 'Ġand', 'ĠTok', 'i', 'ĠWright', ',', 'Ġamong', 'Ġothers', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġre', '-', 'released', 'Ġwith', 'Ġfour', 'Ġremix', 'es', 'Ġand', 'Ġfive', 'Ġsongs', 'Ġfrom', 'ĠSims', \"'\", 'Ġ\"', 'False', 'ĠHop', 'es', 'ĠFour', '\"', 'Ġon', 'Ġvinyl', 'Ġin', 'ĠJune', 'Ġ2015', '.', '<p>', 'ĠJaime', 'ĠM', 'eline', 'Ġ(', 'born', 'ĠMarch', 'Ġ2', ',', 'Ġ1975', '),', 'Ġbetter', 'Ġknown', 'Ġby', 'Ġhis', 'Ġstage', 'Ġname', 'ĠEl', '-', 'P', 'Ġ(', 'short', 'ened', 'Ġfrom', 'ĠEl', 'ĠProduct', 'o', '),', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġrecording', 'Ġartist', ',', 'Ġrecord', 'Ġproducer', ',', 'Ġand', 'Ġrecord', 'Ġexecutive', '.', 'Ġ', '<s>', 'ĠOriginally', 'Ġa', 'Ġmember', 'Ġof', 'ĠCompany', 'ĠFlow', ',', 'ĠEl', '-', 'P', 'Ġhas', 'Ġbeen', 'Ġa', 'Ġmajor', 'Ġdriving', 'Ġforce', 'Ġin', 'Ġalternative', 'Ġhip', 'Ġhop', 'Ġfor', 'Ġmore', 'Ġthan', 'Ġtwo', 'Ġdecades', ',', 'Ġproducing', 'Ġfor', 'Ġseveral', 'Ġnotable', 'Ġrappers', 'Ġsuch', 'Ġas', 'ĠA', 'es', 'op', 'ĠRock', ',', 'ĠMr', '.', 'ĠLif', ',', 'Ġand', 'ĠCage', ',', 'Ġamong', 'Ġothers', '.', '<p>', 'ĠBorn', 'Ġand', 'ĠRa', 'ised', 'Ġis', 'Ġthe', 'Ġdebut', 'ĠEP', 'Ġby', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġduo', 'ĠSm', 'if', '-', 'N', '-', 'W', 'ess', 'un', ',', 'Ġreleased', 'Ġon', 'ĠDecember', 'Ġ3', ',', 'Ġ2013', ',', 'Ġunder', 'ĠDuck', 'ĠDown', 'ĠMusic', 'ĠInc', '..', 'Ġ', '<s>', 'ĠEnt', 'ire', 'ly', 'Ġproduced', 'Ġby', 'ĠBeat', 'nick', 'Ġ&', 'ĠK', '-', 'S', 'ala', 'am', ',', 'Ġthe', 'Ġ6', '-', 'song', 'ĠEP', 'Ġis', 'Ġa', 'Ġblend', 'Ġbetween', 'Ġreg', 'gae', 'Ġand', 'Ġhip', 'Ġhop', ',', 'Ġand', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠJunior', 'ĠReid', ',', 'ĠJr', '.', 'Ġ', '<s>', 'ĠKelly', ',', 'ĠJah', 'dan', 'ĠBl', 'ak', 'k', 'amo', 'ore', ',', 'Ġand', 'ĠDJ', 'ĠFull', 'ĠFactor', '.', 'Ġ', '<s>', 'ĠThe', 'ĠEP', 'Ġwas', 'Ġpreceded', 'Ġby', 'Ġone', 'Ġsingle', 'ĠâĢĶ', 'Ġ\"', 'Solid', 'ĠGround', '\"', 'Ġfeaturing', 'Ġdance', 'hall', 'Ġicon', 'ĠJunior', 'ĠReid', '.', '<p>', 'ĠLord', 'ĠSte', 'pping', 'ton', 'Ġis', 'Ġthe', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠCalifornia', '-', 'based', 'Ġhip', 'Ġhop', 'Ġduo', 'ĠStep', 'ĠBrothers', 'Ġ(', 'ra', 'pper', '/', 'pro', 'ducers', 'ĠThe', 'ĠAlchemist', 'Ġand', 'ĠEvidence', ').', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠJanuary', 'Ġ21', ',', 'Ġ2014', 'Ġby', 'ĠRh', 'ymes', 'ayers', 'ĠEntertainment', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrecord', 'Ġwas', 'Ġproduced', 'Ġentirely', 'Ġby', 'ĠAlchemist', 'Ġand', 'ĠEvidence', ',', 'Ġand', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠAction', 'ĠBr', 'onson', ',', 'ĠRoc', 'ĠMarc', 'iano', ',', 'ĠBlu', ',', 'ĠF', 'ash', 'awn', ',', 'ĠRak', 'aa', ',', 'ĠOh', 'ĠNo', ',', 'ĠStyles', 'ĠP', ',', 'ĠDom', 'o', 'ĠGenesis', 'Ġand', 'ĠThe', 'ĠWh', 'ool', 'igan', 'z', 'ĠâĢĵ', 'ĠAlchemist', \"'s\", 'Ġold', 'Ġgroup', 'Ġwhich', 'Ġincluded', 'Ġactor', 'ĠScott', 'ĠCa', 'an', '.', '<p>', 'ĠControl', 'ĠFree', 'k', 'Ġis', 'Ġthe', 'Ġsecond', 'Ġsolo', 'Ġeffort', 'Ġby', 'Ġrapper', 'ĠT', 'ash', 'Ġof', 'Ġthe', 'ĠWest', 'ĠCoast', 'Ġhip', 'Ġhop', 'Ġcrew', 'ĠTh', 'a', 'ĠAl', 'k', 'ah', 'oli', 'ks', '.', 'Ġ', '<s>', 'ĠThis', 'Ġalbums', 'Ġcomes', 'Ġten', 'Ġyears', 'Ġafter', 'ĠT', 'ash', \"'s\", 'Ġfirst', 'Ġwell', '-', 'received', 'Ġsolo', 'Ġalbum', 'ĠRap', 'ĠLife', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġin', 'Ġ2009', 'Ġon', 'ĠAm', 'alg', 'am', 'ĠDigital', '.', 'Ġ', '<s>', 'ĠIt', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠT', 'ash', \"'s\", 'Ġgroup', 'ĠTh', 'a', 'ĠAl', 'k', 'ah', 'oli', 'ks', 'Ġin', 'Ġaddition', 'Ġto', 'Ġguest', 'Ġspots', 'Ġfrom', 'ĠDel', 'Ġthe', 'ĠFun', 'ky', 'ĠHom', 'os', 'ap', 'ien', ',', 'ĠKing', 'ĠT', ',', 'ĠB', '-', 'Real', 'Ġfrom', 'ĠCyp', 'ress', 'ĠHill', ',', 'ĠKn', 'oc', '-', 'turn', \"'\", 'al', ',', 'ĠKh', 'u', 'jo', 'Ġfrom', 'ĠGood', 'ie', 'ĠMob', ',', 'Ġamong', 'Ġothers', '.', '<p>', 'ĠHip', 'Ġhop', 'Ġor', 'Ġhip', '-', 'hop', 'Ġis', 'Ġa', 'Ġsub', 'culture', 'Ġand', 'Ġart', 'Ġmovement', 'Ġdeveloped', 'Ġin', 'ĠSouth', 'ĠBronx', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', 'Ġduring', 'Ġthe', 'Ġlate', 'Ġ1970', 's', '.', 'Ġ', '<s>', 'ĠWhile', 'Ġpeople', 'Ġunfamiliar', 'Ġwith', 'Ġhip', 'Ġhop', 'Ġculture', 'Ġoften', 'Ġuse', 'Ġthe', 'Ġexpression', 'Ġ\"', 'hip', 'Ġhop', '\"', 'Ġto', 'Ġrefer', 'Ġexclusively', 'Ġto', 'Ġhip', 'Ġhop', 'Ġmusic', 'Ġ(', 'also', 'Ġcalled', 'Ġ\"', 'rap', '\"),', 'ĠHip', 'Ġhop', 'Ġis', 'Ġcharacterized', 'Ġby', 'Ġnine', 'Ġdistinct', 'Ġelements', 'Ġor', 'Ġexpressive', 'Ġrealms', ',', 'Ġof', 'Ġwhich', 'Ġhip', 'Ġhop', 'Ġmusic', 'Ġis', 'Ġonly', 'Ġfour', 'Ġelements', 'Ġ(', 'ra', 'pping', ',', 'Ġdj', 'aying', ',', 'Ġbeat', 'boxing', 'Ġand', 'Ġbreaking', ').', 'Ġ', '<s>', 'ĠAf', 'rika', 'ĠB', 'amba', 'ata', 'a', 'Ġof', 'Ġthe', 'Ġhip', 'Ġhop', 'Ġcollective', 'ĠZ', 'ulu', 'ĠNation', 'Ġoutlined', 'Ġthe', 'Ġpillars', 'Ġof', 'Ġhip', 'Ġhop', 'Ġculture', ',', 'Ġco', 'ining', 'Ġthe', 'Ġterms', ':', 'Ġ\"', 'ra', 'pping', '\"', 'Ġ(', 'also', 'Ġcalled', 'ĠMC', 'ing', 'Ġor', 'Ġem', 'ce', 'e', 'ing', '),', 'Ġa', 'Ġrhyth', 'mic', 'Ġvocal', 'Ġrhy', 'ming', 'Ġstyle', 'Ġ(', 'or', 'ality', ');', 'ĠDJ', 'ing', 'Ġ(', 'and', 'Ġtur', 'nt', 'abl', 'ism', '),', 'Ġwhich', 'Ġis', 'Ġmaking', 'Ġmusic', 'Ġwith', 'Ġrecord', 'Ġplayers', 'Ġand', 'ĠDJ', 'Ġmix', 'ers', 'Ġ(', 'a', 'ural', '/', 'sound', 'Ġand', 'Ġmusic', 'Ġcreation', ');', 'Ġb', '-', 'boy', 'ing', '/', 'b', '-', 'g', 'irling', '/', 'break', 'd', 'ancing', 'Ġ(', 'move', 'ment', '/', 'd', 'ance', ');', 'Ġand', 'Ġgraffiti', 'Ġart', ',', 'Ġwhich', 'Ġhe', 'Ġcalled', 'Ġ\"', 'aer', 'os', 'ol', 'Ġwrit', 'in', \"'\", '\",', 'Ġalthough', 'Ġmany', 'Ġsay', 'Ġthat', 'Ġthe', 'Ġgraffiti', 'Ġthat', 'Ġhip', 'Ġhop', 'Ġadopted', 'Ġhad', 'Ġbeen', 'Ġaround', 'Ġyears', 'Ġearlier', ',', 'Ġand', 'Ġhad', 'Ġnothing', 'Ġto', 'Ġdo', 'Ġwith', 'Ġhip', 'Ġhop', 'Ġculture', '.', 'Ġ', '<s>', 'Ġ(', 'visual', 'Ġart', ').', 'Ġ', '<s>', 'ĠOther', 'Ġelements', 'Ġof', 'Ġhip', 'Ġhop', 'Ġsub', 'culture', 'Ġand', 'Ġarts', 'Ġmovements', 'Ġbeyond', 'Ġthe', 'Ġmain', 'Ġfour', 'Ġare', ':', 'Ġhip', 'Ġhop', 'Ġculture', 'Ġand', 'Ġhistorical', 'Ġknowledge', 'Ġof', 'Ġthe', 'Ġmovement', 'Ġ(', 'int', 'ellectual', '/', 'phil', 'os', 'ophical', ');', 'Ġbeat', 'boxing', ',', 'Ġa', 'Ġper', 'c', 'uss', 'ive', 'Ġvocal', 'Ġstyle', ';', 'Ġstreet', 'Ġentrepreneurship', ';', 'Ġhip', 'Ġhop', 'Ġlanguage', ';', 'Ġand', 'Ġhip', 'Ġhop', 'Ġfashion', 'Ġand', 'Ġstyle', ',', 'Ġamong', 'Ġothers', '.', '<p>', 'ĠFast', 'ĠCars', ',', 'ĠDanger', ',', 'ĠFire', 'Ġand', 'ĠKn', 'ives', 'Ġis', 'Ġan', 'ĠEP', 'Ġby', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġartist', 'ĠA', 'es', 'op', 'ĠRock', '.', 'Ġ', '<s>', 'ĠReleased', 'Ġvia', 'Ġthe', 'ĠDefinitive', 'ĠJ', 'ux', 'Ġlabel', 'Ġon', 'ĠFebruary', 'Ġ22', ',', 'Ġ2005', ',', 'Ġthe', 'Ġrecord', 'Ġis', 'Ġproduced', 'Ġby', 'ĠBlock', 'head', 'Ġand', 'ĠA', 'es', 'op', 'ĠRock', 'Ġhimself', ',', 'Ġwith', 'Ġthe', 'Ġformer', 'Ġproducing', 'Ġthree', 'Ġtracks', 'Ġand', 'Ġthe', 'Ġlatter', 'Ġproducing', 'Ġfour', ',', 'Ġwith', 'Ġone', 'Ġtrack', 'Ġproduced', 'Ġby', 'ĠRob', 'ĠSonic', '.', 'Ġ', '<s>', 'ĠVoc', 'als', 'Ġare', 'Ġhandled', 'Ġby', 'ĠA', 'es', 'op', 'ĠRock', ',', 'Ġwith', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠCam', 'u', 'ĠTao', 'Ġand', 'ĠMetro', 'Ġof', 'ĠS', '.', 'A', '.', 'ĠSmash', 'Ġand', 'ĠDefinitive', 'ĠJ', 'ux', 'Ġlabel', 'Ġhead', 'ĠEl', '-', 'P', '.', 'Ġ', '<s>', 'ĠAll', 'Ġscratches', 'Ġare', 'Ġperformed', 'Ġby', 'ĠDJ', 'ĠBig', 'ĠWiz', '.', '<p>', 'ĠLong', 'term', 'ĠMent', 'ality', 'Ġis', 'Ġthe', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġrecording', 'Ġartist', 'ĠAb', '-', 'Soul', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠApril', 'Ġ5', ',', 'Ġ2011', ',', 'Ġby', 'ĠTop', 'ĠDaw', 'g', 'ĠEntertainment', 'Ġ(', 'T', 'DE', '),', 'Ġexclusively', 'Ġto', 'Ġdigital', 'Ġretailers', ',', 'Ġserving', 'Ġas', 'ĠAb', '-', 'Soul', \"'s\", 'Ġdebut', 'Ġretail', 'Ġrelease', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġfeatures', 'Ġguest', 'Ġappearances', 'Ġfrom', 'ĠJ', 'hen', 'Ã©', 'ĠA', 'iko', ',', 'ĠSchool', 'boy', 'ĠQ', ',', 'ĠKendrick', 'ĠLamar', ',', 'ĠPunch', ',', 'ĠAl', 'ori', 'ĠJoh', ',', 'ĠJa', 'V', 'ont', 'Ã©', ',', 'ĠM', 'UR', 'S', ',', 'ĠBJ', 'Ġthe', 'ĠChicago', 'ĠKid', 'Ġand', 'ĠPat', 'ĠBrown', ',', 'Ġwith', 'Ġthe', 'Ġproduction', 'Ġfrom', 'ĠAmerican', 'Ġhip', 'Ġhop', 'Ġrecord', 'Ġproducers', 'Ġsuch', 'Ġas', 'ĠT', 'ae', 'ĠBeast', ',', 'ĠAy', 'iro', ',', 'ĠS', 'oun', 'wave', ',', 'ĠAA', 'y', 'has', 'is', ',', 'ĠContext', ',', 'ĠAlexis', 'ĠCar', 'rington', 'Ġand', 'ĠTommy', 'ĠBlack', '.', 'Ġ', '<s>', 'ĠUpon', 'Ġits', 'Ġrelease', ',', 'Ġthe', 'Ġalbum', 'Ġreceived', 'Ġa', 'Ġhighly', 'Ġacclaimed', 'Ġby', 'Ġmusic', 'Ġcritics', '.', '<p>', 'ĠExperimental', 'Ġhip', 'Ġhop', ',', 'Ġalso', 'Ġknown', 'Ġas', 'Ġabstract', 'Ġhip', 'Ġhop', ',', 'Ġis', 'Ġa', 'Ġgenre', 'Ġof', 'Ġhip', 'Ġhop', 'Ġthat', 'Ġemploys', 'Ġstructural', 'Ġelements', 'Ġtypically', 'Ġconsidered', 'Ġunconventional', 'Ġin', 'Ġtraditional', 'Ġhip', 'Ġhop', 'Ġmusic', '.', 'Ġ', '<s>', 'ĠSome', 'Ġnotable', 'Ġexperimental', 'Ġhip', 'Ġhop', 'Ġrecord', 'Ġlabels', 'Ġinclude', 'ĠDefinitive', 'ĠJ', 'ux', ',', 'ĠAnt', 'icon', ',', 'ĠBig', 'ĠD', 'ada', 'Ġand', 'ĠNinja', 'ĠTune', '.', 'Ġ', '<s>', 'ĠWhile', 'Ġmost', 'Ġexperimental', 'Ġhip', 'Ġhop', 'Ġincorporates', 'Ġtur', 'nt', 'abl', 'ism', 'Ġand', 'Ġis', 'Ġproduced', 'Ġelectronically', ',', 'Ġsome', 'Ġartists', 'Ġhave', 'Ġintroduced', 'Ġacoustic', 'Ġelements', 'Ġto', 'Ġthe', 'Ġmusic', 'Ġto', 'Ġfacilitate', 'Ġit', 'Ġbeing', 'Ġperformed', 'Ġlive', '.', '<p>', 'ĠChanges', 'Ġis', 'Ġthe', 'Ġthird', 'Ġalbum', 'Ġby', 'ĠSwedish', 'ĠA', 'OR', '/', 'rock', 'Ġband', 'ĠAly', 'son', 'ĠAvenue', 'Ġwith', 'Ġnew', 'Ġvocal', 'ist', 'ĠArab', 'ella', 'ĠVit', 'anc', '.', 'Ġ', '<s>', 'ĠAly', 'son', 'ĠAvenue', 'Ġreleased', 'Ġtheir', 'Ġthird', 'Ġalbum', 'Ġ\"', 'Changes', '\"', 'Ġthrough', 'ĠAvenue', 'Ġof', 'ĠAllies', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrecord', 'Ġwas', 'Ġco', '-', 'produced', 'Ġby', 'Ġband', 'Ġmembers', 'Ġand', 'ĠChris', 'ĠLane', 'y', 'Ġ(', 'C', 'razy', 'ĠL', 'ix', 'x', ',', 'ĠH', '.', 'E', '.', 'A', '.', 'T', '.,', 'ĠBrian', 'ĠRobertson', ')', 'Ġand', 'Ġincludes', 'Ġguest', 'Ġappearances', 'Ġby', 'ĠAn', 'ette', 'ĠOl', 'zon', 'Ġ(', 'Ex', '-', 'Night', 'w', 'ish', ',', 'ĠEx', '-', 'A', 'ly', 'son', 'ĠAvenue', '),', 'ĠMichael', 'ĠB', 'orm', 'ann', 'Ġ(', 'Ex', '-', 'J', 'aded', 'ĠHeart', ',', 'ĠChar', 'ade', ',', 'ĠB', 'ISS', '),', 'ĠRob', 'ĠMar', 'cell', 'o', 'Ġ(', 'D', 'anger', 'ĠDanger', ',', 'ĠMar', 'cell', 'o', 'Ġ-', 'ĠVest', 'ry', '),', 'ĠFred', 'rik', 'ĠBer', 'gh', ',', 'Ġ(', 'Street', 'ĠTalk', ',', 'ĠBlood', 'bound', '),', 'ĠTommy', 'ĠStr', 'Ã¥', 'h', 'le', 'Ġand', 'ĠMike', 'ĠAnders', 'son', 'Ġ(', 'Cloud', 'scape', ',', 'ĠPlanet', 'ĠAlliance', ').']\n",
      "lr:  tensor([4.9000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  The Oberoi family is part of a hotel company that has a head office in what city?\n",
      "orig_answer_text:  Delhi\n",
      "orig_answer_text:  Delhi\n",
      "input:  ['<cls>', '<q>', 'In', 'Ġwhich', 'ĠAmerican', 'Ġfootball', 'Ġgame', 'Ġwas', 'ĠMalcolm', 'ĠSmith', 'Ġnamed', 'ĠMost', 'ĠVal', 'uable', 'Ġplayer', '?', '</q>', '<p>', 'ĠWinston', 'ĠLag', 'oon', 'Ġ(', 'Ġ)', 'Ġis', 'Ġa', 'Ġlag', 'oon', 'Ġindent', 'ing', 'Ġthe', 'Ġsoutheast', 'Ġcoast', 'Ġof', 'ĠHeard', 'ĠIsland', 'Ġin', 'Ġthe', 'Ġsouthern', 'ĠIndian', 'ĠOcean', ',', 'Ġabout', 'Ġ1', 'Ġn', 'autical', 'Ġmile', 'Ġ(', '1', '.', '9', 'Âł', 'km', ')', 'Ġnortheast', 'Ġof', 'ĠCape', 'ĠLock', 'yer', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfeature', 'Ġis', 'Ġroughly', 'Ġportrayed', 'Ġon', 'Ġan', 'ĠAmerican', 'Ġseal', 'er', 'Ġchart', 'Ġof', 'Ġthe', 'Ġ1860', 'Ġperiod', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġsight', 'ed', 'Ġfrom', 'Ġthe', 'Ġair', 'Ġby', 'ĠLieutenant', 'ĠMalcolm', 'ĠSmith', ',', 'ĠR', 'AAF', ',', 'Ġpilot', 'Ġof', 'Ġthe', 'ĠAN', 'ARE', 'Ġ(', 'Australian', 'ĠNational', 'ĠAntarctic', 'ĠResearch', 'ĠExp', 'ed', 'itions', ')', 'Ġsea', 'plane', 'Ġthat', 'Ġmade', 'Ġthe', 'Ġfirst', 'Ġreconnaissance', 'Ġflight', 'Ġover', 'Ġthe', 'Ġisland', 'Ġin', 'Ġ1948', '.', 'Ġ', '<s>', 'ĠLieutenant', 'ĠSmith', 'Ġproposed', 'Ġthat', 'Ġit', 'Ġbe', 'Ġnamed', 'ĠLake', 'ĠWinston', 'Ġafter', 'Ġhis', 'Ġwife', '.', 'Ġ', '<s>', 'ĠIn', 'Ġview', 'Ġof', 'Ġhis', 'Ġdeath', 'Ġin', 'Ġan', 'Ġaircraft', 'Ġaccident', 'Ġshortly', 'Ġafterward', ',', 'Ġthis', 'Ġproposal', 'Ġwas', 'Ġadopted', 'Ġby', 'ĠAustralian', 'ĠAntarctic', 'ĠNames', 'Ġand', 'ĠMedals', 'ĠCommittee', 'Ġ(', 'AN', 'CA', ')', 'Ġwith', 'Ġonly', 'Ġa', 'Ġchange', 'Ġof', 'Ġgeneric', 'Ġterm', '.', 'Ġ', '<s>', 'ĠClick', 'Ġhere', 'Ġto', 'Ġsee', 'Ġa', 'Ġmap', 'Ġof', 'ĠHeard', 'ĠIsland', 'Ġand', 'ĠMcDonald', 'ĠIslands', ',', 'Ġincluding', 'Ġall', 'Ġmajor', 'Ġtop', 'ographical', 'Ġfeatures', '.', '<p>', 'ĠMalcolm', 'ĠXavier', 'ĠSmith', 'Ġ(', 'born', 'ĠJuly', 'Ġ5', ',', 'Ġ1989', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġfootball', 'Ġlinebacker', 'Ġfor', 'Ġthe', 'ĠSan', 'ĠFrancisco', 'Ġ49', 'ers', 'Ġof', 'Ġthe', 'ĠNational', 'ĠFootball', 'ĠLeague', 'Ġ(', 'NFL', ').', 'Ġ', '<s>', 'ĠSmith', 'Ġplayed', 'Ġcollege', 'Ġfootball', 'Ġat', 'ĠUSC', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġdrafted', 'Ġby', 'Ġthe', 'ĠSeattle', 'ĠSeahawks', 'Ġin', 'Ġthe', 'Ġseventh', 'Ġround', 'Ġof', 'Ġthe', 'Ġ2011', 'ĠNFL', 'ĠDraft', '.', 'Ġ', '<s>', 'ĠSmith', 'Ġwas', 'Ġnamed', 'Ġthe', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'ĠSuper', 'ĠBowl', 'ĠXL', 'V', 'III', 'Ġafter', 'Ġthey', 'Ġdefeated', 'Ġthe', 'ĠDenver', 'ĠBroncos', '.', '<p>', 'ĠSuper', 'ĠBowl', 'ĠXL', 'V', 'III', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġfootball', 'Ġgame', 'Ġbetween', 'Ġthe', 'ĠAmerican', 'ĠFootball', 'ĠConference', 'Ġ(', 'A', 'FC', ')', 'Ġchampion', 'ĠDenver', 'ĠBroncos', 'Ġand', 'ĠNational', 'ĠFootball', 'ĠConference', 'Ġ(', 'N', 'FC', ')', 'Ġchampion', 'ĠSeattle', 'ĠSeahawks', 'Ġto', 'Ġdecide', 'Ġthe', 'ĠNational', 'ĠFootball', 'ĠLeague', 'Ġ(', 'NFL', ')', 'Ġchampion', 'Ġfor', 'Ġthe', 'Ġ2013', 'Ġseason', '.', 'Ġ', '<s>', 'ĠThe', 'ĠSeahawks', 'Ġdefeated', 'Ġthe', 'ĠBroncos', 'Ġ43', 'âĢĵ', '8', ',', 'Ġthe', 'Ġlargest', 'Ġmargin', 'Ġof', 'Ġvictory', 'Ġfor', 'Ġan', 'Ġunderdog', 'Ġand', 'Ġtied', 'Ġfor', 'Ġthe', 'Ġthird', 'Ġlargest', 'Ġpoint', 'Ġdifferential', 'Ġoverall', 'Ġ(', '35', ')', 'Ġin', 'ĠSuper', 'ĠBowl', 'Ġhistory', 'Ġwith', 'ĠSuper', 'ĠBowl', 'ĠXX', 'VII', 'Ġ(', '1993', ').', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġtime', 'Ġthe', 'Ġwinning', 'Ġteam', 'Ġscored', 'Ġover', 'Ġ40', 'Ġpoints', ',', 'Ġwhile', 'Ġholding', 'Ġtheir', 'Ġopponent', 'Ġto', 'Ġunder', 'Ġ10', '.', 'Ġ', '<s>', 'ĠThis', 'Ġbecame', 'Ġthe', 'Ġfirst', 'ĠSuper', 'ĠBowl', 'Ġvictory', 'Ġfor', 'Ġthe', 'ĠSeahawks', 'Ġand', 'Ġthe', 'Ġfifth', 'ĠSuper', 'ĠBowl', 'Ġloss', 'Ġfor', 'Ġthe', 'ĠBroncos', ',', 'Ġthe', 'Ġmost', 'Ġof', 'Ġany', 'Ġteam', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġplayed', 'Ġon', 'ĠFebruary', 'Ġ2', ',', 'Ġ2014', ',', 'Ġat', 'ĠMet', 'Life', 'ĠStadium', 'Ġat', 'Ġthe', 'ĠMeadow', 'lands', 'ĠSports', 'ĠComplex', 'Ġin', 'ĠEast', 'ĠRutherford', ',', 'ĠNew', 'ĠJersey', ',', 'Ġthe', 'Ġfirst', 'ĠSuper', 'ĠBowl', 'Ġplayed', 'Ġoutdoors', 'Ġin', 'Ġa', 'Ġcold', '-', 'weather', 'Ġcity', 'Ġand', 'Ġthe', 'Ġfirst', 'ĠSuper', 'ĠBowl', 'Ġto', 'Ġbe', 'Ġplayed', 'Ġon', 'Ġa', 'ĠFebruary', 'Ġ2', '.', '<p>', 'ĠThe', 'Ġ2013', 'ĠNBA', 'ĠSummer', 'ĠLeague', 'Ġis', 'Ġa', 'Ġpro', 'Ġbasketball', 'Ġleague', 'Ġrun', 'Ġby', 'Ġthe', 'ĠNBA', 'Ġjust', 'Ġafter', 'Ġthe', 'Ġ2013', 'ĠNBA', 'Ġdraft', '.', 'Ġ', '<s>', 'ĠIt', 'Ġgives', 'Ġnewly', 'Ġdrafted', 'Ġplayers', 'Ġa', 'Ġchance', 'Ġto', 'Ġtest', 'Ġtheir', 'Ġskills', 'Ġagainst', 'Ġeach', 'Ġother', ',', 'Ġand', 'Ġto', 'Ġgive', 'Ġthem', 'Ġa', 'Ġfeel', 'Ġfor', 'Ġprofessional', 'Ġbasketball', '.', 'Ġ', '<s>', 'ĠAll', 'Ġ30', 'ĠNBA', 'Ġteams', 'Ġparticipated', ',', 'Ġalong', 'Ġwith', 'Ġthe', 'ĠD', '-', 'League', 'ĠSelect', '.', 'Ġ', '<s>', 'ĠThe', 'ĠMiami', 'ĠHeat', 'Ġwere', 'Ġthe', 'Ġonly', 'Ġteam', 'Ġto', 'Ġparticipate', 'Ġin', 'Ġboth', 'ĠSummer', 'ĠLe', 'agues', '.', 'Ġ', '<s>', 'ĠIt', 'Ġran', 'Ġfrom', 'ĠJuly', 'Ġ7', 'âĢĵ', '12', 'Ġin', 'ĠOrlando', 'Ġand', 'ĠJuly', 'Ġ12', 'âĢĵ', '22', 'Ġin', 'ĠLas', 'ĠVegas', '.', 'Ġ', '<s>', 'ĠJeremy', 'ĠLamb', 'Ġof', 'Ġthe', 'ĠOklahoma', 'ĠCity', 'ĠThunder', 'Ġwas', 'Ġnamed', 'Ġthe', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'Ġthe', 'ĠOrlando', 'ĠSummer', 'ĠLeague', '.', 'Ġ', '<s>', 'ĠJonas', 'ĠVal', 'an', 'Äį', 'i', 'Å«', 'nas', 'Ġof', 'Ġthe', 'ĠToronto', 'ĠRaptors', 'Ġwent', 'Ġon', 'Ġto', 'Ġbe', 'Ġnamed', 'Ġthe', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'Ġthe', 'ĠLas', 'ĠVegas', 'ĠSummer', 'ĠLeague', '.', 'Ġ', '<s>', 'ĠIan', 'ĠClark', 'Ġof', 'Ġthe', 'ĠGolden', 'ĠState', 'ĠWarriors', 'Ġwas', 'Ġnamed', 'Ġthe', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'Ġthe', 'ĠLas', 'ĠVegas', 'ĠSummer', 'ĠLeague', 'ĠChampionship', 'ĠGame', '.', '<p>', 'ĠStephen', 'ĠSp', 'ence', 'ĠClark', 'Ġ(', 'born', 'ĠAugust', 'Ġ2', ',', 'Ġ1960', ')', 'Ġis', 'Ġa', 'Ġformer', 'Ġprofessional', 'ĠAmerican', 'Ġfootball', 'Ġplayer', 'Ġwho', 'Ġplayed', 'Ġ[[', 'def', 'ensive', 'Ġtackle', ']', 'and', 'Ġoffensive', 'Ġguard', 'Ġ]', 'Ġfor', 'Ġfive', 'Ġseasons', 'Ġfor', 'Ġthe', 'Ġ[[', 'Miami', 'ĠDolphins', ']', '].', 'Ġ', '<s>', 'ĠHe', 'Ġalso', 'Ġplayed', 'Ġon', 'Ġtwo', 'Ġstate', 'Ġchampionship', 'Ġteams', 'Ġin', 'Ġhigh', 'Ġschool', 'Ġwhich', 'Ġwere', 'Ġa', 'Ġcombined', 'Ġ(', '25', '-', '1', ')', 'Ġover', 'Ġtwo', 'Ġyears', 'Ġand', 'Ġwas', 'Ġa', 'Ġfive', 'Ġteam', 'Ġall', '-', 'American', 'Ġincluding', 'Ġ\"', 'Par', 'ade', 'ĠMagazine', '\",', 'Ġhe', 'Ġwas', 'Ġalso', 'Ġnamed', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'Ġthe', 'Ġstate', 'Ġof', 'ĠUtah', '.', 'Ġ', '<s>', 'ĠAt', 'Ġthe', 'ĠUniversity', 'Ġof', 'ĠUtah', 'Ġhe', 'Ġwas', 'Ġnamed', 'Ġtwo', 'Ġtime', 'ĠAll', '-', 'W', 'AC', 'Ġdefensive', 'Ġtackle', ',', 'ĠDefensive', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġof', 'Ġthe', 'ĠWestern', 'ĠAthletic', 'ĠConference', 'Ġand', 'ĠFirst', 'ĠTeam', 'ĠAll', '-', 'American', '.', 'Ġ', '<s>', 'ĠHe', 'Ġalso', 'Ġplayed', 'Ġin', 'Ġthe', 'ĠEast', '-', 'West', 'ĠShrine', 'ĠGame', 'Ġand', 'Ġwas', 'Ġnamed', 'ĠMVP', 'Ġof', 'Ġthe', 'ĠSenior', 'ĠBowl', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġthe', 'ĠSenior', 'ĠBowl', 'Ġhe', 'Ġwas', 'Ġdrafted', 'Ġby', 'ĠDon', 'ĠSh', 'ula', 'Ġand', 'ĠThe', 'ĠMiami', 'ĠDolphins', ',', 'Ġhis', 'Ġsecond', 'Ġyear', 'Ġin', 'Ġthe', 'ĠNFL', 'Ġhe', 'Ġplayed', 'Ġboth', 'Ġways', 'Ġin', 'Ġa', 'Ġpre', '-', 'season', 'Ġgame', 'Ġand', 'ĠCoach', 'ĠSh', 'ula', 'Ġknew', 'Ġhe', 'Ġhad', 'Ġa', 'Ġguy', 'Ġthat', 'Ġcould', 'Ġback', 'Ġup', 'Ġevery', 'Ġposition', 'Ġon', 'Ġthe', 'Ġoffensive', 'Ġand', 'Ġdefensive', 'Ġline', 'Ġas', 'Ġwell', 'Ġas', 'Ġlong', 'Ġsnap', '.', 'Ġ', '<s>', 'ĠHe', 'Ġearned', 'Ġa', 'Ġstarting', 'Ġposition', 'Ġat', 'Ġright', 'Ġguard', 'Ġand', 'Ġplayed', 'Ġagainst', 'Ġ[[', 'William', 'ĠPerry', 'Ġ(', 'American', 'Ġfootball', ')|', 'the', 'ĠFr', 'idge', ']]', 'Ġwhen', 'Ġthe', 'ĠDolphins', 'Ġbeat', 'Ġthe', 'ĠChicago', 'ĠBears', 'Ġon', 'ĠMonday', 'ĠNight', 'ĠFootball', 'Ġto', 'Ġhelp', 'Ġkeep', 'Ġthe', 'Ġundefeated', 'ĠDolphin', 'Ġrecord', 'Ġintact', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'ĠNFL', ',', 'Ġhe', 'Ġalso', 'Ġplayed', 'Ġon', 'Ġtwo', 'ĠSuper', 'ĠBowl', 'Ġteams', 'Ġwith', 'Ġthe', 'ĠMiami', 'ĠDolphins', 'Ġand', 'Ġwas', 'Ġthe', 'Ġstarting', 'Ġright', 'Ġguard', 'Ġbefore', 'Ġbeing', 'Ġinjured', '.', 'Ġ', '<s>', 'ĠJust', 'Ġrecently', 'ĠSteve', 'Ġwas', 'Ġnamed', 'Ġto', 'Ġthe', 'Ġtop', 'Ġ100', 'Ġgreatest', 'Ġplayers', 'Ġin', 'Ġthe', 'Ġhistory', 'Ġof', 'Ġthe', 'ĠUniversity', 'Ġof', 'ĠUtah', 'Ġactually', 'Ġbeing', 'Ġnamed', 'Ġ9', 'th', 'Ġbest', 'Ġof', 'ĠAll', '-', 'Time', '.', '<p>', 'ĠThe', 'Ġ1959', 'ĠIllinois', 'ĠFighting', 'ĠIll', 'ini', 'Ġfootball', 'Ġteam', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġfootball', 'Ġteam', 'Ġthat', 'Ġrepresented', 'Ġthe', 'ĠUniversity', 'Ġof', 'ĠIllinois', 'Ġduring', 'Ġthe', 'Ġ1959', 'ĠBig', 'ĠTen', 'ĠConference', 'Ġfootball', 'Ġseason', '.', 'Ġ', '<s>', 'ĠIn', 'Ġtheir', 'Ġ18', 'th', 'Ġyear', 'Ġunder', 'Ġhead', 'Ġcoach', 'ĠRay', 'ĠEliot', ',', 'Ġthe', 'ĠIll', 'ini', 'Ġcompiled', 'Ġa', 'Ġ5', 'âĢĵ', '3', 'âĢĵ', '1', 'Ġrecord', 'Ġand', 'Ġfinished', 'Ġin', 'Ġa', 'Ġtie', 'Ġfor', 'Ġthird', 'Ġplace', 'Ġin', 'Ġthe', 'ĠBig', 'ĠTen', 'ĠConference', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġthe', 'Ġseason', ',', 'Ġguard', 'ĠBill', 'ĠBur', 'rell', 'Ġwas', 'Ġselected', 'Ġas', 'Ġthe', 'Ġteam', \"'s\", 'Ġmost', 'Ġvaluable', 'Ġplayer', 'Ġand', 'Ġalso', 'Ġreceived', 'Ġthe', 'ĠChicago', 'ĠTribune', 'ĠSilver', 'ĠFootball', 'Ġtrophy', 'Ġas', 'Ġthe', 'ĠBig', 'ĠTen', \"'s\", 'Ġmost', 'Ġvaluable', 'Ġplayer', '.', '<p>', 'ĠThe', 'Ġ103', 'rd', 'ĠGrey', 'ĠCup', 'Ġwas', 'Ġa', 'ĠCanadian', 'Ġfootball', 'Ġgame', 'Ġthat', 'Ġwas', 'Ġplayed', 'Ġon', 'ĠNovember', 'Ġ29', ',', 'Ġ2015', 'Ġbetween', 'Ġthe', 'ĠEast', 'ĠDivision', 'Ġchampion', 'ĠOttawa', 'ĠRed', 'bl', 'acks', 'Ġand', 'Ġthe', 'ĠWest', 'ĠDivision', 'Ġchampion', 'ĠEdmonton', 'ĠEsk', 'im', 'os', 'Ġto', 'Ġdecide', 'Ġthe', 'ĠCanadian', 'ĠFootball', 'ĠLeague', 'Ġ(', 'C', 'FL', ')', 'Ġchampionship', 'Ġfor', 'Ġthe', 'Ġ2015', 'Ġseason', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġplayed', 'Ġat', 'ĠInvestors', 'ĠGroup', 'ĠField', 'Ġin', 'ĠWinnipeg', ',', 'ĠManitoba', '.', 'Ġ', '<s>', 'ĠShaw', 'ĠCommunications', 'Ġwas', 'Ġthe', 'Ġpresenting', 'Ġsponsor', 'Ġof', 'Ġthe', 'Ġgame', ';', 'Ġit', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġtime', 'Ġin', 'ĠCFL', 'Ġhistory', 'Ġthat', 'Ġthe', 'ĠGrey', 'ĠCup', 'Ġhas', 'Ġbeen', 'Ġsponsored', '.', 'Ġ', '<s>', 'ĠThe', 'ĠEsk', 'im', 'os', 'Ġwon', 'Ġthe', 'Ġcontest', 'Ġ26', 'âĢĵ', '20', 'Ġto', 'Ġclaim', 'Ġtheir', 'Ġ14', 'th', 'ĠGrey', 'ĠCup', 'Ġchampionship', 'Ġin', 'Ġfranchise', 'Ġhistory', 'Ġand', 'Ġfirst', 'Ġsince', 'Ġ2005', '.', 'Ġ', '<s>', 'ĠMike', 'ĠReilly', 'Ġwas', 'Ġnamed', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'Ġand', 'ĠSham', 'aw', 'd', 'ĠChambers', 'Ġreceived', 'Ġthe', 'ĠDick', 'ĠSud', 'erman', 'ĠTrophy', 'Ġas', 'ĠMost', 'ĠVal', 'uable', 'ĠCanadian', '.', '<p>', 'ĠRichard', 'ĠMalcolm', 'ĠSmith', 'Ġ(', 'born', 'Ġ6', 'ĠJune', 'Ġ1973', ')', 'Ġis', 'Ġa', 'Ġformer', 'Ġrugby', 'Ġunion', 'Ġplayer', 'Ġwho', 'Ġplayed', 'Ġscr', 'um', '-', 'half', 'Ġfor', 'ĠE', 'bb', 'w', 'ĠVale', 'ĠRFC', ',', 'ĠSale', 'ĠSharks', ',', 'ĠWorcester', 'ĠWarriors', ',', 'ĠNewport', 'ĠRFC', ',', 'ĠBristol', 'ĠRugby', ',', 'ĠCardiff', 'ĠRFC', ',', 'ĠNew', 'bridge', 'ĠRFC', ',', 'ĠMer', 'th', 'yr', 'ĠRFC', 'Ġand', 'ĠCardiff', 'ĠBlues', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġa', 'Ġregular', 'Ġin', 'Ġthe', 'ĠWales', 'Ġ22', 'Ġbut', 'Ġonly', 'Ġgained', 'Ġone', 'ĠWales', 'Ġcap', 'Ġas', 'Ġhe', 'Ġwas', 'Ġbeing', 'Ġoverlooked', 'Ġfor', 'ĠRobert', 'ĠHow', 'ley', 'Ġand', 'ĠRupert', 'ĠMoon', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġwell', 'Ġknown', 'Ġfor', 'Ġusing', 'Ġthe', 'Ġbox', 'Ġkick', 'Ġto', 'Ġrelieve', 'Ġthe', 'Ġpressure', 'Ġposed', 'Ġby', 'Ġthe', 'Ġopposition', 'Ġand', 'Ġto', 'Ġalso', 'Ġgain', 'Ġterritory', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġa', 'Ġvery', 'Ġsk', 'il', 'ful', ',', 'Ġtechnical', 'Ġand', 'Ġintelligent', 'Ġrugby', 'Ġplayer', 'Ġwith', 'Ġexcellent', 'Ġgame', 'Ġmanagement', '.', '<p>', 'ĠKevin', 'ĠWayne', 'ĠDurant', 'Ġ(', 'born', 'ĠSeptember', 'Ġ29', ',', 'Ġ1988', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġprofessional', 'Ġbasketball', 'Ġplayer', 'Ġfor', 'Ġthe', 'ĠGolden', 'ĠState', 'ĠWarriors', 'Ġof', 'Ġthe', 'ĠNational', 'ĠBasketball', 'ĠAssociation', 'Ġ(', 'NBA', ').', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġwon', 'Ġan', 'ĠNBA', 'Ġchampionship', ',', 'Ġan', 'ĠNBA', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'ĠAward', ',', 'Ġthe', 'ĠBill', 'ĠRussell', 'ĠNBA', 'ĠFinals', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'ĠAward', ',', 'Ġthe', 'ĠNBA', 'ĠAll', '-', 'Star', 'ĠGame', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'ĠAward', ',', 'Ġfour', 'ĠNBA', 'Ġscoring', 'Ġtitles', ',', 'Ġthe', 'ĠNBA', 'ĠRookie', 'Ġof', 'Ġthe', 'ĠYear', 'ĠAward', ',', 'Ġand', 'Ġtwo', 'ĠOlympic', 'Ġgold', 'Ġmedals', '.', 'Ġ', '<s>', 'ĠDurant', 'Ġhas', 'Ġalso', 'Ġbeen', 'Ġselected', 'Ġto', 'Ġseven', 'ĠAll', '-', 'NBA', 'Ġteams', 'Ġand', 'Ġeight', 'ĠNBA', 'ĠAll', '-', 'Star', 'Ġteams', '.', '<p>', 'ĠThe', 'ĠSuper', 'ĠBowl', 'ĠMost', 'ĠVal', 'uable', 'ĠPlayer', 'ĠAward', ',', 'Ġor', 'ĠSuper', 'ĠBowl', 'ĠMVP', ',', 'Ġis', 'Ġpresented', 'Ġannually', 'Ġto', 'Ġthe', 'Ġmost', 'Ġvaluable', 'Ġplayer', 'Ġof', 'Ġthe', 'ĠSuper', 'ĠBowl', ',', 'Ġthe', 'ĠNational', 'ĠFootball', 'ĠLeague', \"'s\", 'Ġ(', 'NFL', ')', 'Ġchampionship', 'Ġgame', '.', 'Ġ', '<s>', 'ĠThe', 'Ġwinner', 'Ġis', 'Ġchosen', 'Ġby', 'Ġa', 'Ġfan', 'Ġvote', 'Ġduring', 'Ġthe', 'Ġgame', 'Ġand', 'Ġby', 'Ġa', 'Ġpanel', 'Ġof', 'Ġ16', 'Ġfootball', 'Ġwriters', 'Ġand', 'Ġbroadcasters', 'Ġwho', 'Ġvote', 'Ġafter', 'Ġthe', 'Ġgame', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmedia', 'Ġpanel', \"'s\", 'Ġballots', 'Ġcount', 'Ġfor', 'Ġ80', 'Âł', 'percent', 'Ġof', 'Ġthe', 'Ġvote', 'Ġtally', ',', 'Ġwhile', 'Ġthe', 'Ġviewers', \"'\", 'Ġballots', 'Ġmake', 'Ġup', 'Ġthe', 'Ġother', 'Ġ20', 'Âł', 'percent', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', \"'s\", 'Ġviewing', 'Ġaudience', 'Ġcan', 'Ġvote', 'Ġon', 'Ġthe', 'ĠInternet', 'Ġor', 'Ġby', 'Ġusing', 'Ġcellular', 'Ġphones', ';', 'ĠSuper', 'ĠBowl', 'ĠXXX', 'V', ',', 'Ġheld', 'Ġin', 'Ġ2001', ',', 'Ġwas', 'Ġthe', 'Ġfirst', 'ĠSuper', 'ĠBowl', 'Ġwith', 'Ġfan', 'Ġvoting', '.']\n",
      "lr:  tensor([5.0000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:   What nationality was James Henry Miller's wife?\n",
      "orig_answer_text:  American\n",
      "input:  ['<cls>', '<q>', 'The', 'Ġ1988', 'ĠAmerican', 'Ġcomedy', 'Ġfilm', ',', 'ĠThe', 'ĠGreat', 'ĠOut', 'doors', ',', 'Ġstarred', 'Ġa', 'Ġfour', '-', 'time', 'ĠAcademy', 'ĠAward', 'Ġnominee', ',', 'Ġwho', 'Ġreceived', 'Ġa', 'Ġstar', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġin', 'Ġwhat', 'Ġyear', '?', '</q>', '<p>', 'ĠShane', 'ĠStanley', 'Ġ(', 'born', 'ĠJune', 'Ġ15', ',', 'Ġ1971', 'Ġin', 'ĠLos', 'ĠAngeles', ')', 'Ġis', 'Ġa', 'Ġmulti', '-', 'Em', 'my', 'ĠAward', '-', 'winning', 'Ġfilmmaker', 'Ġand', 'Ġfounder', 'Ġof', 'ĠVisual', 'ĠArts', 'ĠEntertainment', ',', 'Ġa', 'Ġfilm', 'Ġand', 'Ġtelevision', 'Ġproduction', 'Ġcompany', 'Ġbased', 'Ġin', 'ĠLos', 'ĠAngeles', '.', 'Ġ', '<s>', 'ĠBest', 'Ġknown', 'Ġfor', 'Ġexecutive', 'Ġproducing', 'Ġ\"', 'Grid', 'iron', 'ĠGang', '\"', 'Ġstarring', 'ĠD', 'wayne', 'Ġ\"', 'The', 'ĠRock', '\"', 'ĠJohnson', 'Ġfor', 'ĠSony', 'ĠPictures', 'Ġand', 'Ġdirecting', 'ĠBret', 'ĠMichaels', 'Ġmusic', 'Ġvideos', 'Ġsupporting', 'Ġthe', 'Ġhit', 'Ġshow', 'Ġ\"', 'Rock', 'Ġof', 'ĠLove', '\".', 'Ġ', '<s>', 'ĠStanley', ',', 'Ġa', 'Ġfour', '-', 'time', 'Ġnominee', ',', 'Ġwas', 'Ġthe', 'Ġyoungest', 'Ġto', 'Ġever', 'Ġwin', 'Ġa', 'Ġproduction', 'ĠEmmy', 'ĠAward', ',', 'Ġwinning', 'Ġhis', 'Ġfirst', 'Ġat', 'Ġsixteen', 'Ġand', 'Ġhis', 'Ġsecond', 'Ġat', 'Ġnineteen', 'Ġfor', 'Ġhis', 'Ġwork', 'Ġon', 'ĠThe', 'ĠDes', 'perate', 'ĠPassage', 'ĠSeries', '.', 'Ġ', '<s>', 'ĠStanley', 'Ġmade', 'Ġhis', 'Ġdirector', 'ial', 'Ġdebut', 'Ġhel', 'ming', 'Ġhis', 'Ġown', 'Ġscreenplay', 'Ġ\"', 'A', 'ĠSight', 'Ġfor', 'ĠS', 'ore', 'ĠEyes', '\"', 'Ġwhich', 'Ġstarred', 'ĠAcademy', 'ĠAward', 'Ġnominee', 'ĠGary', 'ĠB', 'use', 'y', '.', 'Ġ', '<s>', 'ĠBesides', 'Ġbeing', 'Ġhonored', 'Ġwith', 'Ġdozens', 'Ġof', 'Ġprestigious', 'Ġawards', 'Ġand', 'Ġfilm', 'Ġfestival', 'Ġhonors', ',', 'Ġthe', 'Ġfilm', 'Ġwas', 'Ġinvited', 'Ġto', 'Ġscreen', 'Ġat', 'Ġthe', 'ĠCannes', 'ĠFilm', 'ĠFestival', 'Ġin', 'Ġ2005', 'Ġand', 'Ġwon', 'ĠBest', 'ĠDrama', 'Ġat', 'Ġthe', 'ĠInternational', 'ĠFamily', 'ĠFilm', 'ĠFestival', 'Ġin', 'Ġ2006', '.', '<p>', 'ĠCharles', 'ĠClarence', 'ĠRobert', 'ĠOr', 'ville', 'ĠCummings', ',', 'Ġknown', 'Ġas', 'ĠBob', 'ĠCummings', 'Ġ(', 'June', 'Ġ9', ',', 'Ġ1910', 'ĠâĢĵ', 'ĠDecember', 'Ġ2', ',', 'Ġ1990', '),', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġfilm', 'Ġand', 'Ġtelevision', 'Ġactor', 'Ġknown', 'Ġmainly', 'Ġfor', 'Ġhis', 'Ġroles', 'Ġin', 'Ġcomedy', 'Ġfilms', 'Ġsuch', 'Ġas', 'Ġ\"', 'The', 'ĠDevil', 'Ġand', 'ĠMiss', 'ĠJones', '\"', 'Ġ(', '19', '41', ')', 'Ġand', 'Ġ\"', 'Prin', 'cess', 'ĠO', \"'\", 'R', 'ourke', '\"', 'Ġ(', '19', '43', '),', 'Ġbut', 'Ġwas', 'Ġalso', 'Ġeffective', 'Ġin', 'Ġdramatic', 'Ġfilms', ',', 'Ġespecially', 'Ġtwo', 'Ġof', 'ĠAlfred', 'ĠHitchcock', \"'s\", 'Ġthrill', 'ers', ',', 'Ġ\"', 'Sab', 'ote', 'ur', '\"', 'Ġ(', '19', '42', ')', 'Ġand', 'Ġ\"', 'Dial', 'ĠM', 'Ġfor', 'ĠMurder', '\"', 'Ġ(', '19', '54', ').', 'Ġ', '<s>', 'ĠCummings', 'Ġreceived', 'Ġfive', 'ĠPrim', 'etime', 'ĠEmmy', 'ĠAward', 'Ġnominations', ',', 'Ġand', 'Ġwon', 'Ġthe', 'ĠPrim', 'etime', 'ĠEmmy', 'ĠAward', 'Ġfor', 'ĠBest', 'ĠActor', 'Ġin', 'Ġa', 'ĠSingle', 'ĠPerformance', 'Ġin', 'Ġ1955', '.', 'Ġ', '<s>', 'ĠOn', 'ĠFebruary', 'Ġ8', ',', 'Ġ1960', ',', 'Ġhe', 'Ġreceived', 'Ġtwo', 'Ġstars', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġfor', 'Ġhis', 'Ġcontributions', 'Ġto', 'Ġthe', 'Ġmotion', 'Ġpicture', 'Ġand', 'Ġtelevision', 'Ġindustries', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmotion', 'Ġpicture', 'Ġstar', 'Ġis', 'Ġat', 'Ġ68', '16', 'ĠHollywood', 'ĠBoulevard', ',', 'Ġthe', 'Ġtelevision', 'Ġstar', 'Ġis', 'Ġon', 'Ġ17', '18', 'ĠVine', 'ĠStreet', '.', '<p>', 'ĠLloyd', 'ĠVern', 'et', 'Ġ\"', 'Be', 'au', '\"', 'ĠBridges', 'ĠIII', 'Ġ(', 'born', 'ĠDecember', 'Ġ9', ',', 'Ġ1941', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactor', 'Ġand', 'Ġdirector', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'Ġthree', '-', 'time', 'ĠEmmy', ',', 'Ġtwo', '-', 'time', 'ĠGolden', 'ĠGlobe', 'Ġand', 'Ġone', '-', 'time', 'ĠGrammy', 'ĠAward', 'Ġwinner', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġalso', 'Ġa', 'Ġtwo', '-', 'time', 'ĠScreen', 'ĠAct', 'ors', 'ĠGuild', 'ĠAward', 'Ġnominee', '.', 'Ġ', '<s>', 'ĠBridges', 'Ġwas', 'Ġawarded', 'Ġa', 'Ġstar', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġon', 'ĠApril', 'Ġ7', ',', 'Ġ2003', 'Ġat', 'Ġ70', '65', 'ĠHollywood', 'ĠBoulevard', 'Ġfor', 'Ġhis', 'Ġcontributions', 'Ġto', 'Ġthe', 'Ġtelevision', 'Ġindustry', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġthe', 'Ġson', 'Ġof', 'Ġactor', 'ĠLloyd', 'ĠBridges', 'Ġand', 'Ġelder', 'Ġbrother', 'Ġof', 'Ġfellow', 'Ġactor', 'ĠJeff', 'ĠBridges', '.', '<p>', 'ĠAn', 'nette', 'ĠCarol', 'ĠB', 'ening', 'Ġ(', 'born', 'ĠMay', 'Ġ29', ',', 'Ġ1958', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactress', '.', 'Ġ', '<s>', 'ĠShe', 'Ġbegan', 'Ġher', 'Ġcareer', 'Ġon', 'Ġstage', 'Ġwith', 'Ġthe', 'ĠColorado', 'ĠShakespeare', 'ĠFestival', 'Ġcompany', 'Ġin', 'Ġ1980', ',', 'Ġand', 'Ġplayed', 'ĠLady', 'ĠMac', 'b', 'eth', 'Ġin', 'Ġ1984', 'Ġat', 'Ġthe', 'ĠAmerican', 'ĠConserv', 'atory', 'ĠTheatre', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġnominated', 'Ġfor', 'Ġthe', 'Ġ1987', 'ĠTony', 'ĠAward', 'Ġfor', 'ĠBest', 'ĠFeatured', 'ĠActress', 'Ġin', 'Ġa', 'ĠPlay', 'Ġfor', 'Ġher', 'ĠBroadway', 'Ġdebut', 'Ġin', 'Ġ\"', 'Co', 'ast', 'al', 'ĠDist', 'urb', 'ances', '\".', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġa', 'Ġfour', '-', 'time', 'ĠAcademy', 'ĠAward', 'Ġnominee', ';', 'Ġfor', 'Ġ\"', 'The', 'ĠGr', 'if', 'ters', '\"', 'Ġ(', '1990', '),', 'Ġ\"', 'American', 'ĠBeauty', '\"', 'Ġ(', '1999', '),', 'Ġ\"', 'Being', 'ĠJulia', '\"', 'Ġ(', '2004', ')', 'Ġand', 'Ġ\"', 'The', 'ĠKids', 'ĠAre', 'ĠAll', 'ĠRight', '\"', 'Ġ(', '2010', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ2006', ',', 'Ġshe', 'Ġreceived', 'Ġa', 'Ġstar', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', '.', '<p>', 'ĠFar', 'rah', 'ĠFaw', 'c', 'ett', 'Ġ(', 'born', 'ĠFer', 'rah', 'ĠLen', 'i', 'ĠFaw', 'c', 'ett', ';', 'ĠFebruary', 'Ġ2', ',', 'Ġ1947', 'ĠâĢĵ', 'ĠJune', 'Ġ25', ',', 'Ġ2009', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġactress', ',', 'Ġmodel', ',', 'Ġand', 'Ġartist', '.', 'Ġ', '<s>', 'ĠA', 'Ġfour', '-', 'time', 'ĠEmmy', 'ĠAward', 'Ġnominee', 'Ġand', 'Ġsix', '-', 'time', 'ĠGolden', 'ĠGlobe', 'ĠAward', 'Ġnominee', ',', 'ĠFaw', 'c', 'ett', 'Ġrose', 'Ġto', 'Ġinternational', 'Ġfame', 'Ġwhen', 'Ġshe', 'Ġposed', 'Ġfor', 'Ġher', 'Ġiconic', 'Ġred', 'Ġswim', 'suit', 'Ġposter', 'ĠâĢĵ', 'Ġwhich', 'Ġbecame', 'Ġthe', 'Ġbest', 'Ġselling', 'Ġpin', '-', 'up', 'Ġposter', 'Ġin', 'Ġhistory', 'ĠâĢĵ', 'Ġand', 'Ġstarred', 'Ġas', 'Ġprivate', 'Ġinvestigator', 'ĠJill', 'ĠMun', 'roe', 'Ġin', 'Ġthe', 'Ġfirst', 'Ġseason', 'Ġof', 'Ġthe', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Charlie', \"'s\", 'ĠAngels', '\"', 'Ġ(', '1976', 'âĢĵ', '1977', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ1996', ',', 'Ġshe', 'Ġwas', 'Ġranked', 'ĠNo', '.', 'Ġ26', 'Ġon', 'Ġ\"', 'TV', 'ĠGuide', '\"\\'', 's', 'Ġ\"', '50', 'ĠGreatest', 'ĠTV', 'Ġstars', 'Ġof', 'ĠAll', '-', 'Time', '\".', '<p>', 'ĠThe', 'Ġfollowing', 'Ġis', 'Ġa', 'Ġlist', 'Ġof', 'Ġthe', 'Ġstars', \"'\", 'Ġactual', 'Ġlocations', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlist', 'Ġdoes', 'Ġnot', 'Ġinclude', 'Ġa', 'Ġstar', \"'s\", 'Ġname', 'Ġuntil', 'Ġhis', 'Ġor', 'Ġher', 'Ġactual', 'Ġaward', 'Ġceremony', ',', 'Ġas', 'Ġon', 'Ġmultiple', 'Ġoccasions', 'Ġand', 'Ġfor', 'Ġvarious', 'Ġreasons', 'Ġstars', 'Ġhave', 'Ġbeen', 'Ġwithdrawn', 'Ġprior', 'Ġto', 'Ġthe', 'Ġaward', 'Ġceremony', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlist', 'Ġshould', 'Ġbe', 'Ġconsistent', 'Ġwith', 'Ġthe', 'Ġlist', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġwebsite', 'Ġmaintained', 'Ġby', 'Ġthe', 'ĠHollywood', 'ĠChamber', 'Ġof', 'ĠCommerce', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstars', 'Ġare', 'Ġordered', 'Ġalphabet', 'ically', 'Ġby', 'Ġsurname', '.', '<p>', 'ĠKevin', 'ĠNor', 'wood', 'ĠBacon', 'Ġ(', 'born', 'ĠJuly', 'Ġ8', ',', 'Ġ1958', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactor', 'Ġand', 'Ġmusician', '.', 'Ġ', '<s>', 'ĠHis', 'Ġnotable', 'Ġfilms', 'Ġinclude', 'Ġmusical', '-', 'd', 'rama', 'Ġfilm', 'Ġ\"', 'Foot', 'lo', 'ose', '\"', 'Ġ(', '1984', '),', 'Ġthe', 'Ġcontroversial', 'Ġhistorical', 'Ġconspiracy', 'Ġlegal', 'Ġthriller', 'Ġ\"', 'J', 'FK', '\"', 'Ġ(', '1991', '),', 'Ġthe', 'Ġlegal', 'Ġdrama', 'Ġ\"', 'A', 'ĠFew', 'ĠGood', 'ĠMen', '\"', 'Ġ(', '1992', '),', 'Ġthe', 'Ġhistorical', 'Ġdoc', 'ud', 'rama', 'Ġ\"', 'Ap', 'ollo', 'Ġ13', '\"', 'Ġ(', '1995', '),', 'Ġand', 'Ġthe', 'Ġmystery', 'Ġdrama', 'Ġ\"', 'My', 'stic', 'ĠRiver', '\"', 'Ġ(', '2003', ').', 'Ġ', '<s>', 'ĠBacon', 'Ġis', 'Ġalso', 'Ġknown', 'Ġfor', 'Ġtaking', 'Ġon', 'Ġdarker', 'Ġroles', 'Ġsuch', 'Ġas', 'Ġthat', 'Ġof', 'Ġa', 'Ġsad', 'istic', 'Ġguard', 'Ġin', 'Ġ\"', 'Sleep', 'ers', '\"', 'Ġ(', '1996', ')', 'Ġand', 'Ġtroubled', 'Ġformer', 'Ġchild', 'Ġabuser', 'Ġin', 'Ġa', 'Ġcritically', 'Ġacclaimed', 'Ġperformance', 'Ġin', 'Ġ\"', 'The', 'ĠWoods', 'man', '\"', 'Ġ(', '2004', ').', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġequally', 'Ġprolific', 'Ġon', 'Ġtelevision', ',', 'Ġhaving', 'Ġstarred', 'Ġin', 'Ġthe', 'ĠFox', 'Ġdrama', 'Ġseries', 'Ġ\"', 'The', 'ĠFollowing', '\"', 'Ġ(', '2013', 'âĢĵ', '2015', ').', 'Ġ', '<s>', 'ĠFor', 'Ġthe', 'ĠHBO', 'Ġoriginal', 'Ġfilm', 'Ġ\"', 'Taking', 'ĠChance', '\"', 'Ġ(', '2009', '),', 'ĠBacon', 'Ġwon', 'Ġa', 'ĠGolden', 'ĠGlobe', 'ĠAward', 'Ġand', 'Ġa', 'ĠScreen', 'ĠAct', 'ors', 'ĠGuild', 'ĠAward', ',', 'Ġalso', 'Ġreceiving', 'Ġa', 'ĠPrim', 'etime', 'ĠEmmy', 'ĠAward', 'Ġnomination', '.', 'Ġ\"', 'Ġ', '<s>', 'ĠThe', 'ĠGuardian', '\"', 'Ġnamed', 'Ġhim', 'Ġone', 'Ġof', 'Ġthe', 'Ġbest', 'Ġactors', 'Ġnever', 'Ġto', 'Ġhave', 'Ġreceived', 'Ġan', 'ĠAcademy', 'ĠAward', 'Ġnomination', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2003', ',', 'ĠBacon', 'Ġreceived', 'Ġa', 'Ġstar', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġfor', 'Ġhis', 'Ġcontributions', 'Ġto', 'Ġthe', 'Ġmotion', 'Ġpictures', 'Ġindustry', '.', '<p>', 'ĠLarry', 'ĠRichard', 'ĠWilliams', 'Ġ(', 'born', 'ĠOctober', 'Ġ6', ',', 'Ġ1942', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġauthor', ',', 'Ġstock', 'Ġand', 'Ġcommodity', 'Ġtrader', ',', 'Ġand', 'Ġpolitician', 'Ġfrom', 'Ġthe', 'Ġstate', 'Ġof', 'ĠMontana', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġthe', 'Ġfather', 'Ġof', 'Ġfour', '-', 'time', 'ĠAcademy', 'ĠAward', 'Ġand', 'Ġone', '-', 'time', 'ĠTony', 'ĠAward', 'Ġnominee', 'Ġactress', 'ĠMichelle', 'ĠWilliams', '.', '<p>', 'ĠThe', 'ĠGreat', 'ĠOut', 'doors', 'Ġis', 'Ġa', 'Ġ1988', 'ĠAmerican', 'Ġcomedy', 'Ġfilm', 'Ġdirected', 'Ġby', 'ĠHoward', 'ĠDe', 'utch', ',', 'Ġand', 'Ġwritten', 'Ġand', 'Ġproduced', 'Ġby', 'ĠJohn', 'ĠHughes', '.', 'Ġ', '<s>', 'ĠIt', 'Ġstars', 'ĠDan', 'ĠAy', 'k', 'roy', 'd', ',', 'ĠJohn', 'ĠCandy', ',', 'ĠStephanie', 'ĠFar', 'acy', 'Ġand', 'ĠAn', 'nette', 'ĠB', 'ening', 'Ġin', 'Ġher', 'Ġfilm', 'Ġdebut', '.', '<p>', 'ĠJohn', 'ĠArthur', 'ĠLith', 'gow', 'Ġ(', 'Ġ;', 'Ġborn', 'ĠOctober', 'Ġ19', 'Ġ,', 'Ġ1945', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactor', ',', 'Ġmusician', ',', 'Ġsinger', ',', 'Ġcomedian', ',', 'Ġvoice', 'Ġactor', ',', 'Ġand', 'Ġauthor', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġreceived', 'Ġtwo', 'ĠTony', 'ĠAwards', ',', 'Ġsix', 'ĠEmmy', 'ĠAwards', ',', 'Ġtwo', 'ĠGolden', 'ĠGlobe', 'ĠAwards', ',', 'Ġthree', 'ĠScreen', 'ĠAct', 'ors', 'ĠGuild', 'ĠAwards', ',', 'Ġan', 'ĠAmerican', 'ĠComedy', 'ĠAward', ',', 'Ġfour', 'ĠDrama', 'ĠDesk', 'ĠAwards', 'Ġand', 'Ġhas', 'Ġalso', 'Ġbeen', 'Ġnominated', 'Ġfor', 'Ġtwo', 'ĠAcademy', 'ĠAwards', 'Ġand', 'Ġfour', 'ĠGrammy', 'ĠAwards', '.', 'Ġ', '<s>', 'ĠLith', 'gow', 'Ġhas', 'Ġreceived', 'Ġa', 'Ġstar', 'Ġon', 'Ġthe', 'ĠHollywood', 'ĠWalk', 'Ġof', 'ĠFame', 'Ġand', 'Ġhas', 'Ġbeen', 'Ġinduct', 'ed', 'Ġinto', 'Ġthe', 'ĠAmerican', 'ĠTheater', 'ĠHall', 'Ġof', 'ĠFame', '.']\n",
      "lr:  tensor([5.0000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Where did the form of music played by Die Rhöner Säuwäntzt originate?\n",
      "orig_answer_text:  United States\n",
      "input:  ['<cls>', '<q>', 'The', 'ĠOber', 'oi', 'Ġfamily', 'Ġis', 'Ġpart', 'Ġof', 'Ġa', 'Ġhotel', 'Ġcompany', 'Ġthat', 'Ġhas', 'Ġa', 'Ġhead', 'Ġoffice', 'Ġin', 'Ġwhat', 'Ġcity', '?', '</q>', '<p>', 'ĠThe', 'ĠR', 'itz', '-', 'Carl', 'ton', 'ĠJakarta', 'Ġis', 'Ġa', 'Ġhotel', 'Ġand', 'Ġskysc', 'raper', 'Ġin', 'ĠJakarta', ',', 'ĠIndonesia', 'Ġand', 'Ġ14', 'th', 'ĠTall', 'est', 'Ġbuilding', 'Ġin', 'ĠJakarta', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġlocated', 'Ġin', 'Ġcity', 'Ġcenter', 'Ġof', 'ĠJakarta', ',', 'Ġnear', 'ĠMega', 'ĠKun', 'ing', 'an', ',', 'Ġadjacent', 'Ġto', 'Ġthe', 'Ġsister', 'ĠJ', 'W', 'ĠMarriott', 'ĠHotel', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġoperated', 'Ġby', 'ĠThe', 'ĠR', 'itz', '-', 'Carl', 'ton', 'ĠHotel', 'ĠCompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcomplex', 'Ġhas', 'Ġtwo', 'Ġtowers', 'Ġthat', 'Ġcomprises', 'Ġa', 'Ġhotel', 'Ġand', 'Ġthe', 'ĠAirl', 'ang', 'ga', 'ĠAp', 'artment', 'Ġrespectively', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhotel', 'Ġwas', 'Ġopened', 'Ġin', 'Ġ2005', '.', '<p>', 'ĠThe', 'ĠOber', 'oi', 'Ġfamily', 'Ġis', 'Ġan', 'ĠIndian', 'Ġfamily', 'Ġthat', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġits', 'Ġinvolvement', 'Ġin', 'Ġhotels', ',', 'Ġnamely', 'Ġthrough', 'ĠThe', 'ĠOber', 'oi', 'ĠGroup', '.', '<p>', 'ĠIsh', 'q', 'ba', 'a', 'az', 'Ġ(', 'English', ':', 'Ġ\"', 'L', 'overs', '\")', 'Ġis', 'Ġan', 'ĠIndian', 'Ġdrama', 'Ġtelevision', 'Ġseries', 'Ġwhich', 'Ġis', 'Ġbroadcast', 'Ġon', 'ĠStar', 'ĠPlus', '.', 'Ġ', '<s>', 'ĠIt', 'Ġpremiered', 'Ġon', 'Ġ27', 'ĠJune', 'Ġ2016', 'Ġand', 'Ġairs', 'ĠMon', '-', 'Fri', 'Ġ10', '-', '11', 'pm', 'ĠIST', '.', 'Ġ', '<s>', 'ĠN', 'aku', 'ul', 'ĠMe', 'ht', 'a', ',', 'ĠK', 'unal', 'ĠJa', 'ising', 'h', 'Ġand', 'ĠLe', 'en', 'esh', 'ĠMatt', 'oo', 'Ġrespectively', 'Ġportray', 'ĠShiva', 'ay', ',', 'ĠOm', 'k', 'ara', 'Ġand', 'ĠRud', 'ra', ',', 'Ġthe', 'Ġthree', 'Ġheirs', 'Ġof', 'Ġthe', 'ĠOber', 'oi', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġinitially', 'Ġfocused', 'Ġon', 'Ġthe', 'Ġtale', 'Ġof', 'Ġthree', 'Ġbrothers', ',', 'Ġlater', 'Ġbecome', 'Ġcentered', 'Ġon', 'Ġthe', 'Ġlove', 'Ġstory', 'Ġof', 'ĠShiva', 'ay', 'Ġand', 'ĠAnn', 'ika', 'Ġ(', 'S', 'urb', 'hi', 'ĠChand', 'na', ');', 'Ġwith', 'Ġthe', 'Ġstory', 'Ġof', 'ĠOm', 'k', 'ara', 'Ġand', 'ĠRud', 'ra', 'Ġbeing', 'Ġshifted', 'Ġto', 'Ġthe', 'Ġspin', 'off', 'Ġseries', 'Ġ\"', 'D', 'il', 'ĠBo', 'ley', 'ĠOber', 'oi', '\".', 'Ġ', '<s>', 'ĠIn', 'ĠJuly', 'Ġ2017', 'Ġ\"', 'D', 'il', 'ĠBo', 'ley', 'ĠOber', 'oi', '\"', 'Ġended', 'Ġand', 'Ġthe', 'Ġstorylines', 'Ġwere', 'Ġmerged', 'Ġback', 'Ġinto', 'Ġ\"', 'I', 'sh', 'q', 'ba', 'a', 'az', '\"', 'Ġwhich', 'Ġdoubled', 'Ġits', 'Ġruntime', '.', '<p>', 'ĠThe', 'ĠHotel', 'ĠTall', 'corn', 'Ġis', 'Ġlocated', 'Ġin', 'ĠMarshall', 'town', ',', 'ĠIowa', '.', 'Ġ', '<s>', 'ĠToday', 'Ġit', 'Ġis', 'Ġcalled', 'Ġthe', 'ĠTall', 'corn', 'ĠTowers', 'ĠApart', 'ments', '.', 'Ġ', '<s>', 'ĠBuilt', 'Ġin', 'Ġ1928', 'Ġby', 'Ġthe', 'ĠE', 'pp', 'ley', 'ĠHotel', 'ĠCompany', ',', 'Ġlocal', 'Ġcitizens', 'Ġcontributed', 'Ġ$', '120', ',', '000', 'Ġto', 'Ġensure', 'Ġthe', 'Ġsuccessful', 'Ġcompletion', 'Ġof', 'Ġthis', 'Ġseven', '-', 'story', 'Ġhotel', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġcompleted', 'Ġin', 'Ġconnection', 'Ġto', 'Ġthe', 'Ġseventy', '-', 'fifth', 'Ġanniversary', 'Ġof', 'ĠMarshall', 'town', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhotel', \"'s\", 'Ġsale', 'Ġin', 'Ġ1956', 'Ġfrom', 'Ġthe', 'ĠE', 'pp', 'ley', 'Ġchain', 'Ġto', 'Ġthe', 'ĠSher', 'aton', 'ĠCorporation', 'Ġwas', 'Ġpart', 'Ġof', 'Ġthe', 'Ġsecond', 'Ġlargest', 'Ġhotel', 'Ġsale', 'Ġin', 'ĠUnited', 'ĠStates', 'Ġhistory', '.', 'Ġ', '<s>', 'ĠThe', 'ĠTall', 'corn', 'Ġwas', 'Ġlisted', 'Ġas', 'Ġa', 'Ġcontributing', 'Ġproperty', 'Ġin', 'Ġthe', 'ĠMarshall', 'town', 'ĠDowntown', 'ĠHistoric', 'ĠDistrict', 'Ġon', 'Ġthe', 'ĠNational', 'ĠRegister', 'Ġof', 'ĠHistoric', 'ĠPlaces', 'Ġin', 'Ġ2002', '.', '<p>', 'ĠRai', 'ĠBah', 'ad', 'ur', 'ĠMoh', 'an', 'ĠSingh', 'ĠOber', 'oi', 'Ġ(', '15', 'ĠAugust', 'Ġ1898', 'Âł', 'âĢĵ', 'Ġ3', 'ĠMay', 'Ġ2002', ')', 'Ġwas', 'Ġan', 'ĠIndian', 'Ġhotel', 'ier', ',', 'Ġthe', 'Ġfounder', 'Ġand', 'Ġchairman', 'Ġof', 'ĠOber', 'oi', 'ĠHot', 'els', 'Ġ&', 'ĠRes', 'orts', ',', 'ĠIndia', \"'s\", 'Ġsecond', '-', 'largest', 'Ġhotel', 'Ġcompany', ',', 'Ġwith', 'Ġ35', 'Ġhotels', 'Ġin', 'ĠIndia', ',', 'ĠSri', 'ĠLanka', ',', 'ĠNepal', ',', 'ĠEgypt', ',', 'ĠAustralia', 'Ġand', 'ĠHungary', '.', '<p>', 'ĠHotel', 'ĠBond', 'Ġis', 'Ġa', 'Ġhistoric', 'Ġhotel', ',', 'Ġbuilt', 'Ġin', 'Ġtwo', 'Ġstages', 'Ġin', 'Ġ1913', 'Ġand', 'Ġ1921', ',', 'Ġin', 'Ġdowntown', 'ĠHartford', ',', 'ĠConnecticut', 'Ġby', 'Ġhotel', 'ier', 'ĠHarry', 'ĠS', '.', 'ĠBond', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġlocated', 'Ġnear', 'ĠBush', 'nell', 'ĠPark', ',', 'Ġand', 'Ġwas', 'Ġconsidered', 'Ġthe', 'Ġgrand', 'est', 'Ġhotel', 'Ġin', 'ĠHartford', 'Ġduring', 'Ġits', 'Ġhey', 'day', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsecond', 'Ġsection', 'Ġis', 'Ġa', 'Ġ12', 'Ġstory', 'Ġbuilding', 'Ġattached', 'Ġto', 'Ġthe', 'Ġ6', 'Ġstory', 'Ġfirst', 'Ġsection', '.', 'Ġ', '<s>', 'ĠA', 'ĠStat', 'ler', 'ĠHotel', 'Ġopened', 'Ġin', 'Ġthe', 'Ġarea', 'Ġin', 'Ġ1954', ',', 'Ġcreating', 'Ġcompetition', ',', 'Ġand', 'Ġthe', 'ĠBond', 'ĠHotel', 'Ġcompany', 'Ġdeclared', 'Ġbankruptcy', 'Ġshortly', 'Ġafter', 'Ġthat', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġbought', 'Ġby', 'Ġthe', 'ĠCalifornia', '-', 'based', 'ĠMas', 'ag', 'lia', 'ĠHotel', 'Ġchain', ',', 'Ġwhich', 'Ġbegan', 'Ġan', 'Ġincremental', 'Ġrenovation', 'Ġprogram', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1964', 'Ġit', 'Ġwas', 'Ġsold', 'Ġto', 'Ġa', 'ĠCincinnati', ',', 'ĠOhio', 'Ġinvestment', 'Ġgroup', 'Ġwhich', 'Ġannounced', 'Ġextensive', 'Ġrenovation', 'Ġplans', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġthe', 'Ġfinancing', 'Ġplans', 'Ġfell', 'Ġthrough', 'Ġand', 'Ġthe', 'Ġhotel', 'Ġwas', 'Ġagain', 'Ġin', 'Ġbankruptcy', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbuilding', 'Ġwas', 'Ġsold', 'Ġat', 'Ġauction', 'Ġto', 'Ġthe', 'ĠRoman', 'ĠCatholic', 'ĠArch', 'di', 'ocese', 'Ġof', 'ĠHartford', 'Ġin', 'Ġ1965', ',', 'Ġand', 'Ġit', 'Ġbecame', 'Ġthe', 'Ġhome', 'Ġof', 'Ġthe', 'ĠSaint', 'ĠFrancis', 'ĠHospital', 'ĠSchool', 'Ġof', 'ĠNursing', '.', 'Ġ', '<s>', 'ĠThe', 'ĠBond', 'ĠBall', 'room', 'Ġreopened', 'Ġin', 'Ġ2001', ',', 'Ġwith', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġbuilding', 'Ġbecoming', 'Ġa', 'ĠHom', 'ew', 'ood', 'ĠSu', 'ites', 'Ġby', 'ĠHilton', 'Ġin', 'Ġ2006', '.', '<p>', 'ĠThe', 'ĠOber', 'oi', 'ĠGroup', 'Ġis', 'Ġa', 'Ġhotel', 'Ġcompany', 'Ġwith', 'Ġits', 'Ġhead', 'Ġoffice', 'Ġin', 'ĠDelhi', '.', 'Ġ', '<s>', 'ĠFound', 'ed', 'Ġin', 'Ġ1934', ',', 'Ġthe', 'Ġcompany', 'Ġowns', 'Ġand', '/', 'or', 'Ġoperates', 'Ġ30', '+', 'Ġluxury', 'Ġhotels', 'Ġand', 'Ġtwo', 'Ġriver', 'Ġcruise', 'Ġships', 'Ġin', 'Ġsix', 'Ġcountries', ',', 'Ġprimarily', 'Ġunder', 'Ġits', 'ĠOber', 'oi', 'ĠHot', 'els', 'Ġ&', 'ĠRes', 'orts', 'Ġand', 'ĠTrident', 'ĠHot', 'els', 'Ġbrands', '.', '<p>', 'ĠFuture', 'ĠFib', 're', 'ĠTechnologies', 'Ġ(', 'FF', 'T', ')', 'Ġis', 'Ġa', 'Ġfiber', 'Ġoptic', 'Ġsensing', 'Ġtechnologies', 'Ġcompany', 'Ġbased', 'Ġin', 'ĠMelbourne', ',', 'ĠAustralia', ',', 'Ġwith', 'Ġits', 'ĠUS', 'Ġhead', 'Ġoffice', 'Ġin', 'ĠMountain', 'ĠView', ',', 'ĠCalifornia', ',', 'ĠMiddle', 'ĠEast', 'Ġhead', 'Ġoffice', 'Ġin', 'ĠDubai', ',', 'ĠIndian', 'Ġhead', 'Ġoffice', 'Ġin', 'ĠNew', 'ĠDelhi', 'Ġand', 'ĠEuropean', 'Ġhead', 'Ġoffice', 'Ġin', 'ĠLondon', '.', 'Ġ', '<s>', 'ĠFound', 'ed', 'Ġin', 'Ġ1994', ',', 'ĠFuture', 'ĠFib', 're', 'ĠTechnologies', 'Ġproduct', 'Ġline', 'Ġprovides', 'Ġoptical', 'Ġfiber', 'Ġintrusion', 'Ġdetection', 'Ġsystems', 'Ġfor', 'Ġper', 'imeters', ',', 'Ġburied', 'Ġoil', 'Ġand', 'Ġgas', 'Ġpipelines', 'Ġand', 'Ġdata', 'Ġcommunication', 'Ġnetworks', '.', '<p>', 'ĠThe', 'Ġ289', 'th', 'ĠMilitary', 'ĠPolice', 'ĠCompany', 'Ġwas', 'Ġactivated', 'Ġon', 'Ġ1', 'ĠNovember', 'Ġ1994', 'Ġand', 'Ġattached', 'Ġto', 'ĠHotel', 'ĠCompany', ',', 'Ġ3', 'rd', 'ĠInfantry', 'Ġ(', 'The', 'ĠOld', 'ĠGuard', '),', 'ĠFort', 'ĠMy', 'er', ',', 'ĠVirginia', '.', 'Ġ', '<s>', 'ĠHotel', 'ĠCompany', 'Ġis', 'Ġthe', 'Ġregiment', \"'s\", 'Ġspecialty', 'Ġcompany', '.', '<p>', 'ĠThe', 'ĠGlenn', 'wan', 'is', 'ĠHotel', 'Ġis', 'Ġa', 'Ġhistoric', 'Ġhotel', 'Ġin', 'ĠGlenn', 'ville', ',', 'ĠGeorgia', ',', 'ĠTatt', 'n', 'all', 'ĠCounty', ',', 'ĠGeorgia', ',', 'Ġbuilt', 'Ġon', 'Ġthe', 'Ġsite', 'Ġof', 'Ġthe', 'ĠHughes', 'ĠHotel', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhotel', 'Ġis', 'Ġlocated', 'Ġat', 'Ġ209', '-', '215', 'ĠEast', 'ĠBarn', 'ard', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠThe', 'Ġold', 'ĠHughes', 'ĠHotel', 'Ġwas', 'Ġbuilt', 'Ġout', 'Ġof', 'ĠGeorgia', 'Ġpine', 'Ġcirca', 'Ġ1905', 'Ġand', 'Ġburned', 'Ġin', 'Ġ1920', '.', 'Ġ', '<s>', 'ĠThe', 'ĠGlenn', 'wan', 'is', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġbrick', 'Ġin', 'Ġ1926', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlocal', 'ĠKi', 'wan', 'is', 'Ġclub', 'Ġled', 'Ġthe', 'Ġeffort', 'Ġto', 'Ġget', 'Ġthe', 'Ġreplacement', 'Ġhotel', 'Ġbuilt', ',', 'Ġand', 'Ġorganized', 'Ġa', 'ĠGlenn', 'ville', 'ĠHotel', 'ĠCompany', 'Ġwith', 'Ġdirectors', 'Ġbeing', 'Ġlocal', 'Ġbusiness', 'Ġleaders', '.', 'Ġ', '<s>', 'ĠThe', 'Ġwife', 'Ġof', 'Ġa', 'Ġlocal', 'Ġdoctor', 'Ġwon', 'Ġa', 'Ġnaming', 'Ġcontest', 'Ġwith', 'Ġthe', 'Ġname', 'Ġ\"', 'Gl', 'enn', 'wan', 'is', 'ĠHotel', '\",', 'Ġa', 'Ġsuggestion', 'Ġcombining', 'Ġ\"', 'Gl', 'enn', 'ville', '\"', 'Ġand', 'Ġ\"', 'K', 'i', 'wan', 'is', '\".']\n",
      "lr:  tensor([5.1000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Cadmium Chloride is slightly soluble in this chemical, it is also called what?\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "orig_answer_text:  alcohol\n",
      "input:  ['<cls>', '<q>', 'ĠWhat', 'Ġnationality', 'Ġwas', 'ĠJames', 'ĠHenry', 'ĠMiller', \"'s\", 'Ġwife', '?', '</q>', '<p>', 'ĠMol', 'och', ':', 'Ġor', ',', 'ĠThis', 'ĠGent', 'ile', 'ĠWorld', 'Ġis', 'Ġa', 'Ġsemi', '-', 'aut', 'obi', 'ographical', 'Ġnovel', 'Ġwritten', 'Ġby', 'ĠHenry', 'ĠMiller', 'Ġin', 'Ġ1927', '-', '28', ',', 'Ġinitially', 'Ġunder', 'Ġthe', 'Ġguise', 'Ġof', 'Ġa', 'Ġnovel', 'Ġwritten', 'Ġby', 'Ġhis', 'Ġwife', ',', 'ĠJune', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbook', 'Ġwent', 'Ġunpublished', 'Ġuntil', 'Ġ1992', ',', 'Ġ65', 'Ġyears', 'Ġafter', 'Ġit', 'Ġwas', 'Ġwritten', 'Ġand', 'Ġ12', 'Ġyears', 'Ġafter', 'ĠMiller', 'âĢ', 'Ļ', 's', 'Ġdeath', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġwidely', 'Ġconsidered', 'Ġto', 'Ġbe', 'Ġof', 'Ġinterest', 'Ġmore', 'Ġas', 'Ġa', 'Ġstudy', 'Ġof', 'ĠMiller', 'âĢ', 'Ļ', 's', 'Ġartistic', 'Ġgrowth', 'Ġthan', 'Ġas', 'Ġa', 'Ġworthy', 'Ġpiece', 'Ġof', 'Ġfiction', '.', '<p>', 'ĠThe', 'ĠLaun', 'cest', 'on', 'Ġby', '-', 'election', 'Ġof', 'Ġ18', '74', 'Ġwas', 'Ġfought', 'Ġon', 'Ġ3', 'ĠJuly', 'Ġ18', '74', '.', 'Ġ', '<s>', 'ĠThe', 'Ġby', 'election', 'Ġwas', 'Ġfought', 'Ġdue', 'Ġto', 'Ġthe', 'Ġvoid', 'ĠElection', 'Ġof', 'Ġthe', 'Ġincumbent', 'ĠConservative', 'ĠMP', ',', 'ĠJames', 'ĠHenry', 'ĠDe', 'akin', 'Ġ(', 'sen', 'ior', ').', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwon', 'Ġby', 'Ġthe', 'ĠConservative', 'Ġcandidate', 'ĠJames', 'ĠHenry', 'ĠDe', 'akin', 'Ġ(', 'jun', 'ior', ').', '<p>', 'ĠInc', 'est', ':', 'ĠFrom', 'Ġa', 'ĠJournal', 'Ġof', 'ĠLove', ':', 'ĠThe', 'ĠU', 'nex', 'p', 'urg', 'ated', 'ĠDiary', 'Ġof', 'ĠAna', 'Ã¯', 's', 'ĠNin', 'Ġ(', '19', '32', 'âĢĵ', '19', '34', ')', 'Ġis', 'Ġa', 'Ġ1992', 'Ġnon', '-', 'fiction', 'Ġbook', 'Ġby', 'ĠAna', 'Ã¯', 's', 'ĠNin', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġcontinuation', 'Ġof', 'Ġthe', 'Ġdiary', 'Ġentries', 'Ġfirst', 'Ġpublished', 'Ġin', 'Ġ\"', 'Henry', 'Ġand', 'ĠJune', ':', 'ĠFrom', 'Ġthe', 'ĠU', 'nex', 'p', 'urg', 'ated', 'ĠDiary', 'Ġof', 'ĠAna', 'Ã¯', 's', 'ĠNin', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġfeatures', 'ĠNin', \"'s\", 'Ġrelationships', 'Ġwith', 'Ġwriter', 'ĠHenry', 'ĠMiller', ',', 'Ġhis', 'Ġwife', 'ĠJune', 'ĠMiller', ',', 'Ġthe', 'Ġpsych', 'oan', 'alyst', 'ĠOtto', 'ĠRank', ',', 'Ġher', 'Ġfather', 'ĠJo', 'aqu', 'ÃŃn', 'ĠNin', ',', 'Ġand', 'Ġher', 'Ġhusband', 'ĠHugh', 'ĠParker', 'ĠGu', 'iler', '.', 'Ġ', '<s>', 'ĠShe', 'Ġalso', 'Ġcopied', 'Ġsome', 'Ġof', 'Ġher', 'Ġcorrespondence', 'Ġwith', 'Ġthese', 'Ġpeople', 'Ġinto', 'Ġher', 'Ġdiary', '.', 'Ġ', '<s>', 'ĠMuch', 'Ġof', 'Ġthis', 'Ġbook', 'Ġwas', 'Ġwritten', 'Ġin', 'ĠEnglish', ',', 'Ġalthough', 'Ġthose', 'Ġof', 'Ġher', 'Ġletters', 'Ġwhich', 'Ġwere', 'Ġoriginally', 'Ġwritten', 'Ġin', 'ĠFrench', 'Ġand', 'ĠSpanish', 'Ġwere', 'Ġtranslated', '.', 'Ġ', '<s>', 'ĠMost', 'Ġof', 'Ġthis', 'Ġdiary', 'Ġtakes', 'Ġplace', 'Ġin', 'ĠFrance', ',', 'Ġparticularly', 'ĠCl', 'ich', 'y', ',', 'ĠParis', 'Ġand', 'ĠLou', 've', 'ci', 'ennes', '.', '<p>', 'ĠJames', 'ĠHenry', 'ĠDe', 'akin', 'Ġ(', '18', '51', 'ĠâĢĵ', 'Ġ8', 'ĠNovember', 'Ġ18', '81', ')', 'Ġwas', 'Ġa', 'ĠBritish', 'ĠConservative', 'Ġpolitician', ',', 'Ġthe', 'Ġson', 'Ġof', 'ĠCol', '.', 'ĠJames', 'ĠHenry', 'ĠDe', 'akin', ',', 'Ġa', 'ĠManchester', 'Ġmerchant', '.', '<p>', 'ĠJames', 'ĠHenry', 'ĠMiller', 'Ġ(', '25', 'ĠJanuary', 'Ġ1915', 'ĠâĢĵ', 'Ġ22', 'ĠOctober', 'Ġ1989', '),', 'Ġbetter', 'Ġknown', 'Ġby', 'Ġhis', 'Ġstage', 'Ġname', 'ĠE', 'wan', 'ĠMac', 'Coll', ',', 'Ġwas', 'Ġan', 'ĠEnglish', 'Ġfolk', 'Ġsinger', ',', 'Ġsong', 'writer', ',', 'Ġcommunist', ',', 'Ġlabour', 'Ġactivist', ',', 'Ġactor', ',', 'Ġpoet', ',', 'Ġplay', 'wright', 'Ġand', 'Ġrecord', 'Ġproducer', '.', '<p>', 'ĠMargaret', 'Ġ\"', 'Pe', 'ggy', '\"', 'ĠSee', 'ger', 'Ġ(', 'born', 'ĠJune', 'Ġ17', ',', 'Ġ1935', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġfolks', 'inger', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġalso', 'Ġwell', 'Ġknown', 'Ġin', 'ĠBritain', ',', 'Ġwhere', 'Ġshe', 'Ġhas', 'Ġlived', 'Ġfor', 'Ġmore', 'Ġthan', 'Ġ30', 'Ġyears', ',', 'Ġand', 'Ġwas', 'Ġmarried', 'Ġto', 'Ġthe', 'Ġsinger', 'Ġand', 'Ġsong', 'writer', 'ĠE', 'wan', 'ĠMac', 'Coll', 'Ġuntil', 'Ġhis', 'Ġdeath', 'Ġin', 'Ġ1989', '.', '<p>', 'ĠThe', 'ĠHenry', 'ĠMiller', 'ĠMemorial', 'ĠLibrary', 'Ġis', 'Ġa', 'Ġnonprofit', 'Ġarts', 'Ġcenter', ',', 'Ġbookstore', ',', 'Ġand', 'Ġperformance', 'Ġvenue', ',', 'Ġchampion', 'ing', 'Ġthe', 'Ġlate', 'Ġwriter', ',', 'Ġartist', ',', 'Ġand', 'ĠBig', 'ĠSur', 'Ġresident', 'ĠHenry', 'ĠMiller', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġmany', 'Ġother', ',', 'Ġboth', 'Ġliving', 'Ġand', 'Ġdead', ',', 'Ġcreative', 'Ġindividuals', 'Ġliving', 'Ġin', 'Ġor', 'Ġnear', 'ĠBig', 'ĠSur', ',', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠHenry', 'ĠMiller', 'âĢ', 'Ļ', 's', 'Ġfriend', 'ĠEmil', 'ĠWhite', 'Ġbuilt', 'Ġthe', 'Ġhouse', 'Ġthat', 'Ġis', 'Ġnow', 'Ġthe', 'ĠLibrary', 'Ġin', 'Ġthe', 'Ġmid', '-', '1960', 's', '.', 'Ġ', '<s>', 'ĠAfter', 'ĠMiller', 'Ġdied', ',', 'Ġin', 'Ġ1980', ',', 'ĠEmil', 'Ġdecided', 'Ġto', 'Ġmaintain', 'Ġhis', 'Ġproperty', 'Ġas', 'Ġa', 'Ġmemorial', 'Ġto', 'Ġhis', 'Ġfriend', 'Ġand', 'Ġas', 'Ġa', 'Ġgallery', 'Ġwhere', 'Ġlocal', 'Ġartists', 'Ġcould', 'Ġshow', 'Ġtheir', 'Ġwork', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1981', 'ĠEmil', 'ĠWhite', ',', 'Ġwith', 'Ġthe', 'Ġhelp', 'Ġof', 'Ġthe', 'ĠBig', 'ĠSur', 'ĠLand', 'ĠTrust', ',', 'Ġcreated', 'Ġ\"', 'The', 'ĠHenry', 'ĠMiller', 'ĠMemorial', 'ĠLibrary', ',', 'ĠFound', 'ed', 'Ġby', 'ĠEmil', 'ĠWhite', '.\"', '<p>', 'ĠJune', 'ĠMiller', 'Ġ(', 'January', 'Ġ7', 'Ġor', 'Ġ28', ',', 'Ġ1902', 'ĠâĢĵ', 'ĠFebruary', 'Ġ1', ',', 'Ġ1979', ')', 'Ġwas', 'Ġthe', 'Ġmuch', '-', 'written', '-', 'about', 'Ġsecond', 'Ġwife', 'Ġof', 'ĠHenry', 'ĠMiller', '.', '<p>', 'ĠJames', 'ĠHenry', 'ĠRobert', 'ĠIn', 'nes', '-', 'K', 'er', ',', 'Ġ7', 'th', 'ĠDuke', 'Ġof', 'ĠRox', 'burg', 'he', 'Ġ(', '5', 'ĠSeptember', 'Ġ18', '39', 'ĠâĢĵ', 'Ġ23', 'ĠOctober', 'Ġ18', '92', '),', 'Ġbecame', 'ĠDuke', 'Ġof', 'ĠRox', 'burg', 'he', 'Ġon', 'Ġthe', 'Ġdeath', 'Ġof', 'Ġhis', 'Ġfather', ',', 'ĠJames', 'ĠHenry', 'ĠRobert', 'ĠIn', 'nes', '-', 'K', 'er', ',', 'Ġ6', 'th', 'ĠDuke', 'Ġof', 'ĠRox', 'burg', 'he', '.', '<p>', 'ĠJames', 'ĠHenry', 'ĠMiller', 'Ġ(', 'born', 'Ġ30', 'ĠMay', 'Ġ1919', ')', 'Ġis', 'Ġa', 'Ġformer', 'ĠAustralian', 'Ġrules', 'Ġfootballer', 'Ġin', 'Ġthe', 'ĠVictorian', 'ĠFootball', 'ĠLeague', 'Ġ(', 'V', 'FL', ').']\n",
      "lr:  tensor([5.1000e-06], device='cuda:0')\n",
      "question text:  Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
      "orig_answer_text:  President Richard Nixon\n",
      "input:  ['<cls>', '<q>', 'Where', 'Ġdid', 'Ġthe', 'Ġform', 'Ġof', 'Ġmusic', 'Ġplayed', 'Ġby', 'ĠDie', 'ĠRh', 'Ã¶', 'ner', 'ĠS', 'Ã¤', 'u', 'w', 'Ã¤', 'nt', 'z', 't', 'Ġoriginate', '?', '</q>', '<p>', 'ĠPant', 'un', 'ĠSund', 'a', 'Ġis', 'Ġa', 'Ġtype', 'Ġof', 'ĠSund', 'an', 'ese', 'Ġoral', 'Ġnarrative', 'Ġperformance', 'Ġinter', 'sp', 'ersed', 'Ġwith', 'Ġsongs', 'Ġand', 'Ġmusic', 'Ġplayed', 'Ġon', 'Ġa', 'Ġ\"', 'k', 'ac', 'api', '\",', 'Ġa', 'Ġkind', 'Ġof', 'Ġz', 'ither', '.', 'Ġ', '<s>', 'ĠA', 'Ġpant', 'un', 'Ġis', 'Ġintended', 'Ġto', 'Ġbe', 'Ġrec', 'ited', 'Ġduring', 'Ġan', 'Ġevening', '-', 'length', 'Ġperformance', 'Ġduring', 'Ġwhich', 'Ġa', 'Ġsingle', 'Ġperformer', 'Ġrelates', 'Ġthe', 'Ġstory', 'Ġof', 'Ġa', 'Ġhero', 'âĢ', 'Ļ', 's', 'Ġinitiation', ':', 'ĠThe', 'Ġprotagonist', 'Ġleaves', 'Ġhis', 'Ġkingdom', 'Ġin', 'Ġorder', 'Ġto', 'Ġseek', 'Ġexperiences', ',', 'Ġbeautiful', 'Ġprincess', 'es', 'Ġto', 'Ġbecome', 'Ġhis', 'Ġwife', ',', 'Ġpower', ',', 'Ġother', 'Ġkingdoms', 'Ġto', 'Ġsubject', ',', 'Ġthe', 'Ġrealization', 'Ġof', 'Ġa', 'Ġdream', 'Ġ(', 'Ros', 'idi', 'Ġ1984', 'a', ':', '143', ');', 'Ġafter', 'Ġhaving', 'Ġsucceeded', 'Ġin', 'Ġreaching', 'Ġhis', 'Ġgoal', 'Ġhe', 'Ġfinally', 'Ġreturns', 'Ġto', 'Ġhis', 'Ġkingdom', '.', 'Ġ', '<s>', 'ĠAlong', 'side', 'Ġdescriptions', 'Ġof', 'Ġhistorical', 'Ġevents', ',', 'Ġthe', 'Ġstories', 'Ġoften', 'Ġcontain', 'Ġmythical', 'Ġelements', '.', 'Ġ', '<s>', 'ĠPant', 'un', 'Ġwere', 'Ġoriginally', 'Ġnot', 'Ġwritten', 'Ġdown', ',', 'Ġthe', 'Ġb', 'ards', 'Ġoften', 'Ġbeing', 'Ġilliter', 'ate', 'Ġand', 'Ġin', 'Ġmany', 'Ġcases', 'Ġblind', '.', 'Ġ', '<s>', 'ĠOriginally', 'Ġthe', 'Ġperformances', 'Ġhad', 'Ġa', 'Ġsacred', 'Ġcharacter', ',', 'Ġas', 'Ġwas', 'Ġclear', 'Ġfrom', 'Ġthe', 'Ġofferings', 'Ġmade', 'Ġat', 'Ġthe', 'Ġbeginning', 'Ġof', 'Ġthe', 'Ġrec', 'itation', 'Ġand', 'Ġalso', 'Ġfrom', 'Ġthe', 'Ġcontent', 'Ġof', 'Ġthe', 'Ġintroductory', 'Ġpart', 'Ġof', 'Ġthe', 'Ġstory', ',', 'Ġcalled', 'Ġr', 'aj', 'ah', ',', 'Ġwhich', 'Ġwas', 'Ġan', 'Ġinv', 'oc', 'atory', 'Ġsong', ',', 'Ġimpl', 'oring', 'Ġthe', 'Ġhelp', 'Ġof', 'Ġdivine', 'Ġfigures', 'Ġto', 'Ġward', 'Ġoff', 'Ġbad', 'Ġinfluences', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlinguistic', 'Ġform', 'Ġof', 'Ġthe', 'Ġpant', 'un', 'Ġwas', 'Ġnot', 'Ġstrictly', 'Ġfixed', ',', 'Ġhowever', 'Ġthe', 'Ġdominant', 'Ġform', 'Ġemployed', 'Ġin', 'Ġmost', 'Ġpant', 'un', 'Ġis', 'Ġthe', 'Ġoct', 'os', 'yll', 'ab', 'ic', 'Ġverse', '.', 'Ġ', '<s>', 'ĠFor', 'Ġa', 'Ġdetailed', 'Ġdescription', 'Ġof', 'Ġthe', 'Ġnature', 'Ġand', 'Ġform', 'Ġof', 'Ġa', 'ĠSund', 'an', 'ese', 'Ġpant', 'un', 'Ġyou', 'Ġare', 'Ġreferred', 'Ġto', 'ĠE', 'ring', 'a', 'Ġ(', '19', '49', '),', 'Ġto', 'ĠHer', 'mans', 'o', 'em', 'ant', 'ri', 'Ġ(', '1977', 'âĢĵ', '79', ').', '<p>', 'ĠBub', 'u', 'Ġmusic', 'Ġis', 'Ġtraditional', 'Ġmusic', 'Ġplayed', 'Ġby', 'Ġthe', 'ĠTem', 'ne', 'Ġpeople', 'Ġin', 'ĠSierra', 'ĠLeone', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmusic', 'Ġwas', 'Ġoriginally', 'Ġused', 'Ġin', 'Ġwitchcraft', 'Ġceremonies', ',', 'Ġbut', 'Ġlater', 'Ġit', 'Ġturned', 'Ġinto', 'Ġa', 'Ġpopular', 'Ġreligious', 'Ġprocess', 'ional', 'Ġstyle', 'Ġplayed', 'Ġduring', 'ĠRamadan', '.', 'Ġ', '<s>', 'ĠIn', 'Ġits', 'Ġfolk', 'Ġform', ',', 'Ġthe', 'Ġmusic', 'Ġis', 'Ġplayed', 'Ġby', 'Ġblowing', 'Ġon', 'Ġbamboo', 'Ġcane', 'Ġfl', 'utes', 'Ġand', 'Ġon', 'Ġmetal', 'Ġpipes', 'Ġ-', 'often', 'Ġrep', 'ur', 'posed', 'Ġauto', 'Ġparts', '.', '<p>', 'ĠPe', 'ÅŁ', 'rev', 'Ġ(', 'pron', 'ounced', 'Ġ]', 'Ġin', 'ĠTurkish', '),', 'Ġ\"', 'Pi', 'ÅŁ', 'rev', '\"', 'Ġ([', 'pi', 'Ê', 'ĥ', 'ËĪ', 'É', '¾', 'ev', ']', 'Ġ),', 'Ġ\"', 'p', 'esh', 'rev', ',\"', 'Ġor', 'Ġ\"', 'p', 'ish', 'rev', ';\"', 'Ġcalled', 'Ġ\"', 'bash', 'raf', '\"', 'ĠØ', '¨', 'Ø', '´', 'Ø±', 'Ù', 'ģ', 'Ġin', 'ĠArabic', ';', 'Ġis', 'Ġan', 'Ġinstrumental', 'Ġform', 'Ġin', 'ĠTurkish', 'Ġclassical', 'Ġmusic', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġname', 'Ġof', 'Ġthe', 'Ġfirst', 'Ġpiece', 'Ġof', 'Ġmusic', 'Ġplayed', 'Ġduring', 'Ġa', 'Ġgroup', 'Ġperformance', 'Ġcalled', 'Ġa', 'Ġf', 'as', 'Ä±', 'l', 'Ġ(', ']', 'Ġ).', 'Ġ', '<s>', 'ĠIt', 'Ġalso', 'Ġserves', 'Ġas', 'Ġthe', 'Ġpen', 'ultimate', 'Ġpiece', 'Ġof', 'Ġthe', 'Ġ\"', 'M', 'ev', 'lev', 'i', 'Ġay', 'ini', '\",', 'Ġritual', 'Ġmusic', 'Ġof', 'Ġthe', 'ĠM', 'ev', 'lev', 'i', 'Ġorder', ',', 'Ġunder', 'Ġthe', 'Ġname', 'Ġ\"', 'son', 'Ġpe', 'ÅŁ', 'rev', '\"', 'Ġ(', 'final', 'Ġpe', 'ÅŁ', 'rev', '),', 'Ġpreceding', 'Ġ\"', 'son', 'Ġsem', 'ai', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġusually', 'Ġuses', 'Ġlong', 'Ġrhythm', 'Ġcycles', ',', 'Ġstretching', 'Ġover', 'Ġmany', 'Ġmeasures', 'Ġas', 'Ġopposed', 'Ġto', 'Ġthe', 'Ġsimpler', 'Ġus', 'ul', 'Ġthe', 'Ġother', 'Ġmajor', 'Ġform', 'Ġof', 'Ġinstrumental', 'Ġmusic', 'Ġuses', ',', 'Ġ\"', 's', 'az', 'Ġsem', 'ai', '\".', '<p>', 'ĠSk', 'iff', 'le', 'Ġis', 'Ġa', 'Ġmusic', 'Ġgenre', 'Ġwith', 'Ġjazz', ',', 'Ġblues', ',', 'Ġfolk', 'Ġand', 'ĠAmerican', 'Ġfolk', 'Ġinfluences', ',', 'Ġusually', 'Ġusing', 'Ġa', 'Ġcombination', 'Ġof', 'Ġmanufactured', 'Ġand', 'Ġhomemade', 'Ġor', 'Ġimprovised', 'Ġinstruments', '.', 'Ġ', '<s>', 'ĠOrig', 'inating', 'Ġas', 'Ġa', 'Ġterm', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġin', 'Ġthe', 'Ġfirst', 'Ġhalf', 'Ġof', 'Ġthe', 'Ġ20', 'th', 'Ġcentury', ',', 'Ġit', 'Ġbecame', 'Ġpopular', 'Ġagain', 'Ġin', 'Ġthe', 'ĠUK', 'Ġin', 'Ġthe', 'Ġ1950', 's', ',', 'Ġwhere', 'Ġit', 'Ġwas', 'Ġassociated', 'Ġwith', 'Ġartists', 'Ġsuch', 'Ġas', 'ĠLon', 'nie', 'ĠDone', 'gan', ',', 'ĠThe', 'ĠV', 'ipers', 'ĠSk', 'iff', 'le', 'ĠGroup', ',', 'ĠKen', 'ĠCo', 'ly', 'er', 'Ġand', 'ĠCh', 'as', 'ĠMc', 'Dev', 'itt', '.', 'Ġ', '<s>', 'ĠSk', 'iff', 'le', 'Ġplayed', 'Ġa', 'Ġmajor', 'Ġpart', 'Ġin', 'Ġbeginning', 'Ġthe', 'Ġcareers', 'Ġof', 'Ġlater', 'Ġeminent', 'Ġjazz', ',', 'Ġpop', ',', 'Ġblues', ',', 'Ġfolk', 'Ġand', 'Ġrock', 'Ġmusicians', 'Ġand', 'Ġhas', 'Ġbeen', 'Ġseen', 'Ġas', 'Ġa', 'Ġcritical', 'Ġstepping', 'Ġstone', 'Ġto', 'Ġthe', 'Ġsecond', 'ĠBritish', 'Ġfolk', 'Ġrevival', ',', 'Ġblues', 'Ġboom', 'Ġand', 'ĠBritish', 'ĠInvasion', 'Ġof', 'Ġthe', 'ĠUS', 'Ġpopular', 'Ġmusic', 'Ġscene', '.', '<p>', 'ĠC', 'achi', 'ĠC', 'achi', 'Ġmusic', ',', 'Ġalso', 'Ġspelled', 'ĠK', 'achi', 'ĠK', 'achi', ',', 'ĠK', 'achi', '-', 'K', 'achi', 'Ġand', 'ĠK', 'atch', 'i', '-', 'K', 'atch', 'i', ',', 'Ġis', 'Ġa', 'Ġterm', 'Ġthat', 'Ġwas', 'Ġcoined', 'Ġto', 'Ġrefer', 'Ġto', 'Ġmusic', 'Ġplayed', 'Ġby', 'ĠPuerto', 'ĠRic', 'ans', 'Ġin', 'ĠHawaii', ',', 'Ġwhen', 'Ġthey', 'Ġmigrated', 'Ġto', 'ĠHawaii', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġ\"', 'vari', 'ation', 'Ġof', 'Ġdance', 'Ġmusic', 'Ġfound', 'Ġin', 'ĠHawaii', '\".', 'Ġ', '<s>', 'ĠSometimes', 'Ġc', 'achi', 'Ġc', 'achi', 'Ġ\"', 'inv', 'olves', 'Ġfast', ',', 'Ġimprovised', 'Ġsol', 'os', '\"', 'Ġon', 'Ġthe', 'Ġguitar', '.', 'Ġ', '<s>', 'ĠThe', 'Ġ\"', 'inf', 'luence', 'Ġon', 'ĠHawai', \"'\", 'i', 'Ġend', 'ures', 'Ġto', 'Ġthis', 'Ġday', 'Ġin', 'Ġthe', 'Ġmusical', 'Ġform', 'Ġknown', 'Ġas', 'Ġ\"', 'c', 'achi', 'Ġc', 'achi', '\"', 'Ġplayed', 'Ġon', 'Ġthe', 'Ġquart', 'o', 'Ġ[', 'sic', ']', 'Ġand', 'Ġderivative', 'Ġof', 'Ġthe', 'ĠPuerto', 'ĠRican', 'Ġj', 'ib', 'aro', 'Ġstyle', '.\"', 'Ġ', '<s>', 'Ġ\"', 'J', 'ib', 'aro', '\"', 'Ġmeans', 'Ġpeasant', 'Ġin', 'ĠSpanish', '.', '<p>', 'ĠBackground', 'Ġmusic', 'Ġrefers', 'Ġto', 'Ġvarious', 'Ġstyles', 'Ġof', 'Ġmusic', 'Ġor', 'Ġsound', 'sc', 'apes', 'Ġprimarily', 'Ġintended', 'Ġto', 'Ġbe', 'Ġpassively', 'Ġlistened', 'Ġto', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġnot', 'Ġmeant', 'Ġto', 'Ġbe', 'Ġthe', 'Ġmain', 'Ġfocus', 'Ġof', 'Ġan', 'Ġaudience', ',', 'Ġbut', 'Ġrather', 'Ġto', 'Ġsupplement', 'Ġthat', 'Ġwhich', 'Ġis', 'Ġmeant', 'Ġto', 'Ġbe', 'Ġfocused', 'Ġupon', '.', 'Ġ', '<s>', 'ĠMusic', 'Ġthat', 'Ġis', 'Ġplayed', 'Ġat', 'Ġa', 'Ġlow', 'Ġvolume', 'Ġand', 'Ġis', 'Ġnot', 'Ġthe', 'Ġmain', 'Ġfocus', 'Ġof', 'Ġan', 'Ġaudience', 'Ġis', 'Ġalso', 'Ġreferred', 'Ġto', 'Ġas', 'Ġbackground', 'Ġmusic', '.', 'Ġ', '<s>', 'ĠTraditional', 'Ġexamples', 'Ġof', 'Ġbackground', 'Ġmusic', 'Ġinclude', 'Ġmusic', 'Ġplayed', 'Ġat', 'Ġvarious', 'Ġsocial', 'Ġgatherings', 'Ġand', 'Ġmusic', 'Ġplayed', 'Ġin', 'Ġcertain', 'Ġretail', 'Ġvenues', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġalso', 'Ġcommon', 'Ġto', 'Ġemploy', 'Ġbackground', 'Ġmusic', 'Ġin', 'Ġvarious', 'Ġelectronic', 'Ġmedia', 'Ġincluding', 'Ġfilm', ',', 'Ġtelevision', ',', 'Ġvideo', 'Ġgames', ',', 'Ġand', 'ĠInternet', 'Ġvideos', 'Ġsuch', 'Ġas', 'Ġvideo', 'Ġblogs', '.', '<p>', 'ĠKant', 'rum', 'Ġ(', 'Th', 'ai', 'Ġ', 'à¸', 'ģ', 'à¸', '±', 'à¸', 'Ļ', 'à¸', 'ķ', 'à¸', '£', 'à¸', '¶', 'à¸', '¡', ')', 'Ġis', 'Ġa', 'Ġtype', 'Ġof', 'Ġfolk', 'Ġmusic', 'Ġplayed', 'Ġby', 'Ġthe', 'ĠKh', 'mer', 'Ġin', 'ĠIs', 'an', ',', 'ĠThailand', ',', 'Ġliving', 'Ġnear', 'Ġthe', 'Ġborder', 'Ġwith', 'ĠCambodia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġfast', ',', 'Ġtraditional', 'Ġdance', 'Ġmusic', '.', 'Ġ', '<s>', 'ĠIn', 'Ġits', 'Ġpure', 'st', 'Ġform', ',', 'Ġcho', '-', 'k', 'ant', 'rum', ',', 'Ġsingers', ',', 'Ġpercussion', 'Ġand', 'Ġf', 'iddles', 'Ġdominate', 'Ġthe', 'Ġsound', '.', 'Ġ', '<s>', 'ĠA', 'Ġmore', 'Ġmodern', 'Ġform', 'Ġusing', 'Ġelectric', 'Ġinstrument', 'ation', 'Ġarose', 'Ġin', 'Ġthe', 'Ġmid', '-', '1980', 's', '.', '<p>', 'ĠA', 'Ġchill', 'ador', 'Ġis', 'Ġa', 'Ġvery', 'Ġsmall', 'Ġguitar', '-', 'shaped', 'Ġfre', 'tted', 'Ġstring', 'ed', 'Ġinstrument', ',', 'Ġusually', 'Ġwith', 'Ġ10', ',', 'Ġ12', ',', 'Ġor', 'Ġ14', 'Ġmetal', 'Ġstrings', ',', 'Ġin', 'Ġpaired', 'Ġor', 'Ġtripled', 'Ġcourses', '.', 'It', 'Ġis', 'Ġplayed', 'Ġin', 'ĠPeru', 'Ġand', 'Ġin', 'Ġsome', 'Ġborder', 'Ġareas', 'Ġin', 'ĠBolivia', ',', 'Ġusually', 'Ġhas', 'Ġ5', 'Ġcourses', 'Ġlike', 'Ġits', 'Ġcousin', ',', 'Ġthe', 'Ġchar', 'ango', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsort', 'Ġof', 'Ġmusic', 'Ġplayed', 'Ġon', 'Ġchill', 'ador', 'Ġit', 'Ġis', 'Ġvery', 'Ġmuch', 'Ġlike', 'Ġthe', 'Ġmusic', 'Ġplayed', 'Ġon', 'Ġchar', 'ango', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmain', 'Ġdifference', 'Ġbetween', 'Ġchar', 'ango', 'Ġand', 'Ġchill', 'ador', 'Ġis', 'Ġthat', 'Ġthe', 'Ġchar', 'ango', 'Ġsound', 'box', 'Ġis', 'Ġmade', 'Ġof', 'Ġan', 'Ġarm', 'ad', 'illo', 'Ġshell', 'Ġwhile', 'Ġthe', 'Ġchill', 'ador', 'Ġis', 'Ġjust', 'Ġa', 'Ġlittle', 'Ġguitar', '.', '<p>', 'ĠDie', 'ĠRh', 'Ã¶', 'ner', 'ĠS', 'Ã¤', 'u', 'w', 'Ã¤', 'nt', 'z', 't', 'Ġare', 'Ġa', 'ĠSk', 'iff', 'le', '-', 'Bl', 'ues', 'band', 'Ġfrom', 'ĠE', 'ichen', 'z', 'ell', '-', 'L', 'Ã¼', 't', 'ter', 'Ġin', 'ĠH', 'essen', ',', 'ĠGermany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġline', '-', 'up', 'Ġconsists', 'Ġof', 'ĠMartin', 'ĠC', 'aba', ',', 'ĠChrist', 'oph', 'ĠG', 'Ã¼', 'nt', 'her', 'Ġand', 'ĠChrist', 'oph', 'ĠLe', 'ip', 'old', 'Ġplaying', 'ĠSk', 'iff', 'le', '-', 'Bl', 'ues', 'Ġwith', 'Ġlyrics', 'Ġbased', 'Ġon', 'ĠRh', 'Ã¶n', 'ĠMountains', 'Ġdialect', 'Ġand', 'Ġother', 'ĠHess', 'ian', 'Ġdialect', 's', 'Ġvarieties', '.', 'Ġ', '<s>', 'ĠThe', 'Ġexpression', 'Ġ\"', 'S', 'Ã¤', 'u', 'w', 'Ã¤', 'nt', 'z', 't', '\"', 'Ġmeans', 'Ġpork', 'Ġbelly', 'Ġand', 'Ġrefers', 'Ġalso', 'Ġto', 'Ġunt', 'idy', 'Ġor', 'Ġun', 'ruly', 'Ġchildren', 'Ġand', 'Ġyouth', '.', '<p>', 'ĠMinor', 'u', 'ĠK', 'oj', 'ima', 'Ġ(', 'born', 'Ġ11', 'ĠOctober', 'Ġ1968', ')', 'Ġwas', 'Ġthe', 'Ġoriginal', 'Ġguitarist', 'Ġfor', 'ĠJapanese', 'Ġexperimental', 'Ġpunk', 'Ġband', 'ĠThe', 'ĠMad', 'ĠCaps', 'ule', 'ĠMarkets', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġalso', 'Ġknown', 'Ġas', 'ĠScene', 'Ġor', 'ĠShin', 'ĠM', 'uro', 'h', 'ime', ',', 'Ġwhich', 'Ġis', 'Ġapparently', 'Ġa', 'Ġconglomer', 'ation', 'Ġof', 'Ġcharacters', 'Ġfrom', 'Ġthe', 'Ġnames', 'Ġof', 'Ġdifferent', 'ĠBo', 'Ã¸', 'wy', 'Ġmembers', '.', 'Ġ', '<s>', 'ĠHe', 'Ġstarted', 'ĠThe', 'ĠMad', 'ĠCaps', 'ule', 'ĠMarkets', 'Ġ(', 'which', 'Ġat', 'Ġthe', 'Ġtime', 'Ġwas', 'Ġcalled', 'ĠBer', 'rie', ')', 'Ġin', 'Ġ1985', ',', 'Ġwith', 'Ġvocal', 'ist', 'ĠHirosh', 'i', 'ĠKy', 'ono', ',', 'Ġin', 'Ġan', 'Ġattempt', 'Ġto', 'Ġcreate', 'Ġ\"', 'l', 'oud', ',', 'Ġpunk', 'Ġmusic', '\"', 'Ġafter', 'Ġbecoming', 'Ġ\"', 'b', 'ored', '\"', 'Ġwith', 'Ġmusic', 'Ġplayed', 'Ġon', 'Ġtelevision', 'Ġand', 'Ġradio', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġthe', 'Ġrelease', 'Ġof', 'ĠMad', \"'s\", 'ĠNo', 'Ã«', 'l', 'ĠCow', 'ard', 'Ġ\"', 'Human', 'ity', '\",', 'ĠMinor', 'u', 'Ġleft', 'Ġthe', 'Ġband', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'Ġ\"', 'support', 'Ġguitarist', '\"', 'ĠAi', 'ĠIsh', 'ig', 'aki', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1991', 'ĠMinor', 'u', 'Ġstarted', 'ĠDie', 'Ġin', 'ĠC', 'ries', 'Ġand', 'Ġin', 'Ġ1994', 'Ġbecame', 'Ġa', 'Ġmember', 'Ġof', 'ĠThe', 'ĠBloody', 'ĠIm', 'itation', 'ĠSociety', '.', 'Ġ', '<s>', 'ĠOver', 'Ġthe', 'Ġyears', 'ĠMinor', 'u', 'Ġworked', 'Ġwith', 'Ġmore', 'Ġbands', 'Ġand', 'Ġeven', 'Ġwent', 'Ġsolo', 'Ġfor', 'Ġa', 'Ġshort', 'Ġtime', 'Ġbefore', 'Ġreturning', 'Ġto', 'ĠMad', 'Ġto', 'Ġplay', 'Ġon', 'Ġ\"', 'Good', 'ĠDay', '\"', 'Ġfrom', 'Ġtheir', 'Ġalbum', 'Ġ\"', '010', '\"', 'Ġand', 'Ġplaying', 'Ġon', 'Ġtheir', 'Ġ\"', 'C', 'ist', 'm', 'ĠKon', 'fl', 'iq', 't', '\"', 'Ġtour', '.']\n",
      "lr:  tensor([5.2000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  What U.S Highway gives access to Zilpo Road, and is also known as Midland Trail?\n",
      "orig_answer_text:  US 60\n",
      "input:  ['<cls>', '<q>', 'C', 'ad', 'm', 'ium', 'ĠCh', 'lor', 'ide', 'Ġis', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġthis', 'Ġchemical', ',', 'Ġit', 'Ġis', 'Ġalso', 'Ġcalled', 'Ġwhat', '?', '</q>', '<p>', 'ĠCad', 'm', 'ium', 'Ġchloride', 'Ġis', 'Ġa', 'Ġwhite', 'Ġcrystall', 'ine', 'Ġcompound', 'Ġof', 'Ġcad', 'm', 'ium', 'Ġand', 'Ġchlorine', ',', 'Ġwith', 'Ġthe', 'Ġformula', 'ĠC', 'd', 'Cl', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġhy', 'gro', 'sc', 'opic', 'Ġsolid', 'Ġthat', 'Ġis', 'Ġhighly', 'Ġsoluble', 'Ġin', 'Ġwater', 'Ġand', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġalcohol', '.', 'Ġ', '<s>', 'ĠAlthough', 'Ġit', 'Ġis', 'Ġconsidered', 'Ġto', 'Ġbe', 'Ġion', 'ic', ',', 'Ġit', 'Ġhas', 'Ġconsiderable', 'Ġc', 'oval', 'ent', 'Ġcharacter', 'Ġto', 'Ġits', 'Ġbonding', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcrystal', 'Ġstructure', 'Ġof', 'Ġcad', 'm', 'ium', 'Ġchloride', 'Ġ(', 'described', 'Ġbelow', '),', 'Ġcomposed', 'Ġof', 'Ġtwo', '-', 'dimensional', 'Ġlayers', 'Ġof', 'Ġions', ',', 'Ġis', 'Ġa', 'Ġreference', 'Ġfor', 'Ġdescribing', 'Ġother', 'Ġcrystal', 'Ġstructures', '.', 'Ġ', '<s>', 'ĠAlso', 'Ġknown', 'Ġare', 'ĠC', 'd', 'Cl', 'âĢ¢', 'HO', 'Ġand', 'ĠC', 'd', 'Cl', 'âĢ¢', '5', 'HO', '.', '<p>', 'ĠWater', 'Ġblue', ',', 'Ġalso', 'Ġknown', 'Ġas', 'Ġan', 'il', 'ine', 'Ġblue', ',', 'ĠAcid', 'Ġblue', 'Ġ22', ',', 'ĠSol', 'uble', 'ĠBlue', 'Ġ3', 'M', ',', 'ĠMarine', 'ĠBlue', 'ĠV', ',', 'Ġor', 'ĠC', '.', 'I', '.', 'Ġ427', '55', ',', 'Ġis', 'Ġa', 'Ġchemical', 'Ġcompound', 'Ġused', 'Ġas', 'Ġa', 'Ġstain', 'Ġin', 'Ġhist', 'ology', '.', 'Ġ', '<s>', 'ĠWater', 'Ġblue', 'Ġstains', 'Ġcollagen', 'Ġblue', 'Ġin', 'Ġtissue', 'Ġsections', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġsoluble', 'Ġin', 'Ġwater', 'Ġand', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġethanol', '.', '<p>', 'ĠD', 'if', 'l', 'uc', 'ort', 'ol', 'one', 'Ġval', 'erate', 'Ġ(', 'also', 'Ġ\"', 'N', 'er', 'is', 'one', '\"', 'Ġcream', '/', 'o', 'ily', 'Ġcream', '/', 'ointment', ',', 'Ġ\"', 'N', 'er', 'ider', 'm', '\"', 'Ġo', 'int', 'ment', ',', 'ĠJapanese', 'ĠãĤ', '¸', 'ãĥķ', 'ãĥ«', 'ãĤ³', 'ãĥ«', 'ãĥĪ', 'ãĥŃ', 'ãĥ³', 'Ġ(', 'J', 'if', 'ur', 'uc', 'or', 'utor', 'on', 'Ġ)', 'Ġis', 'Ġa', 'Ġcort', 'ic', 'oster', 'oid', 'Ġrated', 'ĠClass', 'Ġ2', 'Ġ\"', 'pot', 'ent', '\"', 'Ġ(', '100', '-', '150', 'Ġtimes', ')', 'Ġin', 'Ġthe', 'ĠNew', 'ĠZealand', 'Ġtopical', 'Ġsteroid', 'Ġsystem', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġwhite', 'Ġto', 'Ġcreamy', 'Ġwhite', 'Ġcrystall', 'ine', 'Ġpowder', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġpractically', 'Ġinsol', 'uble', 'Ġin', 'Ġwater', ',', 'Ġfreely', 'Ġsoluble', 'Ġin', 'Ġdich', 'lor', 'omet', 'h', 'ane', 'Ġand', 'Ġin', 'Ġd', 'iox', 'an', ',', 'Ġsparing', 'ly', 'Ġsoluble', 'Ġin', 'Ġether', 'Ġand', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġmethyl', 'Ġalcohol', '.', 'Ġ', '<s>', 'ĠChem', 'ically', ',', 'Ġit', 'Ġis', 'Ġa', 'Ġcort', 'ic', 'oster', 'oid', 'Ġes', 'ter', 'ified', 'Ġwith', 'Ġval', 'eric', 'Ġacid', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġcommonly', 'Ġused', 'Ġtop', 'ically', 'Ġin', 'Ġdermat', 'ology', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbrand', 'Ġname', 'Ġis', 'ĠNer', 'is', 'one', ';', 'Ġits', 'Ġcre', 'ams', 'Ġcome', 'Ġin', 'Ġpot', 'encies', 'Ġof', 'Ġ0', '.', '1', '%', 'Ġand', 'Ġ0', '.', '3', '%.', '<p>', 'ĠHe', 'pt', 'ano', 'ic', 'Ġacid', ',', 'Ġalso', 'Ġcalled', 'Ġen', 'anth', 'ic', 'Ġacid', ',', 'Ġis', 'Ġan', 'Ġorganic', 'Ġcompound', 'Ġcomposed', 'Ġof', 'Ġa', 'Ġseven', '-', 'carbon', 'Ġchain', 'Ġterminating', 'Ġin', 'Ġa', 'Ġcar', 'box', 'y', 'lic', 'Ġacid', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġan', 'Ġoily', 'Ġliquid', 'Ġwith', 'Ġan', 'Ġunpleasant', ',', 'Ġranc', 'id', 'Ġodor', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontributes', 'Ġto', 'Ġthe', 'Ġodor', 'Ġof', 'Ġsome', 'Ġranc', 'id', 'Ġoils', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġwater', ',', 'Ġbut', 'Ġvery', 'Ġsoluble', 'Ġin', 'Ġethanol', 'Ġand', 'Ġether', '.', '<p>', 'ĠMag', 'nesium', 'Ġchloride', 'Ġis', 'Ġthe', 'Ġname', 'Ġfor', 'Ġthe', 'Ġchemical', 'Ġcompound', 'Ġwith', 'Ġthe', 'Ġformula', 'ĠM', 'g', 'Cl', 'Ġand', 'Ġits', 'Ġvarious', 'Ġhy', 'dr', 'ates', 'ĠM', 'g', 'Cl', '(', 'HO', ').', 'Ġ', '<s>', 'ĠThese', 'Ġsalts', 'Ġare', 'Ġtypical', 'Ġion', 'ic', 'Ġhal', 'ides', ',', 'Ġbeing', 'Ġhighly', 'Ġsoluble', 'Ġin', 'Ġwater', '.', 'Ġ', '<s>', 'ĠThe', 'Ġhyd', 'rated', 'Ġmagnesium', 'Ġchloride', 'Ġcan', 'Ġbe', 'Ġextracted', 'Ġfrom', 'Ġbr', 'ine', 'Ġor', 'Ġsea', 'Ġwater', '.', 'Ġ', '<s>', 'ĠIn', 'ĠNorth', 'ĠAmerica', ',', 'Ġmagnesium', 'Ġchloride', 'Ġis', 'Ġproduced', 'Ġprimarily', 'Ġfrom', 'ĠGreat', 'ĠSalt', 'ĠLake', 'Ġbr', 'ine', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġextracted', 'Ġin', 'Ġa', 'Ġsimilar', 'Ġprocess', 'Ġfrom', 'Ġthe', 'ĠDead', 'ĠSea', 'Ġin', 'Ġthe', 'ĠJordan', 'Ġvalley', '.', 'Ġ', '<s>', 'ĠMag', 'nesium', 'Ġchloride', ',', 'Ġas', 'Ġthe', 'Ġnatural', 'Ġmineral', 'Ġb', 'isch', 'of', 'ite', ',', 'Ġis', 'Ġalso', 'Ġextracted', 'Ġ(', 'via', 'Ġsolution', 'Ġmining', ')', 'Ġout', 'Ġof', 'Ġancient', 'Ġse', 'ab', 'eds', ';', 'Ġfor', 'Ġexample', ',', 'Ġthe', 'ĠZ', 'ech', 'stein', 'Ġse', 'ab', 'ed', 'Ġin', 'Ġnorthwest', 'ĠEurope', '.', 'Ġ', '<s>', 'ĠSome', 'Ġmagnesium', 'Ġchloride', 'Ġis', 'Ġmade', 'Ġfrom', 'Ġsolar', 'Ġev', 'ap', 'oration', 'Ġof', 'Ġseaw', 'ater', '.', 'Ġ', '<s>', 'ĠAn', 'hyd', 'rous', 'Ġmagnesium', 'Ġchloride', 'Ġis', 'Ġthe', 'Ġprincipal', 'Ġprecursor', 'Ġto', 'Ġmagnesium', 'Ġmetal', ',', 'Ġwhich', 'Ġis', 'Ġproduced', 'Ġon', 'Ġa', 'Ġlarge', 'Ġscale', '.', 'Ġ', '<s>', 'ĠHyd', 'rated', 'Ġmagnesium', 'Ġchloride', 'Ġis', 'Ġthe', 'Ġform', 'Ġmost', 'Ġreadily', 'Ġavailable', '.', '<p>', 'ĠEth', 'anol', ',', 'Ġalso', 'Ġcalled', 'Ġalcohol', ',', 'Ġeth', 'yl', 'Ġalcohol', ',', 'Ġand', 'Ġdrinking', 'Ġalcohol', ',', 'Ġis', 'Ġa', 'Ġcompound', 'Ġand', 'Ġsimple', 'Ġalcohol', 'Ġwith', 'Ġthe', 'Ġchemical', 'Ġformula', 'ĠC', '2', 'H', '5', 'OH', 'Ġ.', 'Ġ', '<s>', 'ĠIts', 'Ġformula', 'Ġcan', 'Ġbe', 'Ġwritten', 'Ġalso', 'Ġas', 'ĠCH', '3', 'ĠâĪĴ', 'CH', '2', 'ĠâĪĴ', 'OH', 'Ġor', 'ĠC', '2', 'H', '5', 'ĠâĪĴ', 'OH', 'Ġ(', 'an', 'Ġeth', 'yl', 'Ġgroup', 'Ġlinked', 'Ġto', 'Ġa', 'Ġhyd', 'rox', 'yl', 'Ġgroup', '),', 'Ġand', 'Ġis', 'Ġoften', 'Ġabbrevi', 'ated', 'Ġas', 'ĠEt', 'OH', '.', 'Ġ', '<s>', 'ĠEth', 'anol', 'Ġis', 'Ġa', 'Ġvolatile', ',', 'Ġfl', 'amm', 'able', ',', 'Ġcolor', 'less', 'Ġliquid', 'Ġwith', 'Ġa', 'Ġslight', 'Ġcharacteristic', 'Ġodor', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġused', 'Ġas', 'Ġa', 'Ġdrug', 'Ġand', 'Ġis', 'Ġthe', 'Ġprincipal', 'Ġtype', 'Ġof', 'Ġalcohol', 'Ġfound', 'Ġin', 'Ġalcoholic', 'Ġdrinks', '.', '<p>', 'ĠT', 'ribut', 'y', 'lt', 'in', 'Ġoxide', 'Ġ(', 'TB', 'TO', ')', 'Ġis', 'Ġan', 'Ġorgan', 'otin', 'Ġcompound', 'Ġchiefly', 'Ġused', 'Ġas', 'Ġa', 'Ġbi', 'ocide', 'Ġ(', 'f', 'ung', 'icide', 'Ġand', 'Ġm', 'oll', 'usc', 'icide', '),', 'Ġespecially', 'Ġa', 'Ġwood', 'Ġpres', 'ervative', '.', 'Ġ', '<s>', 'ĠIts', 'Ġchemical', 'Ġformula', 'Ġis', 'Ġ<', 'ce', '>[', '(', 'C', '4', 'H', '9', ')', '3', 'Sn', ']', '2', 'O', '</', 'ce', '>.', 'Ġ', '<s>', 'ĠIt', 'Ġhas', 'Ġthe', 'Ġform', 'Ġof', 'Ġa', 'Ġcolor', 'less', 'Ġto', 'Ġpale', 'Ġyellow', 'Ġliquid', 'Ġthat', 'Ġis', 'Ġonly', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġwater', 'Ġ(', '20', 'Ġppm', ')', 'Ġbut', 'Ġhighly', 'Ġsoluble', 'Ġin', 'Ġorganic', 'Ġsol', 'v', 'ents', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġpotent', 'Ġskin', 'Ġirrit', 'ant', '.', '<p>', 'ĠBenz', 'amide', 'Ġis', 'Ġan', 'Ġoff', '-', 'white', 'Ġsolid', 'Ġwith', 'Ġthe', 'Ġchemical', 'Ġformula', 'Ġof', 'ĠCH', 'CON', 'H', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġa', 'Ġderivative', 'Ġof', 'Ġben', 'zo', 'ic', 'Ġacid', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġslightly', 'Ġsoluble', 'Ġin', 'Ġwater', ',', 'Ġand', 'Ġsoluble', 'Ġin', 'Ġmany', 'Ġorganic', 'Ġsol', 'v', 'ents', '.', '<p>', 'ĠGold', '(', 'III', ')', 'Ġchloride', ',', 'Ġtraditionally', 'Ġcalled', 'Ġaur', 'ic', 'Ġchloride', ',', 'Ġis', 'Ġa', 'Ġchemical', 'Ġcompound', 'Ġof', 'Ġgold', 'Ġand', 'Ġchlorine', '.', 'Ġ', '<s>', 'ĠWith', 'Ġthe', 'Ġmolecular', 'Ġformula', 'ĠAu', 'Cl', ',', 'Ġthe', 'Ġname', 'Ġgold', 'Ġtr', 'ich', 'lor', 'ide', 'Ġis', 'Ġa', 'Ġsimpl', 'ification', ',', 'Ġreferring', 'Ġto', 'Ġthe', 'Ġempirical', 'Ġformula', ',', 'ĠAu', 'Cl', '.', 'Ġ', '<s>', 'ĠThe', 'ĠRoman', 'Ġnumer', 'als', 'Ġin', 'Ġthe', 'Ġname', 'Ġindicate', 'Ġthat', 'Ġthe', 'Ġgold', 'Ġhas', 'Ġan', 'Ġoxidation', 'Ġstate', 'Ġof', 'Ġ+', '3', ',', 'Ġwhich', 'Ġis', 'Ġcommon', 'Ġfor', 'Ġgold', 'Ġcompounds', '.', 'Ġ', '<s>', 'ĠThere', 'Ġis', 'Ġalso', 'Ġanother', 'Ġrelated', 'Ġchloride', 'Ġof', 'Ġgold', ',', 'Ġgold', '(', 'I', ')', 'Ġchloride', 'Ġ(', 'A', 'u', 'Cl', ').', 'Ġ', '<s>', 'ĠCh', 'lor', 'o', 'aur', 'ic', 'Ġacid', ',', 'ĠHA', 'u', 'Cl', ',', 'Ġthe', 'Ġproduct', 'Ġformed', 'Ġwhen', 'Ġgold', 'Ġdiss', 'olves', 'Ġin', 'Ġaqu', 'a', 'Ġreg', 'ia', ',', 'Ġis', 'Ġsometimes', 'Ġreferred', 'Ġto', 'Ġas', 'Ġ\"', 'gold', 'Ġchloride', '\"', 'Ġor', 'Ġ\"', 'acid', 'Ġgold', 'Ġtr', 'ich', 'lor', 'ide', '\".', 'Ġ', '<s>', 'ĠGold', '(', 'III', ')', 'Ġchloride', 'Ġis', 'Ġvery', 'Ġhy', 'gro', 'sc', 'opic', 'Ġand', 'Ġhighly', 'Ġsoluble', 'Ġin', 'Ġwater', 'Ġas', 'Ġwell', 'Ġas', 'Ġethanol', '.', 'Ġ', '<s>', 'ĠIt', 'Ġdecom', 'poses', 'Ġabove', 'Ġ160', 'Âł', 'Â°', 'C', 'Ġor', 'Ġin', 'Ġlight', '.', '<p>', 'ĠThe', 'Ġchloride', 'Ġion', 'Ġis', 'Ġthe', 'Ġan', 'ion', 'Ġ(', 'neg', 'atively', 'Ġcharged', 'Ġion', ')', 'ĠCl', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġformed', 'Ġwhen', 'Ġthe', 'Ġelement', 'Ġchlorine', 'Ġ(', 'a', 'Ġhal', 'ogen', ')', 'Ġgains', 'Ġan', 'Ġelectron', 'Ġor', 'Ġwhen', 'Ġa', 'Ġcompound', 'Ġsuch', 'Ġas', 'Ġhydrogen', 'Ġchloride', 'Ġis', 'Ġdissolved', 'Ġin', 'Ġwater', 'Ġor', 'Ġother', 'Ġpolar', 'Ġsol', 'v', 'ents', '.', 'Ġ', '<s>', 'ĠCh', 'lor', 'ide', 'Ġsalts', 'Ġsuch', 'Ġas', 'Ġsodium', 'Ġchloride', 'Ġare', 'Ġoften', 'Ġvery', 'Ġsoluble', 'Ġin', 'Ġwater', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġan', 'Ġessential', 'Ġelectroly', 'te', 'Ġlocated', 'Ġin', 'Ġall', 'Ġbody', 'Ġfluids', 'Ġresponsible', 'Ġfor', 'Ġmaintaining', 'Ġacid', '/', 'base', 'Ġbalance', ',', 'Ġtransmitting', 'Ġnerve', 'Ġimpulses', 'Ġand', 'Ġregulating', 'Ġfluid', 'Ġin', 'Ġand', 'Ġout', 'Ġof', 'Ġcells', '.', 'Ġ', '<s>', 'ĠLess', 'Ġfrequently', ',', 'Ġthe', 'Ġword', 'Ġ\"', 'chlor', 'ide', '\"', 'Ġmay', 'Ġalso', 'Ġform', 'Ġpart', 'Ġof', 'Ġthe', 'Ġ\"', 'common', '\"', 'Ġname', 'Ġof', 'Ġchemical', 'Ġcompounds', 'Ġin', 'Ġwhich', 'Ġone', 'Ġor', 'Ġmore', 'Ġchlorine', 'Ġatoms', 'Ġare', 'Ġc', 'oval', 'ently', 'Ġbonded', '.', 'Ġ', '<s>', 'ĠFor', 'Ġexample', ',', 'Ġmethyl', 'Ġchloride', ',', 'Ġwith', 'Ġthe', 'Ġstandard', 'Ġname', 'Ġchlor', 'omet', 'h', 'ane', 'Ġ(', 'see', 'ĠI', 'UP', 'AC', 'Ġbooks', ')', 'Ġis', 'Ġan', 'Ġorganic', 'Ġcompound', 'Ġwith', 'Ġa', 'Ġc', 'oval', 'ent', 'ĠC', 'âĪĴ', 'Cl', 'Ġbond', 'Ġin', 'Ġwhich', 'Ġthe', 'Ġchlorine', 'Ġis', 'Ġnot', 'Ġan', 'Ġan', 'ion', '.']\n",
      "lr:  tensor([5.2000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring.\n",
      "orig_answer_text:  Badr Hari\n",
      "orig_answer_text:  Badr Hari\n",
      "input:  ['<cls>', '<q>', 'Mus', 'ician', 'Ġand', 'Ġsatir', 'ist', 'ĠAll', 'ie', 'ĠGo', 'ert', 'z', 'Ġwrote', 'Ġa', 'Ġsong', 'Ġabout', 'Ġthe', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġcharacter', 'ĠMil', 'house', ',', 'Ġwho', 'ĠMatt', 'ĠGro', 'ening', 'Ġnamed', 'Ġafter', 'Ġwho', '?', '</q>', '<p>', 'ĠLisa', 'ĠMarie', 'ĠSimpson', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġin', 'Ġthe', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠSimpsons', '\".', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġthe', 'Ġmiddle', 'Ġchild', 'Ġand', 'Ġmost', 'Ġintelligent', 'Ġof', 'Ġthe', 'ĠSimpson', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠVo', 'iced', 'Ġby', 'ĠYe', 'ard', 'ley', 'ĠSmith', ',', 'ĠLisa', 'Ġfirst', 'Ġappeared', 'Ġon', 'Ġtelevision', 'Ġin', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġshort', 'Ġ\"', 'Good', 'ĠNight', '\"', 'Ġon', 'ĠApril', 'Ġ19', ',', 'Ġ1987', '.', 'Ġ', '<s>', 'ĠCartoon', 'ist', 'ĠMatt', 'ĠGro', 'ening', 'Ġcreated', 'Ġand', 'Ġdesigned', 'Ġher', 'Ġwhile', 'Ġwaiting', 'Ġto', 'Ġmeet', 'ĠJames', 'ĠL', '.', 'ĠBrooks', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġhad', 'Ġbeen', 'Ġinvited', 'Ġto', 'Ġpitch', 'Ġa', 'Ġseries', 'Ġof', 'Ġshorts', 'Ġbased', 'Ġon', 'Ġhis', 'Ġcomic', 'Ġ\"', 'Life', 'Ġin', 'ĠHell', '\",', 'Ġbut', 'Ġinstead', 'Ġdecided', 'Ġto', 'Ġcreate', 'Ġa', 'Ġnew', 'Ġset', 'Ġof', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠHe', 'Ġnamed', 'Ġthe', 'Ġelder', 'ĠSimpson', 'Ġdaughter', 'Ġafter', 'Ġhis', 'Ġyounger', 'Ġsister', 'ĠLisa', 'ĠGro', 'ening', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġappearing', 'Ġon', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġfor', 'Ġthree', 'Ġyears', ',', 'Ġthe', 'ĠSimpson', 'Ġfamily', 'Ġwere', 'Ġmoved', 'Ġto', 'Ġtheir', 'Ġown', 'Ġseries', 'Ġon', 'ĠFox', ',', 'Ġwhich', 'Ġdebuted', 'Ġon', 'ĠDecember', 'Ġ17', ',', 'Ġ1989', '.', '<p>', 'ĠMar', 'j', 'orie', 'ĠJacqu', 'eline', 'Ġ\"', 'M', 'arge', '\"', 'ĠSimpson', 'Ġ(', 'n', 'Ã©e', 'ĠBou', 'vier', ')', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġin', 'Ġthe', 'ĠAmerican', 'Ġanimated', 'Ġsitcom', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġand', 'Ġpart', 'Ġof', 'Ġthe', 'Ġep', 'onymous', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġvoiced', 'Ġby', 'ĠJulie', 'ĠK', 'av', 'ner', 'Ġand', 'Ġfirst', 'Ġappeared', 'Ġon', 'Ġtelevision', 'Ġin', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġshort', 'Ġ\"', 'Good', 'ĠNight', '\"', 'Ġon', 'ĠApril', 'Ġ19', ',', 'Ġ1987', '.', 'Ġ', '<s>', 'ĠM', 'arge', 'Ġwas', 'Ġcreated', 'Ġand', 'Ġdesigned', 'Ġby', 'Ġcartoon', 'ist', 'ĠMatt', 'ĠGro', 'ening', 'Ġwhile', 'Ġhe', 'Ġwas', 'Ġwaiting', 'Ġin', 'Ġthe', 'Ġlobby', 'Ġof', 'ĠJames', 'ĠL', '.', 'ĠBrooks', \"'\", 'Ġoffice', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġhad', 'Ġbeen', 'Ġcalled', 'Ġto', 'Ġpitch', 'Ġa', 'Ġseries', 'Ġof', 'Ġshorts', 'Ġbased', 'Ġon', 'Ġ\"', 'Life', 'Ġin', 'ĠHell', '\"', 'Ġbut', 'Ġinstead', 'Ġdecided', 'Ġto', 'Ġcreate', 'Ġa', 'Ġnew', 'Ġset', 'Ġof', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠHe', 'Ġnamed', 'Ġthe', 'Ġcharacter', 'Ġafter', 'Ġhis', 'Ġmother', 'ĠMargaret', 'ĠGro', 'ening', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġappearing', 'Ġon', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġfor', 'Ġthree', 'Ġseasons', ',', 'Ġthe', 'ĠSimpson', 'Ġfamily', 'Ġreceived', 'Ġtheir', 'Ġown', 'Ġseries', 'Ġon', 'ĠFox', ',', 'Ġwhich', 'Ġdebuted', 'ĠDecember', 'Ġ17', ',', 'Ġ1989', '.', '<p>', 'ĠBarth', 'ol', 'omew', 'ĠJo', 'Jo', 'Ġ\"', 'B', 'art', '\"', 'ĠSimpson', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġin', 'Ġthe', 'ĠAmerican', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġand', 'Ġpart', 'Ġof', 'Ġthe', 'ĠSimpson', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġvoiced', 'Ġby', 'ĠNancy', 'ĠCart', 'wright', 'Ġand', 'Ġfirst', 'Ġappeared', 'Ġon', 'Ġtelevision', 'Ġin', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġshort', 'Ġ\"', 'Good', 'ĠNight', '\"', 'Ġon', 'ĠApril', 'Ġ19', ',', 'Ġ1987', '.', 'Ġ', '<s>', 'ĠCartoon', 'ist', 'ĠMatt', 'ĠGro', 'ening', 'Ġcreated', 'Ġand', 'Ġdesigned', 'ĠBart', 'Ġwhile', 'Ġwaiting', 'Ġin', 'Ġthe', 'Ġlobby', 'Ġof', 'ĠJames', 'ĠL', '.', 'ĠBrooks', \"'\", 'Ġoffice', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġhad', 'Ġbeen', 'Ġcalled', 'Ġto', 'Ġpitch', 'Ġa', 'Ġseries', 'Ġof', 'Ġshorts', 'Ġbased', 'Ġon', 'Ġhis', 'Ġcomic', 'Ġstrip', ',', 'Ġ\"', 'Life', 'Ġin', 'ĠHell', '\",', 'Ġbut', 'Ġinstead', 'Ġdecided', 'Ġto', 'Ġcreate', 'Ġa', 'Ġnew', 'Ġset', 'Ġof', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠWhile', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġcharacters', 'Ġwere', 'Ġnamed', 'Ġafter', 'ĠGro', 'ening', \"'s\", 'Ġfamily', 'Ġmembers', ',', 'ĠBart', \"'s\", 'Ġname', 'Ġis', 'Ġan', 'Ġan', 'agram', 'Ġof', 'Ġthe', 'Ġword', 'Ġ\"', 'br', 'at', '\".', 'Ġ', '<s>', 'ĠAfter', 'Ġappearing', 'Ġon', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġfor', 'Ġthree', 'Ġyears', ',', 'Ġthe', 'ĠSimpson', 'Ġfamily', 'Ġreceived', 'Ġits', 'Ġown', 'Ġseries', 'Ġon', 'ĠFox', ',', 'Ġwhich', 'Ġdebuted', 'ĠDecember', 'Ġ17', ',', 'Ġ1989', '.', '<p>', 'ĠAllison', 'ĠBeth', 'Ġ\"', 'All', 'ie', '\"', 'ĠGo', 'ert', 'z', 'Ġ(', 'born', 'ĠMarch', 'Ġ2', ',', 'Ġ1991', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġmusician', '.', 'Ġ', '<s>', 'ĠGo', 'ert', 'z', 'Ġis', 'Ġknown', 'Ġfor', 'Ġher', 'Ġsatirical', 'Ġsongs', 'Ġbased', 'Ġon', 'Ġvarious', 'Ġpop', 'Ġculture', 'Ġtopics', '.', 'Ġ', '<s>', 'ĠHer', 'Ġvideos', 'Ġare', 'Ġposted', 'Ġon', 'ĠYouTube', 'Ġunder', 'Ġthe', 'Ġname', 'Ġof', 'ĠC', 'oss', 'bys', 'we', 'ater', '.', 'Ġ', '<s>', 'ĠSubjects', 'Ġof', 'Ġher', 'Ġsongs', 'Ġhave', 'Ġincluded', 'Ġthe', 'Ġfilm', 'Ġ\"', 'The', 'ĠRoom', '\",', 'Ġthe', 'Ġcharacter', 'ĠMil', 'house', 'Ġfrom', 'Ġthe', 'Ġtelevision', 'Ġshow', 'Ġ\"', 'The', 'ĠSimpsons', '\",', 'Ġand', 'Ġthe', 'Ġgame', 'ĠDungeons', 'Ġ&', 'ĠDragons', '.', 'Ġ', '<s>', 'ĠHer', 'Ġstyle', 'Ġhas', 'Ġbeen', 'Ġcompared', 'Ġto', 'Ġthat', 'Ġof', 'ĠBo', 'ĠBurn', 'ham', '.', 'Ġ', '<s>', 'ĠIn', 'ĠDecember', 'Ġ2015', ',', 'ĠGo', 'ert', 'z', 'Ġreleased', 'Ġa', 'Ġconcept', 'Ġalbum', 'Ġbased', 'Ġon', 'Ġthe', 'ĠAdult', 'ĠSwim', 'Ġseries', 'Ġ\"', 'Rick', 'Ġand', 'ĠMorty', '\",', 'Ġ\"', 'Sad', 'ĠDance', 'ĠSongs', '\",', 'Ġwith', 'Ġthe', 'Ġalbum', \"'s\", 'Ġcover', 'Ġem', 'ulating', 'Ġthe', 'Ġanimation', 'Ġand', 'Ġlogo', 'Ġof', 'Ġthe', 'Ġseries', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġmade', 'Ġpossible', 'Ġthrough', 'ĠKickstarter', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġco', '-', 'host', 'Ġof', 'ĠEverything', \"'s\", 'ĠComing', 'ĠUp', 'ĠPodcast', ',', 'Ġa', 'ĠSimpsons', '-', 'focused', 'Ġpodcast', 'Ġalong', 'Ġwith', 'ĠJulia', 'ĠPrescott', '.', '<p>', 'ĠMil', 'house', 'ĠMuss', 'olini', 'Ġvan', 'ĠH', 'out', 'en', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġfeatured', 'Ġin', 'Ġthe', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠSimpsons', '\",', 'Ġvoiced', 'Ġby', 'ĠPamela', 'ĠHayden', ',', 'Ġand', 'Ġcreated', 'Ġby', 'ĠMatt', 'ĠGro', 'ening', 'Ġwho', 'Ġnamed', 'Ġthe', 'Ġcharacter', 'Ġafter', 'ĠPresident', 'ĠRichard', 'ĠNixon', \"'s\", 'Ġmiddle', 'Ġname', '.', 'Ġ', '<s>', 'ĠLater', 'Ġin', 'Ġthe', 'Ġseries', ',', 'Ġit', 'Ġis', 'Ġrevealed', 'Ġthat', 'ĠMil', 'house', \"'s\", 'Ġmiddle', 'Ġname', 'Ġis', 'Ġ\"', 'M', 'uss', 'olini', '.\"', '<p>', 'ĠLos', 'ĠAngeles', 'ĠReader', 'Ġwas', 'Ġa', 'Ġweekly', 'Ġpaper', 'Ġestablished', 'Ġin', 'Ġ1978', 'Ġand', 'Ġdistributed', 'Ġin', 'ĠLos', 'ĠAngeles', ',', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠIt', 'Ġfollowed', 'Ġthe', 'Ġformat', 'Ġof', 'Ġthe', 'Ġ(', 'still', 'Ġactive', ')', 'ĠChicago', 'ĠReader', '.', 'Ġ', '<s>', 'ĠThe', 'Ġpaper', 'Ġwas', 'Ġknown', 'Ġfor', 'Ġhaving', 'Ġlengthy', ',', 'Ġthoughtful', 'Ġreviews', 'Ġof', 'Ġmovies', ',', 'Ġplays', 'Ġand', 'Ġconcerts', 'Ġin', 'Ġthe', 'ĠLA', 'Ġarea', '.', 'Ġ', '<s>', 'ĠJames', 'ĠV', 'owell', 'Ġwas', 'Ġits', 'Ġfounding', 'Ġeditor', '.', 'Ġ', '<s>', 'ĠAmong', 'Ġits', 'Ġwriters', 'Ġwere', 'ĠKeith', 'ĠFitzgerald', ',', 'ĠNig', 'ey', 'ĠLennon', ',', 'ĠLionel', 'ĠR', 'olf', 'e', ',', 'ĠLawrence', 'ĠWe', 'ch', 's', 'ler', ',', 'ĠMick', 'ĠFar', 'ren', ',', 'ĠRichard', 'ĠMelt', 'zer', ',', 'ĠHeidi', 'ĠD', 'vor', 'ak', ',', 'ĠChris', 'ĠMorris', ',', 'ĠJerry', 'ĠSt', 'ahl', ',', 'ĠSteven', 'ĠKane', ',', 'ĠAndy', 'ĠKlein', ',', 'ĠAllen', 'ĠLevy', ',', 'ĠJim', 'ĠG', 'oad', ',', 'ĠKirk', 'ĠSil', 's', 'bee', ',', 'ĠHenry', 'ĠShe', 'e', 'han', ',', 'ĠSamantha', 'ĠDunn', ',', 'ĠNatalie', 'ĠNichols', ',', 'ĠSteve', 'ĠApple', 'ford', ',', 'ĠEric', 'ĠM', 'ank', 'in', 'Ġ(', 'also', 'Ġeditor', '),', 'ĠPaul', 'ĠBir', 'chall', ',', 'ĠEddie', 'ĠRivera', 'Ġ(', 'who', 'Ġwrote', 'Ġthe', 'Ġpaper', \"'s\", 'Ġfirst', 'Ġcover', 'Ġstory', '),', 'ĠAmy', 'ĠStein', 'berg', ',', 'ĠHarry', 'ĠShe', 'e', 'han', ',', 'ĠDan', 'ĠS', 'all', 'it', ',', 'ĠMy', 'ron', 'ĠMe', 'isel', ',', 'ĠDavid', 'ĠEh', 'ren', 'stein', '.', 'Ġ', '<s>', 'ĠTom', 'ĠDavis', ',', 'ĠBruce', 'ĠBe', 'bb', ',', 'ĠStuart', 'ĠGoldman', ',', 'ĠErnest', 'ĠHardy', ',', 'ĠKevin', 'ĠUh', 'rich', ',', 'ĠErik', 'ĠH', 'imm', 'els', 'bach', 'Ġand', 'ĠDavid', 'ĠL', '.', 'ĠU', 'lin', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġbeing', 'Ġthe', 'Ġfirst', 'Ġnewspaper', 'Ġto', 'Ġpublish', 'ĠMatt', 'ĠGro', 'ening', \"'s\", 'Ġcartoon', 'Ġstrip', ',', 'ĠLife', 'Ġin', 'ĠHell', 'Ġon', 'ĠApril', 'Ġ25', ',', 'Ġ1980', '.', 'Ġ', '<s>', 'ĠJames', 'ĠV', 'owell', 'Ġhired', 'ĠMatt', 'ĠGro', 'ening', 'Ġas', 'Ġhis', 'Ġassistant', 'Ġeditor', 'Ġin', 'Ġ1979', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġwas', 'Ġalso', 'Ġoriginally', 'Ġa', 'ĠReader', 'Ġmusic', 'Ġcritic', '.', 'Ġ', '<s>', 'ĠIt', 'Ġalso', 'Ġran', 'Ġa', 'Ġcartoon', 'Ġstrip', 'Ġby', 'ĠDavid', 'ĠLynch', 'Ġ(', 'director', 'Ġof', 'ĠBlue', 'ĠVelvet', ')', 'Ġcalled', 'ĠThe', 'ĠAng', 'ri', 'est', 'ĠDog', 'Ġin', 'Ġthe', 'ĠWorld', ',', 'Ġa', 'Ġstrip', 'Ġnotable', 'Ġfor', 'Ġhaving', 'Ġexactly', 'Ġthe', 'Ġsame', 'Ġdrawing', 'Ġpanels', 'Ġfor', 'Ġits', 'Ġentire', 'Ġrun', '.', 'Ġ', '<s>', 'ĠJames', 'ĠV', 'owell', 'Ġand', 'Ġhis', 'Ġwife', 'ĠCod', 'ette', 'ĠWallace', 'Ġbought', 'Ġthe', 'ĠReader', 'Ġfrom', 'Ġthe', 'ĠChicago', 'ĠReader', 'Ġin', 'ĠFebruary', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠThey', 'Ġsold', 'Ġ\"', 'The', 'ĠReader', '\"', 'Ġto', 'ĠNew', 'ĠTimes', 'ĠMedia', 'Ġin', 'Ġ1996', ',', 'Ġwhich', 'Ġmerged', 'Ġit', 'Ġwith', 'Ġthe', 'Ġ\"', 'Los', 'ĠAngeles', 'ĠView', '\"', 'Ġto', 'Ġform', 'Ġ\"', 'New', 'ĠTimes', 'ĠLA', '\".', '<p>', 'ĠHomer', 'ĠJay', 'ĠSimpson', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġand', 'Ġthe', 'Ġmain', 'Ġprotagonist', 'Ġof', 'Ġthe', 'ĠAmerican', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġas', 'Ġthe', 'Ġpatriarch', 'Ġof', 'Ġthe', 'Ġep', 'onymous', 'Ġfamily', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġvoiced', 'Ġby', 'ĠDan', 'ĠCast', 'ell', 'an', 'eta', 'Ġand', 'Ġfirst', 'Ġappeared', 'Ġon', 'Ġtelevision', ',', 'Ġalong', 'Ġwith', 'Ġthe', 'Ġrest', 'Ġof', 'Ġhis', 'Ġfamily', ',', 'Ġin', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġshort', 'Ġ\"', 'Good', 'ĠNight', '\"', 'Ġon', 'ĠApril', 'Ġ19', ',', 'Ġ1987', '.', 'Ġ', '<s>', 'ĠHomer', 'Ġwas', 'Ġcreated', 'Ġand', 'Ġdesigned', 'Ġby', 'Ġcartoon', 'ist', 'ĠMatt', 'ĠGro', 'ening', 'Ġwhile', 'Ġhe', 'Ġwas', 'Ġwaiting', 'Ġin', 'Ġthe', 'Ġlobby', 'Ġof', 'ĠJames', 'ĠL', '.', 'ĠBrooks', \"'\", 'Ġoffice', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġhad', 'Ġbeen', 'Ġcalled', 'Ġto', 'Ġpitch', 'Ġa', 'Ġseries', 'Ġof', 'Ġshorts', 'Ġbased', 'Ġon', 'Ġhis', 'Ġcomic', 'Ġstrip', 'Ġ\"', 'Life', 'Ġin', 'ĠHell', '\"', 'Ġbut', 'Ġinstead', 'Ġdecided', 'Ġto', 'Ġcreate', 'Ġa', 'Ġnew', 'Ġset', 'Ġof', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠHe', 'Ġnamed', 'Ġthe', 'Ġcharacter', 'Ġafter', 'Ġhis', 'Ġfather', ',', 'ĠHomer', 'ĠGro', 'ening', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġappearing', 'Ġfor', 'Ġthree', 'Ġseasons', 'Ġon', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\",', 'Ġthe', 'ĠSimpson', 'Ġfamily', 'Ġgot', 'Ġtheir', 'Ġown', 'Ġseries', 'Ġon', 'ĠFox', 'Ġthat', 'Ġdebuted', 'ĠDecember', 'Ġ17', ',', 'Ġ1989', '.', '<p>', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġanimated', 'Ġtelevision', 'Ġsitcom', 'Ġcreated', 'Ġby', 'ĠMatt', 'ĠGro', 'ening', 'Ġfor', 'Ġthe', 'ĠFox', 'ĠBroadcasting', 'ĠCompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', 'Ġis', 'Ġa', 'Ġsatirical', 'Ġparody', 'Ġof', 'Ġa', 'Ġmiddle', 'Ġclass', 'ĠAmerican', 'Ġlifestyle', 'Ġepit', 'om', 'ized', 'Ġby', 'Ġits', 'Ġep', 'onymous', 'Ġfamily', ',', 'Ġwhich', 'Ġconsists', 'Ġof', 'ĠHomer', ',', 'ĠM', 'arge', ',', 'ĠBart', ',', 'ĠLisa', 'Ġand', 'ĠMaggie', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġset', 'Ġin', 'Ġthe', 'Ġfictional', 'Ġtown', 'Ġof', 'ĠSpringfield', ',', 'Ġand', 'Ġlamp', 'oons', 'ĠAmerican', 'Ġculture', ',', 'Ġsociety', 'Ġand', 'Ġtelevision', ',', 'Ġand', 'Ġmany', 'Ġaspects', 'Ġof', 'Ġthe', 'Ġhuman', 'Ġcondition', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfamily', 'Ġwas', 'Ġconceived', 'Ġby', 'ĠGro', 'ening', 'Ġshortly', 'Ġbefore', 'Ġa', 'Ġpitch', 'Ġfor', 'Ġa', 'Ġseries', 'Ġof', 'Ġanimated', 'Ġshorts', 'Ġwith', 'Ġproducer', 'ĠJames', 'ĠL', '.', 'Âł', 'Bro', 'oks', '.', 'Ġ', '<s>', 'ĠGro', 'ening', 'Ġcreated', 'Ġa', 'Ġdysfunctional', 'Ġfamily', 'Ġand', 'Ġnamed', 'Ġthe', 'Ġcharacters', 'Ġafter', 'Ġmembers', 'Ġof', 'Ġhis', 'Ġown', 'Ġfamily', ',', 'Ġsubstit', 'uting', 'ĠBart', 'Ġfor', 'Ġhis', 'Ġown', 'Ġname', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshorts', 'Ġbecame', 'Ġa', 'Ġpart', 'Ġof', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġon', 'ĠApril', 'Ġ19', ',', 'Ġ1987', 'Ġand', 'Ġafter', 'Ġa', 'Ġthree', '-', 'season', 'Ġrun', ',', 'Ġthe', 'Ġsketch', 'Ġwas', 'Ġdeveloped', 'Ġinto', 'Ġa', 'Ġhalf', '-', 'hour', 'Ġprime', 'Ġtime', 'Ġshow', 'Ġand', 'Ġbecame', 'Ġa', 'Ġhit', 'Ġseries', 'Ġfor', 'ĠFox', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgrowing', 'Ġpopularity', 'Ġof', 'Ġthe', 'Ġseries', 'Ġmotivated', 'Ġvideo', 'Ġgame', 'Ġdevelopers', 'Ġto', 'Ġcreate', 'Ġvideo', 'Ġgames', 'Ġbased', 'Ġon', 'Ġthe', 'Ġseries', '.', 'Ġ', '<s>', 'ĠTwo', 'Ġpin', 'ball', 'Ġmachines', 'Ġhave', 'Ġalso', 'Ġbeen', 'Ġproduced', ';', 'Ġone', 'Ġself', '-', 't', 'itled', ',', 'Ġthat', 'Ġwas', 'Ġonly', 'Ġmade', 'Ġavailable', 'Ġfor', 'Ġa', 'Ġlimited', 'Ġtime', 'Ġafter', 'Ġthe', 'Ġfirst', 'Ġseason', 'Ġfinale', 'Ġ(', '1990', ')', 'Ġand', 'Ġ\"', 'The', 'ĠSimpsons', 'ĠPinball', 'ĠParty', '\"', 'Ġ(', '2003', ').', 'Ġ', '<s>', 'ĠAdditionally', ',', 'Ġseveral', 'Ġhandheld', 'Ġdevice', 'Ġgames', 'Ġhave', 'Ġbeen', 'Ġreleased', ',', 'Ġsuch', 'Ġas', 'Ġ\"', 'B', 'art', 'man', ':', 'ĠAvenger', 'Ġof', 'ĠEvil', '\"', 'Ġ(', '1990', ')', 'Ġand', 'Ġ\"', 'B', 'art', 'ĠSimpson', \"'s\", 'ĠCup', 'cake', 'ĠCrisis', '\"', 'Ġ(', '1991', ').', '<p>', 'ĠThe', 'ĠSimpsons', ':', 'ĠAn', 'ĠUnc', 'ens', 'ored', ',', 'ĠUn', 'authorized', 'ĠHistory', 'Ġis', 'Ġa', 'Ġnon', '-', 'fiction', 'Ġbook', 'Ġabout', 'Ġthe', 'ĠAmerican', 'Ġanimated', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'The', 'ĠSimpsons', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠJohn', 'ĠOrt', 'ved', ',', 'Ġand', 'Ġfirst', 'Ġpublished', 'Ġin', 'ĠOctober', 'Ġ2009', 'Ġby', 'ĠFab', 'er', 'Ġand', 'ĠFab', 'er', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'ĠUnited', 'ĠKingdom', ',', 'Ġthe', 'Ġbook', 'Ġis', 'Ġcalled', 'ĠSimpsons', 'ĠConf', 'idential', ':', 'ĠThe', 'Ġunc', 'ens', 'ored', ',', 'Ġtotally', 'Ġun', 'author', 'ised', 'Ġhistory', 'Ġof', 'Ġthe', 'Ġworld', \"'s\", 'Ġgreatest', 'ĠTV', 'Ġshow', 'Ġby', 'Ġthe', 'Ġpeople', 'Ġthat', 'Ġmade', 'Ġit', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbook', 'Ġis', 'Ġan', 'Ġoral', 'Ġhistory', 'Ġof', 'Ġthe', 'Ġshow', ',', 'Ġand', 'Ġconcent', 'rates', 'Ġparticularly', 'Ġon', 'Ġthe', 'Ġwriters', 'Ġand', 'Ġproducers', 'Ġof', 'Ġthe', 'Ġshow', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbook', 'Ġincludes', 'Ġentire', 'Ġchapters', 'Ġdevoted', 'Ġto', 'Ġkey', 'Ġfigures', 'Ġsuch', 'Ġas', 'Ġcreator', 'ĠMatt', 'ĠGro', 'ening', 'Ġand', 'ĠJames', 'ĠL', '.', 'ĠBrooks', 'Ġand', 'ĠSam', 'ĠSimon', ',', 'Ġwho', 'Ġhelped', 'Ġdevelop', 'Ġthe', 'Ġseries', '.', 'Ġ', '<s>', 'ĠAccording', 'Ġto', 'ĠNational', 'ĠPublic', 'ĠRadio', 'Ġreviewer', 'ĠLinda', 'ĠHolmes', ',', 'Ġ\"', 'Or', 't', 'ved', \"'s\", 'Ġthesis', ',', 'Ġessentially', ',', 'Ġis', 'Ġthat', 'Ġlots', 'Ġof', 'Ġpeople', 'Ġare', 'Ġresponsible', 'Ġfor', 'Ġthe', 'Ġsuccess', 'Ġof', 'Ġ\"', 'The', 'ĠSimpsons', '\",', 'Ġand', 'Ġtheir', 'Ġcreator', ',', 'ĠMatt', 'ĠGro', 'ening', ',', 'Ġhas', 'Ġtoo', 'Ġoften', 'Ġbeen', 'Ġviewed', 'Ġas', 'Ġthe', 'Ġsole', 'Ġsource', 'Ġto', 'Ġthe', 'Ġdetriment', 'Ġof', 'Ġothers', 'Ġwho', 'Ġalso', 'Ġdeserve', 'Ġto', 'Ġbe', 'Ġpraised', '.\"', '<p>', 'ĠIn', 'Ġaddition', 'Ġto', 'Ġthe', 'Ġshow', \"'s\", 'Ġregular', 'Ġcast', 'Ġof', 'Ġvoice', 'Ġactors', ',', 'Ġcelebrity', 'Ġguest', 'Ġstars', 'Ġhave', 'Ġbeen', 'Ġa', 'Ġstaple', 'Ġof', 'Ġ\"', 'The', 'ĠSimpsons', '\",', 'Ġan', 'ĠAmerican', 'Ġanimated', 'Ġtelevision', 'Ġsitcom', 'Ġcreated', 'Ġby', 'ĠMatt', 'ĠGro', 'ening', 'Ġfor', 'Ġthe', 'ĠFox', 'ĠBroadcasting', 'ĠCompany', ',', 'Ġsince', 'Ġits', 'Ġfirst', 'Ġseason', '.', 'Ġ', '<s>', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġep', 'onymous', 'Ġfamily', ',', 'Ġwhich', 'Ġconsists', 'Ġof', 'ĠHomer', ',', 'ĠM', 'arge', ',', 'ĠBart', ',', 'ĠLisa', 'Ġand', 'ĠMaggie', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfamily', 'Ġwas', 'Ġinitially', 'Ġconceived', 'Ġby', 'ĠGro', 'ening', 'Ġfor', 'Ġa', 'Ġseries', 'Ġof', 'Ġanimated', 'Ġshorts', ',', 'Ġwhich', 'Ġoriginally', 'Ġaired', 'Ġas', 'Ġa', 'Ġpart', 'Ġof', 'Ġ\"', 'The', 'ĠTr', 'acey', 'ĠU', 'll', 'man', 'ĠShow', '\"', 'Ġbetween', 'Ġ1987', 'Ġand', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshorts', 'Ġwere', 'Ġdeveloped', 'Ġinto', 'Ġa', 'Ġhalf', '-', 'hour', 'Ġprime', 'Ġtime', 'Ġseries', 'Ġwhich', 'Ġbegan', 'Ġin', 'ĠDecember', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', \"'\", 'Ġ27', 'th', 'Ġseason', 'Ġbegan', 'Ġin', 'ĠSeptember', 'Ġ2015', 'Ġand', 'Ġepisodes', 'Ġof', 'Ġ\"', 'The', 'ĠSimpsons', '\"', 'Ġhave', 'Ġaired', '.', 'Ġ', '<s>', 'ĠA', 'Ġfeature', 'Ġfilm', 'Ġadaptation', 'Ġof', 'Ġthe', 'Ġseries', 'Ġcalled', 'Ġ\"', 'The', 'ĠSimpsons', 'ĠMovie', '\",', 'Ġwas', 'Ġreleased', 'Ġin', 'Ġ2007', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  tensor([5.3000e-06], device='cuda:0')\n",
      "question text:  Which magazine was started first Arthur's Magazine or First for Women?\n",
      "orig_answer_text:  Arthur's Magazine\n",
      "input:  ['<cls>', '<q>', 'What', 'ĠU', '.', 'S', 'ĠHighway', 'Ġgives', 'Ġaccess', 'Ġto', 'ĠZ', 'il', 'po', 'ĠRoad', ',', 'Ġand', 'Ġis', 'Ġalso', 'Ġknown', 'Ġas', 'ĠMid', 'land', 'ĠTrail', '?', '</q>', '<p>', 'ĠZ', 'il', 'po', 'ĠRoad', 'Ġis', 'Ġa', 'ĠNational', 'ĠForest', 'ĠSc', 'enic', 'ĠBy', 'way', 'Ġin', 'Ġthe', 'Ġforest', 'ed', 'Ġhills', 'Ġof', 'Ġeastern', 'ĠKentucky', ',', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠThe', 'Ġnine', 'Ġmile', 'Ġby', 'way', 'Ġstarts', 'Ġsouth', 'Ġof', 'ĠMore', 'head', ',', 'ĠKentucky', 'Ġand', 'Ġcan', 'Ġbe', 'Ġaccessed', 'Ġby', 'ĠU', '.', 'S', '.', 'ĠHighway', 'Ġ60', '.', 'Ġ', '<s>', 'ĠThe', 'Ġby', 'way', 'Ġtravels', 'Ġthrough', 'Ġthe', 'ĠDaniel', 'ĠBoone', 'ĠNational', 'ĠForest', 'Ġand', 'Ġends', 'Ġon', 'Ġthe', 'Ġwestern', 'Ġshore', 'Ġof', 'ĠCave', 'ĠRun', 'ĠLake', 'Ġat', 'Ġthe', 'ĠZ', 'il', 'po', 'ĠRecreation', 'ĠArea', '.', 'Ġ', '<s>', 'ĠIt', 'Ġfollows', 'ĠF', 'SR', 'Ġ9', '18', ',', 'Ġwhich', 'Ġis', 'Ġa', 'Ġtwo', 'Ġlane', 'Ġpaved', 'Ġroad', 'Ġsuitable', 'Ġfor', 'Ġall', 'Ġmotor', 'Ġvehicles', 'Ġand', 'Ġis', 'Ġusually', 'Ġopen', 'Ġthroughout', 'Ġthe', 'Ġyear', '.', '<p>', 'ĠR', 'ISE', 'Ġis', 'Ġa', 'Ġconcept', 'ĠÂ£', '400', ',', '000', 'Ġpublic', 'Ġart', 'Ġspherical', 'Ġmetal', 'Ġsculpture', 'Ġin', 'ĠBelfast', 'Ġby', 'ĠWolfgang', 'ĠButt', 'ress', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġ37', '.', '5', 'Ġm', 'Ġhigh', 'Ġand', 'Ġ30', 'Ġm', 'Ġwide', 'Ġand', 'Ġwas', 'Ġconstructed', 'Ġin', 'Ġearly', 'Ġ2011', 'Ġin', 'Ġthe', 'Ġcentre', 'Ġof', 'Ġthe', 'ĠBroadway', 'Ġround', 'about', ',', 'Ġat', 'Ġthe', 'Ġjunction', 'Ġof', 'Ġthe', 'ĠWest', 'link', 'Ġand', 'ĠM', '1', 'Ġmotor', 'way', ',', 'Ġa', 'Ġmain', 'Ġgateway', 'Ġto', 'Ġthe', 'Ġcity', 'Ġwhere', 'Ġ(', 'as', 'Ġof', 'Ġ2009', ')', 'Ġmore', 'Ġthan', 'Ġ80', ',', '000', 'Ġcars', 'Ġon', 'Ġaverage', 'Ġflow', 'Ġpast', 'Ġit', 'Ġeach', 'Ġday', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġinform', 'ally', 'Ġknown', 'Ġas', 'ĠThe', 'ĠBalls', 'Ġon', 'Ġthe', 'ĠFalls', 'Ġas', 'Ġthis', 'Ġjunction', 'Ġalso', 'Ġgives', 'Ġaccess', 'Ġto', 'Ġthe', 'ĠFalls', 'ĠRoad', 'Ġarea', 'Ġvia', 'ĠBroadway', '.', '<p>', 'ĠPet', 'erman', 'ĠHill', 'Ġis', 'Ġan', 'Ġun', 'inc', 'orporated', 'Ġcommunity', 'Ġlocated', 'Ġon', 'Ġa', 'Ġhigh', 'Ġridge', 'Ġin', 'ĠBoyd', 'ĠCounty', ',', 'ĠKentucky', ',', 'Ġon', 'Ġthe', 'ĠCat', 'let', 'ts', 'burg', '-', 'C', 'ann', 'ons', 'burg', 'ĠPike', 'Ġ(', 'the', 'ĠCann', 'ons', 'burg', 'ĠRoad', '),', 'Ġthree', 'Ġmiles', 'Ġ(', '5', 'Âł', 'km', ')', 'Ġwest', 'Ġof', 'ĠCat', 'let', 'ts', 'burg', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroad', 'Ġwas', 'Ġoriginally', 'Ġknown', 'Ġas', 'ĠMid', 'land', 'ĠTrail', 'Ġand', 'Ġlater', 'ĠU', '.', 'S', '.', 'Ġ60', 'Ġalternate', 'Ġuntil', 'Ġ1964', 'Ġwhen', 'Ġit', 'Ġreverted', 'Ġto', 'Ġcounty', 'Ġmaintenance', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġnow', 'ĠState', 'ĠRoute', 'Ġ3', '294', '.', '<p>', 'ĠArkansas', 'ĠHighway', 'Ġ113', 'Ġ(', 'AR', 'Ġ113', 'Ġand', 'ĠH', 'wy', '.', 'Ġ', '<s>', 'Ġ113', ')', 'Ġis', 'Ġa', 'Ġnorth', 'âĢĵ', 'south', 'Ġstate', 'Ġhighway', 'Ġthat', 'Ġruns', 'Ġin', 'ĠCentral', 'ĠArkansas', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroute', 'Ġruns', 'Ġ29', '.', '48', 'Ġmi', 'Ġfrom', 'ĠArkansas', 'ĠHighway', 'Ġ10', 'Ġto', 'ĠMor', 'r', 'ilton', '.', 'Ġ', '<s>', 'ĠThis', 'Ġalso', 'Ġgives', 'Ġaccess', 'Ġto', 'Ġsome', 'Ġrural', 'Ġareas', 'Ġwest', 'Ġof', 'ĠMor', 'r', 'ilton', '.', 'Ġ', '<s>', 'ĠIt', 'Ġruns', 'Ġthrough', 'ĠPul', 'ask', 'i', ',', 'ĠPerry', ',', 'Ġand', 'ĠConway', 'ĠCount', 'ies', '.', 'Ġ', '<s>', 'ĠIt', 'Ġcontains', 'Ġno', 'Ġspur', 'Ġof', 'Ġbusiness', 'Ġroutes', '.', '<p>', 'ĠState', 'ĠRoute', 'Ġ266', 'Ġ(', 'SR', 'Ġ266', ')', 'Ġis', 'Ġa', 'Ġstate', 'Ġhighway', 'Ġin', 'Ġthe', 'ĠU', '.', 'S', '.', 'Ġstate', 'Ġof', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroute', 'Ġtravers', 'es', 'ĠFish', 'ĠLake', 'ĠValley', ',', 'Ġwhich', 'Ġis', 'Ġpart', 'Ġin', 'ĠCalifornia', 'Ġand', 'Ġpart', 'Ġin', 'ĠNevada', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroute', 'Ġconnects', 'Ġtwo', 'ĠNevada', 'Ġstate', 'Ġroutes', 'Ġthat', 'Ġtraverse', 'Ġthe', 'ĠNevada', 'Ġportion', 'Ġof', 'Ġthe', 'Ġvalley', ',', 'ĠNV', 'Ġ264', 'Ġand', 'ĠNV', 'Ġ266', '.', 'Ġ', '<s>', 'ĠThe', 'Ġonly', 'Ġconnection', 'Ġfrom', 'ĠSR', 'Âł', '266', 'Ġto', 'Ġthe', 'Ġrest', 'Ġof', 'ĠCalifornia', \"'s\", 'Ġroad', 'Ġnetwork', 'Ġis', 'Ġvia', 'ĠSR', 'Ġ168', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġ1986', 'Ġthe', 'Ġsouthern', 'Ġand', 'Ġnorthern', 'Ġhalves', 'Ġof', 'Ġmodern', 'ĠSR', 'Ġ266', 'Ġhad', 'Ġseparate', 'Ġnumerical', 'Ġdesign', 'ations', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsouthern', 'Ġportion', 'Ġof', 'Ġthe', 'Ġhighway', ',', 'Ġalong', 'Ġwith', 'Ġmodern', 'ĠSR', 'Ġ168', ',', 'Ġdates', 'Ġto', 'Ġthe', 'Ġauto', 'Ġtrail', 'Ġera', ',', 'Ġforming', 'Ġpart', 'Ġof', 'Ġthe', 'ĠMid', 'land', 'ĠTrail', '.', '<p>', 'ĠMore', 'head', 'Ġis', 'Ġa', 'Ġhome', 'Ġrule', '-', 'class', 'Ġcity', 'Ġlocated', 'Ġalong', 'ĠUS', 'Ġ60', 'Ġ(', 'the', 'Ġhistoric', 'ĠMid', 'land', 'ĠTrail', ')', 'Ġand', 'ĠInterstate', 'Ġ64', 'Ġin', 'ĠRow', 'an', 'ĠCounty', ',', 'ĠKentucky', ',', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġseat', 'Ġof', 'Ġits', 'Ġcounty', '.', 'Ġ', '<s>', 'ĠThe', 'Ġpopulation', 'Ġwas', 'Ġ6', ',', '8', '45', 'Ġat', 'Ġthe', 'Ġtime', 'Ġof', 'Ġthe', 'Ġ2010', 'ĠU', '.', 'S', '.', 'Ġcensus', '.', '<p>', 'ĠThe', 'ĠRoman', 'Ġbridge', 'Ġof', 'ĠSalam', 'anca', 'Ġ(', 'in', 'ĠSpanish', ':', 'Ġ\"', 'P', 'u', 'ente', 'Ġr', 'oman', 'o', 'Ġde', 'ĠSalam', 'anca', '\"),', 'Ġalso', 'Ġknown', 'Ġas', 'ĠPu', 'ente', 'ĠMayor', 'Ġdel', 'ĠT', 'orm', 'es', 'Ġis', 'Ġa', 'ĠRoman', 'Ġbridge', 'Ġcrossing', 'Ġthe', 'ĠT', 'orm', 'es', 'ĠRiver', 'Ġon', 'Ġthe', 'Ġbanks', 'Ġof', 'Ġthe', 'Ġcity', 'Ġof', 'ĠSalam', 'anca', ',', 'Ġin', 'ĠCast', 'ile', 'Ġand', 'ĠLe', 'Ã³n', ',', 'ĠSpain', '.', 'Ġ', '<s>', 'ĠThe', 'Ġimportance', 'Ġof', 'Ġthe', 'Ġbridge', 'Ġas', 'Ġa', 'Ġsymbol', 'Ġof', 'Ġthe', 'Ġcity', 'Ġcan', 'Ġbe', 'Ġseen', 'Ġin', 'Ġthe', 'Ġfirst', 'Ġquarter', 'ing', 'Ġof', 'Ġcity', \"'s\", 'Ġcoat', 'Ġof', 'Ġarms', 'Ġ(', 'along', 'Ġwith', 'Ġits', 'Ġstone', 'Ġbull', '-', 'ver', 'r', 'aco', '.)', 'Ġ', '<s>', 'ĠHas', 'Ġbeen', 'Ġknown', 'Ġtraditionally', 'Ġas', 'Ġ\"', 'pu', 'ente', 'Ġmayor', '\"', 'Ġand', 'Ġas', 'Ġ\"', 'pu', 'ente', 'Ġprin', 'Ã§', 'ipal', '\"', 'Ġ(', 'main', 'Ġbridge', ')', 'Ġwhich', 'Ġgives', 'Ġaccess', 'Ġto', 'Ġthe', 'Ġsouthern', 'Ġpart', 'Ġof', 'Ġthe', 'Ġcity', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbridge', 'Ġis', 'Ġpresented', 'Ġin', 'Ġthe', 'Ġ21', 'st', 'Ġcentury', 'Ġas', 'Ġa', 'Ġresult', 'Ġof', 'Ġseveral', 'Ġrest', 'or', 'ations', '.', 'Ġ', '<s>', 'ĠOne', 'Ġof', 'Ġthe', 'Ġdisasters', 'Ġthat', 'Ġmost', 'Ġaffected', 'Ġit', 'Ġwas', 'Ġthe', 'ĠFlood', 'Ġof', 'ĠSan', 'ĠPolic', 'arp', 'o', 'Ġ(', 'January', 'Ġ26', \"'s\", 'Ġnight', ')', 'Ġof', 'Ġyear', 'Ġ16', '26', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġdeclared', 'ĠArt', 'istic', 'ĠHistoric', 'ĠMonument', 'Ġon', 'ĠJune', 'Ġ3', ',', 'Ġ1931', ',', 'Ġand', 'ĠB', 'ien', 'Ġde', 'ĠInter', 'Ã©s', 'ĠCultural', 'Ġsince', 'Ġ1998', '.', 'Ġ', '<s>', 'ĠUntil', 'Ġthe', 'Ġbeginning', 'Ġof', 'Ġ20', 'th', 'Ġcentury', 'Ġit', 'Ġdid', 'Ġnot', 'Ġlose', 'Ġits', 'Ġstatus', 'Ġas', 'Ġthe', 'Ġsingle', 'Ġpoint', 'Ġof', 'Ġaccess', 'Ġto', 'Ġthe', 'Ġcity', ',', 'Ġand', 'Ġfor', 'Ġmany', 'Ġyears', 'Ġcontinued', 'Ġto', 'Ġbear', 'Ġheavy', 'Ġtraffic', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġthe', 'Ġconstruction', 'Ġof', 'Ġa', 'Ġthird', 'Ġbridge', 'Ġfor', 'Ġroad', 'Ġtraffic', 'Ġit', 'Ġremains', 'Ġa', 'Ġunique', 'Ġway', 'Ġof', 'Ġpedestrian', 'Ġand', 'Ġwalking', 'Ġuses', '.', '<p>', 'ĠHawk', \"'s\", 'ĠNest', ',', 'Ġthe', 'Ġsite', 'Ġof', 'ĠHawks', 'ĠNest', 'ĠState', 'ĠPark', ',', 'Ġis', 'Ġa', 'Ġpeak', 'Ġon', 'ĠGau', 'ley', 'ĠMountain', 'Ġin', 'ĠAn', 'sted', ',', 'ĠWest', 'ĠVirginia', ',', 'ĠUSA', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcliffs', 'Ġat', 'Ġthis', 'Ġpoint', 'Ġrise', 'Ġ5', '85', 'Âł', 'ft', 'Ġ(', '178', 'Ġm', ')', 'Ġabove', 'Ġthe', 'ĠNew', 'ĠRiver', '.', 'Ġ', '<s>', 'ĠLocated', 'Ġon', 'Ġthe', 'ĠJames', 'ĠRiver', 'Ġand', 'ĠKan', 'aw', 'ha', 'ĠTurn', 'p', 'ike', 'Ġ(', 'the', 'Ġroad', 'Ġthat', 'Ġserved', 'Ġas', 'Ġan', 'Ġextension', 'Ġof', 'Ġthe', 'Ġcanal', 'Ġacross', 'Ġwhat', 'Ġis', 'Ġnow', 'ĠWest', 'ĠVirginia', '),', 'Ġmany', 'Ġearly', 'Ġtravelers', 'Ġon', 'Ġthis', 'Ġroad', 'Ġstopped', 'Ġto', 'Ġsee', 'Ġthe', 'Ġview', 'Ġof', 'Ġthe', 'Ġriver', 'Ġbelow', '.', 'Ġ', '<s>', 'ĠIn', 'Ġmodern', 'Ġtimes', ',', 'Ġthe', 'ĠMid', 'land', 'ĠTrail', 'Ġcarries', 'ĠU', '.', 'S', '.', 'ĠRoute', 'Ġ60', 'Ġthrough', 'Ġthe', 'Ġsame', 'Ġgeneral', 'Ġroute', '.', 'Ġ', '<s>', 'ĠAm', 'ple', 'Ġparking', 'Ġat', 'Ġthe', 'Ġoverlook', 'Ġin', 'Ġthe', 'Ġstate', 'Ġpark', 'Ġprovides', 'Ġtourists', 'Ġwith', 'Ġfree', 'Ġaccess', 'Ġto', 'Ġthe', 'Ġviews', '.', '<p>', 'ĠRoute', 'Ġ64', 'Ġis', 'Ġa', 'Ġthree', '-', 'mile', 'Ġ(', '5', 'Âł', 'km', ')', 'Ġroad', 'Ġthat', 'Ġstretches', 'Ġfrom', 'ĠNim', 'itz', 'ĠHighway', 'Ġ(', 'Haw', 'aii', 'ĠRoute', 'Ġ92', ')', 'Ġto', 'Ġthe', 'Ġentrance', 'Ġof', 'ĠSand', 'ĠIsland', 'ĠState', 'ĠRecreation', 'ĠArea', 'Ġjust', 'Ġwest', 'Ġof', 'Ġdowntown', 'ĠHonolulu', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroute', 'Ġalso', 'Ġgoes', 'Ġby', 'Ġthe', 'Ġstreet', 'Ġname', 'Ġas', 'ĠSand', 'ĠIsland', 'ĠParkway', '.', 'Ġ', '<s>', 'ĠThe', 'Ġroute', 'Ġgives', 'Ġaccess', 'Ġto', 'ĠSand', 'ĠIsland', 'ĠState', 'ĠRecreation', 'ĠArea', 'Ġand', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠCoast', 'ĠGuard', 'ĠHonolulu', 'ĠBranch', 'Ġby', 'Ġcrossing', 'Ġthe', 'ĠKap', 'al', 'ama', 'ĠChannel', '.', '<p>', 'ĠGlen', 'ĠFer', 'ris', 'Ġis', 'Ġa', 'Ġcensus', '-', 'design', 'ated', 'Ġplace', 'Ġ(', 'C', 'DP', ')', 'Ġon', 'Ġthe', 'Ġwestern', 'Ġbank', 'Ġof', 'Ġthe', 'ĠKan', 'aw', 'ha', 'ĠRiver', 'Ġin', 'ĠF', 'ayette', 'ĠCounty', ',', 'ĠWest', 'ĠVirginia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġsituated', 'Ġapproximately', 'Ġone', 'Ġmile', 'Ġsouth', 'Ġof', 'Ġthe', 'Ġtown', 'Ġof', 'ĠGau', 'ley', 'ĠBridge', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsole', 'Ġhighway', 'Ġlinking', 'ĠGlen', 'ĠFer', 'ris', 'Ġto', 'Ġthe', 'Ġarea', 'Ġis', 'ĠU', '.', 'S', '.', 'ĠRoute', 'Ġ60', ',', 'Ġknown', 'Ġalso', 'Ġas', 'Ġthe', 'ĠMid', 'land', 'ĠTrail', '.', 'Ġ', '<s>', 'ĠAs', 'Ġof', 'Ġthe', 'Ġ2010', 'Ġcensus', ',', 'Ġits', 'Ġpopulation', 'Ġwas', 'Ġ203', ';', 'Ġthe', 'Ġcommunity', 'Ġhad', 'Ġ104', 'Ġhousing', 'Ġunits', ',', 'Ġ87', 'Ġof', 'Ġwhich', 'Ġwere', 'Ġoccupied', '.', 'Ġ', '<s>', 'ĠThe', 'Ġvillage', 'Ġis', 'Ġroughly', 'Ġa', 'Ġmile', 'Ġand', 'Ġa', 'Ġhalf', 'Ġin', 'Ġlength', '.', 'Ġ', '<s>', 'ĠGlen', 'ĠFer', 'ris', 'Ġis', 'Ġhome', 'Ġto', 'Ġtwo', 'Ġchurches', ',', 'Ġone', 'ĠApost', 'olic', 'Ġand', 'Ġone', 'ĠMethodist', '.', 'Ġ', '<s>', 'ĠA', 'Ġrailway', 'Ġowned', 'Ġby', 'ĠNorfolk', 'ĠSouthern', 'Ġruns', 'Ġparallel', 'Ġto', 'ĠUS', 'ĠRoute', 'Ġ60', 'Ġthrough', 'Ġthe', 'Ġvillage', '.']\n",
      "lr:  tensor([5.3000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  ['<cls>', '<q>', 'Who', 'Ġwas', 'Ġonce', 'Ġconsidered', 'Ġthe', 'Ġbest', 'Ġkick', 'Ġboxer', 'Ġin', 'Ġthe', 'Ġworld', ',', 'Ġhowever', 'Ġhe', 'Ġhas', 'Ġbeen', 'Ġinvolved', 'Ġin', 'Ġa', 'Ġnumber', 'Ġof', 'Ġcontroversies', 'Ġrelating', 'Ġto', 'Ġhis', 'Ġ\"', 'uns', 'ports', 'man', 'like', 'Ġconducts', '\"', 'Ġin', 'Ġthe', 'Ġsport', 'Ġand', 'Ġcrimes', 'Ġof', 'Ġviolence', 'Ġoutside', 'Ġof', 'Ġthe', 'Ġring', '.', '</q>', '<p>', 'ĠThe', 'Ġ1998', 'ĠVer', 'ano', 'Ġde', 'ĠEsc', 'Ã¡', 'nd', 'alo', 'Ġ(', 'Spanish', 'Ġfor', 'Ġ\"', 'Summer', 'Ġof', 'ĠSc', 'andal', '\")', 'Ġwas', 'Ġthe', 'Ġsecond', 'Ġannual', 'Ġ\"', 'Ver', 'ano', 'Ġde', 'ĠEsc', 'and', 'alo', '\"', 'Ġprofessional', 'Ġwrestling', 'Ġshow', 'Ġpromoted', 'Ġby', 'ĠAAA', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġtook', 'Ġplace', 'Ġon', 'ĠSeptember', 'Ġ18', ',', 'Ġ1998', ',', 'Ġin', 'ĠMad', 'ero', ',', 'ĠT', 'ama', 'ul', 'ip', 'as', ',', 'ĠMexico', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmain', 'Ġevent', 'Ġfeatured', 'Ġsteel', 'Ġcage', 'Ġmatch', 'Ġbetween', 'Ġthe', 'Ġteams', 'Ġof', 'ĠHeavy', 'ĠMetal', 'Ġand', 'ĠBlue', 'ĠDemon', 'ĠJr', '.', 'Ġand', 'ĠKick', 'ĠBox', 'er', 'Ġand', 'ĠAb', 'ismo', 'ĠNegro', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstip', 'ulation', 'Ġof', 'Ġthe', 'Ġmain', 'Ġevent', 'Ġwas', 'Ġthat', 'Ġif', 'Ġthe', 'Ġteam', 'Ġof', 'ĠHeavy', 'ĠMetal', 'Ġand', 'ĠBlue', 'ĠDemon', 'ĠJr', '.', 'Ġlost', 'Ġreferee', 'ĠGu', 'icho', 'ĠD', 'oming', 'uez', 'Ġwould', 'Ġbe', 'Ġreferee', 'ĠEl', 'ĠTir', 'ante', \"'s\", 'Ġ\"', 'slave', '\"', 'Ġfor', 'Ġa', 'Ġweek', '.', 'Ġ', '<s>', 'ĠIf', 'ĠKick', 'ĠBox', 'er', 'Ġand', 'ĠAb', 'ismo', 'ĠNegro', 'Ġlost', 'ĠEl', 'ĠTir', 'antes', 'Ġwould', 'Ġbe', 'ĠGu', 'icho', 'ĠD', 'oming', 'uez', \"'s\", 'Ġslave', 'Ġfor', 'Ġa', 'Ġweek', '.', '<p>', 'ĠTriple', 'man', 'ÃŃa', 'ĠVII', 'Ġwas', 'Ġthe', 'Ġseventh', 'Ġ\"', 'Tri', 'ple', 'man', 'ÃŃa', '\"', 'Ġwrestling', 'Ġshow', 'Ġpromoted', 'Ġby', 'ĠAAA', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġtook', 'Ġplace', 'Ġon', 'ĠJune', 'Ġ11', ',', 'Ġ1999', ',', 'Ġin', 'ĠMad', 'ero', ',', 'ĠMexico', '.', 'Ġ', '<s>', 'ĠThe', 'ĠMain', 'Ġevent', 'Ġfeatured', 'Ġa', 'ĠSix', '-', 'man', 'Ġ\"', 'L', 'ucha', 'ĠLibre', 'Ġrules', '\"', 'Ġtag', 'Ġteam', 'Ġmatch', 'Ġbetween', 'Ġthe', 'Ġteams', 'Ġof', 'ĠPer', 'ro', 'ĠAg', 'uay', 'o', ',', 'ĠOct', 'ag', 'Ã³n', 'Ġand', 'ĠEl', 'ĠCob', 'arde', 'ĠII', 'Ġand', 'ĠEl', 'ĠTex', 'ano', ',', 'ĠPer', 'ro', 'ĠAg', 'uay', 'o', 'ĠJr', '.', 'Ġand', 'ĠSang', 're', 'ĠChic', 'ana', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'Ġsemi', '-', 'main', 'Ġevent', 'ĠHeavy', 'ĠMetal', 'Ġand', 'ĠEl', 'ĠFel', 'ino', 'Ġdefended', 'Ġthe', 'Ġhair', 'Ġof', 'Ġtheir', 'Ġfather', ',', 'Ġreferee', 'ĠPepe', 'Ġ\"', 'T', 'rop', 'i', '\"', 'ĠCas', 'as', 'Ġwhile', 'ĠKick', 'ĠBox', 'er', 'Ġand', 'ĠThai', 'ĠBox', 'er', 'Ġdefended', 'Ġthe', 'Ġhair', 'Ġof', 'Ġreferee', 'ĠEl', 'ĠTir', 'antes', '.', 'Ġ', '<s>', 'ĠAs', 'Ġa', 'Ġresult', ',', 'ĠEl', 'ĠTir', 'antes', 'Ġhad', 'Ġhis', 'Ġhair', 'Ġshaved', 'Ġoff', 'Ġafter', 'Ġthe', 'Ġmatch', '.', '<p>', 'ĠA', 'Ġprotection', 'Ġracket', 'Ġis', 'Ġa', 'Ġscheme', 'Ġwhereby', 'Ġa', 'Ġgroup', 'Ġprovides', 'Ġprotection', 'Ġto', 'Ġbusinesses', 'Ġor', 'Ġother', 'Ġgroups', 'Ġthrough', 'Ġviolence', 'Ġoutside', 'Ġthe', 'Ġsanction', 'Ġof', 'Ġthe', 'Ġlaw', '.', 'Ġ', '<s>', 'ĠThrough', 'Ġthe', 'Ġcredible', 'Ġthreat', 'Ġof', 'Ġviolence', ',', 'Ġthe', 'Ġracket', 'eers', 'Ġdeter', 'Ġpeople', 'Ġfrom', 'Ġsw', 'ind', 'ling', ',', 'Ġrobbing', ',', 'Ġinjuring', ',', 'Ġsabot', 'aging', 'Ġor', 'Ġotherwise', 'Ġharming', 'Ġtheir', 'Ġclients', '.', 'Ġ', '<s>', 'ĠProtection', 'Ġrack', 'ets', 'Ġtend', 'Ġto', 'Ġappear', 'Ġin', 'Ġmarkets', 'Ġwhere', 'Ġthe', 'Ġpolice', 'Ġand', 'Ġjudiciary', 'Ġcannot', 'Ġbe', 'Ġcounted', 'Ġon', 'Ġto', 'Ġprovide', 'Ġlegal', 'Ġprotection', ',', 'Ġeither', 'Ġbecause', 'Ġof', 'Ġincompetence', 'Ġ(', 'as', 'Ġin', 'Ġweak', 'Ġor', 'Ġfailed', 'Ġstates', ')', 'Ġor', 'Ġilleg', 'ality', 'Ġ(', 'black', 'Ġmarkets', ').', '<p>', 'ĠEl', 'wood', 'ĠGordon', 'ĠG', 'ee', 'Ġ(', 'born', 'ĠFebruary', 'Ġ2', ',', 'Ġ1944', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġacademic', 'Ġand', 'Ġis', 'Ġcurrently', 'Ġserving', 'Ġhis', 'Ġsecond', 'Ġterm', 'Ġas', 'ĠPresident', 'Ġof', 'ĠWest', 'ĠVirginia', 'ĠUniversity', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġserved', 'Ġas', 'Ġthe', 'Ġchief', 'Ġexecutive', 'Ġat', 'Ġseveral', 'Ġuniversities', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġpreviously', 'Ġserving', 'Ġat', 'ĠOhio', 'ĠState', 'ĠUniversity', '.', 'Ġ', '<s>', 'ĠG', 'ee', 'Ġhad', 'Ġbeen', 'Ġheading', 'Ġan', 'ĠOhio', 'ĠState', '-', 'based', 'Ġthink', 'Ġtank', 'Ġfollowing', 'Ġhis', 'Ġretirement', 'Ġfrom', 'Ġthe', 'ĠOhio', 'ĠState', 'Ġpresidency', 'Ġon', 'ĠJuly', 'Ġ1', ',', 'Ġ2013', '.', 'Ġ', '<s>', 'ĠHe', 'Ġretired', 'Ġin', 'Ġresponse', 'Ġto', 'Ġa', 'Ġseries', 'Ġof', 'Ġcontroversies', 'Ġrelating', 'Ġto', 'Ġcomments', 'Ġhe', 'Ġmade', ',', 'Ġthe', 'Ġlast', 'Ġof', 'Ġwhich', 'Ġinvolved', 'Ġanti', '-', 'Catholic', 'Ġcomments', 'Ġallegedly', 'Ġmade', 'Ġin', 'Ġj', 'est', 'Ġabout', 'Ġthe', 'ĠUniversity', 'Ġof', 'ĠNotre', 'ĠDame', '.', 'Ġ', '<s>', 'ĠHis', 'Ġresignation', 'Ġthus', 'Ġended', 'Ġhis', 'Ġsecond', 'Ġterm', 'Ġas', 'Ġthe', 'Ġpresident', ';', 'Ġhe', 'Ġhad', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġpresident', 'Ġof', 'ĠOhio', 'ĠState', 'Ġfrom', 'Ġ1990', 'Ġto', 'Ġ1997', '.', '<p>', 'ĠBad', 'r', 'ĠHar', 'i', 'Ġ(', 'Arab', 'ic', ':', 'ĠØ', '¨', 'Ø¯', 'Ø±', 'ĠÙ', 'ĩ', 'Ø§', 'Ø±', 'ÙĬ', 'âĢİ', 'ĠâĢİ', 'Ġ;', 'Ġborn', 'Ġ8', 'ĠDecember', 'Ġ1984', ')', 'Ġis', 'Ġa', 'ĠMoroccan', '-', 'Dutch', 'Ġsuper', 'Ġheavyweight', 'Ġkick', 'box', 'er', 'Ġfrom', 'ĠAmsterdam', ',', 'Ġfighting', 'Ġout', 'Ġof', 'ĠMike', \"'s\", 'ĠGym', 'Ġin', 'ĠO', 'ost', 'za', 'an', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'Ġformer', 'ĠK', '-', '1', 'ĠHeavy', 'weight', 'Ġchampion', 'Ġ(', '2007', 'âĢĶ', '2008', '),', 'ĠIt', \"'s\", 'ĠShowtime', 'ĠHeavy', 'weight', 'Ġworld', 'Ġchampion', 'Ġ(', '2009', '-', '2010', ')', 'Ġand', 'Ġ\"', 'K', '-', '1', 'ĠWorld', 'ĠGrand', 'ĠPrix', 'Ġ2009', '\"', 'Ġfinal', 'ist', '.', 'Ġ', '<s>', 'ĠHar', 'i', 'Ġhas', 'Ġbeen', 'Ġa', 'Ġprominent', 'Ġfigure', 'Ġin', 'Ġthe', 'Ġworld', 'Ġof', 'Ġkick', 'boxing', 'Ġand', 'Ġwas', 'Ġonce', 'Ġconsidered', 'Ġthe', 'Ġbest', 'Ġkick', 'box', 'er', 'Ġin', 'Ġthe', 'Ġworld', ',', 'Ġhowever', 'Ġhe', 'Ġhas', 'Ġbeen', 'Ġinvolved', 'Ġin', 'Ġa', 'Ġnumber', 'Ġof', 'Ġcontroversies', 'Ġrelating', 'Ġto', 'Ġhis', 'Ġ\"', 'uns', 'ports', 'man', 'like', 'Ġconducts', '\"', 'Ġin', 'Ġthe', 'Ġsport', 'Ġand', 'Ġcrimes', 'Ġof', 'Ġviolence', 'Ġoutside', 'Ġof', 'Ġthe', 'Ġring', '.', '<p>', 'Ġ\"', 'Gu', 'er', 'ra', 'Ġde', 'ĠTit', 'anes', '\"', 'Ġ(', '1998', ')', 'Ġ(\"', 'War', 'Ġof', 'Ġthe', 'ĠTitans', '\")', 'Ġwas', 'Ġthe', 'Ġsecond', 'Ġ\"', 'Gu', 'er', 'ra', 'Ġde', 'ĠTit', 'anes', '\"', 'Ġprofessional', 'Ġwrestling', 'Ġshow', 'Ġpromoted', 'Ġby', 'ĠAAA', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġtook', 'Ġplace', 'Ġon', 'ĠDecember', 'Ġ13', ',', 'Ġ1998', 'Ġin', 'ĠCh', 'ihu', 'ah', 'ua', ',', 'ĠCh', 'ihu', 'ah', 'ua', ',', 'ĠMexico', '.', 'Ġ', '<s>', 'ĠThe', 'ĠMain', 'Ġevent', 'Ġfeatured', 'Ġa', 'ĠSteel', 'ĠCage', 'ĠMatch', 'Ġthat', 'Ġhighlighted', 'Ġtwo', 'Ġstoryline', 'Ġfeud', 's', 'Ġbetween', 'ĠOct', 'ag', 'Ã³n', 'Ġand', 'Ġhis', 'Ġ\"', 'Evil', 'Ġtwin', '\"', 'ĠPent', 'ag', 'Ã³n', 'Ġand', 'Ġthe', 'Ġfeud', 'Ġbetween', 'ĠHeavy', 'ĠMetal', 'Ġand', 'ĠKick', 'ĠBox', 'er', 'Ġas', 'ĠOct', 'ag', 'Ã³n', 'Ġand', 'ĠHeavy', 'ĠMetal', 'Ġteamed', 'Ġtogether', 'Ġto', 'Ġtake', 'Ġon', 'ĠPent', 'ag', 'Ã³n', 'Ġand', 'ĠKick', 'ĠBox', 'er', '.', '<p>', 'ĠGlobal', 'ĠFighting', 'ĠChampionship', 'Ġ(', 'also', 'Ġknown', 'Ġas', 'ĠG', 'FC', ')', 'Ġwas', 'Ġa', 'ĠUAE', '-', 'based', 'Ġkick', 'boxing', 'Ġand', 'Ġmixed', 'Ġmartial', 'Ġarts', 'Ġ(', 'M', 'MA', ')', 'Ġevent', '.', 'Ġ', '<s>', 'ĠFighters', 'Ġfrom', 'Ġaround', 'Ġworld', 'Ġon', 'Ġthe', 'Ġroster', 'Ġinclude', 'ĠBad', 'r', 'ĠHar', 'i', ',', 'ĠPeter', 'ĠA', 'ert', 's', ',', 'ĠPeter', 'ĠGraham', ',', 'ĠDew', 'ey', 'ĠCooper', ',', 'ĠZ', 'abit', 'ĠS', 'amed', 'ov', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġconsidered', 'Ġas', 'Ġone', 'Ġof', 'Ġthe', 'Ġbiggest', 'Ġkick', 'boxing', 'Ġand', 'ĠMMA', 'Ġpromotion', 'Ġin', 'ĠMiddle', 'ĠEast', '.', 'Ġ', '<s>', 'Ġ<', 'ref', 'Ġname', '=\"', 'Em', 'ir', 'ates', 'Ġ24', '/', '7', '\">', 'Ġ</', 'ref', '>', '<p>', 'ĠOut', 'rage', 'ous', 'ĠBet', 'ray', 'al', ':', 'ĠThe', 'ĠDark', 'ĠJourney', 'Ġof', 'ĠWerner', 'ĠEr', 'hard', 'Ġfrom', 'Ġest', 'Ġto', 'ĠExile', 'Ġis', 'Ġa', 'Ġnon', '-', 'fiction', 'Ġbook', 'Ġwritten', 'Ġby', 'Ġfreelance', 'Ġjournalist', 'ĠSteven', 'ĠPress', 'man', 'Ġand', 'Ġfirst', 'Ġpublished', 'Ġin', 'Ġ1993', 'Ġby', 'ĠSt', '.', 'ĠMartin', \"'s\", 'ĠPress', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbook', 'Ġgives', 'Ġan', 'Ġaccount', 'Ġof', 'ĠWerner', 'ĠH', '.', 'ĠEr', 'hard', \"'s\", 'Ġearly', 'Ġlife', 'Ġas', 'ĠJack', 'ĠRosenberg', ',', 'Ġhis', 'Ġexploration', 'Ġof', 'Ġvarious', 'Ġforms', 'Ġof', 'Ġself', '-', 'improve', 'ment', 'Ġtechniques', ',', 'Ġand', 'Ġhis', 'Ġfoundation', 'Ġof', 'ĠEr', 'hard', 'ĠSemin', 'ars', 'ĠTraining', 'Ġ\"', 'est', '\"', 'Ġand', 'Ġlater', 'Ġof', 'ĠWerner', 'ĠEr', 'hard', 'Ġand', 'ĠAssociates', 'Ġand', 'Ġof', 'Ġthe', 'ĠEst', 'Ġsuccessor', 'Ġcourse', ',', 'Ġ\"', 'The', 'ĠForum', '\".', 'Ġ', '<s>', 'ĠPress', 'man', 'Ġdetails', 'Ġthe', 'Ġrapid', 'Ġfinancial', 'Ġsuccess', 'ĠEr', 'hard', 'Ġhad', 'Ġwith', 'Ġthese', 'Ġcompanies', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġcontroversies', 'Ġrelating', 'Ġto', 'Ġlitigation', 'Ġinvolving', 'Ġformer', 'Ġparticipants', 'Ġin', 'Ġhis', 'Ġcourses', '.', 'Ġ', '<s>', 'ĠThe', 'Ġwork', 'Ġconcludes', 'Ġby', 'Ġgoing', 'Ġover', 'Ġthe', 'Ġimpact', 'Ġof', 'Ġa', 'ĠMarch', 'Ġ3', ',', 'Ġ1991', 'Ġ\"', '60', 'ĠMinutes', '\"', 'Ġbroadcast', 'Ġon', 'ĠCBS', 'Ġwhere', 'Ġmembers', 'Ġof', 'ĠEr', 'hard', \"'s\", 'Ġfamily', 'Ġmade', 'Ġallegations', 'Ġagainst', 'Ġhim', ',', 'Ġand', 'ĠEr', 'hard', \"'s\", 'Ġdecision', 'Ġto', 'Ġleave', 'Ġthe', 'ĠUnited', 'ĠStates', '.', '<p>', 'ĠCricket', 'Ġhas', 'Ġhad', 'Ġa', 'Ġnumber', 'Ġof', 'Ġcontroversies', 'Ġrelating', 'Ġto', 'Ġplayers', 'Ġbeing', 'Ġinvolved', 'Ġwith', 'Ġthe', 'Ġbetting', 'Ġaspects', 'Ġof', 'Ġthe', 'Ġgame', '.', 'Ġ', '<s>', 'ĠIn', 'Ġparticular', ',', 'Ġnumerous', 'Ġplayers', 'Ġhave', 'Ġbeen', 'Ġapproached', 'Ġby', 'Ġbook', 'makers', 'Ġand', 'Ġb', 'ribed', 'Ġto', 'Ġthrow', 'Ġmatches', ',', 'Ġaspects', 'Ġof', 'Ġmatches', 'Ġ(', 'e', '.', 'g', '.', 'Ġthe', 'Ġtoss', ')', 'Ġor', 'Ġprovide', 'Ġother', 'Ġinformation', '.', '<p>', 'ĠPro', 'secution', 'Ġof', 'Ġgender', '-', 'target', 'ed', 'Ġcrimes', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġproceedings', 'Ġto', 'Ġprosecute', 'Ġcrimes', 'Ġsuch', 'Ġas', 'Ġrape', 'Ġand', 'Ġdomestic', 'Ġviolence', '.', 'Ġ', '<s>', 'ĠThe', 'Ġearliest', 'Ġdocumented', 'Ġprosecution', 'Ġof', 'Ġgender', '-', 'based', '/', 'target', 'ed', 'Ġcrimes', 'Ġis', 'Ġfrom', 'Ġ14', '74', 'Ġwhen', 'ĠSir', 'ĠPeter', 'Ġvon', 'ĠH', 'agen', 'bach', 'Ġwas', 'Ġconvicted', 'Ġfor', 'Ġrapes', 'Ġcommitted', 'Ġby', 'Ġhis', 'Ġtroops', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġthe', 'Ġtrial', 'Ġwas', 'Ġunsuccessful', 'Ġin', 'Ġindict', 'ing', 'ĠSir', 'Ġvon', 'ĠH', 'agen', 'bach', 'Ġwith', 'Ġthe', 'Ġcharge', 'Ġof', 'Ġrape', 'Ġbecause', 'Ġthe', 'Ġwar', 'Ġin', 'Ġwhich', 'Ġthe', 'Ġrapes', 'Ġoccurred', 'Ġwas', 'Ġ\"', 'und', 'e', 'cl', 'ared', '\"', 'Ġand', 'Ġthus', 'Ġthe', 'Ġrapes', 'Ġwere', 'Ġonly', 'Ġconsidered', 'Ġillegal', '.', 'Ġ', '<s>', 'ĠGender', '-', 'target', 'ed', 'Ġcrimes', 'Ġcontinued', 'Ġto', 'Ġbe', 'Ġprosecuted', ',', 'Ġbut', 'Ġit', 'Ġwas', 'Ġnot', 'Ġuntil', 'Ġafter', 'ĠWorld', 'ĠWar', 'ĠII', 'Ġwhen', 'Ġan', 'Ġinternational', 'Ġcriminal', 'Ġtribunal', '-', 'Ġthe', 'ĠInternational', 'ĠMilitary', 'ĠTribunal', 'Ġfor', 'Ġthe', 'ĠFar', 'ĠEast', 'Ġ(', 'Tok', 'yo', 'ĠTribunal', ')-', 'Ġwere', 'Ġofficers', 'Ġcharged', 'Ġfor', 'Ġbeing', 'Ġresponsible', 'Ġof', 'Ġthe', 'Ġgender', '-', 'target', 'ed', 'Ġcrimes', 'Ġ(', 'particularly', 'Ġrape', ')', 'Ġand', 'Ġother', 'Ġcrimes', 'Ġagainst', 'Ġhumanity', '.', 'Ġ', '<s>', 'ĠDespite', 'Ġthe', 'Ġvarious', 'Ġrape', 'Ġcharges', ',', 'Ġthe', 'ĠCharter', 'Ġof', 'Ġthe', 'ĠTokyo', 'ĠTribunal', 'Ġdid', 'Ġnot', 'Ġmake', 'Ġreferences', 'Ġto', 'Ġrape', ',', 'Ġand', 'Ġrape', 'Ġwas', 'Ġconsidered', 'Ġas', 'Ġsubordinate', 'Ġto', 'Ġother', 'Ġwar', 'Ġcrimes', '.', 'Ġ', '<s>', 'ĠThis', 'Ġis', 'Ġalso', 'Ġthe', 'Ġsituation', 'Ġfor', 'Ġother', 'Ġtrib', 'un', 'als', 'Ġthat', 'Ġfollowed', ',', 'Ġbut', 'Ġwith', 'Ġthe', 'Ġestablishments', 'Ġof', 'Ġthe', 'ĠInternational', 'ĠCriminal', 'ĠTribunal', 'Ġfor', 'Ġthe', 'Ġformer', 'ĠYugoslavia', 'Ġ(', 'IC', 'TY', ')', 'Ġand', 'Ġthe', 'ĠInternational', 'ĠCriminal', 'ĠTribunal', 'Ġfor', 'ĠRwanda', 'Ġ(', 'IC', 'TR', '),', 'Ġthere', 'Ġwas', 'Ġmore', 'Ġattention', 'Ġto', 'Ġthe', 'Ġprosecution', 'Ġof', 'Ġgender', '-', 'target', 'ed', 'Ġcrimes', 'Ġwith', 'Ġeach', 'Ġof', 'Ġthe', 'Ġstatutes', 'Ġexplicitly', 'Ġreferring', 'Ġto', 'Ġrape', 'Ġand', 'Ġother', 'Ġforms', 'Ġof', 'Ġgender', '-', 'target', 'ed', 'Ġviolence', '.']\n",
      "lr:  tensor([5.4000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  ['<cls>', '<q>', 'Which', 'Ġmagazine', 'Ġwas', 'Ġstarted', 'Ġfirst', 'ĠArthur', \"'s\", 'ĠMagazine', 'Ġor', 'ĠFirst', 'Ġfor', 'ĠWomen', '?', '</q>', '<p>', 'ĠRadio', 'ĠCity', 'Ġis', 'ĠIndia', \"'s\", 'Ġfirst', 'Ġprivate', 'ĠFM', 'Ġradio', 'Ġstation', 'Ġand', 'Ġwas', 'Ġstarted', 'Ġon', 'Ġ3', 'ĠJuly', 'Ġ2001', '.', 'Ġ', '<s>', 'ĠIt', 'Ġbroadcasts', 'Ġon', 'Ġ91', '.', '1', 'Ġ(', 'ear', 'lier', 'Ġ91', '.', '0', 'Ġin', 'Ġmost', 'Ġcities', ')', 'Ġmega', 'her', 'tz', 'Ġfrom', 'ĠMumbai', 'Ġ(', 'where', 'Ġit', 'Ġwas', 'Ġstarted', 'Ġin', 'Ġ2004', '),', 'ĠBengal', 'uru', 'Ġ(', 'started', 'Ġfirst', 'Ġin', 'Ġ2001', '),', 'ĠLuck', 'now', 'Ġand', 'ĠNew', 'ĠDelhi', 'Ġ(', 'since', 'Ġ2003', ').', 'Ġ', '<s>', 'ĠIt', 'Ġplays', 'ĠHindi', ',', 'ĠEnglish', 'Ġand', 'Ġregional', 'Ġsongs', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġlaunched', 'Ġin', 'ĠHyder', 'abad', 'Ġin', 'ĠMarch', 'Ġ2006', ',', 'Ġin', 'ĠChennai', 'Ġon', 'Ġ7', 'ĠJuly', 'Ġ2006', 'Ġand', 'Ġin', 'ĠVis', 'akh', 'ap', 'at', 'nam', 'ĠOctober', 'Ġ2007', '.', 'Ġ', '<s>', 'ĠRadio', 'ĠCity', 'Ġrecently', 'Ġfor', 'ayed', 'Ġinto', 'ĠNew', 'ĠMedia', 'Ġin', 'ĠMay', 'Ġ2008', 'Ġwith', 'Ġthe', 'Ġlaunch', 'Ġof', 'Ġa', 'Ġmusic', 'Ġportal', 'Ġ-', 'ĠPlanet', 'R', 'adi', 'ocity', '.', 'com', 'Ġthat', 'Ġoffers', 'Ġmusic', 'Ġrelated', 'Ġnews', ',', 'Ġvideos', ',', 'Ġsongs', ',', 'Ġand', 'Ġother', 'Ġmusic', '-', 'related', 'Ġfeatures', '.', 'Ġ', '<s>', 'ĠThe', 'ĠRadio', 'Ġstation', 'Ġcurrently', 'Ġplays', 'Ġa', 'Ġmix', 'Ġof', 'ĠHindi', 'Ġand', 'ĠRegional', 'Ġmusic', '.', 'Ġ', '<s>', 'ĠAbraham', 'ĠThomas', 'Ġis', 'Ġthe', 'ĠCEO', 'Ġof', 'Ġthe', 'Ġcompany', '.', '<p>', 'ĠFootball', 'Ġin', 'ĠAlbania', 'Ġexisted', 'Ġbefore', 'Ġthe', 'ĠAlban', 'ian', 'ĠFootball', 'ĠFederation', 'Ġ(', 'F', 'SH', 'F', ')', 'Ġwas', 'Ġcreated', '.', 'Ġ', '<s>', 'ĠThis', 'Ġwas', 'Ġevidenced', 'Ġby', 'Ġthe', 'Ġteam', \"'s\", 'Ġregistration', 'Ġat', 'Ġthe', 'ĠBalk', 'an', 'ĠCup', 'Ġtournament', 'Ġduring', 'Ġ1929', '-', '19', '31', ',', 'Ġwhich', 'Ġstarted', 'Ġin', 'Ġ1929', 'Ġ(', 'although', 'ĠAlbania', 'Ġeventually', 'Ġhad', 'Ġpressure', 'Ġfrom', 'Ġthe', 'Ġteams', 'Ġbecause', 'Ġof', 'Ġcompetition', ',', 'Ġcompetition', 'Ġstarted', 'Ġfirst', 'Ġand', 'Ġwas', 'Ġstrong', 'Ġenough', 'Ġin', 'Ġthe', 'Ġdu', 'els', ')', 'Ġ.', 'Ġ', '<s>', 'ĠAlban', 'ian', 'ĠNational', 'ĠTeam', 'Ġwas', 'Ġfounded', 'Ġon', 'ĠJune', 'Ġ6', ',', 'Ġ1930', ',', 'Ġbut', 'ĠAlbania', 'Ġhad', 'Ġto', 'Ġwait', 'Ġ16', 'Ġyears', 'Ġto', 'Ġplay', 'Ġits', 'Ġfirst', 'Ġinternational', 'Ġmatch', 'Ġand', 'Ġthen', 'Ġdefeated', 'ĠYugoslavia', 'Ġin', 'Ġ1946', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1932', ',', 'ĠAlbania', 'Ġjoined', 'ĠFIFA', 'Ġ(', 'during', 'Ġthe', 'Ġ12', 'âĢĵ', '16', 'ĠJune', 'Ġconvention', 'Ġ)', 'ĠAnd', 'Ġin', 'Ġ1954', 'Ġshe', 'Ġwas', 'Ġone', 'Ġof', 'Ġthe', 'Ġfounding', 'Ġmembers', 'Ġof', 'ĠUEFA', '.', '<p>', 'ĠE', 'ch', 'os', 'mith', 'Ġis', 'Ġan', 'ĠAmerican', ',', 'ĠCorporate', 'Ġindie', 'Ġpop', 'Ġband', 'Ġformed', 'Ġin', 'ĠFebruary', 'Ġ2009', 'Ġin', 'ĠCh', 'ino', ',', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠOriginally', 'Ġformed', 'Ġas', 'Ġa', 'Ġquart', 'et', 'Ġof', 'Ġsiblings', ',', 'Ġthe', 'Ġband', 'Ġcurrently', 'Ġconsists', 'Ġof', 'ĠSydney', ',', 'ĠNoah', 'Ġand', 'ĠGraham', 'ĠS', 'ier', 'ota', ',', 'Ġfollowing', 'Ġthe', 'Ġdeparture', 'Ġof', 'Ġeldest', 'Ġsibling', 'ĠJamie', 'Ġin', 'Ġlate', 'Ġ2016', '.', 'Ġ', '<s>', 'ĠE', 'ch', 'os', 'mith', 'Ġstarted', 'Ġfirst', 'Ġas', 'Ġ\"', 'Ready', 'ĠSet', 'ĠGo', '!\"', 'Ġ', '<s>', 'Ġuntil', 'Ġthey', 'Ġsigned', 'Ġto', 'ĠWarner', 'ĠBros', '.', 'Ġ', '<s>', 'ĠRecords', 'Ġin', 'ĠMay', 'Ġ2012', '.', 'Ġ', '<s>', 'ĠThey', 'Ġare', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġtheir', 'Ġhit', 'Ġsong', 'Ġ\"', 'Cool', 'ĠKids', '\",', 'Ġwhich', 'Ġreached', 'Ġnumber', 'Ġ13', 'Ġon', 'Ġthe', 'Ġ\"', 'Bill', 'board', '\"', 'ĠHot', 'Ġ100', 'Ġand', 'Ġwas', 'Ġcertified', 'Ġdouble', 'Ġplatinum', 'Ġby', 'Ġthe', 'ĠR', 'IA', 'A', 'Ġwith', 'Ġover', 'Ġ1', ',', '200', ',', '000', 'Ġsales', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġand', 'Ġalso', 'Ġdouble', 'Ġplatinum', 'Ġby', 'ĠAR', 'IA', 'Ġin', 'ĠAustralia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'ĠWarner', 'ĠBros', '.', 'Ġ', '<s>', 'ĠRecords', \"'\", 'Ġfifth', '-', 'big', 'gest', '-', 'selling', '-', 'digital', 'Ġsong', 'Ġof', 'Ġ2014', ',', 'Ġwith', 'Ġ1', '.', '3', 'Ġmillion', 'Ġdownloads', 'Ġsold', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', \"'s\", 'Ġdebut', 'Ġalbum', ',', 'Ġ\"', 'Talking', 'ĠDreams', '\",', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠOctober', 'Ġ8', ',', 'Ġ2013', '.', '<p>', 'ĠWomen', \"'s\", 'Ġcolleges', 'Ġin', 'Ġthe', 'ĠSouthern', 'ĠUnited', 'ĠStates', 'Ġrefers', 'Ġto', 'Ġundergraduate', ',', 'Ġbachelor', \"'s\", 'Ġdegree', 'âĢĵ', 'gr', 'anting', 'Ġinstitutions', ',', 'Ġoften', 'Ġliberal', 'Ġarts', 'Ġcolleges', ',', 'Ġwhose', 'Ġstudent', 'Ġpopulations', 'Ġconsist', 'Ġexclusively', 'Ġor', 'Ġalmost', 'Ġexclusively', 'Ġof', 'Ġwomen', ',', 'Ġlocated', 'Ġin', 'Ġthe', 'ĠSouthern', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠMany', 'Ġstarted', 'Ġfirst', 'Ġas', 'Ġgirls', \"'\", 'Ġsemin', 'aries', 'Ġor', 'Ġacad', 'emies', '.', 'Ġ', '<s>', 'ĠSalem', 'ĠCollege', 'Ġis', 'Ġthe', 'Ġoldest', 'Ġfemale', 'Ġeducational', 'Ġinstitution', 'Ġin', 'Ġthe', 'ĠSouth', 'Ġand', 'ĠWesley', 'an', 'ĠCollege', 'Ġis', 'Ġthe', 'Ġfirst', 'Ġthat', 'Ġwas', 'Ġestablished', 'Ġspecifically', 'Ġas', 'Ġa', 'Ġcollege', 'Ġfor', 'Ġwomen', '.', 'Ġ', '<s>', 'ĠSome', 'Ġschools', ',', 'Ġsuch', 'Ġas', 'ĠMary', 'ĠBaldwin', 'ĠUniversity', 'Ġand', 'ĠSalem', 'ĠCollege', ',', 'Ġoffer', 'Ġco', 'educ', 'ational', 'Ġcourses', 'Ġat', 'Ġthe', 'Ġgraduate', 'Ġlevel', '.', '<p>', 'ĠThe', 'ĠFirst', 'ĠArthur', 'ĠCounty', 'ĠCour', 'thouse', 'Ġand', 'ĠJail', ',', 'Ġwas', 'Ġperhaps', 'Ġthe', 'Ġsmallest', 'Ġcourt', 'Ġhouse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġand', 'Ġserves', 'Ġnow', 'Ġas', 'Ġa', 'Ġmuseum', '.', '<p>', 'ĠArthur', \"'s\", 'ĠMagazine', 'Ġ(', '18', '44', 'âĢĵ', '18', '46', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġliterary', 'Ġperiod', 'ical', 'Ġpublished', 'Ġin', 'ĠPhiladelphia', 'Ġin', 'Ġthe', 'Ġ19', 'th', 'Ġcentury', '.', 'Ġ', '<s>', 'ĠEdited', 'Ġby', 'ĠT', '.', 'S', '.', 'ĠArthur', ',', 'Ġit', 'Ġfeatured', 'Ġwork', 'Ġby', 'ĠEdgar', 'ĠA', '.', 'ĠPoe', ',', 'ĠJ', '.', 'H', '.', 'ĠIng', 'raham', ',', 'ĠSarah', 'ĠJoseph', 'a', 'ĠHale', ',', 'ĠThomas', 'ĠG', '.', 'ĠSpear', ',', 'Ġand', 'Ġothers', '.', 'Ġ', '<s>', 'ĠIn', 'ĠMay', 'Ġ18', '46', 'Ġit', 'Ġwas', 'Ġmerged', 'Ġinto', 'Ġ\"', 'G', 'ode', 'y', \"'s\", 'ĠLady', \"'s\", 'ĠBook', '\".', '<p>', 'ĠThe', 'Ġ2014', 'âĢĵ', '15', 'ĠUkrainian', 'ĠHockey', 'ĠChampionship', 'Ġwas', 'Ġthe', 'Ġ23', 'rd', 'Ġseason', 'Ġof', 'Ġthe', 'ĠUkrainian', 'ĠHockey', 'ĠChampionship', '.', 'Ġ', '<s>', 'ĠOnly', 'Ġfour', 'Ġteams', 'Ġparticipated', 'Ġin', 'Ġthe', 'Ġleague', 'Ġthis', 'Ġseason', ',', 'Ġbecause', 'Ġof', 'Ġthe', 'Ġinstability', 'Ġin', 'ĠUkraine', 'Ġand', 'Ġthat', 'Ġmost', 'Ġof', 'Ġthe', 'Ġclubs', 'Ġhad', 'Ġeconomical', 'Ġissues', '.', 'Ġ', '<s>', 'ĠGener', 'als', 'ĠKiev', 'Ġwas', 'Ġthe', 'Ġonly', 'Ġteam', 'Ġthat', 'Ġparticipated', 'Ġin', 'Ġthe', 'Ġleague', 'Ġthe', 'Ġprevious', 'Ġseason', ',', 'Ġand', 'Ġthe', 'Ġseason', 'Ġstarted', 'Ġfirst', 'Ġafter', 'Ġthe', 'Ġyear', '-', 'end', 'Ġof', 'Ġ2014', '.', 'Ġ', '<s>', 'ĠThe', 'Ġregular', 'Ġseason', 'Ġincluded', 'Ġjust', 'Ġ12', 'Ġrounds', ',', 'Ġwhere', 'Ġall', 'Ġthe', 'Ġteams', 'Ġwent', 'Ġto', 'Ġthe', 'Ġsemifinals', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'Ġfinal', ',', 'ĠAT', 'E', 'K', 'ĠKiev', 'Ġdefeated', 'Ġthe', 'Ġregular', 'Ġseason', 'Ġwinner', 'ĠHK', 'ĠK', 'rem', 'ench', 'uk', '.', '<p>', 'ĠFirst', 'Ġfor', 'ĠWomen', 'Ġis', 'Ġa', 'Ġwoman', \"'s\", 'Ġmagazine', 'Ġpublished', 'Ġby', 'ĠBauer', 'ĠMedia', 'ĠGroup', 'Ġin', 'Ġthe', 'ĠUSA', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmagazine', 'Ġwas', 'Ġstarted', 'Ġin', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġbased', 'Ġin', 'ĠEng', 'le', 'wood', 'ĠCl', 'iffs', ',', 'ĠNew', 'ĠJersey', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2011', 'Ġthe', 'Ġcirculation', 'Ġof', 'Ġthe', 'Ġmagazine', 'Ġwas', 'Ġ1', ',', '310', ',', '696', 'Ġcopies', '.', '<p>', 'ĠThe', 'ĠFre', 'eway', 'ĠComplex', 'ĠFire', 'Ġwas', 'Ġa', 'Ġ2008', 'Ġwildfire', 'Ġin', 'Ġthe', 'ĠSanta', 'ĠAna', 'ĠCanyon', 'Ġarea', 'Ġof', 'ĠOrange', 'ĠCounty', ',', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfire', 'Ġstarted', 'Ġas', 'Ġtwo', 'Ġseparate', 'Ġfires', 'Ġon', 'ĠNovember', 'Ġ15', ',', 'Ġ2008', '.', 'Ġ', '<s>', 'ĠThe', 'Ġ\"', 'Fre', 'eway', 'ĠFire', '\"', 'Ġstarted', 'Ġfirst', 'Ġshortly', 'Ġafter', 'Ġ9', 'am', 'Ġwith', 'Ġthe', 'Ġ\"', 'Land', 'fill', 'ĠFire', '\"', 'Ġign', 'iting', 'Ġapproximately', 'Ġ2', 'Ġhours', 'Ġlater', '.', 'Ġ', '<s>', 'ĠThese', 'Ġtwo', 'Ġseparate', 'Ġfires', 'Ġmerged', 'Ġa', 'Ġday', 'Ġlater', 'Ġand', 'Ġultimately', 'Ġdestroyed', 'Ġ314', 'Ġresidences', 'Ġin', 'ĠAnaheim', 'ĠHills', 'Ġand', 'ĠYor', 'ba', 'ĠLinda', '.', '<p>', 'ĠWilliam', 'ĠR', 'ast', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġclothing', 'Ġline', 'Ġfounded', 'Ġby', 'ĠJustin', 'ĠTimber', 'lake', 'Ġand', 'ĠTrace', 'ĠAy', 'ala', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġmost', 'Ġknown', 'Ġfor', 'Ġtheir', 'Ġpremium', 'Ġjeans', '.', 'Ġ', '<s>', 'ĠOn', 'ĠOctober', 'Ġ17', ',', 'Ġ2006', ',', 'ĠJustin', 'ĠTimber', 'lake', 'Ġand', 'ĠTrace', 'ĠAy', 'ala', 'Ġput', 'Ġon', 'Ġtheir', 'Ġfirst', 'Ġfashion', 'Ġshow', 'Ġto', 'Ġlaunch', 'Ġtheir', 'Ġnew', 'ĠWilliam', 'ĠR', 'ast', 'Ġclothing', 'Ġline', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlabel', 'Ġalso', 'Ġproduces', 'Ġother', 'Ġclothing', 'Ġitems', 'Ġsuch', 'Ġas', 'Ġjackets', 'Ġand', 'Ġtops', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcompany', 'Ġstarted', 'Ġfirst', 'Ġas', 'Ġa', 'Ġdenim', 'Ġline', ',', 'Ġlater', 'Ġevolving', 'Ġinto', 'Ġa', 'Ġmen', 'âĢ', 'Ļ', 's', 'Ġand', 'Ġwomen', 'âĢ', 'Ļ', 's', 'Ġclothing', 'Ġline', '.']\n",
      "lr:  tensor([5.4000e-06], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Which state does the drug stores, of which the CEO is Warren Bryant, are located?\n",
      "orig_answer_text:  Hawaii\n",
      "question text:  Which  American politician did Donahue replaced \n",
      "orig_answer_text:  Kelli Ward\n",
      "orig_answer_text:  Kelli Ward\n",
      "question text:  New Faces of 1952 is a musical revue with songs and comedy skits, it helped jump start the career of which young performer, and American actress?\n",
      "orig_answer_text:  Carol Lawrence\n",
      "orig_answer_text:  Carol Lawrence\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġstate', 'Ġdoes', 'Ġthe', 'Ġdrug', 'Ġstores', ',', 'Ġof', 'Ġwhich', 'Ġthe', 'ĠCEO', 'Ġis', 'ĠWarren', 'ĠBryant', ',', 'Ġare', 'Ġlocated', '?', '</q>', '<p>', 'ĠUSA', 'ĠDrug', 'Ġis', 'Ġa', 'Ġconvenience', 'Ġstore', 'Ġand', 'Ġpharmacy', 'Ġchain', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġthat', 'Ġoperates', 'Ġmore', 'Ġthan', 'Ġ160', 'Ġstores', 'Ġin', 'ĠArkansas', ',', 'ĠOklahoma', ',', 'ĠMississippi', ',', 'ĠMissouri', ',', 'Ġand', 'ĠTennessee', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġfounded', 'Ġin', 'ĠPine', 'ĠBl', 'uff', ',', 'ĠArkansas', 'Ġin', 'Ġ1986', '.', 'Ġ', '<s>', 'ĠIts', 'Ġheadquarters', 'Ġare', 'Ġstill', 'Ġlocated', 'Ġin', 'ĠPine', 'ĠBl', 'uff', 'Ġwith', 'Ġadditional', 'Ġoffices', 'Ġin', 'ĠLittle', 'ĠRock', ',', 'ĠArkansas', ',', 'ĠTulsa', ',', 'ĠOklahoma', ',', 'Ġand', 'ĠMemphis', ',', 'ĠTennessee', '.', 'Ġ', '<s>', 'ĠIts', 'Ġparent', 'Ġcompany', ',', 'ĠWal', 'g', 'reens', ',', 'Ġoperates', 'ĠSuper', 'ĠD', 'ĠDrug', 'ĠStores', 'Ġand', 'ĠI', 'kes', 'ĠDeep', 'ĠDiscount', 'ĠDrug', ',', 'Ġboth', 'Ġacquired', 'Ġin', 'ĠOctober', 'Ġ1997', ',', 'Ġand', 'ĠMay', \"'s\", 'ĠDrug', ',', 'ĠMed', '-', 'X', 'ĠDrug', ',', 'ĠDrug', 'ĠWarehouse', ',', 'Ġand', 'ĠDrug', 'ĠMart', ',', 'Ġall', 'Ġacquired', 'Ġin', 'ĠJuly', 'Ġ2004', ',', 'Ġas', 'Ġ\"', 'Part', 'Ġof', 'Ġthe', 'ĠUSA', 'ĠDrug', 'ĠFamily', '\".', 'Ġ', '<s>', 'ĠWal', '-', 'Mart', 'Ġand', 'ĠC', 'VS', '/', 'Ph', 'arm', 'acy', 'Ġare', 'Ġtwo', 'Ġof', 'Ġits', 'Ġprimary', 'Ġcompetitors', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcompany', \"'s\", 'Ġslogan', 'Ġis', 'Ġ\"', 'America', \"'s\", 'ĠLow', 'ĠPrice', 'ĠDrug', 'ĠStore', '\".', '<p>', 'ĠPerry', 'ĠDrug', 'ĠStores', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġretail', 'Ġpharmacy', 'Ġchain', 'Ġfounded', 'Ġin', 'Ġ1957', 'Ġin', 'Ġthe', 'Ġcity', 'Ġof', 'ĠPont', 'iac', ',', 'ĠMichigan', ',', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠAt', 'Ġits', 'Ġpeak', 'Ġin', 'Ġthe', 'Ġ1980', 's', ',', 'ĠPerry', 'Ġoperated', 'Ġmore', 'Ġthan', 'Ġ200', 'Ġdrug', 'Ġstores', ',', 'Ġprimarily', 'Ġin', 'Ġthe', 'Ġstate', 'Ġof', 'ĠMichigan', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġ200', 'ĠAuto', 'ĠWorks', 'Ġauto', 'Ġparts', 'Ġstores', 'Ġand', 'Ġfourteen', 'ĠA', '.', 'ĠL', '.', 'ĠPrice', 'Ġdiscount', 'Ġhealth', 'Ġand', 'Ġbeauty', 'Ġaids', 'Ġoutlets', '.', '<p>', 'ĠLong', 's', 'ĠDrugs', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġchain', 'Ġwith', 'Ġapproximately', 'Ġ40', 'Ġdrug', 'Ġstores', 'Ġthroughout', 'Ġthe', 'Ġstate', 'Ġof', 'ĠHawaii', '.', '<p>', 'ĠThr', 'ifty', 'ĠPay', 'Less', 'ĠHoldings', ',', 'ĠInc', '.', 'Ġwas', 'Ġa', 'Ġpharmacy', 'Ġholding', 'Ġcompany', 'Ġthat', 'Ġowned', 'Ġthe', 'ĠThr', 'ifty', 'ĠDrugs', 'Ġand', 'ĠPay', 'Less', 'ĠDrug', 'ĠStores', 'Ġchains', 'Ġin', 'Ġthe', 'Ġwestern', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcombined', 'Ġcompany', 'Ġwas', 'Ġformed', 'Ġin', 'ĠApril', 'Ġ1994', 'Ġwhen', 'ĠLos', 'ĠAngeles', '-', 'based', 'ĠT', 'CH', 'ĠCorporation', ',', 'Ġthe', 'Ġparent', 'Ġcompany', 'Ġof', 'ĠThr', 'ifty', 'ĠCorporation', 'Ġand', 'ĠThr', 'ifty', 'ĠDrug', 'ĠStores', ',', 'ĠInc', '.,', 'Ġacquired', 'Ġthe', 'ĠK', 'mart', 'Ġsubsidiary', 'ĠPay', 'Less', 'ĠDrug', 'ĠStores', 'ĠNorthwest', ',', 'ĠInc', '.', 'Ġ', '<s>', 'ĠAt', 'Ġthe', 'Ġtime', 'Ġof', 'Ġthe', 'Ġmerger', ',', 'ĠT', 'CH', 'ĠCorporation', 'Ġwas', 'Ġrenamed', 'ĠThr', 'ifty', 'ĠPay', 'Less', 'ĠHoldings', ',', 'ĠInc', '.', 'Ġand', 'ĠThr', 'ifty', 'Ġoperated', 'Ġ4', '95', 'Ġstores', ',', 'ĠPay', 'Less', 'Ġoperated', 'Ġ5', '43', 'Ġstores', '.', '<p>', 'ĠLeader', 'ĠDrug', 'ĠStores', 'Ġis', 'Ġa', 'Ġnetwork', 'Ġof', 'Ġover', 'Ġ3', ',', '100', 'Ġindependently', 'Ġowned', 'Ġand', 'Ġoperated', 'Ġpharmacies', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhas', 'Ġa', 'Ġbusiness', 'Ġaffiliation', 'Ġwith', 'ĠCardinal', 'ĠHealth', ',', 'Ġwhich', 'Ġsponsors', 'Ġthe', 'Ġnetwork', 'Ġand', 'Ġowns', 'Ġthe', 'Ġname', 'Ġ\"', 'Leader', 'ĠDrug', 'ĠStores', '\".', 'Ġ', '<s>', 'ĠCardinal', 'ĠHealth', 'Ġalso', 'Ġowns', 'Ġthe', 'Ġfranchise', 'Ġchain', 'ĠThe', 'ĠMedicine', 'ĠSh', 'opp', 'e', '.', 'Ġ', '<s>', 'ĠIt', 'Ġoperates', 'Ġlike', 'Ġa', 'Ġretailers', \"'\", 'Ġcooperative', ',', 'Ġthough', 'Ġit', 'Ġis', 'Ġnot', 'Ġowned', 'Ġby', 'Ġits', 'Ġmembers', '.', '<p>', 'ĠGray', 'ĠDrug', 'Ġwas', 'Ġa', 'Ġdrug', 'store', 'Ġchain', 'Ġin', 'ĠCleveland', ',', 'ĠOhio', '.', 'Ġ', '<s>', 'ĠThe', 'Ġchain', 'Ġbegan', 'Ġin', 'Ġ1912', 'Ġand', 'Ġgrew', 'Ġto', 'Ġ46', 'Ġstores', 'Ġby', 'Ġ1946', 'Ġand', 'Ġover', 'Ġ100', 'Ġby', 'Ġthe', 'Ġ1970', 's', '.', 'Ġ', '<s>', 'ĠBesides', 'ĠOhio', ',', 'Ġstores', 'Ġlater', 'Ġopened', 'Ġin', 'ĠFlorida', 'Ġand', 'ĠMaryland', '.', 'Ġ', '<s>', 'ĠThe', 'Ġchain', 'Ġlater', 'Ġacquired', 'ĠDrug', 'ĠFair', 'Ġin', 'Ġ1981', ',', 'Ġshortly', 'Ġbefore', 'ĠSher', 'win', 'ĠWilliams', 'Ġbought', 'Ġthe', 'Ġchain', '.', 'Ġ', '<s>', 'ĠGray', 'ĠDrug', 'Ġacquired', 'Ġseveral', 'ĠCunningham', 'ĠDrug', 'Ġstores', 'Ġin', 'Ġ1982', '.', '<p>', 'ĠHart', 'ig', 'ĠDrug', 'ĠStores', 'Ġis', 'Ġa', 'Ġchain', 'Ġof', 'Ġpharmacy', '/', 'ret', 'ail', 'Ġstores', 'Ġbased', 'Ġout', 'Ġof', 'ĠDub', 'u', 'que', ',', 'ĠIowa', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcompany', 'Ġprovides', 'Ġpharmacy', 'Ġservices', 'Ġnot', 'Ġonly', 'Ġto', 'Ġthe', 'Ġgeneral', 'Ġpublic', ',', 'Ġbut', 'Ġto', 'Ġarea', 'Ġinstitutions', 'Ġas', 'Ġwell', '.', 'Ġ', '<s>', 'ĠAlong', 'Ġwith', 'Ġthis', 'Ġpharmacy', 'Ġfocus', ',', 'ĠHart', 'ig', 'ĠDrug', 'Ġstores', 'Ġoffer', 'Ġconvenience', 'Ġretail', 'Ġitems', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcompany', 'Ġhas', 'Ġoperated', 'Ġfor', 'Ġover', 'Ġ100', 'Ġyears', ';', 'Ġcurrently', ',', 'Ġit', 'Ġis', 'Ġthe', 'Ġsecond', '-', 'old', 'est', 'Ġfamily', '-', 'run', 'Ġpharmacy', 'Ġchain', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.', '<p>', 'ĠWarren', 'ĠBryant', 'Ġwas', 'Ġthe', 'ĠCEO', 'Ġof', 'ĠLong', 's', 'ĠDrugs', 'ĠStore', 'ĠCorporation', 'Ġout', 'Ġof', 'ĠCalifornia', 'Ġprior', 'Ġto', 'Ġthe', 'Ġretail', 'Ġchain', \"'s\", 'Ġacquisition', 'Ġby', 'ĠC', 'VS', '/', 'Care', 'mark', '.', 'Ġ', '<s>', 'ĠH', 'ired', 'Ġin', 'Ġ2002', 'Ġto', 'ĠLong', 's', ',', 'Ġhe', 'Ġwas', 'ĠSenior', 'ĠVice', 'ĠPresident', 'Ġof', 'ĠThe', 'ĠKro', 'ger', 'ĠCompany', '.', 'Ġ', '<s>', 'Ġ,', 'Ġa', 'Ġretail', 'Ġgrocery', 'Ġchain', ',', 'Ġfrom', 'Ġ1999', 'Ġto', 'Ġ2002', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġthat', ',', 'Ġfrom', 'Ġ1996', 'Ġto', 'Ġ1999', ',', 'Ġhe', 'Ġwas', 'ĠPresident', 'Ġand', 'ĠChief', 'ĠExecutive', 'ĠOfficer', 'Ġof', 'ĠDillon', 'ĠCompanies', ',', 'ĠInc', '.,', 'Ġa', 'Ġretail', 'Ġgrocery', 'Ġchain', 'Ġand', 'Ġsubsidiary', 'Ġof', 'ĠThe', 'ĠKro', 'ger', 'ĠCo', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġalso', 'Ġa', 'Ġdirector', 'Ġof', 'ĠOffice', 'Max', 'ĠInc', 'orporated', '.', '<p>', 'ĠCunningham', 'ĠDrug', 'Ġwas', 'Ġa', 'Ġdrug', 'store', 'Ġchain', 'Ġbased', 'Ġin', 'ĠDetroit', ',', 'ĠMichigan', '.', 'Ġ', '<s>', 'ĠFound', 'ed', 'Ġin', 'ĠOctober', 'Ġ1889', 'Ġby', 'ĠAndrew', 'ĠCunningham', ',', 'Ġthe', 'Ġchain', 'Ġoperated', 'Ġprimarily', 'Ġwithin', 'Ġthe', 'Ġstate', 'Ġof', 'ĠMichigan', ',', 'Ġand', 'Ġwas', 'Ġonce', 'Ġthe', 'Ġlargest', 'Ġdrug', 'store', 'Ġchain', 'Ġin', 'Ġthe', 'Ġstate', '.', 'Ġ', '<s>', 'ĠIts', 'ĠMichigan', 'Ġlocations', 'Ġwere', 'Ġclosed', 'Ġand', 'Ġreopened', 'Ġin', 'Ġ1982', 'Ġas', 'ĠApex', 'ĠDrug', ',', 'Ġand', 'Ġwere', 'Ġlater', 'Ġsold', 'Ġto', 'ĠPerry', 'ĠDrug', 'ĠStores', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlast', 'Ġstores', 'Ġremained', 'Ġopen', 'Ġin', 'ĠFlorida', 'Ġuntil', 'Ġ1991', ',', 'Ġwhen', 'Ġthey', 'Ġwere', 'Ġsold', 'Ġto', 'ĠWal', 'g', 'reens', '.', '<p>', 'ĠRex', 'all', 'Ġis', 'Ġa', 'Ġchain', 'Ġof', 'ĠAmerican', 'Ġdrug', 'stores', ',', 'Ġand', 'Ġthe', 'Ġname', 'Ġof', 'Ġtheir', 'Ġstore', '-', 'branded', 'Ġproducts', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstores', ',', 'Ġhaving', 'Ġroots', 'Ġin', 'Ġthe', 'Ġfederation', 'Ġof', 'ĠUnited', 'ĠDrug', 'ĠStores', 'Ġstarting', 'Ġin', 'Ġ1903', ',', 'Ġlicensed', 'Ġthe', 'ĠRex', 'all', 'Ġbrand', 'Ġname', 'Ġto', 'Ġas', 'Ġmany', 'Ġas', 'Ġ12', ',', '000', 'Ġdrug', 'Ġstores', 'Ġacross', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġfrom', 'Ġ1920', 'Ġto', 'Ġ1977', '.', 'Ġ', '<s>', 'Ġ(', 'The', 'Ġ\"', 'Rex', '\"', 'Ġin', 'Ġthe', 'Ġname', 'Ġcame', 'Ġfrom', 'Ġthe', 'Ġcommon', 'ĠRx', 'Ġabbre', 'viation', 'Ġfor', 'Ġmedical', 'Ġprescriptions', '.)']\n",
      "decode\n",
      "answers: [{'text': ' was', 'score': tensor([0.7530], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' was', 'score': tensor([0.7530], device='cuda:0')}]\n",
      "answer_score: tensor([0.7530], device='cuda:0')\n",
      "answer_text:  was\n",
      "answer_gold_token_ids: tensor([6467,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠHawaii', '.']\n",
      "answer_gold:  Hawaii.\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġ', 'ĠAmerican', 'Ġpolitician', 'Ġdid', 'ĠDon', 'ah', 'ue', 'Ġreplaced', 'Ġ', '</q>', '<p>', 'ĠMike', 'ĠDmit', 'rich', 'Ġ(', 'born', 'Ġ1936', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'ĠNatural', 'ĠResource', 'ĠConsult', 'ant', 'Ġfrom', 'ĠUtah', '.', 'Ġ', '<s>', 'ĠA', 'ĠDemocrat', ',', 'Ġhe', 'Ġserved', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠUtah', 'ĠState', 'ĠSenate', ',', 'Ġrepresenting', 'Ġthe', 'Ġstate', \"'s\", 'Ġ27', 'th', 'Ġsenate', 'Ġdistrict', 'Ġin', 'ĠPrice', '.', 'Ġ', '<s>', 'ĠDmit', 'rich', 'Ġserved', 'Ġas', 'Ġthe', 'ĠMinority', 'ĠLeader', 'Ġin', 'Ġthe', 'ĠUtah', 'ĠSenate', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġbeing', 'Ġelected', 'Ġto', 'Ġthe', 'ĠUtah', 'ĠSenate', 'ĠDmit', 'rich', 'Ġserved', 'Ġin', 'Ġthe', 'ĠState', 'ĠHouse', 'Ġfrom', 'Ġ1969', 'Ġto', 'Ġ1992', '.', 'Ġ', '<s>', 'ĠHe', 'Ġretired', 'Ġprior', 'Ġto', 'Ġthe', 'Ġ2008', 'Ġelections', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠDavid', 'ĠP', '.', 'ĠH', 'ink', 'ins', '.', '<p>', 'ĠMaurice', 'ĠA', '.', 'ĠDon', 'ah', 'ue', 'Ġ(', 'September', 'Ġ21', ',', 'Ġ1918', 'ĠâĢĵ', 'ĠJanuary', 'Ġ13', ',', 'Ġ1999', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġas', 'ĠPresident', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠSenate', 'Ġfrom', 'Ġ1964', 'Ġto', 'Ġ1971', '.', '<p>', 'ĠJohn', 'ĠHenry', 'ĠH', 'oe', 'ven', 'ĠIII', 'Ġ(', 'born', 'ĠMarch', 'Ġ13', ',', 'Ġ1957', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'Ġthe', 'Ġsenior', 'ĠUnited', 'ĠStates', 'ĠSenator', 'Ġfrom', 'ĠNorth', 'ĠDakota', ',', 'Ġin', 'Ġoffice', 'Ġsince', 'Ġ2011', '.', 'Ġ', '<s>', 'ĠA', 'Ġmember', 'Ġof', 'Ġthe', 'ĠNorth', 'ĠDakota', 'ĠRepublican', 'ĠParty', ',', 'Ġhe', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġthe', 'Ġ31', 'st', 'ĠGovernor', 'Ġof', 'ĠNorth', 'ĠDakota', 'Ġfrom', 'ĠDecember', 'Ġ2000', 'Ġto', 'ĠDecember', 'Ġ2010', '.', 'Ġ', '<s>', 'ĠH', 'oe', 'ven', 'Ġwas', 'Ġelected', 'Ġto', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠSenate', 'Ġin', 'Ġthe', 'ĠNovember', 'Ġ2', ',', 'Ġ2010', 'Ġgeneral', 'Ġelection', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreplaced', 'Ġjunior', 'ĠSenator', 'ĠByron', 'ĠL', '.', 'ĠD', 'organ', ',', 'Ġwho', 'Ġchose', 'Ġnot', 'Ġto', 'Ġseek', 'Ġre', '-', 'election', '.', 'Ġ', '<s>', 'ĠH', 'oe', 'ven', 'Ġbecame', 'Ġthe', 'Ġsenior', 'ĠSenator', 'Ġin', 'Ġ2013', 'Ġafter', 'ĠKent', 'ĠConrad', 'Ġretired', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠHeidi', 'ĠHe', 'it', 'kamp', ',', 'Ġwho', 'Ġwas', 'Ġonce', 'ĠH', 'oe', 'ven', \"'s\", 'Ġopponent', 'Ġfor', 'Ġthe', 'ĠGovernor', \"'s\", 'Ġoffice', '.', '<p>', 'ĠAnne', 'Ġde', 'Ġla', 'ĠBlanc', 'het', 'ai', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġfrom', 'Ġthe', 'Ġstate', 'Ġof', 'ĠVermont', '.', 'Ġ', '<s>', 'ĠShe', 'Ġhas', 'Ġserved', 'Ġas', 'Ġa', 'ĠRepublican', 'Ġmember', 'Ġof', 'Ġthe', 'ĠVermont', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġsince', 'Ġ2003', ',', 'Ġrepresenting', 'Ġthe', 'ĠWashington', '-', '2', 'Ġdistrict', ',', 'Ġwhich', 'Ġincludes', 'Ġthe', 'ĠWashington', 'ĠCounty', 'Ġtowns', 'Ġof', 'ĠBerlin', 'Ġand', 'ĠNorth', 'field', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġalso', 'Ġeditor', 'Ġof', 'Ġ\"', 'Counter', 'point', '\",', 'Ġa', 'Ġquarterly', 'Ġmental', 'Ġhealth', 'Ġpublication', 'Ġdistributed', 'Ġfor', 'Ġfree', 'Ġthroughout', 'ĠVermont', '.', '<p>', 'ĠSue', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġwas', 'Ġappointed', 'Ġin', 'Ġ2016', 'Ġto', 'Ġserve', 'Ġin', 'Ġthe', 'ĠArizona', 'ĠState', 'ĠSenate', 'Ġrepresenting', 'Ġthe', 'Ġfifth', 'Ġlegislative', 'Ġdistrict', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠRepublican', 'ĠParty', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġreplaced', 'ĠK', 'elli', 'ĠWard', 'Ġwho', 'Ġresigned', 'Ġto', 'Ġrun', 'Ġfor', 'Ġthe', 'ĠUnited', 'ĠStates', 'ĠSenate', '.', 'Ġ', '<s>', 'ĠDon', 'ah', 'ue', 'Ġdid', 'Ġnot', 'Ġrun', 'Ġfor', 'Ġre', '-', 'election', 'Ġin', 'Ġ2016', 'Ġand', 'Ġwas', 'Ġreplaced', 'Ġby', 'ĠSonny', 'ĠBor', 'rell', 'i', '.', '<p>', 'ĠFrank', 'ĠJ', '.', 'ĠDon', 'ah', 'ue', 'Ġ(', '18', '81', 'âĢĵ', '1979', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġas', 'Ġthe', 'ĠMassachusetts', 'ĠSecretary', 'Ġof', 'Ġthe', 'ĠCommonwealth', ',', 'ĠChairman', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠDemocratic', 'ĠState', 'ĠCommittee', ',', 'Ġand', 'Ġas', 'Ġan', 'ĠAssociate', 'ĠJustice', 'Ġof', 'Ġthe', 'ĠMassachusetts', 'ĠSuperior', 'ĠCourt', '.', '<p>', 'ĠCharles', 'ĠW', '.', 'ĠHar', 'low', 'Ġ(', 'born', 'ĠMay', 'Ġ25', ',', 'Ġ1942', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġfrom', 'ĠMaine', '.', 'Ġ', '<s>', 'ĠHar', 'low', 'Ġserved', 'Ġon', 'Ġthe', 'ĠPortland', ',', 'ĠMaine', 'ĠCity', 'ĠCouncil', 'Ġfrom', 'Ġ1990', 'Ġto', 'Ġ1999', ',', 'Ġincluding', 'Ġa', 'Ġterm', 'Ġas', 'Ġceremonial', 'Ġmayor', 'Ġfrom', 'Ġ1992', 'Ġto', 'Ġ1993', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2004', ',', 'ĠHar', 'low', 'Ġwas', 'Ġelected', 'Ġas', 'Ġa', 'ĠDemocrat', 'Ġto', 'Ġthe', 'ĠMaine', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġfrom', 'ĠDistrict', 'Ġ116', '.', 'Ġ', '<s>', 'ĠHe', 'Ġserved', 'Ġuntil', 'Ġ2010', ',', 'Ġwhen', 'Ġhe', 'Ġwas', 'Ġreplaced', 'Ġby', 'Ġhis', 'Ġdaughter', ',', 'ĠDenise', 'ĠHar', 'low', '.', '<p>', 'ĠK', 'elli', 'ĠWard', 'Ġ(\"', 'n', 'Ã©e', '\"', 'ĠKaz', 'nos', 'ki', ';', 'Ġborn', 'ĠJanuary', 'Ġ25', ',', 'Ġ1969', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġand', 'Ġoste', 'opathic', 'Ġphysician', '.', 'Ġ', '<s>', 'ĠA', 'Ġmember', 'Ġof', 'Ġthe', 'ĠRepublican', 'ĠParty', ',', 'ĠWard', 'Ġwas', 'Ġelected', 'Ġin', 'Ġ2012', 'Ġto', 'Ġserve', 'Ġin', 'Ġthe', 'ĠArizona', 'ĠState', 'ĠSenate', 'Ġrepresenting', 'Ġthe', 'Ġfifth', 'Ġlegislative', 'Ġdistrict', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġun', 'opp', 'osed', 'Ġfor', 'Ġelection', 'Ġin', 'Ġ2014', '.', 'Ġ', '<s>', 'ĠWhile', 'Ġserving', 'Ġin', 'Ġoffice', ',', 'Ġshe', 'Ġcontinued', 'Ġto', 'Ġpractice', 'Ġmedicine', 'Ġin', 'Ġthe', 'Ġemergency', 'Ġdepartments', 'Ġin', 'ĠLake', 'ĠHav', 'asu', 'ĠCity', 'Ġand', 'ĠKing', 'man', ',', 'ĠArizona', '.', '<p>', 'ĠDaniel', 'ĠM', '.', 'ĠDon', 'ah', 'ue', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġserving', 'Ġin', 'Ġthe', 'ĠMassachusetts', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġsince', 'ĠSeptember', 'Ġ2013', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'ĠWorcester', 'Ġresident', 'Ġand', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠDemocratic', 'ĠParty', '.', '<p>', 'ĠWarren', 'ĠT', '.', 'ĠFur', 'ut', 'ani', 'Ġ(', 'born', 'ĠOctober', 'Ġ16', ',', 'Ġ1947', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġserved', 'Ġin', 'Ġthe', 'ĠCalifornia', 'ĠState', 'ĠAssembly', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġa', 'ĠDemocrat', 'Ġand', 'Ġa', 'Ġfourth', '-', 'generation', 'ĠJapanese', 'ĠAmerican', '.', 'Ġ', '<s>', 'ĠFur', 'ut', 'ani', 'Ġwas', 'Ġelected', 'Ġin', 'Ġa', 'Ġspecial', 'Ġelection', 'Ġin', 'Ġ2008', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreplaced', 'ĠLaura', 'ĠRichardson', 'Ġas', 'Ġthe', 'Ġmember', 'Ġof', 'Ġthe', 'ĠUS', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġfrom', 'ĠCalifornia', \"'s\", 'Ġ37', 'th', 'Ġdistrict', '.', 'Ġ', '<s>', 'ĠPrior', 'Ġto', 'Ġbeing', 'Ġelected', ',', 'Ġhe', 'Ġserved', 'Ġon', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠUnified', 'ĠSchool', 'ĠDistrict', 'Ġand', 'Ġthen', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCommunity', 'ĠCollege', 'ĠDistrict', 'ĠBoard', 'Ġof', 'ĠTrust', 'ees', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġthe', 'Ġfirst', 'ĠAsian', 'ĠPacific', 'ĠAmerican', 'Ġever', 'Ġelected', 'Ġto', 'Ġthe', 'ĠLA', 'USD', 'Ġin', 'Ġ1987', 'Ġand', 'Ġbecame', 'Ġthe', 'Ġboard', \"'s\", 'Ġpresident', 'Ġin', 'Ġ1991', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  750 7th Avenue and 101 Park Avenue, are located in which city?\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "orig_answer_text:  New York City\n",
      "question text:  American politician Joe Heck ran unsuccessfully against Democrat Catherine Cortez Masto, a woman who previously served as the 32nd Attorney General of where?\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "orig_answer_text:  Nevada\n",
      "decode\n",
      "answers: [{'text': ' District 116. <s> He served until 2010, when he was', 'score': tensor([0.7522], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' District 116. <s> He served until 2010, when he was', 'score': tensor([0.7522], device='cuda:0')}]\n",
      "answer_score: tensor([0.7522], device='cuda:0')\n",
      "answer_text:  District 116. <s> He served until 2010, when he was\n",
      "answer_gold_token_ids: tensor([  229, 13750,  5986], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠK', 'elli', 'ĠWard']\n",
      "answer_gold:  Kelli Ward\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', 'Ġis', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġwith', 'Ġsongs', 'Ġand', 'Ġcomedy', 'Ġsk', 'its', ',', 'Ġit', 'Ġhelped', 'Ġjump', 'Ġstart', 'Ġthe', 'Ġcareer', 'Ġof', 'Ġwhich', 'Ġyoung', 'Ġperformer', ',', 'Ġand', 'ĠAmerican', 'Ġactress', '?', '</q>', '<p>', 'Ġ\"', 'Gu', 'ess', 'ĠWho', 'ĠI', 'ĠSaw', 'ĠToday', '\"', 'Ġis', 'Ġa', 'Ġpopular', 'Ġjazz', 'Ġsong', 'Ġwritten', 'Ġby', 'ĠMurray', 'ĠGrand', 'Ġwith', 'Ġlyrics', 'Ġby', 'ĠEl', 'isse', 'ĠBoyd', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġoriginally', 'Ġcomposed', 'Ġfor', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠBroadway', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\"', 'Ġin', 'Ġwhich', 'Ġit', 'Ġwas', 'Ġsung', 'Ġby', 'ĠJune', 'ĠCarroll', '.', '<p>', 'ĠPaul', 'ĠDavid', 'ĠNass', 'au', 'Ġ(', 'January', 'Ġ30', ',', 'Ġ1930', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', 'ĠâĢĵ', 'ĠMarch', 'Ġ9', ',', 'Ġ2013', 'Ġin', 'ĠPalm', 'ĠBeach', 'ĠGardens', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġcomposer', 'Ġand', 'Ġlyric', 'ist', 'Ġfor', 'Ġthe', 'Ġstage', '.', 'Ġ', '<s>', 'ĠHe', 'Ġcontributed', 'Ġsongs', 'Ġto', 'Ġthe', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1956', '\",', 'Ġand', 'Ġwrote', 'Ġboth', 'Ġthe', 'Ġmusic', 'Ġand', 'Ġlyric', 'Ġto', 'Ġthe', 'ĠBroadway', 'Ġshows', 'Ġ\"', 'Happy', 'ĠTown', '\"', 'Ġ(', '1959', '),', 'Ġ\"', 'A', 'ĠJoy', 'ful', 'ĠNoise', '\"', 'Ġ(', '1966', '),', 'Ġand', 'Ġ\"', 'The', 'ĠEducation', 'Ġof', 'ĠH', '*', 'Y', '*', 'M', '*', 'A', '*', 'N', 'ĠK', '*', 'A', '*', 'P', '*', 'L', '*', 'A', '*', 'N', '\"', 'Ġ(', '1968', ').', 'Ġ', '<s>', 'ĠHe', 'Ġmarried', 'ĠChloe', 'ĠAnderson', 'Ġon', 'ĠDecember', 'Ġ23', ',', 'Ġ1953', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcouple', 'Ġhad', 'Ġtwo', 'Ġchildren', ':', 'ĠRobert', 'Ġand', 'ĠJulie', '.', '<p>', 'ĠNew', 'ĠFaces', 'Ġof', 'Ġ1952', 'Ġis', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġwith', 'Ġsongs', 'Ġand', 'Ġcomedy', 'Ġsk', 'its', '.', 'Ġ', '<s>', 'ĠIt', 'Ġran', 'Ġon', 'ĠBroadway', 'Ġfor', 'Ġnearly', 'Ġa', 'Ġyear', 'Ġin', 'Ġ1952', 'Ġand', 'Ġwas', 'Ġthen', 'Ġmade', 'Ġinto', 'Ġa', 'Ġmotion', 'Ġpicture', 'Ġin', 'Ġ1954', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhelped', 'Ġjump', 'Ġstart', 'Ġthe', 'Ġcareers', 'Ġof', 'Ġseveral', 'Ġyoung', 'Ġperformers', 'Ġincluding', 'ĠPaul', 'ĠLynd', 'e', ',', 'ĠAlice', 'ĠGhost', 'ley', ',', 'ĠEarth', 'a', 'ĠKitt', ',', 'ĠRobert', 'ĠCl', 'ary', ',', 'ĠCarol', 'ĠLawrence', ',', 'ĠRon', 'ny', 'ĠGraham', ',', 'Ġperformer', '/', 'writer', 'ĠMel', 'ĠBrooks', 'Ġ(', 'as', 'ĠMelvin', 'ĠBrooks', '),', 'Ġand', 'Ġlyric', 'ist', 'ĠSheldon', 'ĠH', 'arn', 'ick', '.', '<p>', 'ĠCarol', 'ĠLawrence', 'Ġ(', 'born', 'ĠSeptember', 'Ġ5', ',', 'Ġ1932', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġactress', ',', 'Ġmost', 'Ġoften', 'Ġassociated', 'Ġwith', 'Ġmusical', 'Ġtheatre', ',', 'Ġbut', 'Ġwho', 'Ġhas', 'Ġalso', 'Ġappeared', 'Ġextensively', 'Ġon', 'Ġtelevision', '.', '<p>', 'Ġ\"', 'Mon', 'oton', 'ous', '\"', 'Ġis', 'Ġa', 'Ġpopular', 'Ġsong', 'Ġwritten', 'Ġby', 'ĠJune', 'ĠCarroll', 'Ġand', 'ĠArthur', 'ĠS', 'iegel', 'Ġfor', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠBroadway', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġwritten', 'Ġbased', 'Ġon', 'Ġthe', 'Ġexperiences', 'Ġof', 'Ġits', 'Ġsinger', 'ĠEarth', 'a', 'ĠKitt', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġperformed', ',', 'Ġat', 'Ġthe', 'Ġinsistence', 'Ġof', 'ĠKitt', ',', 'Ġon', 'Ġthree', 'Ġcha', 'ise', 'Ġlong', 'ues', 'Ġ(', 'K', 'itt', 'Ġtried', 'Ġoriginally', 'Ġfor', 'Ġsix', 'Ġand', 'Ġwas', 'Ġgiven', 'Ġthree', 'Ġin', 'Ġcompromise', '),', 'Ġcrawling', 'Ġcat', '-', 'like', 'Ġfrom', 'Ġone', 'Ġto', 'Ġthe', 'Ġother', ',', 'Ġdemonstrating', 'Ġher', 'Ġflexibility', 'Ġand', 'Ġher', 'Ġdance', 'Ġtraining', 'Ġfrom', 'Ġthe', 'ĠKatherine', 'ĠDunham', 'ĠCompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġalso', 'Ġincludes', 'Ġreferences', 'Ġto', 'Ġmany', 'Ġwell', '-', 'known', 'Ġpeople', 'Ġof', 'Ġthe', 'Ġ1950', 's', '.', 'Ġ', '<s>', 'ĠPeople', 'Ġreferenced', 'Ġin', 'Ġthe', 'Ġsong', 'Ġinclude', ':', '<p>', 'ĠHow', 'Ġto', 'ĠEat', 'ĠLike', 'Ġa', 'ĠChild', 'ĠâĢĵ', 'ĠAnd', 'ĠOther', 'ĠLessons', 'Ġin', 'ĠNot', 'ĠBeing', 'Ġa', 'ĠG', 'rown', '-', 'up', 'Ġis', 'Ġan', 'Ġoriginal', 'Ġmusical', 'Ġcomedy', 'Ġtelevision', 'Ġspecial', 'Ġthat', 'Ġaired', 'Ġon', 'ĠNBC', 'Ġon', 'ĠSeptember', 'Ġ22', ',', 'Ġ1981', '.', 'Ġ', '<s>', 'ĠBased', 'Ġon', 'ĠDel', 'ia', 'ĠE', 'ph', 'ron', \"'s\", 'Ġbest', '-', 'selling', 'Ġbook', 'Ġof', 'Ġthe', 'Ġsame', 'Ġname', ',', 'Ġand', 'Ġadapted', 'Ġfor', 'Ġtelevision', 'Ġby', 'ĠJudith', 'ĠK', 'ahan', 'Ġwith', 'Ġmusic', 'Ġand', 'Ġlyrics', 'Ġby', 'ĠJohn', 'ĠFor', 'ster', ',', 'Ġthe', 'Ġone', '-', 'hour', 'Ġspecial', ',', 'Ġthrough', 'Ġa', 'Ġseries', 'Ġof', 'Ġcomedy', 'Ġsk', 'its', 'Ġand', 'Ġsongs', ',', 'Ġlamp', 'oons', 'Ġthe', 'Ġadult', 'Ġworld', 'Ġthrough', 'Ġthe', 'Ġeyes', 'Ġof', 'Ġchildren', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmusical', 'Ġvariety', 'Ġstars', 'ĠDick', 'ĠVan', 'ĠDy', 'ke', 'Ġas', 'Ġthe', 'Ġresident', 'Ġ\"', 'grown', '-', 'up', '\"', 'Ġalongside', 'Ġ15', 'Ġchildren', 'Ġ(', '8', 'Ġboys', 'Ġand', 'Ġ7', 'Ġgirls', ')', 'Ġranging', 'Ġin', 'Ġage', 'Ġfrom', 'Ġ7', 'Ġto', 'Ġ13', '.', 'Ġ', '<s>', 'ĠSeveral', 'Ġof', 'Ġthe', 'Ġspecial', \"'s\", 'Ġyoung', 'Ġperformers', 'Ġwould', 'Ġsubsequently', 'Ġgo', 'Ġon', 'Ġto', 'Ġachieve', 'Ġchild', 'Ġst', 'ard', 'om', 'Ġin', 'Ġtheir', 'Ġown', 'Ġright', ',', 'Ġmost', 'Ġnotably', 'ĠCorey', 'ĠFeldman', ',', 'ĠBilly', 'ĠJacob', 'y', 'Ġand', 'ĠGeorg', 'ĠOld', 'en', '.', '<p>', 'ĠNew', 'ĠFaces', 'Ġis', 'Ġa', 'Ġ1954', 'ĠAmerican', 'Ġfilm', 'Ġadaptation', 'Ġof', 'Ġthe', 'Ġmusical', 'Ġrev', 'ue', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1952', '\"', 'Ġdirected', 'Ġby', 'ĠHarry', 'ĠHor', 'ner', 'Ġand', 'Ġsketches', 'Ġdirected', 'Ġby', 'ĠJohn', 'ĠBe', 'al', '.', 'Ġ', '<s>', 'ĠFil', 'med', 'Ġin', 'ĠCinem', 'asc', 'ope', 'Ġand', 'ĠEast', 'man', 'color', 'Ġit', 'Ġwas', 'Ġreleased', 'Ġby', 'ĠTw', 'ent', 'ieth', 'ĠCentury', 'ĠFox', 'Ġon', 'ĠMarch', 'Ġ6', ',', 'Ġ1954', '.', '<p>', 'ĠMary', 'ĠBe', 'go', 'Ã±a', 'Ġ(', 'born', 'Ġ1929', 'Ġin', 'ĠBil', 'b', 'ao', ',', 'ĠSpain', ')', 'Ġwas', 'Ġthe', 'Ġstage', 'Ġname', 'Ġof', 'ĠMar', 'ÃŃa', 'ĠBr', 'ag', 'as', 'ĠBe', 'go', 'Ã±a', 'Ġwho', 'Ġwas', 'Ġa', 'ĠSpanish', 'Ġv', 'ed', 'ette', 'Ġand', 'Ġactress', '.', 'Ġ', '<s>', 'ĠShe', 'Ġstarted', 'Ġdancing', 'Ġat', 'Ġage', 'Ġ7', 'Ġand', 'Ġperformed', 'Ġin', 'Ġvenues', 'Ġin', 'ĠMadrid', 'Ġwhile', 'Ġshe', 'Ġwas', 'Ġstudying', 'Ġat', 'Ġthe', 'ĠAcad', 'emies', 'Ġof', 'ĠQu', 'i', 'rog', 'a', ',', 'ĠO', 'mp', 'ÃŃn', 'Ġand', 'ĠMon', 'real', '.', 'Ġ', '<s>', 'ĠThen', 'Ġshe', 'Ġstudied', 'Ġwith', 'ĠAntonio', 'ĠB', 'aut', 'ista', 'Ġand', 'ĠSach', 'a', 'ĠG', 'oud', 'ine', 'Ġin', 'ĠBarcelona', '.', 'Ġ', '<s>', 'ĠShe', 'Ġdebuted', 'Ġin', 'Ġa', 'Ġmusical', 'Ġrev', 'ue', 'Ġat', 'Ġthe', 'Ġage', 'Ġof', 'Ġfourteen', 'Ġand', 'Ġduring', 'ĠSpanish', 'ĠCivil', 'ĠWar', 'Ġ(', 'from', 'Ġ1936', 'Ġto', 'Ġ1939', ')', 'Ġwas', 'Ġpart', 'Ġof', 'Ġthe', 'ĠC', 'NT', 'ĠUnion', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1943', ',', 'ĠBe', 'go', 'Ã±a', 'Ġworked', 'Ġin', 'ĠValencia', 'Ġin', 'ĠJuan', 'ita', 'ĠRe', 'ina', \"'s\", 'Ġacting', 'Ġtrou', 'pe', ',', 'Ġbut', 'Ġreturned', 'Ġto', 'ĠMadrid', 'Ġto', 'Ġdebut', 'Ġin', 'Ġthe', 'ĠTe', 'atro', 'ĠCalder', 'Ã³n', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1945', 'Ġshe', 'Ġappeared', 'Ġin', 'Ġthe', 'Ġrev', 'ue', 'Ġ\"', 'Dan', 'ub', 'io', 'ĠAz', 'ul', '\"', 'Ġ(', 'Blue', 'ĠDan', 'ube', ')', 'Ġwith', 'ĠMan', 'olo', 'ĠCar', 'ac', 'ol', 'Ġand', 'ĠL', 'ola', 'ĠFlores', 'Ġand', 'Ġthe', 'Ġfollowing', 'Ġyear', 'Ġwas', 'Ġthe', 'Ġprincipal', 'Ġv', 'ed', 'ette', 'Ġin', 'Ġthe', 'Ġrev', 'ue', 'Ġ\"', 'De', 'Ġla', 'ĠTier', 'ra', 'Ġa', 'ĠVenus', '\"', 'Ġ(', 'From', 'Ġthe', 'ĠEarth', 'Ġto', 'ĠVenus', ').', 'Ġ', '<s>', 'ĠFor', 'Ġthe', 'Ġnext', 'Ġseveral', 'Ġyears', 'Ġshe', 'Ġperformed', 'Ġin', 'Ġvariety', 'Ġshows', 'Ġwith', 'Ġvarious', 'Ġacting', 'Ġt', 'roup', 'es', ',', 'Ġsuch', 'Ġas', 'Ġ\"', 'T', 'res', 'Ġd', 'ÃŃ', 'as', 'Ġpara', 'Ġqu', 'erer', 'te', '\"', 'Ġ(', '1945', '),', 'Ġ\"', 'Â', '¡', 'R', 'Ã³', 'b', 'ame', 'Ġest', 'a', 'Ġn', 'oche', '!\"', 'Ġ', '<s>', 'Ġ(', '19', '47', '),', 'Ġ\"', 'A', 'ĠLa', 'ĠHab', 'ana', 'Ġme', 'Ġvoy', '\"', 'Ġ(', '19', '48', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ1951', ',', 'Ġshe', 'Ġdid', 'Ġa', 'Ġseason', 'Ġin', 'Ġthe', 'ĠUS', 'Ġand', 'Ġthen', 'Ġreturned', 'Ġto', 'ĠSpain', 'Ġappearing', 'Ġin', 'Ġ\"', 'Â', '¡', 'A', 'Ġv', 'iv', 'ir', 'Ġdel', 'Ġcu', 'ento', '!\"', 'Ġ', '<s>', 'Ġ(', '19', '52', ')', 'Ġand', 'Ġ\"', 'Los', 'Ġl', 'ÃŃ', 'os', 'Ġde', 'ĠEl', 'ÃŃ', 'as', '\"', 'Ġ(', '19', '54', ').', 'Ġ', '<s>', 'ĠBe', 'go', 'Ã±a', 'Ġthen', 'Ġformed', 'Ġher', 'Ġown', 'Ġcompany', ',', 'Ġwhich', 'Ġbetween', 'Ġ1953', 'Ġand', 'Ġ1960', 'Ġperformed', 'Ġten', 'Ġdifferent', 'Ġplays', '.', 'Ġ', '<s>', 'ĠAs', 'Ġher', 'Ġcareer', 'Ġdeclined', 'Ġin', 'Ġrev', 'ue', 'Ġstyle', 'Ġshows', ',', 'Ġshe', 'Ġbegan', 'Ġperforming', 'Ġin', 'Ġcomedy', 'Ġtheater', ',', 'Ġfilm', ',', 'Ġand', 'Ġtelevision', '.', '<p>', 'ĠLeonard', 'ĠS', 'ill', 'man', 'Ġ(', 'May', 'Ġ9', ',', 'Ġ1908', 'Ġ-', 'ĠJanuary', 'Ġ23', ',', 'Ġ1982', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'ĠBroadway', 'Ġproducer', '.', 'Ġ', '<s>', 'ĠBorn', 'Ġin', 'ĠDetroit', ',', 'ĠMichigan', 'Ġon', 'ĠMay', 'Ġ9', ',', 'Ġ1908', ',', 'Ġhe', 'Ġwas', 'Ġthe', 'Ġbrother', 'Ġof', 'ĠJune', 'ĠCarroll', ',', 'Ġthe', 'Ġbrother', '-', 'in', '-', 'law', 'Ġof', 'ĠSidney', 'ĠCarroll', 'Ġand', 'Ġthe', 'Ġuncle', 'Ġof', 'ĠSteve', 'ĠReich', 'Ġand', 'ĠJonathan', 'ĠCarroll', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġperhaps', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġseries', 'Ġof', 'Ġmusical', 'Ġrev', 'ues', ',', 'Ġ\"', 'Leon', 'ard', 'ĠS', 'ill', 'man', \"'s\", 'ĠNew', 'ĠFaces', '\",', 'Ġwhich', 'Ġintroduced', 'Ġmany', 'Ġmajor', 'Ġstars', 'Ġto', 'ĠBroadway', 'Ġaudiences', ',', 'Ġsuch', 'Ġas', 'ĠEarth', 'a', 'ĠKitt', ',', 'ĠIn', 'ga', 'ĠSw', 'enson', ',', 'ĠPaul', 'ĠLynd', 'e', 'Ġand', 'ĠMaggie', 'ĠSmith', '.', 'Ġ', '<s>', 'ĠVers', 'ions', 'Ġof', 'Ġ\"', 'New', 'ĠFaces', '\"', 'Ġwere', 'Ġproduced', 'Ġin', 'Ġ1934', ',', 'Ġ1936', 'Ġ(', 'made', 'Ġinto', 'Ġthe', 'Ġfilm', 'Ġ\"', 'New', 'ĠFaces', 'Ġof', 'Ġ1937', '\"),', 'Ġ1943', ',', 'Ġ1952', 'Ġ(', 'made', 'Ġinto', 'Ġthe', 'Ġfilm', 'Ġ\"', 'New', 'ĠFaces', '\"),', 'Ġ1956', ',', 'Ġ1962', 'Ġand', 'Ġ1968', '.', 'Ġ', '<s>', 'ĠThe', 'Ġvery', 'Ġfirst', 'Ġ\"', 'New', 'ĠFaces', '\"', 'Ġin', 'Ġ1934', 'Ġincluded', 'Ġactors', 'ĠHenry', 'ĠF', 'onda', ',', 'ĠIm', 'ogene', 'ĠCoca', 'Ġand', 'ĠFrances', 'ĠDew', 'ey', 'ĠWorm', 'ser', '.', '<p>', 'ĠLeonard', 'ĠS', 'ill', 'man', \"'s\", 'ĠNew', 'ĠFaces', 'Ġof', 'Ġ1968', 'Ġis', 'Ġa', 'Ġ1968', 'Ġmusical', 'Ġrev', 'ue', 'Ġproduced', 'Ġby', 'ĠLeonard', 'ĠS', 'ill', 'man', '.', 'Ġ', '<s>', 'ĠThe', 'Ġoriginal', 'Ġproduction', 'Ġincluded', 'ĠMad', 'eline', 'ĠKahn', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Who is the director of the 2003 film which has scenes in it filmed at the Quality Cafe in Los Angeles?\n",
      "orig_answer_text:  Todd Phillips\n",
      "decode\n",
      "answers: [{'text': ' other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the', 'score': tensor([0.7622], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the', 'score': tensor([0.7622], device='cuda:0')}]\n",
      "answer_score: tensor([0.7622], device='cuda:0')\n",
      "answer_text:  other, demonstrating her flexibility and her dance training from the Katherine Dunham Company. <s> The song also includes references to many well-known people of the\n",
      "answer_gold_token_ids: tensor([9347, 6226,    6], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠCarol', 'ĠLawrence', ',']\n",
      "answer_gold:  Carol Lawrence,\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', '750', 'Ġ7', 'th', 'ĠAvenue', 'Ġand', 'Ġ101', 'ĠPark', 'ĠAvenue', ',', 'Ġare', 'Ġlocated', 'Ġin', 'Ġwhich', 'Ġcity', '?', '</q>', '<p>', 'Ġ655', 'ĠPark', 'ĠAvenue', 'Ġis', 'Ġa', 'ĠGeorgian', '-', 'style', 'Ġco', '-', 'op', 'Ġresidential', 'Ġbuilding', 'Ġon', 'ĠManhattan', \"'s\", 'ĠUpper', 'ĠEast', 'ĠSide', ',', 'Ġlocated', 'Ġon', 'ĠPark', 'ĠAvenue', 'Ġbetween', 'Ġ67', 'th', 'ĠStreet', 'Ġand', 'Ġ68', 'th', 'ĠStreet', ',', 'Ġadjacent', 'Ġto', 'Ġthe', 'ĠPark', 'ĠAvenue', 'ĠArmory', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġdeveloped', 'Ġin', 'Ġ1924', 'Ġby', 'ĠDwight', 'ĠP', '.', 'ĠRobinson', 'Ġ&', 'ĠCompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbuilding', 'Ġat', 'Ġ655', 'ĠPark', 'ĠAvenue', 'Ġwas', 'Ġdesigned', 'Ġby', 'Ġarchitects', 'ĠJames', 'ĠEdwin', 'ĠRuth', 'ven', 'ĠCarpenter', ',', 'ĠJr', '.,', 'Ġoften', 'Ġreferred', 'Ġto', 'Ġby', 'Ġthe', 'Ġinitials', 'Ġ\"', 'J', '.', 'E', '.', 'R', '.', 'ĠCarpenter', '\",', 'Ġand', 'ĠM', 'ott', 'ĠB', '.', 'ĠSchmidt', '.', 'Ġ', '<s>', 'ĠCarpenter', 'Ġis', 'Ġconsidered', 'Ġthe', 'Ġleading', 'Ġarchitect', 'Ġfor', 'Ġluxury', 'Ġresidential', 'Ġhigh', '-', 'rise', 'Ġbuildings', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', 'Ġin', 'Ġthe', 'Ġearly', 'Ġ1900', 's', ',', 'Ġwhile', 'ĠSchmidt', 'Ġis', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġbuildings', 'Ġin', 'Ġthe', 'ĠAmerican', 'ĠGeorgian', 'ĠClassical', 'Ġstyle', ',', 'Ġincluding', 'ĠSutton', 'ĠPlace', 'Ġand', 'Ġhouses', 'Ġfor', 'ĠNew', 'ĠYork', 'ĠCity', \"'s\", 'Ġsociety', 'Ġfigures', 'Ġand', 'Ġbusiness', 'Ġelite', '.', '<p>', 'Ġ101', 'ĠPark', 'ĠAvenue', 'Ġis', 'Ġa', 'Ġ6', '29', 'Ġft', 'Ġtall', 'Ġskysc', 'raper', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', ',', 'ĠNew', 'ĠYork', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġcompleted', 'Ġin', 'Ġ1979', 'Ġto', 'Ġ1982', 'Ġand', 'Ġhas', 'Ġ49', 'Ġfloors', '.', 'Ġ', '<s>', 'ĠEli', 'ĠAtt', 'ia', 'ĠArchitects', 'Ġdesigned', 'Ġthe', 'Ġbuilding', ',', 'Ġwhich', 'Ġis', 'Ġthe', 'Ġ64', 'th', 'Ġtallest', 'Ġin', 'ĠNew', 'ĠYork', '.', '<p>', 'ĠSouth', 'ĠPhoenix', 'Ġis', 'Ġa', 'Ġregion', 'Ġof', 'ĠPhoenix', ',', 'ĠArizona', ',', 'Ġwith', 'Ġthe', 'Ġboundaries', 'Ġof', 'Ġthe', 'ĠG', 'ila', 'ĠRiver', 'ĠIndian', 'ĠCommunity', 'Ġto', 'Ġthe', 'Ġsouth', 'Ġand', 'Ġwest', ',', 'Ġ48', 'th', 'ĠStreet', 'Ġor', 'ĠInterstate', '-', '10', 'Ġ(', 'Phoenix', '/', 'Tem', 'pe', 'Ġand', 'ĠPhoenix', '/', 'Ch', 'and', 'ler', 'Ġborders', ')', 'Ġto', 'Ġthe', 'Ġeast', ',', 'Ġand', 'Ġthe', 'ĠSalt', 'ĠRiver', 'Ġto', 'Ġthe', 'Ġnorth', '.', 'Ġ', '<s>', 'ĠThis', 'Ġarea', 'Ġincludes', 'ĠPhoenix', \"'s\", 'Ġfollowing', 'ĠUrban', 'ĠVill', 'ages', ':', 'ĠSouth', 'ĠMountain', 'ĠVillage', 'Ġ(', 'aka', 'ĠSouth', 'ĠMountain', 'ĠDistrict', ')', 'Ġalong', 'Ġwith', 'ĠL', 'ave', 'en', 'ĠVillage', 'Ġand', 'ĠAh', 'wat', 'uke', 'e', 'ĠVillage', '.', 'Ġ', '<s>', 'ĠThe', 'Ġarea', 'Ġis', 'Ġsometimes', 'Ġsimply', 'Ġreferred', 'Ġto', 'Ġas', 'Ġ\"', 'the', 'ĠSouth', 'side', '\"', 'Ġby', 'Ġits', 'Ġresidents', '.', 'Ġ', '<s>', 'ĠMajor', 'Ġarter', 'ial', 'Ġeast', '-', 'west', 'Ġstreets', 'Ġinclude', 'ĠBroadway', 'ĠRoad', ',', 'ĠSouthern', 'ĠAvenue', ',', 'ĠBas', 'eline', 'ĠRoad', ',', 'ĠD', 'obb', 'ins', 'ĠRoad', ',', 'ĠElliott', 'ĠRoad', ',', 'ĠWarner', 'ĠRoad', ',', 'ĠChandler', 'ĠBoulevard', ',', 'Ġand', 'ĠP', 'ec', 'os', 'ĠRoad', ',', 'Ġmost', 'Ġof', 'Ġwhich', 'Ġconnect', 'ĠSouth', 'ĠPhoenix', 'Ġwith', 'Ġthe', 'Ġsuburbs', 'Ġof', 'ĠTem', 'pe', 'Ġand', 'ĠChandler', '.', 'Ġ', '<s>', 'ĠMajor', 'Ġarter', 'ial', 'Ġsouth', '-', 'north', 'Ġstreets', 'Ġinclude', 'Ġ24', 'th', 'ĠStreet', ',', 'Ġ16', 'th', 'ĠStreet', ',', 'Ġ7', 'th', 'ĠStreet', ',', 'ĠCentral', 'ĠAvenue', ',', 'Ġ7', 'th', 'ĠAvenue', ',', 'Ġand', 'Ġ19', 'th', 'ĠAvenue', 'Ġconnecting', 'ĠSouth', 'ĠMountain', 'ĠVillage', 'Ġto', 'ĠCentral', 'Ġand', 'ĠNorth', 'ĠPhoenix', ';', 'Ġ27', 'th', 'ĠAvenue', ',', 'Ġ35', 'th', 'ĠAvenue', ',', 'Ġ43', 'rd', 'ĠAvenue', ',', 'Ġ51', 'st', 'ĠAvenue', ',', 'Ġ59', 'th', 'ĠAvenue', ',', 'Ġ67', 'th', 'ĠAvenue', ',', 'Ġand', 'Ġ75', 'th', 'ĠAvenue', 'Ġconnecting', 'ĠL', 'ave', 'en', 'Ġto', 'Ġwest', 'ĠPhoenix', ';', 'Ġand', 'Ġ32', 'nd', 'ĠStreet', ',', 'Ġ40', 'th', 'ĠStreet', ',', 'Ġand', 'Ġ48', 'th', 'ĠStreet', 'Ġconnecting', 'ĠSouth', 'ĠMountain', 'ĠVillage', 'Ġto', 'Ġeast', 'ĠPhoenix', 'Ġand', 'ĠTem', 'pe', '.', '<p>', 'Ġ750', 'ĠSeventh', 'ĠAvenue', 'Ġis', 'Ġa', 'Ġ6', '15', 'Ġft', 'Ġ(', '187', 'm', ')', 'Ġtall', 'ĠClass', '-', 'A', 'Ġoffice', 'Ġskysc', 'raper', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġcompleted', 'Ġin', 'Ġ1989', 'Ġin', 'Ġthe', 'Ġpost', 'modern', 'Ġstyle', 'Ġand', 'Ġhas', 'Ġ36', 'Ġfloors', '.', 'Ġ', '<s>', 'ĠKevin', 'ĠRoche', 'ĠJohn', 'ĠDin', 'kel', 'oo', 'Ġ&', 'ĠAssociates', 'Ġdesigned', 'Ġthe', 'Ġbuilding', ',', 'Ġand', 'Ġit', 'Ġis', 'Ġowned', 'Ġby', 'ĠH', 'ines', ',', 'Ġa', 'ĠTexas', 'Ġbased', 'Ġreal', 'Ġestate', 'Ġinvestment', 'Ġcompany', '.', 'Ġ', '<s>', 'ĠThe', 'Ġbuilding', \"'s\", 'Ġcontinuous', 'Ġhel', 'ix', 'Ġdesign', ',', 'Ġculminating', 'Ġin', 'Ġa', 'Ġchim', 'ney', '-', 'like', 'Ġextension', ',', 'Ġwas', 'Ġcaused', 'Ġby', 'Ġthe', 'ĠNew', 'ĠYork', 'ĠCity', 'ĠBuilding', 'ĠCode', ',', 'Ġwhich', 'Ġrequires', 'Ġsetbacks', '.', 'Ġ', '<s>', 'ĠThe', 'Ġ84', 'Ġexterior', 'Ġcolumn', 'Ġtransfers', 'Ġexist', 'Ġbecause', 'Ġof', 'Ġthe', 'Ġowner', \"'s\", 'Ġrequirement', 'Ġfor', 'Ġa', 'Ġcolumn', '-', 'free', 'Ġspace', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġtied', 'Ġwith', 'Ġthe', 'ĠNew', 'ĠYork', 'ĠLife', 'ĠBuilding', 'Ġfor', 'Ġthe', 'Ġ74', 'th', 'Ġtallest', 'Ġbuilding', 'Ġin', 'ĠNew', 'ĠYork', 'ĠCity', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġalso', 'ĠLE', 'ED', 'Ġcertified', '.', '<p>', 'ĠBerkeley', 'Ġis', 'Ġa', 'Ġcity', '-', 'center', 'Ġneighborhood', 'Ġin', 'ĠDenver', ',', 'ĠColorado', ',', 'Ġlocated', 'Ġin', 'Ġthe', 'Ġarea', 'Ġtraditionally', 'Ġcalled', 'ĠNorthwest', 'ĠDenver', ',', 'Ġon', 'Ġthe', 'Ġwest', 'Ġside', 'Ġof', 'ĠInterstate', 'Ġ25', 'Ġand', 'Ġjust', 'Ġsouth', 'Ġof', 'ĠInterstate', 'Ġ70', '.', 'Ġ', '<s>', 'ĠThe', 'Ġneighborhood', 'Ġis', 'Ġbounded', 'Ġby', 'ĠFederal', 'ĠBoulevard', 'Ġon', 'Ġthe', 'Ġeast', ',', 'ĠI', '-', '70', 'Ġon', 'Ġthe', 'Ġnorth', ',', 'ĠSheridan', 'ĠBoulevard', 'Ġon', 'Ġthe', 'ĠWest', 'Ġand', 'Ġ38', 'th', 'Ġavenue', 'Ġon', 'Ġthe', 'Ġsouth', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġb', 'ordered', 'Ġby', 'Ġthe', 'ĠWest', 'ĠHighland', 'Ġneighborhood', 'Ġon', 'Ġthe', 'Ġsouth', 'Ġand', 'Ġis', 'Ġoften', 'Ġerrone', 'ously', 'Ġgrouped', 'Ġtogether', 'Ġwith', 'Ġthe', 'ĠHighlands', '.', 'Ġ', '<s>', 'ĠThe', 'Ġneighborhood', 'Ġcontains', 'Ġtwo', 'Ġlakes', 'Ġsurrounded', 'Ġby', 'Ġparks', ',', 'Ġone', 'Ġep', 'onymous', 'Ġ(', 'st', 'ret', 'ching', 'Ġfrom', 'Ġ46', 'th', 'ĠAvenue', 'Ġto', 'ĠI', '-', '70', 'Ġand', 'ĠSheridan', 'ĠBoulevard', 'Ġto', 'ĠTenn', 'yson', 'ĠStreet', ')', 'Ġand', 'ĠRocky', 'ĠMountain', 'ĠLake', 'ĠPark', 'Ġ(', 'st', 'ret', 'ching', 'Ġfrom', 'ĠLowell', 'ĠBoulevard', 'Ġto', 'ĠGrove', 'ĠStreet', 'Ġand', 'Ġ46', 'th', 'ĠAvenue', 'Ġto', 'ĠI', '-', '70', ').', 'Ġ', '<s>', 'ĠBerkeley', 'ĠPark', 'Ġalso', 'Ġcontains', 'Ġthe', 'ĠWilliam', 'ĠSche', 'it', 'ler', 'ĠRecreation', 'ĠCenter', ',', 'Ġrun', 'Ġby', 'Ġthe', 'ĠCity', 'Ġand', 'ĠCounty', 'Ġof', 'ĠDenver', 'Ġand', 'Ġincluding', 'Ġboth', 'Ġindoor', 'Ġand', 'Ġoutdoor', 'Ġpublic', 'Ġpools', '.', 'Ġ', '<s>', 'ĠBerkeley', 'Ġhas', 'Ġexperienced', 'Ġrapid', 'Ġgrowth', 'Ġand', 'Ġrise', 'Ġin', 'Ġproperty', 'Ġvalues', 'Ġin', 'Ġthe', 'Ġlast', 'Ġ20', 'Ġyears', 'Ġand', 'Ġparticularly', 'Ġsince', 'Ġthe', 'Ġclosing', 'Ġof', 'ĠEl', 'itch', 'ĠGardens', 'ĠAm', 'use', 'ment', 'ĠPark', 'Ġin', 'ĠOctober', 'Ġ1994', '.', 'Ġ', '<s>', 'ĠParticularly', ',', 'ĠTenn', 'yson', 'ĠStreet', 'Ġhas', 'Ġbecome', 'Ġa', 'Ġcommercial', 'Ġand', 'Ġcultural', 'Ġcenter', 'Ġfor', 'ĠNorthwest', 'ĠDenver', ',', 'Ġbeginning', 'Ġin', 'Ġthe', 'Ġcurrent', 'Ġdecade', 'Ġto', 'Ġrival', 'ĠHighland', 'ĠSquare', 'Ġin', 'Ġnearby', 'ĠHighland', '.', 'Ġ', '<s>', 'ĠCity', 'ĠCongressman', 'ĠRick', 'ĠGarcia', 'Ġpushed', 'Ġfor', 'Ġthe', 'Ġfurther', 'Ġdevelopment', 'Ġof', 'ĠTenn', 'yson', 'ĠStreet', 'Ġin', 'Ġthe', 'ĠNovember', 'Ġ2011', 'Ġelection', 'Ġseason', 'Ġand', 'Ġsucceeded', 'Ġin', 'Ġobtaining', 'Ġthe', 'Ġvoters', \"'\", 'Ġapproval', 'Ġfor', 'Ġ$', '2', '.', '5', 'Ġmillion', 'Ġin', 'Ġpublic', 'Ġworks', 'Ġfunding', '.', 'Ġ', '<s>', 'ĠBusiness', 'Ġowners', 'Ġon', 'ĠTenn', 'yson', 'Ġfrom', 'Ġ48', 'th', 'ĠAvenue', 'Ġto', 'Ġ38', 'th', 'ĠAvenue', 'Ġcurrently', 'Ġcollaborate', 'Ġin', 'Ġan', 'ĠArt', 'ĠWalk', 'Ġheld', 'Ġon', 'Ġthe', 'Ġfirst', 'ĠFriday', 'Ġof', 'Ġevery', 'Ġmonth', '.', '<p>', 'ĠThe', 'ĠChurch', 'Ġof', 'ĠSt', '.', 'ĠIgn', 'at', 'ius', 'Ġof', 'ĠL', 'oy', 'ola', 'Ġis', 'Ġa', 'ĠRoman', 'ĠCatholic', 'Ġparish', 'Ġchurch', 'Ġlocated', 'Ġon', 'Ġthe', 'ĠUpper', 'ĠEast', 'ĠSide', 'Ġof', 'ĠManhattan', ',', 'ĠNew', 'ĠYork', 'ĠCity', ',', 'Ġadministered', 'Ġby', 'Ġthe', 'ĠSociety', 'Ġof', 'ĠJesus', 'Ġ(', 'Jes', 'uits', ').', 'Ġ', '<s>', 'ĠThe', 'Ġparish', 'Ġis', 'Ġunder', 'Ġthe', 'Ġauthority', 'Ġof', 'Ġthe', 'ĠArch', 'di', 'ocese', 'Ġof', 'ĠNew', 'ĠYork', ',', 'Ġand', 'Ġwas', 'Ġestablished', 'Ġin', 'Ġ18', '51', 'Ġas', 'ĠSt', '.', 'ĠLawrence', 'ĠO', \"'\", 'Too', 'le', \"'s\", 'ĠChurch', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1898', ',', 'Ġpermission', 'Ġto', 'Ġchange', 'Ġthe', 'Ġpatron', 'Ġsaint', 'Ġof', 'Ġthe', 'Ġparish', 'Ġfrom', 'ĠSt', '.', 'ĠLawrence', 'ĠO', 'âĢ', 'Ļ', 'Too', 'le', 'Ġto', 'ĠSt', '.', 'ĠIgn', 'at', 'ius', 'Ġof', 'ĠL', 'oy', 'ola', 'Ġwas', 'Ġgranted', 'Ġby', 'ĠRome', '.', 'Ġ', '<s>', 'ĠThe', 'Ġaddress', 'Ġis', 'Ġ980', 'ĠPark', 'ĠAvenue', ',', 'ĠNew', 'ĠYork', 'ĠCity', ',', 'ĠNew', 'ĠYork', 'Ġ100', '28', '.', 'Ġ', '<s>', 'ĠThe', 'Ġchurch', 'Ġon', 'Ġthe', 'Ġsouthwest', 'Ġcorner', 'Ġof', 'ĠPark', 'ĠAvenue', 'Ġand', 'Ġ84', 'th', 'ĠStreet', 'Ġis', 'Ġpart', 'Ġof', 'Ġa', 'ĠJesuit', 'Ġcomplex', 'Ġon', 'Ġthe', 'Ġblock', 'Ġthat', 'Ġincludes', 'ĠWallace', 'ĠHall', ',', 'Ġthe', 'Ġparish', 'Ġhall', ',', 'Ġbeneath', 'Ġthe', 'Ġchurch', ',', 'Ġthe', 'Ġrect', 'ory', 'Ġat', 'Ġthe', 'Ġmid', 'block', 'Ġlocation', 'Ġon', 'ĠPark', 'ĠAvenue', ',', 'Ġthe', 'Ġgrade', 'Ġschool', 'Ġof', 'ĠSt', '.', 'ĠIgn', 'at', 'ius', \"'s\", 'ĠSchool', 'Ġon', 'Ġthe', 'Ġnorth', 'Ġmid', 'block', 'Ġlocation', 'Ġof', 'Ġ84', 'th', 'ĠStreet', 'Ġbehind', 'Ġthe', 'Ġchurch', 'Ġand', 'Ġthe', 'Ġhigh', 'Ġschool', 'Ġof', 'ĠL', 'oy', 'ola', 'ĠSchool', 'Ġ(', 'also', 'Ġ980', 'ĠPark', 'ĠAvenue', ')', 'Ġat', 'Ġthe', 'Ġnorthwest', 'Ġcorner', 'Ġof', 'ĠPark', 'ĠAvenue', 'Ġand', 'Ġ83', 'rd', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', ',', 'Ġanother', 'ĠJesuit', 'Ġhigh', 'Ġschool', ',', 'ĠReg', 'is', 'ĠHigh', 'ĠSchool', 'Ġ(', '55', 'ĠE', 'Ġ84', 'th', 'ĠStreet', '),', 'Ġoccupies', 'Ġthe', 'Ġmid', 'block', 'Ġlocation', 'Ġon', 'Ġthe', 'Ġnorth', 'Ġside', 'Ġof', 'Ġ84', 'th', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠThe', 'Ġchurch', 'Ġwas', 'Ġadded', 'Ġto', 'Ġthe', 'ĠNational', 'ĠRegister', 'Ġof', 'ĠHistoric', 'ĠPlaces', 'Ġon', 'ĠJuly', 'Ġ24', ',', 'Ġ1980', '.', '<p>', 'ĠSqu', 'ire', 'ĠPark', 'Ġis', 'Ġa', 'Ġdistrict', 'Ġin', 'Ġthe', 'Ġcity', 'Ġof', 'ĠSeattle', ',', 'Ġin', 'Ġthe', 'ĠU', '.', 'S', '.', 'Ġstate', 'Ġof', 'ĠWashington', '.', 'Ġ', '<s>', 'ĠAccording', 'Ġto', 'Ġthe', 'ĠSqu', 'ire', 'ĠPark', 'ĠCommunity', 'ĠCouncil', ',', 'Ġit', 'Ġis', 'Ġbounded', 'Ġon', 'Ġthe', 'Ġsouth', 'Ġby', 'ĠS', '.', 'ĠJackson', 'ĠStreet', ',', 'Ġon', 'Ġthe', 'Ġwest', 'Ġby', 'Ġ12', 'th', 'ĠAvenue', 'Ġand', 'Ġ12', 'th', 'ĠAvenue', 'ĠS', '.,', 'Ġon', 'Ġthe', 'Ġnorth', 'Ġby', 'ĠE', '.', 'ĠUnion', 'ĠStreet', ',', 'Ġand', 'Ġon', 'Ġthe', 'Ġeast', 'Ġby', 'Ġ23', 'rd', 'ĠAvenue', 'Ġand', 'Ġ23', 'rd', 'ĠAvenue', 'ĠS', '.,', 'Ġplacing', 'Ġit', 'Ġwithin', 'Ġwhat', 'Ġare', 'Ġcommonly', 'Ġthought', 'Ġof', 'Ġas', 'ĠFirst', 'ĠHill', 'Ġand', 'Ġthe', 'ĠCentral', 'ĠDistrict', '.', 'Ġ', '<s>', 'ĠIts', 'Ġmain', 'Ġthorough', 'f', 'ares', 'Ġare', 'ĠE', '.', 'ĠJefferson', 'Ġand', 'ĠCherry', 'ĠStreets', 'Ġand', 'ĠE', '.', 'ĠYes', 'ler', 'ĠWay', 'Ġ(', 'east', '-', 'Ġand', 'Ġwest', '-', 'bound', ')', 'Ġand', 'Ġ14', 'th', 'ĠAvenue', 'Ġ(', 'north', '-', 'Ġand', 'Ġsouth', '-', 'bound', ').', 'Ġ', '<s>', 'ĠSwedish', 'ĠMedical', 'ĠCenter', \"'s\", 'ĠCherry', 'ĠHill', 'Ġcampus', 'Ġis', 'Ġlocated', 'Ġhere', ',', 'ĠSeattle', 'ĠUniversity', ',', 'Ġa', 'ĠJesuit', 'ĠUniversity', 'Ġhas', 'Ġpart', 'Ġof', 'Ġits', 'Ġcampus', 'Ġin', 'ĠSqu', 'ire', 'ĠPark', ',', 'Ġas', 'Ġthe', 'ĠAd', 'missions', ',', 'Ġsome', 'Ġdorm', 'it', 'ories', 'Ġand', 'ĠAthletics', 'Ġdepartments', 'Ġare', 'Ġeast', 'Ġof', 'Ġ12', 'th', 'ĠAvenue', '.', '<p>', 'ĠH', 'oun', 's', 'field', 'ĠHeights', '/', 'B', 'ri', 'ar', 'ĠHill', 'Ġis', 'Ġan', 'Ġinner', 'Ġsuburban', 'Ġneighbourhood', 'Ġin', 'Ġnorthwest', 'ĠCalgary', ',', 'ĠAlberta', ',', 'ĠCanada', '.', 'Ġ', '<s>', 'ĠLocated', 'Ġnorth', 'Ġof', 'Ġthe', 'ĠHill', 'hurst', 'Ġand', 'ĠWest', 'ĠHill', 'hurst', 'Ġcommunities', ',', 'Ġthe', 'Ġboundaries', 'Ġof', 'Ġthe', 'Ġdistrict', 'Ġare', 'Ġ16', 'th', 'ĠAvenue', 'ĠN', 'Ġ(', 'Trans', '-', 'Canada', 'ĠHighway', ')', 'to', 'Ġthe', 'Ġnorth', ';', 'Ġ14', 'th', 'ĠStreet', 'ĠW', 'Ġto', 'Ġthe', 'Ġeast', ';', 'ĠLane', 'Ġnorth', 'Ġof', 'Ġ7', 'th', 'ĠAvenue', 'ĠN', 'Ġto', 'Ġ19', 'th', 'ĠStreet', 'ĠW', 'Ġand', 'Ġ8', 'th', 'ĠAvenue', 'ĠN', 'Ġto', 'Ġthe', 'Ġsouth', ';', 'Ġand', 'ĠCrow', 'child', 'ĠTrail', ',', 'Ġ12', 'th', 'ĠAvenue', 'ĠN', ',', 'ĠJun', 'iper', 'ĠRoad', ',', 'Ġand', 'Ġ22', 'nd', 'ĠStreet', 'ĠW', 'Ġto', 'Ġthe', 'Ġwest', '.', 'Ġ', '<s>', 'ĠLions', 'ĠPark', 'ĠC', '-', 'Train', 'Ġstation', 'Ġis', 'Ġlocated', 'Ġwithin', 'Ġthe', 'Ġcommunity', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcommunity', 'Ġis', 'Ġbuilt', 'Ġon', 'Ġan', 'Ġesc', 'arp', 'ment', 'Ġand', 'Ġis', 'Ġpopular', 'Ġfor', 'Ġits', 'Ġviews', 'Ġof', 'Ġdowntown', 'Ġto', 'Ġthe', 'Ġsouth', 'Ġand', 'Ġthe', 'ĠRocky', 'ĠMountains', 'Ġto', 'Ġthe', 'Ġwest', '.', '<p>', 'ĠGreenwich', 'ĠAvenue', ',', 'Ġformerly', 'ĠGreenwich', 'ĠLane', ',', 'Ġis', 'Ġa', 'Ġsoutheast', '-', 'north', 'west', 'Ġavenue', 'Ġlocated', 'Ġin', 'Ġthe', 'ĠGreenwich', 'ĠVillage', 'Ġneighborhood', 'Ġof', 'ĠManhattan', ',', 'ĠNew', 'ĠYork', 'ĠCity', '.', 'Ġ', '<s>', 'ĠIt', 'Ġextends', 'Ġfrom', 'Ġthe', 'Ġintersection', 'Ġof', 'Ġ6', 'th', 'ĠAvenue', 'Ġand', 'Ġ8', 'th', 'ĠStreet', 'Ġat', 'Ġits', 'Ġsoutheast', 'Ġend', 'Ġto', 'Ġits', 'Ġnorthwestern', 'Ġend', 'Ġat', 'Ġ8', 'th', 'ĠAvenue', 'Ġbetween', 'Ġ14', 'th', 'ĠStreet', 'Ġand', 'Ġ13', 'th', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġsometimes', 'Ġconfused', 'Ġwith', 'ĠGreenwich', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠConstruction', 'Ġof', 'ĠWest', 'ĠVillage', 'ĠPark', ',', 'Ġbounded', 'Ġby', 'ĠGreenwich', 'ĠAvenue', ',', 'Ġ7', 'th', 'ĠAvenue', ',', 'Ġand', 'Ġ12', 'th', 'ĠStreet', ',', 'Ġbegan', 'Ġin', 'Ġ2016', '.', '<p>', 'ĠTin', 'ley', 'ĠPark', 'ĠStation', 'Ġ(', 'also', 'Ġknown', 'Ġas', 'ĠTin', 'ley', 'ĠPark', '-', 'Oak', 'ĠPark', 'ĠAvenue', 'ĠStation', ')', 'Ġis', 'Ġan', 'Ġelaborate', 'Ġcommuter', 'Ġrailroad', 'Ġstation', 'Ġalong', 'ĠMet', 'ra', \"'s\", 'ĠRock', 'ĠIsland', 'ĠDistrict', 'Ġline', 'Ġin', 'ĠTin', 'ley', 'ĠPark', ',', 'ĠIllinois', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstation', 'Ġis', 'Ġofficially', 'Ġlocated', 'Ġat', 'Ġ67', '00', 'ĠSouth', 'ĠStreet', 'Ġbetween', 'ĠOak', 'ĠPark', 'ĠAvenue', 'Ġand', 'Ġ66', 'th', 'ĠCourt', ',', 'Ġhowever', 'Ġparking', 'Ġis', 'Ġalso', 'Ġavailable', 'Ġon', 'Ġthe', 'Ġopposite', 'Ġside', 'Ġof', 'Ġthe', 'Ġstation', 'Ġalong', 'ĠNorth', 'ĠStreet', 'Ġbetween', 'ĠOak', 'ĠPark', 'ĠAvenue', 'Ġand', 'Ġ67', 'th', 'ĠAvenue', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġthe', 'Ġcenter', 'Ġof', 'Ġthe', 'Ġblock', 'Ġof', 'ĠOak', 'ĠPark', 'ĠAvenue', ',', 'Ġ173', 'rd', 'ĠStreet', ',', 'Ġ67', 'th', 'ĠCourt', 'Ġand', 'Ġ172', 'nd', 'ĠStreet', '.', 'Ġ', '<s>', 'ĠAnother', 'Ġparking', 'Ġarea', 'Ġexists', 'Ġalong', 'ĠSouth', 'ĠStreet', 'Ġopposite', 'Ġthe', 'Ġmain', 'Ġparking', 'Ġlot', 'Ġat', 'Ġthe', 'Ġstation', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstation', 'Ġitself', 'Ġis', 'Ġlies', 'Ġ23', '.', '5', 'Ġmi', 'Ġaway', 'Ġfrom', 'ĠLa', 'S', 'alle', 'ĠStreet', ',', 'Ġthe', 'Ġnorthern', 'Ġtermin', 'us', 'Ġof', 'Ġthe', 'Ġline', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Which band was founded first, Hole, the rock band that Courtney Love was a frontwoman of, or The Wolfhounds?\n",
      "orig_answer_text:  The Wolfhounds\n",
      "decode\n",
      "answers: [{'text': '-Canada Highway)to the north; 14th Street', 'score': tensor([0.7569], device='cuda:0')}]\n",
      "answers_pred: [{'text': '-Canada Highway)to the north; 14th Street', 'score': tensor([0.7569], device='cuda:0')}]\n",
      "answer_score: tensor([0.7569], device='cuda:0')\n",
      "answer_text: -Canada Highway)to the north; 14th Street\n",
      "answer_gold_token_ids: tensor([188, 469, 412], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNew', 'ĠYork', 'ĠCity']\n",
      "answer_gold:  New York City\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'American', 'Ġpolitician', 'ĠJoe', 'ĠHeck', 'Ġran', 'Ġunsuccessfully', 'Ġagainst', 'ĠDemocrat', 'ĠCatherine', 'ĠCort', 'ez', 'ĠMast', 'o', ',', 'Ġa', 'Ġwoman', 'Ġwho', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġthe', 'Ġ32', 'nd', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'Ġwhere', '?', '</q>', '<p>', 'ĠKam', 'ala', 'ĠDevi', 'ĠHarris', 'Ġ(', 'Ġ,', 'Ġ;', 'Ġborn', 'ĠOctober', 'Ġ20', ',', 'Ġ1964', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġattorney', 'Ġand', 'Ġpolitician', '.', 'Ġ', '<s>', 'ĠA', 'Ġmember', 'Ġof', 'Ġthe', 'ĠDemocratic', 'ĠParty', ',', 'Ġshe', 'Ġcurrently', 'Ġserves', 'Ġas', 'Ġthe', 'Ġjunior', 'Ġsenator', 'Ġfrom', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠShe', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġthe', 'Ġ32', 'nd', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'ĠCalifornia', '.', '<p>', 'ĠThe', 'ĠMaryland', 'ĠAttorney', 'ĠGeneral', 'Ġelection', 'Ġof', 'Ġ2014', 'Ġwas', 'Ġheld', 'Ġon', 'ĠNovember', 'Ġ4', ',', 'Ġ2014', ',', 'Ġto', 'Ġelect', 'Ġthe', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'ĠMaryland', '.', 'Ġ', '<s>', 'ĠInc', 'umb', 'ent', 'ĠDemocratic', 'ĠAttorney', 'ĠGeneral', 'ĠDoug', 'ĠG', 'ans', 'ler', 'Ġwas', 'Ġeligible', 'Ġto', 'Ġseek', 'Ġa', 'Ġthird', 'Ġterm', 'Ġin', 'Ġoffice', ',', 'Ġbut', 'Ġinstead', 'Ġran', 'Ġunsuccessfully', 'Ġfor', 'Ġthe', 'ĠDemocratic', 'Ġnomination', 'Ġfor', 'ĠGovernor', 'Ġof', 'ĠMaryland', '.', '<p>', 'ĠCorey', 'ĠLee', 'ĠPal', 'umbo', 'Ġ(', 'born', 'ĠAugust', 'Ġ16', ',', 'Ġ1972', ')', 'Ġis', 'Ġa', 'ĠWest', 'ĠVirginia', 'ĠState', 'ĠSenator', 'Ġrepresenting', 'Ġthe', 'Ġ17', 'th', 'Ġdistrict', 'Ġin', 'Ġthe', 'ĠWest', 'ĠVirginia', 'ĠSenate', '.', 'Ġ', '<s>', 'ĠA', 'Ġstate', 'Ġsenator', 'Ġsince', 'Ġ2009', ',', 'Ġhe', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠWest', 'ĠVirginia', 'ĠHouse', 'Ġof', 'ĠDe', 'legates', 'Ġfrom', 'Ġ2003', 'Ġto', 'Ġ2009', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġthe', 'Ġson', 'Ġof', 'ĠMario', 'ĠPal', 'umbo', ',', 'Ġthe', 'Ġ32', 'nd', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'ĠWest', 'ĠVirginia', 'Ġas', 'Ġwell', 'Ġas', 'Ġa', 'Ġformer', 'Ġfive', '-', 'term', 'Ġstate', 'Ġsenator', '.', '<p>', 'ĠCatherine', 'ĠMarie', 'ĠCort', 'ez', 'ĠMast', 'o', 'Ġ(', 'born', 'ĠMarch', 'Ġ29', ',', 'Ġ1964', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġattorney', 'Ġand', 'Ġpolitician', 'Ġwho', 'Ġis', 'Ġthe', 'Ġjunior', 'ĠUnited', 'ĠStates', 'ĠSenator', 'Ġfrom', 'ĠNevada', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠDemocratic', 'ĠParty', '.', 'Ġ', '<s>', 'ĠShe', 'Ġpreviously', 'Ġserved', 'Ġas', 'Ġthe', 'Ġ32', 'nd', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'ĠNevada', 'Ġfrom', 'Ġ2007', 'Ġto', 'Ġ2015', '.', '<p>', 'ĠJoseph', 'ĠJohn', 'ĠâĢ', 'ľ', 'Joe', 'âĢ', 'Ŀ', 'ĠHeck', 'Ġ(', 'born', 'ĠOctober', 'Ġ30', ',', 'Ġ1961', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', ',', 'Ġphysician', ',', 'Ġand', 'ĠU', '.', 'S', '.', 'ĠArmy', 'ĠBrig', 'adier', 'ĠGeneral', 'Ġwho', 'Ġhad', 'Ġserved', 'Ġas', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠRepresentative', 'Ġfor', 'ĠNevada', \"'s\", 'Ġ3', 'rd', 'Ġcongressional', 'Ġdistrict', 'Ġfrom', 'Ġ2011', 'Ġto', 'Ġ2017', '.', 'Ġ', '<s>', 'ĠHeck', ',', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠRepublican', 'ĠParty', ',', 'Ġis', 'Ġa', 'Ġboard', '-', 'cert', 'ified', 'Ġphysician', 'Ġand', 'Ġserved', 'Ġas', 'Ġa', 'ĠNevada', 'ĠState', 'ĠSenator', 'Ġfrom', 'Ġ2004', '-', '08', '.', 'Ġ', '<s>', 'ĠHe', 'Ġran', 'Ġunsuccessfully', 'Ġagainst', 'ĠDemocrat', 'ĠCatherine', 'ĠCort', 'ez', 'ĠMast', 'o', 'Ġin', 'Ġthe', 'Ġgeneral', 'Ġelection', 'Ġfor', 'Ġthe', 'Ġopen', 'ĠNevada', 'ĠUnited', 'ĠStates', 'ĠSenate', 'Ġseat', 'Ġin', 'Ġ2016', '.', 'Ġ', '<s>', 'ĠIn', 'Ġthe', 'Ġsame', 'Ġyear', ',', 'ĠHeck', 'Ġmade', 'Ġheadlines', 'Ġby', 'Ġjoining', 'Ġa', 'Ġlong', 'Ġlist', 'Ġof', 'ĠRepublicans', 'Ġwho', 'Ġopposed', 'Ġthe', 'ĠGOP', 'Ġnominee', 'Ġfor', 'ĠPresident', ',', 'ĠDonald', 'ĠTrump', '.', '<p>', 'ĠNevada', 'Ġwas', 'Ġadmitted', 'Ġto', 'Ġthe', 'ĠUnion', 'Ġon', 'ĠOctober', 'Ġ31', ',', 'Ġ18', '64', '.', 'Ġ', '<s>', 'ĠIts', 'Ġcurrent', 'Ġsenators', 'Ġare', 'ĠDemocrat', 'ĠCatherine', 'ĠCort', 'ez', 'ĠMast', 'o', 'Ġ(', 'Class', 'Ġ3', ')', 'Ġand', 'ĠRepublican', 'ĠDean', 'ĠHeller', 'Ġ(', 'Class', 'Ġ1', ').', '<p>', 'ĠDennis', 'ĠLynn', 'Ġ\"', 'D', 'enny', '\"', 'ĠHeck', 'Ġ(', 'born', 'ĠJuly', 'Ġ29', ',', 'Ġ1952', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġpolitician', 'Ġwho', 'Ġhas', 'Ġbeen', 'Ġthe', 'ĠUnited', 'ĠStates', 'ĠRepresentative', 'Ġfor', 'ĠWashington', \"'s\", 'Ġ10', 'th', 'Ġcongressional', 'Ġdistrict', 'Ġsince', 'Ġ2013', '.', 'Ġ', '<s>', 'ĠHeck', 'Ġwas', 'Ġpreviously', 'Ġthe', 'ĠDemocratic', 'Ġnominee', 'Ġfor', 'ĠU', '.', 'S', '.', 'ĠRepresentative', 'Ġfor', 'Ġthe', 'Ġ3', 'rd', 'Ġdistrict', 'Ġin', 'Ġ2010', ',', 'Ġbut', 'Ġwas', 'Ġdefeated', 'Ġby', 'ĠJaime', 'ĠHerrera', 'ĠBe', 'ut', 'ler', 'Ġ(', 'R', ').', 'Ġ', '<s>', 'ĠIn', 'Ġ2012', 'ĠHeck', 'Ġran', 'Ġand', 'Ġwon', 'Ġin', 'Ġthe', 'Ġnewly', 'Ġcreated', 'Ġ10', 'th', 'Ġdistrict', ',', 'Ġdefeating', 'ĠRepublican', 'ĠDick', 'ĠMur', 'i', '.', '<p>', 'ĠSamuel', 'ĠDillon', 'ĠJackson', 'Ġ(', 'May', 'Ġ28', ',', 'Ġ1895', 'March', 'Ġ8', ',', 'Ġ1951', ')', 'Ġwas', 'Ġa', 'ĠUnited', 'ĠStates', 'ĠSenator', 'Ġfrom', 'ĠIndiana', '.', 'Ġ', '<s>', 'ĠBorn', 'Ġnear', 'ĠZ', 'anes', 'ville', ',', 'ĠIndiana', ',', 'Ġhe', 'Ġattended', 'Ġthe', 'Ġpublic', 'Ġschools', 'Ġof', 'ĠFort', 'ĠWayne', 'Ġand', 'Ġgraduated', 'Ġfrom', 'Ġa', 'Ġpredecessor', 'Ġof', 'Ġthe', 'Ġnow', 'ĠIndiana', 'ĠUniversity', 'ĠRobert', 'ĠH', '.', 'ĠMcKin', 'ney', 'ĠSchool', 'Ġof', 'ĠLaw', 'Ġin', 'ĠIndianapolis', 'Ġin', 'Ġ1917', ',', 'Ġgaining', 'Ġadmission', 'Ġto', 'Ġthe', 'Ġbar', 'Ġthe', 'Ġsame', 'Ġyear', '.', 'Ġ', '<s>', 'ĠDuring', 'Ġthe', 'ĠFirst', 'ĠWorld', 'ĠWar', ',', 'Ġhe', 'Ġserved', 'Ġas', 'Ġa', 'Ġcaptain', 'Ġof', 'Ġinfantry', 'Ġfrom', 'Ġ1917', 'Ġto', 'Ġ1919', ',', 'Ġand', 'Ġengaged', 'Ġin', 'Ġthe', 'Ġpractice', 'Ġof', 'Ġlaw', 'Ġat', 'ĠFort', 'ĠWayne', 'Ġin', 'Ġ1919', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġprosecuting', 'Ġattorney', 'Ġof', 'ĠAllen', 'ĠCounty', 'Ġfrom', 'Ġ1924', 'Ġto', 'Ġ1928', '.', 'Ġ', '<s>', 'ĠHe', 'Ġran', 'Ġunsuccessfully', 'Ġas', 'Ġa', 'ĠDemocrat', 'Ġfor', 'Ġelection', 'Ġin', 'Ġ1928', 'Ġto', 'Ġthe', 'ĠSevent', 'y', '-', 'first', 'ĠCongress', ',', 'Ġand', 'Ġwas', 'Ġattorney', 'Ġgeneral', 'Ġof', 'ĠIndiana', 'Ġfrom', 'Ġ1940', 'Ġto', 'Ġ1941', '.', 'Ġ', '<s>', 'ĠOn', 'ĠJanuary', 'Ġ28', ',', 'Ġ1944', ',', 'Ġhe', 'Ġwas', 'Ġappointed', 'Ġas', 'Ġa', 'ĠDemocrat', 'Ġto', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠSenate', 'Ġto', 'Ġfill', 'Ġthe', 'Ġvacancy', 'Ġcaused', 'Ġby', 'Ġthe', 'Ġdeath', 'Ġof', 'ĠFrederick', 'ĠVan', 'ĠNu', 'ys', 'Ġand', 'Ġserved', 'Ġfrom', 'ĠJanuary', 'Ġ28', ',', 'Ġ1944', ',', 'Ġto', 'ĠNovember', 'Ġ13', ',', 'Ġ1944', ',', 'Ġwhen', 'Ġa', 'Ġduly', 'Ġelected', 'Ġsuccessor', 'Ġqualified', '.', 'Ġ', '<s>', 'ĠJackson', 'Ġwas', 'Ġnot', 'Ġa', 'Ġcandidate', 'Ġfor', 'Ġelection', 'Ġto', 'Ġfill', 'Ġthe', 'Ġvacancy', ',', 'Ġand', 'Ġwas', 'Ġan', 'Ġunsuccessful', 'ĠDemocratic', 'Ġcandidate', 'Ġfor', 'ĠGovernor', 'Ġof', 'ĠIndiana', 'Ġin', 'Ġ1944', '.', 'Ġ', '<s>', 'ĠHe', 'Ġresumed', 'Ġthe', 'Ġpractice', 'Ġof', 'Ġlaw', ',', 'Ġand', 'Ġdied', 'Ġin', 'ĠFort', 'ĠWayne', 'Ġin', 'Ġ1951', ';', 'Ġinter', 'ment', 'Ġwas', 'Ġin', 'ĠLind', 'en', 'wood', 'ĠCemetery', '.', '<p>', 'ĠGeorge', 'ĠHenry', 'ĠWilliams', 'Ġ(', 'March', 'Ġ26', ',', 'Ġ18', '23', 'April', 'Ġ4', ',', 'Ġ1910', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġjudge', 'Ġand', 'Ġpolitician', '.', 'Ġ', '<s>', 'ĠHe', 'Ġserved', 'Ġas', 'ĠChief', 'ĠJustice', 'Ġof', 'Ġthe', 'ĠOregon', 'ĠSupreme', 'ĠCourt', ',', 'Ġwas', 'Ġthe', 'Ġ32', 'nd', 'ĠAttorney', 'ĠGeneral', 'Ġof', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġand', 'Ġwas', 'Ġelected', 'ĠOregon', \"'s\", 'ĠU', '.', 'S', '.', 'ĠSenator', ',', 'Ġand', 'Ġserved', 'Ġone', 'Ġterm', '.', 'Ġ', '<s>', 'ĠWilliams', ',', 'Ġas', 'ĠU', '.', 'S', '.', 'ĠSenator', ',', 'Ġauthored', 'Ġand', 'Ġsupported', 'Ġlegislation', 'Ġthat', 'Ġallowed', 'Ġthe', 'ĠU', '.', 'S', '.', 'Ġmilitary', 'Ġto', 'Ġbe', 'Ġdeployed', 'Ġin', 'ĠReconstruction', 'Ġsouthern', 'Ġstates', 'Ġto', 'Ġallow', 'Ġfor', 'Ġan', 'Ġorderly', 'Ġprocess', 'Ġof', 'Ġread', 'mitt', 'ance', 'Ġinto', 'Ġthe', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠWilliams', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġpresidential', 'ĠCabinet', 'Ġmember', 'Ġto', 'Ġbe', 'Ġappointed', 'Ġfrom', 'Ġthe', 'ĠPacific', 'ĠCoast', '.', 'Ġ', '<s>', 'ĠAs', 'Ġattorney', 'Ġgeneral', 'Ġunder', 'ĠPresident', 'ĠU', 'lyss', 'es', 'ĠS', '.', 'ĠGrant', ',', 'ĠWilliams', 'Ġcontinued', 'Ġthe', 'Ġprosecutions', 'Ġthat', 'Ġshut', 'Ġdown', 'Ġthe', 'ĠKu', 'ĠKlux', 'ĠKlan', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhad', 'Ġto', 'Ġcontend', 'Ġwith', 'Ġcontroversial', 'Ġelection', 'Ġdisputes', 'Ġin', 'ĠRecon', 'structed', 'Ġsouthern', 'Ġstates', '.', 'Ġ', '<s>', 'ĠPresident', 'ĠGrant', 'Ġand', 'ĠWilliams', 'Ġlegally', 'Ġrecognized', 'ĠP', '.', 'ĠB', '.', 'ĠS', '.', 'ĠP', 'inch', 'back', 'Ġas', 'Ġthe', 'Ġfirst', 'ĠAfrican', 'ĠAmerican', 'Ġstate', 'Ġgovernor', '.', 'Ġ', '<s>', 'ĠWilliams', 'Ġruled', 'Ġthat', 'Ġthe', 'Ġ\"', 'Virgin', 'ius', '\",', 'Ġa', 'Ġgun', '-', 'running', 'Ġship', 'Ġcaptured', 'Ġby', 'ĠSpain', 'Ġduring', 'Ġthe', 'ĠVirgin', 'ius', 'ĠAff', 'air', ',', 'Ġdid', 'Ġnot', 'Ġhave', 'Ġthe', 'Ġright', 'Ġto', 'Ġbear', 'Ġthe', 'ĠU', '.', 'S', '.', 'Ġflag', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġhe', 'Ġargued', 'Ġthat', 'ĠSpain', 'Ġdid', 'Ġnot', 'Ġhave', 'Ġthe', 'Ġright', 'Ġto', 'Ġexecute', 'ĠAmerican', 'Ġcrew', 'Ġmembers', '.', 'Ġ', '<s>', 'ĠNom', 'inated', 'Ġfor', 'ĠSupreme', 'ĠCourt', 'ĠChief', 'ĠJustice', 'Ġby', 'ĠPresident', 'ĠGrant', ',', 'ĠWilliams', 'Ġfailed', 'Ġto', 'Ġbe', 'Ġconfirmed', 'Ġby', 'Ġthe', 'ĠU', '.', 'S', '.', 'ĠSenate', 'Ġprimarily', 'Ġdue', 'Ġto', 'ĠWilliams', \"'\", 'Ġremoval', 'Ġof', 'ĠA', '.', 'ĠC', '.', 'ĠGibbs', 'ĠUnited', 'ĠStates', 'ĠDistrict', 'ĠAttorney', 'Ġat', 'ĠPortland', ',', 'ĠOregon', '.', '<p>', 'ĠJeff', 'ĠHarris', 'Ġ(', 'born', 'ĠOctober', 'Ġ7', ',', 'Ġ1964', ')', 'Ġis', 'Ġan', 'Ġattorney', 'Ġand', 'Ġa', 'ĠMissouri', 'ĠDemocratic', 'Ġpolitician', '.', 'Ġ', '<s>', 'ĠHe', 'Ġrepresented', 'Ġthe', 'Ġ23', 'rd', 'ĠDistrict', 'Ġof', 'ĠMissouri', 'Ġin', 'Ġthe', 'ĠMissouri', 'ĠHouse', 'Ġof', 'ĠRepresentatives', 'Ġfrom', 'Ġ2003', 'âĢĵ', '2009', 'Ġand', 'Ġran', 'Ġunsuccessfully', 'Ġfor', 'Ġthe', 'Ġoffice', 'Ġof', 'Ġattorney', 'Ġgeneral', 'Ġin', 'Ġ2008', '.', 'Ġ', '<s>', 'ĠHe', 'Ġserved', 'Ġas', 'ĠMinority', 'ĠFloor', 'ĠLeader', 'Ġbefore', 'Ġgiving', 'Ġup', 'Ġthe', 'Ġpost', 'Ġin', 'Ġorder', 'Ġto', 'Ġfocus', 'Ġmore', 'Ġtime', 'Ġon', 'Ġthe', 'Ġattorney', 'Ġgeneral', 'Ġrace', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Are both The New Pornographers and Kings of Leon American rock bands?\n",
      "orig_answer_text:  no\n",
      "decode\n",
      "answers: [{'text': ' by President Grant, Williams failed to be confirmed by the', 'score': tensor([0.7587], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' by President Grant, Williams failed to be confirmed by the', 'score': tensor([0.7587], device='cuda:0')}]\n",
      "answer_score: tensor([0.7587], device='cuda:0')\n",
      "answer_text:  by President Grant, Williams failed to be confirmed by the\n",
      "answer_gold_token_ids: tensor([5077,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠNevada', '.']\n",
      "answer_gold:  Nevada.\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Who', 'Ġis', 'Ġthe', 'Ġdirector', 'Ġof', 'Ġthe', 'Ġ2003', 'Ġfilm', 'Ġwhich', 'Ġhas', 'Ġscenes', 'Ġin', 'Ġit', 'Ġfilmed', 'Ġat', 'Ġthe', 'ĠQuality', 'ĠCafe', 'Ġin', 'ĠLos', 'ĠAngeles', '?', '</q>', '<p>', 'ĠThe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwas', 'Ġstarted', 'Ġin', 'Ġ18', '85', '.', 'Ġ', '<s>', 'ĠOriginally', ',', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwas', 'Ġsplit', 'Ġinto', 'Ġfive', 'Ġindividual', 'Ġunions', 'Ġof', 'Ġb', 'akers', ',', 'Ġcigar', 'Ġmakers', ',', 'Ġprinters', ',', 'Ġtail', 'ors', ',', 'Ġand', 'Ġcar', 'pent', 'ers', '.', 'Ġ', '<s>', 'ĠNow', 'Ġthey', 'Ġrepresent', 'Ġover', 'Ġ300', 'Ġunions', ',', 'Ġabout', 'Ġ800', ',', '000', 'Ġpeople', ',', 'Ġthroughout', 'ĠLos', 'ĠAngeles', 'ĠCounty', ',', 'Ġmaking', 'Ġit', 'Ġthe', 'Ġsecond', 'Ġlargest', 'Ġin', 'Ġthe', 'Ġcountry', '.', 'Ġ', '<s>', 'ĠâĢ', 'ľ', 'A', 'Ġsurvey', 'Ġpublished', 'Ġin', 'ĠDecember', 'Ġ2003', 'Ġshowed', 'Ġthat', 'Ġthe', 'Ġthree', 'Ġlargest', 'Ġunions', 'Ġin', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', 'Ġwere', 'ĠSE', 'IU', 'Ġ4', '34', 'B', 'Ġ(', 'with', 'Ġseventy', '-', 'four', 'Ġthousand', 'Ġhome', 'care', 'Ġand', 'Ġnursing', 'Ġhome', 'Ġworkers', '),', 'ĠSE', 'IU', 'Ġ399', 'Ġwith', 'Ġforty', '-', 'five', 'Ġthousand', 'Ġhealth', 'Ġcare', 'Ġand', 'Ġother', 'Ġemployees', ',', 'Ġand', 'Ġthe', 'ĠUnited', 'ĠTeachers', 'Ġof', 'ĠLos', 'ĠAngeles', 'Ġ(', 'with', 'Ġthirty', 'Ġthousand', 'Ġteachers', 'Ġfrom', 'Ġthe', 'ĠAmerican', 'ĠFederation', 'Ġand', 'Ġthe', 'ĠNational', 'ĠEducation', 'ĠAssociation', ').', 'âĢ', 'Ŀ', 'Ġ', '<s>', 'ĠThey', 'Ġhave', 'Ġhelped', 'Ġmake', 'ĠLos', 'ĠAngeles', 'Ġa', 'Ġunion', 'Ġcity', '.', 'Ġ', '<s>', 'ĠTheir', 'Ġmission', 'Ġis', 'Ġto', 'ĠâĢ', 'ľ', 'Ġpromote', 'Ġa', 'Ġvoice', 'Ġfor', 'Ġworkers', 'Ġthrough', 'Ġorganizing', 'Ġthemselves', 'Ġinto', 'Ġunions', ',', 'Ġbuilding', 'Ġstrong', 'Ġcoal', 'itions', 'Ġof', 'Ġlabor', ',', 'Ġcommunity', ',', 'Ġfaith', ',', 'Ġand', 'Ġresponsible', 'Ġbusinesses', ',', 'Ġengaging', 'Ġin', 'Ġboth', 'Ġorganizing', 'Ġand', 'Ġpolitical', 'Ġcampaigns', ',', 'Ġelecting', 'Ġpro', '-', 'union', 'Ġand', 'Ġpro', '-', 'worker', 'Ġcandidates', 'Ġand', 'Ġadvancing', 'Ġpublic', 'Ġpolicies', 'Ġthat', 'Ġsupport', 'Ġworkers', ',', 'Ġfamilies', 'Ġand', 'Ġlocal', 'Ġcommunities', '.', 'âĢ', 'Ŀ', 'Ġ', '<s>', 'ĠThey', 'Ġalso', 'Ġencourage', 'Ġpeople', 'Ġto', 'Ġhelp', 'Ġmake', 'Ġchange', 'Ġby', 'Ġvoting', '.', 'Ġ', '<s>', 'ĠThe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'Ġlabor', 'Ġis', 'Ġa', 'Ġmajor', 'Ġfocal', 'Ġpoint', 'Ġfor', 'Ġnew', 'ĠAmerican', 'Ġlabor', 'Ġmovement', '.', 'Ġ', '<s>', 'ĠRecently', ',', 'Ġthe', 'Ġimpressive', 'Ġprogression', 'Ġof', 'ĠLos', 'ĠAngeles', 'Ġbecoming', 'Ġa', 'Ġunion', 'Ġcity', 'Ġhas', 'Ġbecome', 'Ġa', 'Ġstand', 'Ġout', 'Ġmodel', 'Ġfor', 'Ġother', 'Ġnon', '-', 'union', 'Ġcities', 'Ġbecause', 'Ġof', 'ĠLos', 'ĠAngeles', 'âĢ', 'Ļ', 'Ġanti', '-', 'union', 'Ġhistory', '.', 'Ġ', '<s>', 'ĠLos', 'ĠAngeles', 'Ġcombines', 'Ġthe', 'Ġeconomic', 'Ġdevelopment', 'Ġactivism', 'Ġand', 'Ġthe', 'Ġrefined', 'Ġpolitical', 'Ġwork', 'Ġof', 'Ġthe', 'ĠLos', 'ĠAngeles', 'ĠCounty', 'ĠFederation', 'Ġof', 'ĠLabor', '.', '<p>', 'ĠThe', 'ĠGood', 'ĠLife', 'ĠCafe', 'Ġwas', 'Ġa', 'Ġhealth', 'Ġfood', 'Ġmarket', 'Ġand', 'Ġcafe', 'Ġin', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', ',', 'Ġknown', 'Ġfor', 'Ġits', 'Ġopen', 'Ġmic', 'Ġnights', 'Ġthat', 'Ġhelped', 'Ġthe', 'Ġ1990', 's', 'ĠLos', 'ĠAngeles', 'Ġalternative', 'Ġhip', 'Ġhop', 'Ġmovement', 'Ġflourish', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2008', ',', 'Ġdirector', 'ĠAv', 'a', 'ĠDu', 'V', 'ern', 'ay', ',', 'Ġwho', 'Ġhad', 'Ġperformed', 'Ġat', 'Ġthe', 'Ġcafe', 'Ġwith', 'Ġthe', 'ĠFigures', 'Ġof', 'ĠSpeech', 'Ġhip', 'Ġhop', 'Ġgroup', ',', 'Ġreleased', 'Ġa', 'Ġdocumentary', 'Ġabout', 'Ġthe', 'Ġcafe', ',', 'Ġ\"', 'This', 'ĠIs', 'ĠThe', 'ĠLife', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġfeatured', 'Ġa', 'Ġnumber', 'Ġof', 'Ġhip', 'Ġhop', 'Ġartists', 'Ġdiscussing', 'Ġthe', 'Ġimportance', 'Ġof', 'Ġthe', 'ĠGood', 'ĠLife', 'ĠCafe', 'Ġto', 'Ġthemselves', 'Ġand', 'Ġthe', 'Ġhip', 'Ġhop', 'Ġscene', '.', 'Ġ', '<s>', 'ĠThe', 'ĠCafe', 'Ġwas', 'Ġopen', 'Ġfrom', 'Ġ1989', 'Ġto', 'Ġ1999', '.', '<p>', 'ĠAustin', 'ĠYoung', 'Ġ(', 'born', 'ĠApril', 'Ġ12', ',', 'Ġ1966', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġphotographer', ',', 'Ġfilm', 'Ġmaker', 'Ġand', 'Ġnew', 'Ġmedia', 'Ġartist', 'Ġcurrently', 'Ġbased', 'Ġin', 'ĠLos', 'ĠAngeles', '.', 'Ġ', '<s>', 'ĠHis', 'Ġwork', 'Ġhas', 'Ġcreated', 'Ġan', 'Ġen', 'cycl', 'oped', 'ic', 'Ġdocumentation', 'Ġof', 'Ġsub', 'Ġand', 'Ġtrans', 'Ġculture', 'Ġin', 'ĠNew', 'ĠYork', ',', 'ĠLos', 'ĠAngeles', 'Ġand', 'ĠSan', 'ĠFrancisco', '.', 'Ġ', '<s>', 'ĠYoung', \"'s\", 'Ġphotographs', 'Ġhave', 'Ġbeen', 'Ġfeatured', 'Ġin', 'Ġmajor', 'Ġpublications', 'Ġsuch', 'Ġas', 'ĠInterview', 'Ġmagazine', ',', 'ĠOK', ',', 'Ġand', 'ĠFl', 'aunt', 'Ġand', 'Ġhave', 'Ġbeen', 'Ġshown', 'Ġin', 'Ġsolo', 'Ġexhibitions', 'Ġand', 'Ġprojects', 'Ġat', 'ĠL', 'AC', 'MA', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠMachine', 'ĠProject', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠHammer', 'ĠMuseum', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', '),', 'ĠBerkeley', 'ĠArt', 'ĠMuseum', 'Ġ(', 'Ber', 'keley', ',', 'ĠCalifornia', ');', 'Ġand', 'Ġas', 'Ġwell', 'Ġas', 'Ġgroups', 'Ġshows', 'Ġat', 'ĠLos', 'ĠAngeles', 'ĠContemporary', 'ĠEx', 'hib', 'itions', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', ')', 'Ġand', 'ĠStephen', 'ĠCohen', 'ĠGallery', 'Ġ(', 'Los', 'ĠAngeles', ',', 'ĠCA', ').', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', 'Ġto', 'Ġphotography', 'Ġand', 'Ġfilm', 'Ġmaking', ',', 'ĠYoung', 'Ġis', 'Ġco', '-', 'founder', 'Ġof', 'ĠFallen', 'ĠFruit', ',', 'Ġan', 'Ġart', 'Ġcollective', 'Ġwho', 'Ġuse', 'Ġfruit', 'Ġas', 'Ġa', 'Ġcommon', 'Ġdenomin', 'ator', 'Ġfor', 'Ġpublic', 'Ġengagement', 'Ġand', 'Ġcollaboration', '.', '<p>', 'ĠOld', 'ĠSchool', 'Ġis', 'Ġa', 'Ġ2003', 'ĠAmerican', 'Ġcomedy', 'Ġfilm', 'Ġreleased', 'Ġby', 'ĠDream', 'Works', 'ĠPictures', 'Ġand', 'ĠThe', 'ĠMonte', 'c', 'ito', 'ĠPicture', 'ĠCompany', 'Ġand', 'Ġdirected', 'Ġby', 'ĠTodd', 'ĠPhillips', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠCourt', 'ĠCr', 'and', 'all', ',', 'Ġand', 'Ġthe', 'Ġfilm', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠPhillips', 'Ġand', 'ĠScot', 'ĠArmstrong', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġstars', 'ĠLuke', 'ĠWilson', ',', 'ĠVince', 'ĠVaughn', ',', 'Ġand', 'ĠWill', 'ĠFer', 'rell', 'Ġas', 'Ġthree', 'Ġdepressed', 'Ġthirty', '-', 's', 'omet', 'h', 'ings', 'Ġwho', 'Ġseek', 'Ġto', 'Ġre', '-', 'live', 'Ġtheir', 'Ġcollege', 'Ġdays', 'Ġby', 'Ġstarting', 'Ġa', 'Ġfraternity', ',', 'Ġand', 'Ġthe', 'Ġtrib', 'ulations', 'Ġthey', 'Ġencounter', 'Ġin', 'Ġdoing', 'Ġso', '.', 'Ġ', '<s>', 'ĠSince', 'Ġits', 'Ġrelease', 'Ġit', 'Ġhas', 'Ġgained', 'Ġa', 'Ġmassive', 'Ġcult', 'Ġfollowing', ',', 'Ġsince', 'Ġa', 'Ġlot', 'Ġof', 'Ġminor', 'Ġcharacters', 'Ġin', 'Ġthe', 'Ġfilm', 'Ġwent', 'Ġon', 'Ġto', 'Ġhave', 'Ġhuge', 'Ġcareers', 'Ġsuch', 'Ġas', 'ĠSimon', 'ĠHel', 'berg', ',', 'ĠE', 'lish', 'a', 'ĠC', 'uth', 'bert', ',', 'ĠRob', 'ĠCord', 'dry', 'Ġand', 'ĠArt', 'ie', 'ĠLange', '.', '<p>', 'ĠStephen', 'ĠNicholas', 'Ġ(', 'born', 'Ġ23', 'ĠAugust', 'Ġ1978', ')', 'Ġalso', 'Ġknown', 'Ġas', 'ĠStephen', 'ĠCharles', 'ĠNicholas', 'Ġis', 'Ġan', 'Ġactor', 'Ġand', 'Ġpresenter', 'Ġfrom', 'ĠDon', 'caster', ',', 'ĠSouth', 'ĠYorkshire', ',', 'ĠEngland', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġcurrently', 'Ġlives', 'Ġin', 'ĠSheffield', ',', 'Ġhis', 'Ġfirst', 'Ġrole', 'Ġwas', 'Ġon', 'ĠSky', 'ĠOne', \"'s\", 'ĠDream', 'ĠTeam', ',', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠScott', 'ĠWard', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġthere', ',', 'Ġhe', 'Ġfilmed', 'Ġthe', 'Ġfirst', 'Ġin', 'Ġthe', 'Ġtrilogy', 'ĠGoal', '!', 'Ġ', '<s>', 'Ġ(', 'In', 'Ġwhich', 'Ġhe', 'Ġplayed', 'Ġa', 'ĠNewcastle', 'ĠUnited', 'ĠRes', 'erves', 'Ġplayer', ').', 'Ġ', '<s>', 'ĠFollowing', 'Ġthis', ',', 'Ġhe', 'Ġmoved', 'Ġto', 'ĠLos', 'ĠAngeles', ',', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠSmith', 'Ġin', 'Ġthe', 'Ġfeature', 'Ġfilm', 'ĠFut', 'ba', 'al', ':', 'ĠThe', 'ĠPrice', 'Ġof', 'ĠDreams', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġthen', 'Ġreturned', 'Ġto', 'Ġthe', 'ĠUK', 'Ġto', 'Ġmake', 'Ġa', 'ĠB', 'ollywood', 'Ġfilm', 'Ġcalled', 'ĠDh', 'ana', 'ĠDh', 'ana', 'ĠGoal', 'Ġwith', 'ĠJohn', 'ĠAbraham', '.', 'Ġ', '<s>', 'ĠStephen', 'Ġthen', 'Ġexperienced', 'Ġhis', 'Ġfirst', 'Ġopportunity', 'Ġin', 'Ġreality', 'ĠTV', 'Ġwith', 'Ġthe', 'Ġshow', 'ĠPremier', 'ĠLeague', 'ĠAll', 'ĠStars', 'Ġfor', 'ĠSky', 'ĠOne', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġplaying', 'Ġa', 'Ġfootballer', ',', 'Ġhe', 'Ġwas', 'Ġon', '-', 'hand', 'Ġto', 'Ġpresent', 'Ġcelebrity', 'Ġgossip', 'Ġand', 'Ġpitch', 'Ġside', 'Ġreports', '.', 'Ġ', '<s>', 'ĠHe', 'Ġthen', 'Ġappeared', 'Ġin', 'ĠCelebrity', 'ĠMost', 'ĠHaunted', 'Ġand', 'ĠDate', 'Ġthe', 'ĠEnemy', '.', 'Ġ', '<s>', 'ĠFrom', 'Ġthere', 'Ġhe', 'Ġthen', 'Ġwent', 'Ġon', 'Ġto', 'Ġstar', 'Ġin', 'ĠGoal', 'Ġ3', 'Ġwhere', 'Ġhe', 'Ġnot', 'Ġonly', 'Ġacted', 'Ġin', 'Ġthe', 'Ġfilm', 'Ġhe', 'Ġalso', 'Ġbecame', 'Ġthe', 'Ġfootball', 'Ġchore', 'ographer', 'Ġand', 'Ġchore', 'ographed', 'Ġall', 'Ġthe', 'Ġfootball', 'Ġscenes', 'Ġin', 'Ġthe', 'Ġfilm', '.', 'Ġ', '<s>', 'ĠNicholas', 'Ġthen', 'Ġstarred', 'Ġin', 'Ġthe', 'Ġfilm', 'ĠDam', 'ned', 'ĠUnited', 'Ġwhere', 'Ġhe', 'Ġplayed', 'ĠWelsh', 'Ġinternational', 'ĠAlan', 'ĠDur', 'ban', ',', 'Ġthe', 'Ġfilm', 'Ġwas', 'Ġfilmed', 'Ġin', 'ĠChester', 'field', 'Ġand', 'ĠLeeds', 'Ġand', 'Ġwas', 'Ġdirected', 'Ġby', 'ĠOscar', 'Ġwinner', 'ĠTom', 'ĠHo', 'oper', 'Ġand', 'Ġalso', 'Ġstarred', 'ĠOscar', 'Ġnominated', 'ĠMichael', 'ĠSheen', '.', 'Ġ', '<s>', 'ĠStephens', 'Ġnext', 'Ġproduction', 'Ġwas', 'Ġthe', 'Ġfeature', 'Ġfilm', 'Ġcalled', \"Ġ'\", 'No', 'ĠWay', 'ĠBack', 'ĠNow', \"'\", 'about', 'Ġthe', 'Ġnotorious', 'ĠManchester', 'Ġdistrict', 'Ġof', 'ĠMoss', 'ĠSide', ',', 'Ġwhere', 'ĠStephen', 'Ġplayed', 'Ġthe', 'Ġlead', 'Ġactor', 'ĠStuart', 'ĠGavin', ',', 'The', 'Ġfeature', 'Ġis', 'Ġroughly', 'Ġbased', 'Ġon', 'Ġthe', 'Ġnotorious', 'ĠGo', 'och', 'Ġgang', 'Ġthat', 'Ġterror', 'ised', 'ĠManchester', 'Ġthroughout', 'Ġthe', 'Ġyears', '.', 'Ġ', '<s>', 'ĠThe', 'Ġnext', 'Ġmove', 'Ġfor', 'ĠStephen', 'Ġwas', 'Ġp', 'antom', 'ime', 'Ġwhere', 'Ġhe', 'Ġwas', 'Ġpart', 'Ġof', 'Ġthe', 'Ġproduction', 'ĠAl', 'addin', 'Ġover', 'Ġthe', 'ĠChristmas', 'Ġperiod', 'Ġof', 'Ġ2015', 'Ġin', 'ĠDon', 'caster', 'Ġplaying', 'ĠAb', 'an', 'aza', 'Ġthe', 'Ġmain', 'Ġvillain', 'Ġwhich', 'Ġhe', 'Ġdid', 'Ġuntil', 'ĠJanuary', 'Ġ7', ',', 'Ġ2016', '!', 'Ġ', '<s>', 'Ġ.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġrecently', 'Ġbeen', 'Ġcast', 'Ġin', 'Ġthe', 'Ġup', '-', 'and', '-', 'coming', 'ĠFeature', 'ĠFilm', \"Ġ'\", 'White', 'blade', \"'\", 'Ġwhere', 'Ġhe', 'Ġwill', 'Ġplay', 'ĠThur', 'stan', 'Ġthe', 'Ġhead', 'ĠWar', 'lord', 'ĠWhite', 'blade', 'Ġis', 'Ġcurrently', 'Ġin', 'Ġproduction', 'Ġand', 'ĠStephen', 'Ġis', 'Ġshooting', 'Ġhis', 'Ġscenes', 'Ġin', 'ĠAugust', 'Ġ2016', '.', 'Ġ', '<s>', 'ĠIn', 'ĠSeptember', 'Ġ2016', 'ĠStephen', 'Ġwill', 'Ġbe', 'Ġpresenting', 'Ġthe', 'ĠSky', 'ĠTV', 'Ġshow', \"Ġ'\", 'Brit', 'z', 'Ġgo', 'ĠB', 'ollywood', \"'\", 'Ġthe', 'Ġshow', 'Ġconsists', 'Ġof', 'Ġa', 'Ġgroup', 'Ġof', 'ĠCeleb', 'rities', 'Ġbeing', 'Ġdressed', 'Ġby', 'ĠThe', 'Ġbest', 'ĠIndian', 'Ġdesigners', ',', 'ĠStephen', 'Ġis', 'Ġthe', 'Ġmain', 'Ġpresenter', 'Ġof', 'Ġthe', 'Ġshow', 'Ġwhich', 'Ġwill', 'Ġbe', 'Ġscreened', 'Ġlive', 'ĠSeptember', 'Ġ2', ',', 'Ġ2016', '.', '<p>', 'ĠCompos', 'er', 'ĠJohn', 'ĠMiner', 'Ġmay', 'Ġbe', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġrock', 'Ġopera', 'ĠHeaven', 's', 'ĠCafe', ',', 'Ġwhich', 'Ġwas', 'Ġstaged', 'Ġat', 'Ġthe', 'ĠFl', 'aming', 'o', 'ĠTheater', 'Ġin', 'ĠLas', 'ĠVegas', 'Ġ1996', ',', 'Ġthe', 'ĠCharleston', 'ĠPer', 'forming', 'ĠArts', 'ĠCenter', 'Ġin', 'Ġ1997', ',', 'Ġand', 'Ġlater', 'Ġat', 'ĠIns', 'ur', 'go', 'ĠTheater', 'Ġin', 'ĠLos', 'ĠAngeles', 'Ġin', 'Ġ2004', '.', 'Ġ', '<s>', 'ĠMiner', 'Ġformed', 'Ġthe', 'Ġprogressive', 'Ġrock', 'Ġgroup', 'ĠArt', 'ĠRock', 'ĠCircus', 'Ġto', 'Ġperform', 'Ġthe', 'Ġmusic', 'Ġwith', 'Ġa', 'Ġlive', 'Ġband', 'Ġon', 'Ġstage', 'Ġalongside', 'Ġthe', 'Ġsingers', 'Ġand', 'Ġactors', '.', 'Ġ', '<s>', 'ĠInvestor', 'ĠMike', 'ĠLewis', 'Ġwas', 'Ġinstrumental', 'Ġin', 'Ġfinancing', 'Ġand', 'Ġstaging', 'ĠHeaven', 's', 'ĠCafe', '.', 'Ġ', '<s>', 'ĠThe', 'ĠT', 'ribut', 'ary', 'ĠMusic', 'ĠLabel', 'Ġreleased', 'Ġa', 'Ġlive', 'ĠCD', 'Ġof', 'ĠHeaven', 's', 'ĠCafe', 'Ġto', 'Ġthe', 'Ġprogressive', 'Ġrock', 'Ġcommunity', 'Ġin', 'Ġ2000', '.', '<p>', 'ĠQuality', 'ĠCafe', 'Ġis', 'Ġthe', 'Ġname', 'Ġof', 'Ġtwo', 'Ġdifferent', 'Ġformer', 'Ġlocations', 'Ġin', 'ĠDowntown', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', '.', '<p>', 'ĠQuality', 'ĠCafe', 'Ġwas', 'Ġa', 'Ġhistorical', 'Ġrestaurant', 'Ġand', 'Ġjazz', 'Ġclub', 'Ġlocated', 'Ġat', 'Ġ11', '43', 'ĠEast', 'Ġ12', 'th', 'ĠStreet', 'Ġnear', 'Ġthe', 'Ġcorner', 'Ġof', 'ĠCentral', 'ĠAvenue', 'Ġin', 'ĠDowntown', 'ĠLos', 'ĠAngeles', '.', 'Ġ', '<s>', 'ĠQuality', 'ĠFour', ',', 'Ġa', 'Ġjazz', 'Ġquart', 'et', 'Ġfounded', 'Ġby', 'Ġsax', 'ophon', 'ist', 'ĠPaul', 'ĠHoward', 'Ġand', 'Ġfeaturing', 'Ġyoung', 'Ġvib', 'raph', 'on', 'ist', 'ĠLionel', 'ĠHampton', ',', 'Ġwas', 'Ġformed', 'Ġin', 'Ġ1924', 'Ġto', 'Ġplay', 'Ġat', 'ĠQuality', 'ĠCafe', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġsoon', 'Ġbecame', 'ĠQuality', 'ĠQuint', 'et', 'Ġand', 'Ġthen', 'ĠQuality', 'ĠS', 'eren', 'ades', ',', 'Ġand', 'Ġwas', 'Ġdisbanded', 'Ġafter', 'Ġa', 'Ġtour', 'Ġwith', 'ĠHazel', 'ĠMyers', 'Ġlater', 'Ġin', 'Ġthe', 'Ġsame', 'Ġyear', '.', 'Ġ', '<s>', 'ĠOn', 'ĠJune', 'Ġ7', ',', 'Ġ1924', ',', 'Ġthe', 'Ġvenue', 'Ġchanged', 'Ġits', 'Ġname', 'Ġto', 'ĠHum', 'ming', 'ĠBird', 'ĠCafe', 'Ġand', 'Ġbecame', 'Ġ\"', 'one', 'Ġof', 'Ġthe', 'Ġhottest', 'Ġnightclub', 's', 'Ġin', 'Ġthe', 'Ġarea', '\"', 'Ġunder', 'Ġthis', 'Ġname', '.', '<p>', 'ĠFil', 'and', 'ia', 'Ġis', 'Ġa', 'Ġtown', 'Ġand', 'Ġmunicipality', 'Ġin', 'Ġthe', 'Ġnorthern', 'Ġpart', 'Ġof', 'Ġthe', 'Ġdepartment', 'Ġof', 'ĠQu', 'ind', 'ÃŃ', 'o', ',', 'ĠColombia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġlocated', 'Ġon', 'Ġthe', 'Ġwest', 'Ġside', 'Ġof', 'ĠCord', 'iller', 'a', 'ĠCentral', 'Ġof', 'Ġthe', 'ĠAnd', 'es', 'Ġmountain', 'Ġrange', 'Ġrunning', 'Ġthrough', 'Ġcentral', 'ĠColombia', ',', 'Ġ26', 'Âł', 'km', 'Ġnorth', 'Ġof', 'Ġthe', 'Ġdepartment', 'al', 'Ġcapital', 'ĠArmenia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġthe', 'Ġnorthern', 'most', 'Ġof', 'Ġtwelve', 'Ġmunicipalities', 'Ġthat', 'Ġform', 'ĠQu', 'ind', 'ÃŃ', 'o', ',', 'Ġthe', 'Ġsecond', 'Ġsmallest', 'Ġdepartment', 'Ġof', 'ĠColombia', '.', 'Ġ', '<s>', 'ĠIt', 'Ġhouses', 'Ġa', 'Ġsmall', 'Ġcommunity', 'Ġeconomically', 'Ġsupported', 'Ġby', 'Ġagriculture', 'Ġand', 'Ġtourism', '.', 'Ġ', '<s>', 'ĠAlthough', 'Ġcoffee', 'Ġis', 'Ġthe', 'Ġmajor', 'Ġagricultural', 'Ġproduct', ',', 'Ġthe', 'Ġmunicipality', \"'s\", 'Ġdiverse', 'Ġecosystem', 'Ġmakes', 'Ġit', 'Ġperfect', 'Ġfor', 'Ġthe', 'Ġproduction', 'Ġof', 'Ġnumerous', 'Ġfruits', 'Ġand', 'Ġvegetables', '.', 'Ġ', '<s>', 'ĠThe', 'Ġpopulation', 'Ġis', 'Ġevenly', 'Ġsplit', 'Ġbetween', 'Ġthe', 'Ġurban', 'Ġand', 'Ġrural', 'Ġareas', ',', 'Ġwith', 'Ġan', 'Ġurban', 'Ġpopulation', 'Ġin', 'Ġthe', 'Ġtown', 'Ġof', 'ĠFil', 'and', 'ia', 'Ġitself', 'Ġof', 'Ġnearly', 'Ġ7000', 'Ġinhabitants', 'Ġand', 'Ġa', 'Ġpopulation', 'Ġof', 'Ġaround', 'Ġ6', '500', 'Ġin', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġmunicipality', '.', 'Ġ', '<s>', 'ĠMost', 'Ġof', 'Ġthe', 'Ġpopulation', 'Ġis', 'Ġclassified', 'Ġas', 'Ġm', 'est', 'izo', 'Ġ(', '63', ',', '2', '%)', 'Ġand', 'Ġthe', 'Ġmost', 'Ġcommon', 'Ġreligion', 'Ġis', 'ĠRoman', 'ĠCatholic', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtown', \"'s\", 'Ġarchitecture', ',', 'Ġlandscapes', 'Ġand', 'Ġthe', 'Ġsoc', 'iability', 'Ġof', 'Ġthe', 'Ġlocals', 'Ġmakes', 'ĠFil', 'and', 'ia', 'Ġone', 'Ġof', 'Ġthe', 'Ġmost', 'Ġbeautiful', 'Ġand', 'Ġattractive', 'Ġtowns', 'Ġin', 'Ġthe', 'Ġdepartment', 'Ġof', 'ĠQu', 'ind', 'io', 'Ġand', 'Ġthe', 'Ġnation', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtown', \"'s\", 'Ġbest', '-', 'known', 'Ġtourist', 'Ġattractions', 'Ġare', 'Ġits', 'Ġ\"', 'mir', 'ador', '\"', 'Ġ(', 'view', 'ing', 'Ġtower', ')', 'Ġwith', 'Ġits', 'Ġextensive', 'Ġviews', 'Ġover', 'Ġthe', 'ĠC', 'au', 'ca', 'ĠRiver', 'Ġvalley', 'Ġto', 'Ġthe', 'Ġwest', 'Ġand', 'Ġthe', 'ĠPar', 'que', 'ĠN', 'ac', 'ional', 'ĠNatural', 'Ġlos', 'ĠNev', 'ados', 'Ġto', 'Ġthe', 'Ġeast', 'Ġ(', 'it', 'Ġis', 'Ġalso', 'Ġpossible', 'Ġto', 'Ġsee', 'Ġboth', 'ĠArmenia', 'Ġand', 'ĠPere', 'ira', 'Ġfrom', 'Ġthe', 'Ġtop', 'Ġof', 'Ġthe', 'Ġtower', '),', 'Ġand', 'Ġthe', 'Ġcafe', 'Ġin', 'Ġthe', 'Ġmain', 'Ġsquare', 'Ġwhere', 'Ġscenes', 'Ġfrom', 'Ġthe', 'Ġpopular', 'ĠColombian', 'Ġtel', 'eno', 'vel', 'a', 'Ġ\"', 'C', 'afe', ',', 'Ġcon', 'Ġaroma', 'Ġde', 'Ġm', 'uj', 'er', '\"', 'Ġwere', 'Ġfilmed', '.', '<p>', 'ĠThe', 'ĠQuality', 'ĠCafe', 'Ġ(', 'also', 'Ġknown', 'Ġas', 'ĠQuality', 'ĠD', 'iner', ')', 'Ġis', 'Ġa', 'Ġnow', '-', 'def', 'unct', 'Ġdiner', 'Ġat', 'Ġ12', '36', 'ĠWest', 'Ġ7', 'th', 'ĠStreet', 'Ġin', 'ĠLos', 'ĠAngeles', ',', 'ĠCalifornia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġrestaurant', 'Ġceased', 'Ġto', 'Ġfunction', 'Ġas', 'Ġa', 'Ġdiner', 'Ġin', 'Ġlate', 'Ġ2006', 'Ġbut', 'Ġhas', 'Ġappeared', 'Ġas', 'Ġa', 'Ġlocation', 'Ġfeatured', 'Ġin', 'Ġa', 'Ġnumber', 'Ġof', 'ĠHollywood', 'Ġfilms', ',', 'Ġincluding', 'Ġ\"', 'Training', 'ĠDay', '\",', 'Ġ\"', 'Old', 'ĠSchool', '\",', 'Ġ\"', 'Se', '7', 'en', '\",', 'Ġ\"', 'Ghost', 'ĠWorld', '\",', 'Ġ\"', 'G', 'one', 'Ġin', 'Ġ60', 'ĠSeconds', '\",', 'Ġ\"', 'The', 'ĠStep', 'father', '\",', 'Ġ\"', 'What', \"'s\", 'ĠLove', 'ĠGot', 'Ġto', 'ĠDo', 'Ġwith', 'ĠIt', '\",', 'Ġ\"', 'Sex', 'Ġand', 'ĠDeath', 'Ġ101', '\",', 'Ġand', 'Ġ\"', 'C', 'atch', 'ĠMe', 'ĠIf', 'ĠYou', 'ĠCan', '.\"', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġalso', 'Ġfeatured', 'Ġin', 'ĠSeason', 'Ġ1', 'Ġof', 'Ġthe', 'Ġ2007', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Mad', 'ĠMen', ',\"', 'Ġin', 'Ġthe', 'Ġepisode', 'Ġ\"', '5', 'G', '\".']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Dua Lipa, an English singer, songwriter and model, the album spawned the number-one single \"New Rules\" is a song by English singer Dua Lipa from her eponymous debut studio album, released in what year?\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "orig_answer_text:  2017\n",
      "decode\n",
      "answers: [{'text': ' started in 1885. <s> Originally, the Los Angeles', 'score': tensor([0.7647], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' started in 1885. <s> Originally, the Los Angeles', 'score': tensor([0.7647], device='cuda:0')}]\n",
      "answer_score: tensor([0.7647], device='cuda:0')\n",
      "answer_text:  started in 1885. <s> Originally, the Los Angeles\n",
      "answer_gold_token_ids: tensor([6540, 7431,    4], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠTodd', 'ĠPhillips', '.']\n",
      "answer_gold:  Todd Phillips.\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Which', 'Ġband', 'Ġwas', 'Ġfounded', 'Ġfirst', ',', 'ĠHole', ',', 'Ġthe', 'Ġrock', 'Ġband', 'Ġthat', 'ĠCourtney', 'ĠLove', 'Ġwas', 'Ġa', 'Ġfront', 'woman', 'Ġof', ',', 'Ġor', 'ĠThe', 'ĠWolf', 'h', 'ounds', '?', '</q>', '<p>', 'ĠNobody', \"'s\", 'ĠDaughter', 'Ġis', 'Ġthe', 'Ġfourth', 'Ġand', 'Ġfinal', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġreleased', 'Ġworldwide', 'Ġon', 'ĠApril', 'Ġ27', ',', 'Ġ2010', ',', 'Ġthrough', 'ĠMercury', 'ĠRecords', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġoriginally', 'Ġconceived', 'Ġby', 'ĠHole', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġas', 'Ġa', 'Ġsolo', 'Ġproject', 'Ġtitled', 'Ġ\"', 'How', 'ĠDirty', 'ĠGirls', 'ĠGet', 'ĠClean', '\",', 'Ġfollowing', 'Ġher', 'Ġpoorly', 'Ġreceived', 'Ġsolo', 'Ġdebut', 'Ġ\"', 'America', \"'s\", 'ĠSweet', 'heart', '\"', 'Ġ(', '2004', ').', 'Ġ', '<s>', 'ĠMuch', 'Ġof', 'Ġthe', 'Ġmaterial', 'Ġfeatured', 'Ġon', 'Ġ\"', 'Nobody', \"'s\", 'ĠDaughter', '\"', 'Ġoriginated', 'Ġfrom', 'Ġstudio', 'Ġsessions', 'Ġfor', 'Ġ\"', 'How', 'ĠDirty', 'ĠGirls', 'ĠGet', 'ĠClean', '\",', 'Ġwhich', 'Ġhad', 'Ġbeen', 'Ġconceived', 'Ġin', 'Ġ2006', 'Ġafter', 'Ġa', 'Ġmultitude', 'Ġof', 'Ġlegal', 'Ġissues', ',', 'Ġdrug', 'Ġaddiction', ',', 'Ġand', 'Ġrehabilitation', 'Ġsentences', 'Ġhad', 'Ġleft', 'ĠLove', 'Ġ\"', 'su', 'icidal', '\".', 'Ġ', '<s>', 'ĠLove', 'Ġfinanced', 'Ġthe', 'Ġmaking', 'Ġof', 'Ġthe', 'Ġrecord', 'Ġherself', ',', 'Ġwhich', 'Ġcost', 'Ġnearly', 'Ġtwo', 'Ġmillion', 'Ġdollars', '.', '<p>', 'ĠCourtney', 'ĠLove', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġmusician', 'Ġand', 'Ġactress', 'Ġwho', 'Ġbegan', 'Ġher', 'Ġprofessional', 'Ġcareer', 'Ġin', 'Ġfilm', 'Ġin', 'Ġ1986', 'Ġwith', 'Ġa', 'Ġsupporting', 'Ġrole', 'Ġin', 'ĠAlex', 'ĠCox', \"'s\", 'Ġ\"', 'S', 'id', 'Ġand', 'ĠNancy', '\"', 'Ġ(', '1986', ');', 'Ġshe', 'Ġhad', 'Ġprior', 'Ġstudied', 'Ġfilm', 'Ġwith', 'Ġexperimental', 'Ġdirector', 'ĠGeorge', 'ĠK', 'uch', 'ar', 'Ġat', 'Ġthe', 'ĠSan', 'ĠFrancisco', 'ĠArt', 'ĠInstitute', 'Ġin', 'Ġ1984', ',', 'Ġand', 'Ġappeared', 'Ġin', 'Ġone', 'Ġof', 'ĠK', 'uch', 'ar', \"'s\", 'Ġshort', 'Ġfilms', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġpursuing', 'Ġmusic', 'Ġand', 'Ġhaving', 'Ġa', 'Ġsuccessful', 'Ġcareer', 'Ġas', 'Ġthe', 'Ġfront', 'woman', 'Ġof', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'ĠLove', 'Ġalso', 'Ġhad', 'Ġintermittent', 'Ġroles', 'Ġin', 'Ġfilms', ',', 'Ġmost', 'Ġnotably', 'Ġreceiving', 'Ġcritical', 'Ġattention', 'Ġfor', 'Ġher', 'Ġperformance', 'Ġas', 'ĠAl', 'the', 'a', 'ĠFly', 'nt', 'Ġin', 'ĠMilo', 'Å¡', 'ĠForm', 'an', \"'s\", 'Ġ1996', 'Ġbi', 'opic', 'Ġ\"', 'The', 'ĠPeople', 'Ġvs', '.', 'ĠLarry', 'ĠFly', 'nt', '\",', 'Ġwhich', 'Ġearned', 'Ġher', 'Ġa', 'ĠGolden', 'ĠGlobe', 'ĠNom', 'ination', 'Ġfor', 'ĠBest', 'ĠActress', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġawards', 'Ġfrom', 'Ġthe', 'ĠBoston', ',', 'ĠChicago', ',', 'ĠNew', 'ĠYork', ',', 'Ġand', 'ĠLos', 'ĠAngeles', 'Ġfilm', 'Ġcritics', 'Ġassociations', '.', 'Ġ', '<s>', 'ĠLove', 'Ġlater', 'Ġappeared', 'Ġamong', 'Ġan', 'Ġensemble', 'Ġcast', 'Ġin', 'Ġ\"', '200', 'ĠCig', 'arettes', '\"', 'Ġ(', '1998', '),', 'Ġas', 'Ġwell', 'Ġas', 'Ġin', 'Ġa', 'Ġleading', 'Ġrole', 'Ġin', 'Ġ\"', 'Man', 'Ġon', 'Ġthe', 'ĠMoon', '\"', 'Ġ(', '1999', ')', 'Ġalongside', 'ĠJim', 'ĠCar', 'rey', ',', 'Ġfor', 'Ġwhich', 'Ġshe', 'Ġreceived', 'Ġcritical', 'Ġrecognition', '.', 'Ġ', '<s>', 'ĠShe', 'Ġlater', 'Ġappeared', 'Ġin', 'Ġseveral', 'Ġindependent', 'Ġfilms', 'Ġand', 'Ġshort', 'Ġsubjects', 'Ġas', 'Ġwell', 'Ġas', 'Ġthe', 'Ġthriller', 'Ġ\"', 'Tra', 'pped', '\"', 'Ġ(', '2002', ')', 'Ġalongside', 'ĠCharl', 'ize', 'ĠTher', 'on', 'Ġand', 'ĠKevin', 'ĠBacon', ',', 'Ġand', 'Ġ\"', 'Jul', 'ie', 'ĠJohnson', '\"', 'Ġ(', '2001', '),', 'Ġfor', 'Ġwhich', 'Ġshe', 'Ġreceived', 'Ġan', 'Ġaward', 'Ġfor', 'ĠBest', 'ĠActress', 'Ġat', 'ĠLos', 'ĠAngeles', \"'\", 'Ġgay', 'Ġand', 'Ġlesbian', 'ĠOut', 'fest', 'Ġfilm', 'Ġfestival', '.', '<p>', 'ĠPatricia', 'ĠTheresa', 'ĠSc', 'hem', 'el', 'Ġ(', 'born', 'ĠApril', 'Ġ24', ',', 'Ġ1967', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġdrummer', 'Ġand', 'Ġmusician', 'Ġwho', 'Ġrose', 'Ġto', 'Ġprominence', 'Ġas', 'Ġthe', 'Ġdrummer', 'Ġof', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', 'Ġfrom', 'Ġ1992', 'Ġuntil', 'Ġ1998', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1998', ',', 'ĠSc', 'hem', 'el', 'Ġleft', 'ĠHole', ',', 'Ġand', 'Ġin', 'Ġthe', 'Ġearly', 'Ġ2000', 's', 'Ġreunited', 'Ġwith', 'ĠHole', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġduring', 'Ġher', 'Ġsolo', 'Ġcareer', ',', 'Ġand', 'Ġlater', 'Ġdrum', 'med', 'Ġfor', 'ĠJuliet', 'te', 'Ġand', 'Ġthe', 'ĠL', 'icks', '.', 'Ġ', '<s>', 'ĠAs', 'Ġof', 'Ġ2010', ',', 'ĠSc', 'hem', 'el', 'Ġcontinues', 'Ġto', 'Ġplay', 'Ġmusic', 'Ġand', 'Ġgives', 'Ġdrum', 'Ġlessons', ',', 'Ġin', 'Ġaddition', 'Ġto', 'Ġowning', 'Ġa', 'Ġdog', 'Ġday', 'care', '/', 'boarding', 'Ġbusiness', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2013', ',', 'ĠSc', 'hem', 'el', 'Ġjoined', 'Ġthe', 'Ġindie', 'Ġrock', 'Ġgroup', 'ĠUps', 'et', ',', 'Ġformed', 'Ġby', 'ĠAli', 'ĠK', 'oe', 'hler', ',', 'Ġpreviously', 'Ġof', 'ĠViv', 'ian', 'ĠGirls', 'Ġand', 'ĠBest', 'ĠCoast', '.', 'Ġ', '<s>', 'ĠShe', 'Ġalso', 'Ġformed', 'Ġa', 'Ġrock', 'Ġand', 'Ġroll', 'Ġband', 'Ġwith', 'Ġher', 'Ġbrother', ',', 'ĠLarry', 'ĠSc', 'hem', 'el', ',', 'Ġcalled', 'ĠDeath', 'ĠValley', 'ĠGirls', '.', '<p>', 'Ġ\"', 'Beaut', 'iful', 'ĠSon', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġcollectively', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', ',', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', 'Ġand', 'Ġdrummer', 'ĠPatty', 'ĠSc', 'hem', 'el', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġfourth', 'Ġsingle', 'Ġin', 'ĠApril', 'Ġ1993', 'Ġon', 'Ġthe', 'ĠEuropean', 'Ġlabel', 'ĠCity', 'ĠSl', 'ang', '.', 'Ġ', '<s>', 'ĠTo', 'Ġcoincide', 'Ġwith', 'Ġthe', 'Ġsong', \"'s\", 'Ġlyrics', ',', 'ĠLove', 'Ġused', 'Ġa', 'Ġphotograph', 'Ġof', 'Ġher', 'Ġhusband', ',', 'ĠKurt', 'ĠCob', 'ain', ',', 'Ġat', 'Ġage', 'Ġ7', 'Ġas', 'Ġthe', 'Ġsingle', \"'s\", 'Ġartwork', '.', '<p>', 'ĠThe', 'ĠWolf', 'h', 'ounds', 'Ġare', 'Ġan', 'Ġindie', 'Ġpop', '/', 'no', 'ise', 'Ġpop', 'Ġband', 'Ġformed', 'Ġin', 'ĠRom', 'ford', ',', 'ĠUK', 'Ġin', 'Ġ1985', 'Ġby', 'ĠDave', 'ĠCall', 'ahan', ',', 'ĠPaul', 'ĠClark', ',', 'ĠAndy', 'ĠGold', 'ing', ',', 'ĠAndy', 'ĠBolton', 'Ġand', 'ĠFrank', 'ĠSt', 'eb', 'bing', ',', 'Ġand', 'Ġoriginally', 'Ġactive', 'Ġuntil', 'Ġ1990', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġreformed', 'Ġin', 'Ġ2005', 'Ġand', 'Ġcontinues', 'Ġto', 'Ġwrite', ',', 'Ġrecord', 'Ġand', 'Ġplay', 'Ġlive', ',', 'Ġreleasing', 'Ġnew', 'Ġalbums', 'Ġin', 'Ġ2014', 'Ġand', 'Ġ2016', '.', '<p>', 'ĠLive', 'ĠThrough', 'ĠThis', 'Ġis', 'Ġthe', 'Ġsecond', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġby', 'ĠD', 'GC', 'ĠRecords', 'Ġon', 'ĠApril', 'Ġ12', ',', 'Ġ1994', ',', 'Ġjust', 'Ġone', 'Ġweek', 'Ġafter', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', \"'s\", 'Ġhusband', ',', 'ĠKurt', 'ĠCob', 'ain', ',', 'Ġdied', 'Ġin', 'Ġtheir', 'Ġhome', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'ĠHole', \"'s\", 'Ġonly', 'Ġalbum', 'Ġto', 'Ġfeature', 'Ġbass', 'ist', 'ĠKristen', 'ĠPf', 'aff', 'Ġbefore', 'Ġher', 'Ġdeath', 'Ġin', 'ĠJune', 'Ġ1994', '.', 'Ġ', '<s>', 'ĠRecorded', 'Ġin', 'ĠOctober', 'Ġ1993', ',', 'Ġthe', 'Ġalbum', 'Ġmarked', 'Ġa', 'Ġdivergence', 'Ġfrom', 'Ġthe', 'Ġband', \"'s\", 'Ġunp', 'ol', 'ished', 'Ġhardcore', 'Ġaesthetics', 'Ġto', 'Ġmore', 'Ġrefined', 'Ġmelodies', 'Ġand', 'Ġsong', 'Ġstructure', ',', 'Ġand', 'Ġfeatures', 'Ġproduction', 'Ġby', 'ĠSean', 'ĠSl', 'ade', 'Ġand', 'ĠPaul', 'ĠQ', '.', 'ĠK', 'old', 'erie', ',', 'Ġwith', 'Ġmixing', 'Ġby', 'ĠScott', 'ĠL', 'itt', 'Ġand', 'ĠJ', 'ĠM', 'asc', 'is', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', \"'s\", 'Ġlyrics', 'Ġand', 'Ġpackaging', 'Ġreflect', 'ĠLove', \"'s\", 'Ġpre', 'occup', 'ation', 'Ġwith', 'Ġbeauty', ',', 'Ġand', 'Ġits', 'Ġsongs', 'Ġcontain', 'Ġrepeated', 'Ġmotif', 's', 'Ġof', 'Ġmilk', ',', 'Ġmother', 'hood', ',', 'Ġanti', '-', 'el', 'itism', ',', 'Ġand', 'Ġviolence', 'Ġagainst', 'Ġwomen', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', \"'s\", 'Ġtitle', 'Ġis', 'Ġderived', 'Ġfrom', 'Ġa', 'Ġquote', 'Ġin', 'Ġ\"', 'G', 'one', 'Ġwith', 'Ġthe', 'ĠWind', '\".', '<p>', 'Ġ\"', 'Tur', 'pent', 'ine', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'Ġvocal', 'ist', 'Ġand', 'Ġrhythm', 'Ġguitarist', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġone', 'Ġof', 'Ġthe', 'Ġband', \"'s\", 'Ġfirst', 'Ġcompositions', 'Ġand', 'Ġremained', 'Ġunre', 'leased', 'Ġfor', 'Ġseven', 'Ġyears', 'Ġbefore', 'Ġbeing', 'Ġreleased', 'Ġon', 'Ġthe', 'Ġband', \"'s\", 'Ġsecond', 'ĠEP', ',', 'Ġ\"', 'The', 'ĠFirst', 'ĠSession', '\"', 'Ġon', 'ĠAugust', 'Ġ26', ',', 'Ġ1997', '.', 'Ġ', '<s>', 'ĠAlthough', 'Ġnot', 'Ġas', 'Ġwell', 'Ġknown', 'Ġas', 'ĠHole', \"'s\", 'Ġlater', 'Ġsongs', ',', 'Ġ\"', 'Tur', 'pent', 'ine', '\"', 'Ġis', 'Ġa', 'Ġnotable', 'Ġsong', 'Ġfor', 'Ġthe', 'Ġband', 'Ġas', 'Ġit', 'Ġis', 'Ġoften', 'Ġcited', 'Ġas', 'Ġ\"', 'the', 'Ġfirst', 'ĠHole', 'Ġsong', '.\"', '<p>', 'Ġ\"', 'Miss', 'ĠWorld', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġfifth', 'Ġsingle', 'Ġand', 'Ġthe', 'Ġfirst', 'Ġfrom', 'Ġtheir', 'Ġsecond', 'Ġstudio', 'Ġalbum', ',', 'Ġ\"', 'Live', 'ĠThrough', 'ĠThis', '\",', 'Ġin', 'ĠMarch', 'Ġ1994', '.', '<p>', 'Ġ\"', 'So', 'fter', ',', 'ĠSoft', 'est', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠAmerican', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwritten', 'Ġby', 'Ġfront', 'woman', 'ĠCourtney', 'ĠLove', 'Ġand', 'Ġlead', 'Ġguitarist', 'ĠEric', 'ĠEr', 'land', 'son', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġthe', 'Ġband', \"'s\", 'Ġeighth', 'Ġsingle', 'Ġand', 'Ġfourth', 'Ġand', 'Ġfinal', 'Ġsingle', 'Ġfrom', 'Ġtheir', 'Ġsecond', 'Ġstudio', 'Ġalbum', ',', 'Ġ\"', 'Live', 'ĠThrough', 'ĠThis', '\",', 'Ġin', 'ĠDecember', 'Ġ1995', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsingle', 'Ġwas', 'Ġreleased', 'Ġjust', 'Ġas', 'Ġthe', 'Ġband', 'Ġfinished', 'Ġtheir', 'Ġextensive', 'Ġtouring', 'Ġin', 'Ġ1995', '.', '<p>', 'ĠCourtney', 'ĠMichelle', 'ĠLove', 'Ġ(', 'born', 'ĠCourtney', 'ĠMichelle', 'ĠHarrison', ';', 'ĠJuly', 'Ġ9', ',', 'Ġ1964', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġsinger', ',', 'Ġsong', 'writer', ',', 'Ġactress', ',', 'Ġand', 'Ġvisual', 'Ġartist', '.', 'Ġ', '<s>', 'ĠProl', 'ific', 'Ġin', 'Ġthe', 'Ġpunk', 'Ġand', 'Ġgrun', 'ge', 'Ġscenes', 'Ġof', 'Ġthe', 'Ġ1990', 's', ',', 'ĠLove', 'Ġhas', 'Ġenjoyed', 'Ġa', 'Ġcareer', 'Ġthat', 'Ġspans', 'Ġfour', 'Ġdecades', '.', 'Ġ', '<s>', 'ĠShe', 'Ġrose', 'Ġto', 'Ġprominence', 'Ġas', 'Ġthe', 'Ġfront', 'woman', 'Ġof', 'Ġthe', 'Ġalternative', 'Ġrock', 'Ġband', 'ĠHole', ',', 'Ġwhich', 'Ġshe', 'Ġformed', 'Ġin', 'Ġ1989', '.', 'Ġ', '<s>', 'ĠLove', 'Ġhas', 'Ġdrawn', 'Ġpublic', 'Ġattention', 'Ġfor', 'Ġher', 'Ġunin', 'hibited', 'Ġlive', 'Ġperformances', 'Ġand', 'Ġconfront', 'ational', 'Ġlyrics', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġher', 'Ġhighly', 'Ġpublicized', 'Ġpersonal', 'Ġlife', 'Ġfollowing', 'Ġher', 'Ġmarriage', 'Ġto', 'ĠKurt', 'ĠCob', 'ain', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "orig_answer_text:  no\n",
      "decode\n",
      "answers: [{'text': \"' gay and lesbian Outfest film festival.<p> Patricia Theresa Schemel (born April 24,\", 'score': tensor([0.7453], device='cuda:0')}]\n",
      "answers_pred: [{'text': \"' gay and lesbian Outfest film festival.<p> Patricia Theresa Schemel (born April 24,\", 'score': tensor([0.7453], device='cuda:0')}]\n",
      "answer_score: tensor([0.7453], device='cuda:0')\n",
      "answer_text: ' gay and lesbian Outfest film festival.<p> Patricia Theresa Schemel (born April 24,\n",
      "answer_gold_token_ids: tensor([   20,  7602,   298, 12363], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠThe', 'ĠWolf', 'h', 'ounds']\n",
      "answer_gold:  The Wolfhounds\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Are', 'Ġboth', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', 'Ġand', 'ĠKings', 'Ġof', 'ĠLeon', 'ĠAmerican', 'Ġrock', 'Ġbands', '?', '</q>', '<p>', 'ĠWhite', 'out', 'ĠConditions', 'Ġis', 'Ġthe', 'Ġseventh', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠCanadian', 'Ġindie', 'Ġrock', 'Ġband', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠApril', 'Ġ7', ',', 'Ġ2017', ',', 'Ġand', 'Ġis', 'Ġthe', 'Ġfirst', 'Ġalbum', 'Ġnot', 'Ġto', 'Ġfeature', 'Ġeither', 'Ġlongtime', 'Ġdrummer', 'ĠKurt', 'ĠDah', 'le', 'Ġor', 'Ġsinger', '-', 'song', 'writer', 'ĠDan', 'ĠBe', 'jar', '.', '<p>', 'ĠAllan', 'ĠCarl', 'ĠNewman', 'Ġ(', 'born', 'ĠApril', 'Ġ14', ',', 'Ġ1968', ')', 'Ġis', 'Ġa', 'ĠCanadian', 'Ġmusician', 'Ġand', 'Ġsinger', 'âĢĵ', 'song', 'writer', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'Ġindie', 'Ġrock', 'Ġbands', 'ĠSuper', 'cond', 'uctor', 'Ġand', 'ĠZ', 'ump', 'ano', 'Ġin', 'Ġthe', 'Ġ1990', 's', '.', 'Ġ', '<s>', 'ĠFollowing', 'Ġthe', 'Ġbreakup', 'Ġof', 'Ġthose', 'Ġbands', ',', 'Ġhe', 'Ġre', 'emer', 'ged', 'Ġas', 'Ġthe', 'Ġleader', 'Ġof', 'Ġthe', 'ĠNew', 'ĠPorn', 'ographers', 'Ġin', 'Ġ2000', ',', 'Ġa', 'Ġband', 'Ġwho', 'Ġhave', 'Ġenjoyed', 'Ġcommercial', 'Ġand', 'Ġcritical', 'Ġsuccess', '.', '<p>', 'ĠKings', 'Ġof', 'ĠLeon', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġrock', 'Ġband', 'Ġthat', 'Ġformed', 'Ġin', 'ĠNashville', ',', 'ĠTennessee', ',', 'Ġin', 'Ġ1999', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġis', 'Ġcomposed', 'Ġof', 'Ġbrothers', 'ĠCaleb', 'ĠFollow', 'ill', 'Ġ(', 'b', '.', 'ĠJanuary', 'Ġ14', ',', 'Ġ1982', ',', 'Ġlead', 'Ġvocals', ',', 'Ġrhythm', 'Ġguitar', '),', 'ĠNathan', 'ĠFollow', 'ill', 'Ġ(', 'b', '.', 'ĠJune', 'Ġ26', ',', 'Ġ1979', ',', 'Ġdrums', ',', 'Ġpercussion', ',', 'Ġbacking', 'Ġvocals', ')', 'Ġand', 'ĠJared', 'ĠFollow', 'ill', 'Ġ(', 'b', '.', 'ĠNovember', 'Ġ20', ',', 'Ġ1986', ',', 'Ġbass', 'Ġguitar', ',', 'Ġbacking', 'Ġvocals', '),', 'Ġwith', 'Ġtheir', 'Ġcousin', 'ĠMatthew', 'ĠFollow', 'ill', 'Ġ(', 'b', '.', 'ĠSeptember', 'Ġ10', ',', 'Ġ1984', ',', 'Ġlead', 'Ġguitar', ',', 'Ġbacking', 'Ġvocals', ').', '<p>', 'ĠLittle', 'ĠScout', 'Ġare', 'Ġan', 'Ġindependent', 'Ġband', 'Ġfrom', 'ĠBrisbane', ',', 'ĠAustralia', '.', 'Ġ', '<s>', 'ĠThey', 'Ġhave', 'Ġreleased', 'Ġtwo', 'ĠE', 'Ps', 'Ġand', 'Ġone', 'Ġalbum', ',', 'Ġand', 'Ġhave', 'Ġtoured', 'Ġwith', 'Ġestablished', 'ĠAustralian', 'Ġbands', 'ĠY', 'ves', 'ĠKlein', 'ĠBlue', ',', 'ĠThe', 'ĠHol', 'idays', ',', 'ĠHolly', 'ĠTh', 'ros', 'by', ',', 'ĠClare', 'ĠBow', 'd', 'itch', 'Ġand', 'ĠCloud', 'ĠControl', ';', 'Ġand', 'Ġinternational', 'Ġbands', 'ĠBelle', 'Ġand', 'ĠSebastian', ',', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', ',', 'ĠSharon', 'ĠVan', 'ĠE', 'tten', ',', 'ĠSchool', 'Ġof', 'ĠSeven', 'ĠBell', 's', 'Ġand', 'ĠCamera', 'ĠOb', 'sc', 'ura', '.', 'Ġ', '<s>', 'ĠSoon', 'Ġafter', 'Ġforming', 'Ġin', 'Ġ2008', 'Ġthey', 'Ġwere', 'Ġnamed', 'Ġas', 'Ġone', 'Ġof', 'ĠTriple', 'ĠJ', \"'s\", 'Ġ\"', 'Next', 'ĠC', 'rop', '\"', 'Ġartists', 'Ġand', 'Ġhave', 'Ġbeen', 'Ġfeatured', 'Ġon', 'ĠV', 'imeo', ',', 'Ġreceiving', 'Ġover', 'Ġ69', ',', '000', 'Ġviews', '.', 'Ġ', '<s>', 'ĠTheir', 'Ġdebut', 'Ġalbum', 'Ġ\"', 'Take', 'ĠYour', 'ĠLight', '\"', 'Ġwas', 'Ġreleased', 'Ġin', 'Ġ2011', ',', 'Ġto', 'Ġpositive', 'Ġreviews', '.', '<p>', 'ĠNek', 'o', 'ĠRic', 'helle', 'ĠCase', 'Ġ(', 'Ġ;', 'Ġborn', 'ĠSeptember', 'Ġ8', ',', 'Ġ1970', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġsinger', '-', 'song', 'writer', ',', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġher', 'Ġsolo', 'Ġcareer', 'Ġand', 'Ġher', 'Ġcontributions', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠCanadian', 'Ġindie', 'Ġrock', 'Ġgroup', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '.', '<p>', 'ĠGOOD', 'ĠPEOPLE', 'ĠROCK', ':', 'ĠA', 'ĠYellow', 'ĠBird', 'ĠProject', 'ĠCo', 'vers', 'ĠComp', 'ilation', 'Ġis', 'Ġan', 'Ġexclusive', 'Ġalbum', 'Ġof', 'ĠYellow', 'ĠBird', 'ĠProject', 'Ġbands', 'Ġcovering', 'Ġother', 'ĠYellow', 'ĠBird', 'ĠProject', 'Ġbands', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġin', 'Ġvinyl', 'Ġand', 'Ġdigital', 'Ġformats', 'Ġvia', 'ĠMad', 'ic', 'ĠRecords', ',', 'Ġwhich', 'Ġis', 'Ġa', 'Ġlabel', 'Ġimprint', 'Ġof', 'ĠArts', 'Ġ&', 'ĠCraft', 's', 'ĠProductions', ',', 'Ġowned', 'Ġand', 'Ġoperated', 'Ġby', 'ĠDan', 'ĠMang', 'an', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġwas', 'Ġcrowd', '-', 'funded', 'Ġon', 'ĠPledge', 'Music', 'Ġand', 'Ġtook', 'Ġseveral', 'Ġyears', 'Ġto', 'Ġproduce', 'ĠThe', 'Ġalbum', \"'s\", 'Ġfirst', 'Ġsingle', ',', 'ĠAndrew', 'ĠBird', \"'s\", 'Ġcover', 'Ġof', 'Ġ\"', 'The', 'ĠFake', 'ĠHead', 'lines', '\"', 'Ġ(', 'orig', 'inally', 'Ġby', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '),', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠApril', 'Ġ7', ',', 'Ġ2015', 'Ġwith', 'Ġa', 'Ġmusic', 'Ġvideo', 'Ġthat', 'Ġwas', 'Ġpremiered', 'Ġon', 'ĠPitch', 'fork', 'ĠMedia', '.', '<p>', 'ĠKathryn', 'ĠJane', 'ĠCalder', 'Ġ(', 'born', 'ĠJune', 'Ġ17', ',', 'Ġ1982', ')', 'Ġis', 'Ġa', 'ĠCanadian', 'Ġindie', 'Ġrock', 'Ġmusician', ',', 'Ġwho', 'Ġperforms', 'Ġas', 'Ġa', 'Ġsolo', 'Ġartist', ',', 'Ġand', 'Ġis', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'Ġband', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġa', 'Ġformer', 'Ġmember', 'Ġof', 'ĠImm', 'ac', 'ulate', 'ĠMachine', '.', 'Ġ', '<s>', 'ĠCalder', 'Ġstarted', 'Ġwith', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', 'Ġby', 'Ġfilling', 'Ġin', 'Ġfor', 'ĠNek', 'o', 'ĠCase', 'Ġfor', 'Ġlive', 'Ġperformances', 'Ġand', 'Ġwas', 'Ġmade', 'Ġa', 'Ġpermanent', 'Ġmember', 'Ġin', 'Ġ2006', '.', '<p>', 'ĠKurt', 'ĠColin', 'ĠDah', 'le', 'Ġis', 'Ġa', 'ĠCanadian', 'Ġmusician', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġwork', 'Ġas', 'Ġa', 'Ġdrummer', 'Ġand', 'Ġvocal', 'ist', 'Ġwith', 'Ġthe', 'Ġrock', 'Ġbands', 'ĠAge', 'Ġof', 'ĠElectric', ',', 'ĠLim', 'bl', 'ifter', ',', 'Ġand', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '.', '<p>', 'ĠPhantom', 'ĠBuffalo', 'Ġis', 'Ġan', 'Ġindie', '-', 'rock', 'Ġband', 'Ġfrom', 'ĠPortland', ',', 'ĠMaine', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġwas', 'Ġknown', 'Ġas', 'ĠThe', 'ĠPon', 'ys', 'Ġuntil', 'Ġ2004', ',', 'Ġwhen', 'Ġboth', 'ĠPortland', \"'s\", 'ĠPon', 'ys', 'Ġand', 'ĠChicago', '-', 'based', 'Ġband', 'ĠThe', 'ĠPon', 'ys', 'Ġwere', 'Ġinvited', 'Ġto', 'Ġperform', 'Ġat', 'ĠSouth', 'Ġby', 'ĠSouthwest', '.', 'Ġ', '<s>', 'ĠBeing', 'Ġthe', 'Ġlower', '-', 'profile', 'Ġof', 'Ġthe', 'Ġtwo', 'Ġbands', ',', 'Ġthe', 'ĠPortland', 'Ġgroup', 'Ġdecided', 'Ġon', 'Ġa', 'Ġname', 'Ġchange', 'Ġshortly', 'Ġthereafter', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcurrent', 'Ġlineup', 'Ġconsists', 'Ġof', 'ĠJonathan', 'ĠBal', 'z', 'ano', '-', 'Bro', 'okes', 'Ġ(', 'voc', 'als', ',', 'Ġguitar', '),', 'ĠTim', 'ĠBurns', 'Ġ(', 'g', 'uit', 'ar', ',', 'Ġvocals', '),', 'ĠJoe', 'ĠDom', 'rad', 'Ġ(', 'dr', 'ums', '),', 'ĠJacob', 'ĠChamberlain', 'Ġ(', 'dr', 'ums', '),', 'ĠSean', 'ĠNewton', 'Ġ(', 'bass', '),', 'Ġand', 'ĠPhilip', 'ĠWil', 'ley', 'Ġ(', 'g', 'uit', 'ar', ',', 'Ġaccord', 'ion', ',', 'Ġkeyboards', ').', 'Ġ', '<s>', 'ĠThe', 'Ġband', 'Ġhas', 'Ġreleased', 'Ġmusic', 'Ġdomestically', 'Ġon', 'Ġthe', 'ĠTime', '-', 'L', 'ag', 'ĠRecords', 'Ġlabel', 'Ġand', 'Ġin', 'Ġthe', 'ĠUK', 'Ġon', 'ĠRough', 'ĠTrade', 'ĠRecords', '.', 'Ġ', '<s>', 'ĠThe', 'Ġband', \"'s\", 'Ġj', 'ang', 'ly', ',', 'Ġpsychedelic', 'Ġpop', 'Ġmusic', 'Ġhas', 'Ġbeen', 'Ġcompared', 'Ġto', 'ĠThe', 'ĠByr', 'ds', 'Ġand', 'ĠNew', 'ĠZealand', \"'s\", 'ĠThe', 'ĠCh', 'ills', ',', 'Ġas', 'Ġwell', 'Ġas', 'ĠNorth', 'ĠAmerican', 'Ġindie', '-', 'pop', 'Ġacts', 'Ġlike', 'ĠThe', 'ĠSh', 'ins', 'Ġand', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', '.', '<p>', 'ĠThe', 'ĠNew', 'ĠPorn', 'ographers', 'Ġis', 'Ġa', 'ĠCanadian', 'Ġindie', 'Ġrock', 'Ġband', 'Ġformed', 'Ġin', 'Ġ1997', 'Ġin', 'ĠVancouver', ',', 'ĠBritish', 'ĠColumbia', '.', 'Ġ', '<s>', 'ĠPres', 'ented', 'Ġas', 'Ġa', 'Ġmusical', 'Ġcollective', 'Ġof', 'Ġsinger', '-', 'song', 'writers', 'Ġand', 'Ġmusicians', 'Ġfrom', 'Ġmultiple', 'Ġprojects', ',', 'Ġthe', 'Ġband', 'Ġhas', 'Ġreleased', 'Ġseven', 'Ġstudio', 'Ġalbums', 'Ġto', 'Ġcritical', 'Ġacclaim', 'Ġfor', 'Ġtheir', 'Ġuse', 'Ġof', 'Ġmultiple', 'Ġvocal', 'ists', 'Ġand', 'Ġelements', 'Ġof', 'Ġpower', 'Ġpop', 'Ġincorporated', 'Ġinto', 'Ġtheir', 'Ġmusic', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  How old is the female main protagonist of Catching Fire?\n",
      "orig_answer_text:  16-year-old\n",
      "decode\n",
      "answers: [{'text': ' by Southwest. <s> Being the lower-profile of the', 'score': tensor([0.7660], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' by Southwest. <s> Being the lower-profile of the', 'score': tensor([0.7660], device='cuda:0')}]\n",
      "answer_score: tensor([0.7660], device='cuda:0')\n",
      "answer_text:  by Southwest. <s> Being the lower-profile of the\n",
      "answer_gold: no\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'D', 'ua', 'ĠLip', 'a', ',', 'Ġan', 'ĠEnglish', 'Ġsinger', ',', 'Ġsong', 'writer', 'Ġand', 'Ġmodel', ',', 'Ġthe', 'Ġalbum', 'Ġspawned', 'Ġthe', 'Ġnumber', '-', 'one', 'Ġsingle', 'Ġ\"', 'New', 'ĠRules', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', ',', 'Ġreleased', 'Ġin', 'Ġwhat', 'Ġyear', '?', '</q>', '<p>', 'Ġ\"', 'Last', 'ĠDance', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠLip', 'a', 'Ġwrote', 'Ġthe', 'Ġsong', 'Ġwith', 'ĠStephen', 'Ġ\"', 'K', 'oz', '\"', 'ĠKoz', 'men', 'i', 'uk', 'Ġand', 'ĠTal', 'ay', 'ĠRiley', ',', 'Ġwith', 'ĠKoz', 'men', 'i', 'uk', 'Ġhandling', 'Ġthe', 'Ġsong', \"'s\", 'Ġproduction', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ9', 'ĠFebruary', 'Ġ2016', 'Ġas', 'Ġthe', 'Ġalbum', \"'s\", 'Ġsecond', 'Ġsingle', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtrack', 'Ġappears', 'Ġon', 'Ġthe', 'Ġdel', 'uxe', 'Ġedition', 'Ġof', 'Ġ\"', 'D', 'ua', 'ĠLip', 'a', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġpeaked', 'Ġat', 'Ġnumber', 'Ġfour', 'Ġon', 'Ġthe', 'Ġ\"', 'Bill', 'board', '\"', 'ĠTwitter', 'ĠEmerging', 'ĠArtists', 'Ġchart', ',', 'Ġspending', 'Ġseven', 'Ġweeks', 'Ġon', 'Ġit', '.', '<p>', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġ(', 'Ġ;', 'Ġ]', 'Ġ;', 'Ġborn', 'Ġ22', 'ĠAugust', 'Ġ1995', ')', 'Ġis', 'Ġan', 'ĠEnglish', 'Ġsinger', ',', 'Ġsong', 'writer', 'Ġand', 'Ġmodel', '.', 'Ġ', '<s>', 'ĠHer', 'Ġmusical', 'Ġcareer', 'Ġbegan', 'Ġat', 'Ġage', 'Ġ16', ',', 'Ġwhen', 'Ġshe', 'Ġbegan', 'Ġcovering', 'Ġsongs', 'Ġby', 'Ġother', 'Ġartists', 'Ġon', 'ĠYouTube', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2015', ',', 'Ġshe', 'Ġwas', 'Ġsigned', 'Ġwith', 'ĠWarner', 'ĠMusic', 'ĠGroup', ',', 'Ġand', 'Ġreleased', 'Ġher', 'Ġfirst', 'Ġsingle', 'Ġsoon', 'Ġafter', '.', 'Ġ', '<s>', 'ĠIn', 'ĠDecember', 'Ġ2016', ',', 'Ġa', 'Ġdocumentary', 'Ġabout', 'ĠLip', 'a', 'Ġwas', 'Ġcommissioned', 'Ġby', 'Ġ\"', 'The', 'ĠF', 'ader', '\"', 'Ġmagazine', ',', 'Ġtitled', 'Ġ\"', 'See', 'Ġin', 'ĠBlue', '\".', 'Ġ', '<s>', 'ĠIn', 'ĠJanuary', 'Ġ2017', ',', 'Ġshe', 'Ġwon', 'Ġthe', 'ĠEB', 'BA', 'ĠPublic', 'ĠChoice', 'ĠAward', '.', 'Ġ', '<s>', 'ĠHer', 'Ġself', '-', 't', 'itled', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ2', 'ĠJune', 'Ġ2017', '.', 'Ġ', '<s>', 'ĠThe', 'Ġalbum', 'Ġspawned', 'Ġseven', 'Ġsingles', ',', 'Ġincluding', 'Ġthe', 'Ġtop', '-', '10', 'Ġsingle', 'Ġ\"', 'Be', 'Ġthe', 'ĠOne', '\"', 'Ġand', 'Ġthe', 'Ġnumber', '-', 'one', 'Ġsingle', 'Ġ\"', 'New', 'ĠRules', '\".', '<p>', 'Ġ\"', 'Lost', 'Ġin', 'ĠYour', 'ĠLight', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', ',', 'Ġfeaturing', 'ĠAmerican', 'Ġsinger', 'ĠMiguel', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ21', 'ĠApril', 'Ġ2017', 'Ġas', 'Ġthe', 'Ġfifth', 'Ġsingle', 'Ġfrom', 'ĠLip', 'a', \"'s\", 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġas', 'Ġan', 'Ġinstant', '-', 'gr', 'at', 'Ġtrack', 'Ġto', 'Ġthose', 'Ġwho', 'Ġpre', '-', 'ordered', 'Ġthe', 'Ġsong', 'Ġon', 'Ġthe', 'ĠiTunes', 'ĠStore', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠLip', 'a', ',', 'ĠMiguel', ',', 'Ġand', 'ĠRick', 'ĠNow', 'els', ',', 'Ġwhile', 'Ġproduction', 'Ġwas', 'Ġhandled', 'Ġby', 'ĠMiguel', 'Ġand', 'ĠStephen', 'Ġ\"', 'K', 'oz', '\"', 'ĠKoz', 'men', 'i', 'uk', '.', 'Ġ', '<s>', 'ĠThe', 'Ġaccompanying', 'Ġmusic', 'Ġvideo', ',', 'Ġdirected', 'Ġby', 'ĠHenry', 'ĠSch', 'of', 'ield', ',', 'Ġwas', 'Ġfilmed', 'Ġin', 'ĠLos', 'ĠAngeles', 'Ġand', 'Ġpremiered', 'Ġon', 'Ġ26', 'ĠMay', 'Ġ2017', '.', '<p>', 'Ġ\"', 'Be', 'Ġthe', 'ĠOne', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠLucy', 'ĠTaylor', ',', 'ĠDigital', 'ĠFarm', 'ĠAnimals', 'Ġand', 'ĠJack', 'ĠT', 'arr', 'ant', ',', 'Ġand', 'Ġproduced', 'Ġby', 'ĠDigital', 'ĠFarm', 'ĠAnimals', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ30', 'ĠOctober', 'Ġ2015', 'Ġas', 'Ġthe', 'Ġalbum', \"'s\", 'Ġlead', 'Ġsingle', '.', '<p>', 'ĠHot', 'ter', 'Ġthan', 'ĠHell', 'ĠTour', 'Ġis', 'Ġthe', 'Ġsecond', 'Ġofficial', 'Ġconcert', 'Ġtour', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', ',', 'Ġin', 'Ġsupport', 'Ġof', 'Ġher', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ\"', 'D', 'ua', 'ĠLip', 'a', '\"', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġnamed', 'Ġafter', 'Ġher', 'Ġhit', 'Ġsingle', 'Ġ\"', 'Hot', 'ter', 'Ġthan', 'ĠHell', '\".', '<p>', 'Ġ\"', 'Bl', 'ow', 'ĠYour', 'ĠMind', 'Ġ(', 'M', 'w', 'ah', ')\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ26', 'ĠAugust', 'Ġ2016', 'Ġas', 'Ġthe', 'Ġalbum', \"'s\", 'Ġfourth', 'Ġsingle', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġdebuted', 'Ġat', 'Ġnumber', 'Ġ50', 'Ġand', 'Ġpeaked', 'Ġat', 'Ġnumber', 'Ġ30', 'Ġon', 'Ġthe', 'ĠUK', 'ĠSing', 'les', 'ĠChart', ';', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġit', 'Ġreached', 'Ġnumber', 'Ġ72', 'Ġon', 'Ġthe', 'Ġ\"', 'Bill', 'board', '\"', 'ĠHot', 'Ġ100', ',', 'Ġbecoming', 'ĠLip', 'a', \"'s\", 'Ġfirst', 'Ġsong', 'Ġto', 'Ġchart', 'Ġin', 'Ġthe', 'Ġcountry', '.', 'Ġ', '<s>', 'ĠIt', 'Ġalso', 'Ġtopped', 'Ġthe', 'Ġ\"', 'Bill', 'board', '\"', 'ĠDance', 'ĠClub', 'ĠSongs', 'Ġchart', ',', 'Ġbecoming', 'ĠLip', 'a', \"'s\", 'Ġfirst', 'Ġnumber', '-', 'one', 'Ġsingle', 'Ġon', 'Ġthat', 'Ġchart', '.', '<p>', 'ĠThe', 'ĠUS', 'Ġand', 'ĠEurope', 'ĠTour', 'Ġis', 'Ġthe', 'Ġthird', 'Ġofficial', 'Ġconcert', 'Ġtour', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtour', 'Ġsupports', 'Ġher', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ\"', 'D', 'ua', 'ĠLip', 'a', '\"', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠThe', 'Ġtour', 'Ġbegan', 'Ġon', 'Ġ24', 'ĠFebruary', 'Ġ2017', 'Ġin', 'ĠChicago', '.', '<p>', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġis', 'Ġthe', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ2', 'ĠJune', 'Ġ2017', 'Ġby', 'ĠWarner', 'ĠBros', '.', 'Ġ', '<s>', 'ĠRecords', '.', 'Ġ', '<s>', 'ĠThe', 'Ġlyr', 'ical', 'Ġthemes', 'Ġrev', 'olve', 'Ġaround', 'Ġher', 'Ġpersonal', 'Ġviews', 'Ġof', 'Ġlove', ',', 'Ġrising', 'Ġabove', ',', 'Ġsex', 'Ġand', 'Ġself', '-', 'em', 'power', 'ment', '.', '<p>', 'Ġ\"', 'New', 'ĠRules', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠThe', 'Ġtrack', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠCaroline', 'ĠA', 'il', 'in', ',', 'ĠEmily', 'ĠWarren', 'Ġand', 'ĠIan', 'ĠKirk', 'patrick', ',', 'Ġwhile', 'Ġproduction', 'Ġwas', 'Ġhandled', 'Ġby', 'Ġthe', 'Ġlatter', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġto', 'Ġcontemporary', 'Ġhit', 'Ġradio', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠKingdom', 'Ġon', 'Ġ21', 'ĠJuly', 'Ġ2017', 'Ġas', 'Ġthe', 'Ġalbum', \"'s\", 'Ġsixth', 'Ġsingle', '.', 'Ġ', '<s>', 'ĠIt', 'Ġimpacted', 'Ġthe', 'Ġsame', 'Ġformat', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġon', 'Ġ22', 'ĠAugust', 'Ġ2017', '.', '<p>', 'Ġ\"', 'Hot', 'ter', 'Ġthan', 'ĠHell', '\"', 'Ġis', 'Ġa', 'Ġsong', 'Ġby', 'ĠEnglish', 'Ġsinger', 'ĠD', 'ua', 'ĠLip', 'a', 'Ġfrom', 'Ġher', 'Ġep', 'onymous', 'Ġdebut', 'Ġstudio', 'Ġalbum', 'Ġ(', '2017', ').', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'ĠLip', 'a', ',', 'ĠAdam', 'ĠMid', 'g', 'ley', ',', 'ĠTommy', 'ĠBaxter', 'Ġand', 'ĠGerard', 'ĠO', \"'\", 'Connell', ',', 'Ġand', 'Ġproduced', 'Ġby', 'ĠStephen', 'Ġ\"', 'K', 'oz', '\"', 'ĠKoz', 'men', 'i', 'uk', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsong', 'Ġwas', 'Ġreleased', 'Ġon', 'Ġ6', 'ĠMay', 'Ġ2016', 'Ġas', 'Ġthe', 'Ġalbum', \"'s\", 'Ġthird', 'Ġsingle', '.', 'Ġ', '<s>', 'Ġ\"', 'Hot', 'ter', 'Ġthan', 'ĠHell', '\"', 'Ġpeaked', 'Ġat', 'Ġnumber', 'Ġ15', 'Ġon', 'Ġthe', 'ĠUK', 'ĠSing', 'les', 'ĠChart', ',', 'Ġwhile', 'Ġreaching', 'Ġthe', 'Ġtop', 'Ġ20', 'Ġin', 'ĠAustralia', ',', 'ĠBelgium', 'Ġand', 'Ġthe', 'ĠNetherlands', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Chang Ucchin was born in korea during a time that ended with the conclusion of what? \n",
      "orig_answer_text:  World War II\n",
      "orig_answer_text:  World War II\n",
      "orig_answer_text:  World War II\n",
      "answers: [{'text': ' (Mwah)\" is a song by English singer Dua Lipa from her eponymous debut studio', 'score': tensor([0.7564], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' (Mwah)\" is a song by English singer Dua Lipa from her eponymous debut studio', 'score': tensor([0.7564], device='cuda:0')}]\n",
      "answer_score: tensor([0.7564], device='cuda:0')\n",
      "answer_text:  (Mwah)\" is a song by English singer Dua Lipa from her eponymous debut studio\n",
      "answer_gold_token_ids: tensor([  36, 3789,  322], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ(', '2017', ').']\n",
      "answer_gold:  (2017).\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Were', 'ĠPavel', 'ĠU', 'ry', 'so', 'hn', 'Ġand', 'ĠLeon', 'id', 'ĠLevin', 'Ġknown', 'Ġfor', 'Ġthe', 'Ġsame', 'Ġtype', 'Ġof', 'Ġwork', '?', '</q>', '<p>', 'ĠLeon', 'id', 'ĠKon', 'stant', 'in', 'ovich', 'ĠRam', 'zin', 'Ġ(', 'Russian', ':', 'ĠÐ', 'Ľ', 'Ðµ', 'Ð¾', 'Ð½', 'Ð¸', 'Ì', 'ģ', 'Ð´', 'ĠÐ', 'ļ', 'Ð¾', 'Ð½', 'Ñģ', 'ÑĤ', 'Ð°', 'Ð½', 'ÑĤ', 'Ð¸', 'Ì', 'ģ', 'Ð½', 'Ð¾Ð', '²', 'Ð¸', 'Ñ', 'ĩ', 'ĠÐ', 'ł', 'Ð°', 'Ð¼', 'Ð', '·', 'Ð¸', 'Ì', 'ģ', 'Ð½', 'Ġ)', 'Ġ(', '18', '87', 'âĢĵ', '19', '48', ')', 'Ġwas', 'Ġa', 'ĠSoviet', 'Ġthermal', 'Ġengineer', ',', 'Ġand', 'Ġthe', 'Ġinventor', 'Ġof', 'Ġa', 'Ġtype', 'Ġof', 'Ġflow', '-', 'through', 'Ġboiler', 'Ġknown', 'Ġas', 'Ġthe', 'Ġstraight', '-', 'flow', 'Ġboiler', ',', 'Ġor', 'ĠRam', 'zin', 'Ġboiler', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġa', 'Ġlaureate', 'Ġof', 'Ġthe', 'ĠStalin', 'ĠPrize', 'ĠFirst', '-', 'Class', ',', 'Ġwhich', 'Ġhe', 'Ġreceived', 'Ġin', 'Ġ1943', '.', '<p>', 'ĠThe', 'Ġleftover', 'Ġhash', 'Ġle', 'mma', 'Ġis', 'Ġa', 'Ġle', 'mma', 'Ġin', 'Ġcryptography', 'Ġfirst', 'Ġstated', 'Ġby', 'ĠRussell', 'ĠImp', 'ag', 'lia', 'zzo', ',', 'ĠLeon', 'id', 'ĠLevin', ',', 'Ġand', 'ĠMichael', 'ĠLub', 'y', '.', '<p>', 'ĠPh', 'th', 'inosaur', 'us', 'Ġis', 'Ġan', 'Ġextinct', 'Ġgenus', 'Ġof', 'Ġthe', 'ra', 'ps', 'id', 'Ġfrom', 'Ġthe', 'ĠMiddle', 'ĠPer', 'm', 'ian', 'Ġof', 'ĠRussia', '.', 'Ġ', '<s>', 'ĠThe', 'Ġtype', 'Ġspecies', 'ĠPh', 'th', 'inosaur', 'us', 'Ġb', 'or', 'ris', 'i', 'aki', 'Ġwas', 'Ġnamed', 'Ġby', 'ĠSoviet', 'Ġpale', 'ont', 'ologist', 'ĠIvan', 'ĠY', 'ef', 'rem', 'ov', 'Ġin', 'Ġ1940', 'Ġon', 'Ġthe', 'Ġbasis', 'Ġof', 'Ġan', 'Ġisolated', 'Ġlower', 'Ġjaw', '.', 'Ġ', '<s>', 'ĠBecause', 'Ġthis', 'Ġjaw', 'Ġprovides', 'Ġfew', 'Ġdistinguishing', 'Ġcharacteristics', ',', 'Ġthe', 'Ġevolutionary', 'Ġrelationships', 'Ġof', 'Ġ\"', 'Ph', 'th', 'inosaur', 'us', '\"', 'Ġare', 'Ġpoorly', 'Ġknown', '.', 'Ġ', '<s>', 'ĠY', 'ef', 'rem', 'ov', 'Ġnamed', 'Ġthe', 'Ġfamily', 'ĠPh', 'th', 'inos', 'uch', 'idae', 'Ġin', 'Ġ1954', 'Ġto', 'Ġinclude', 'Ġ\"', 'Ph', 'th', 'inosaur', 'us', '\"', 'Ġand', 'Ġthe', 'Ġnewly', 'Ġnamed', 'Ġ\"', 'Ph', 'th', 'inos', 'uch', 'us', '\",', 'Ġwhich', 'Ġwas', 'Ġdescribed', 'Ġon', 'Ġthe', 'Ġbasis', 'Ġof', 'Ġa', 'Ġcrushed', 'Ġpartial', 'Ġskull', '.', 'Ġ', '<s>', 'ĠAmerican', 'Ġpale', 'ont', 'ologist', 'ĠEverett', 'ĠC', '.', 'ĠOlson', 'Ġplaced', 'Ġboth', 'Ġof', 'Ġthese', 'Ġthe', 'ra', 'ps', 'ids', 'Ġin', 'Ġthe', 'Ġlarger', 'Ġinf', 'ra', 'order', 'ĠPh', 'th', 'inos', 'uch', 'ia', 'Ġin', 'Ġ1961', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1974', 'ĠLeon', 'id', 'ĠT', 'atar', 'in', 'ov', 'Ġnamed', 'Ġthe', 'Ġfamily', 'ĠPh', 'th', 'inosaur', 'idae', 'Ġto', 'Ġinclude', 'Ġ\"', 'Ph', 'th', 'inosaur', 'us', '\"', 'Ġalone', ',', 'Ġretaining', 'Ġ\"', 'Ph', 'th', 'inos', 'uch', 'us', '\"', 'Ġwithin', 'ĠPh', 'th', 'inos', 'uch', 'idae', '.', '<p>', 'ĠKate', 'ĠDillon', 'ĠLevin', 'Ġ(', 'born', 'ĠMarch', 'Ġ2', ',', 'Ġ1974', 'Ġin', 'ĠWashington', 'ĠD', '.', 'C', '.)', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġmodel', ',', 'Ġactivist', 'Ġand', 'Ġactress', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġher', 'Ġwork', 'Ġas', 'Ġa', 'Ġplus', '-', 'size', 'Ġmodel', 'Ġwhere', 'Ġshe', 'Ġappeared', 'Ġin', 'Ġmultiple', 'Ġeditor', 'ials', 'Ġin', 'Ġfashion', 'Ġmagazines', ',', 'Ġappeared', 'Ġin', 'Ġcosmetics', ',', 'Ġplus', '-', 'size', ',', 'Ġand', 'Ġdesigner', 'Ġcampaigns', ',', 'Ġworked', 'Ġwith', 'Ġtop', 'Ġphotographers', 'Ġon', 'Ġcampaigns', 'Ġand', 'Ġin', 'Ġeditor', 'ials', 'Ġand', 'Ġappeared', 'Ġin', 'Ġmany', 'Ġmass', 'Ġmedia', 'Ġoutlets', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġplus', '-', 'size', 'Ġmodel', 'Ġto', 'Ġappear', 'Ġin', 'ĠU', '.', 'S', '.', 'ĠV', 'ogue', 'Ġand', 'Ġwas', 'Ġthe', 'Ġfirst', 'Ġplus', '-', 'size', 'Ġmodel', 'Ġto', 'Ġappear', 'Ġin', 'Ġa', 'ĠGu', 'cci', 'Ġcampaign', '.', 'Ġ', '<s>', 'ĠDillon', 'Ġhas', 'Ġalso', 'Ġbeen', 'Ġinvolved', 'Ġwith', 'Ġmany', 'Ġnon', '-', 'profit', 'Ġorganizations', ',', 'Ġand', 'Ġis', 'Ġan', 'Ġadvocate', 'Ġfor', 'Ġeating', 'Ġdisorder', 'Ġawareness', 'Ġand', 'Ġtreatment', ',', 'Ġsustainability', ',', 'Ġglobal', 'Ġpoverty', 'Ġreduction', 'Ġand', 'Ġsocial', 'Ġjustice', '.', 'Ġ', '<s>', 'ĠShe', 'Ġreceived', 'Ġher', 'Ġbachelor', \"'s\", 'Ġdegree', 'Ġin', 'Ġpolitical', 'Ġscience', 'Ġand', 'Ġinternational', 'Ġstudies', 'Ġfrom', 'ĠUniversity', 'Ġof', 'ĠSt', '.', 'ĠThomas', 'Ġand', 'Ġmaster', \"'s\", 'Ġdegree', 'Ġin', 'Ġinternational', 'Ġdevelopment', 'Ġfrom', 'ĠHarvard', 'ĠUniversity', \"'s\", 'ĠJohn', 'ĠF', '.', 'ĠKennedy', 'ĠSchool', 'Ġof', 'ĠGovernment', '.', 'Ġ', '<s>', 'ĠDillon', 'Ġwas', 'Ġbriefly', 'Ġmarried', 'Ġto', 'ĠGabe', 'ĠLevin', '.', 'Ġ', '<s>', 'ĠDuring', 'Ġthe', 'Ġmarriage', 'Ġthey', 'Ġhad', 'Ġa', 'Ġson', '.', '<p>', 'ĠAnthony', 'ĠFrederick', 'ĠLevin', 'Ġ(', 'born', 'ĠJune', 'Ġ6', ',', 'Ġ1946', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġmusician', 'Ġand', 'Ġcomposer', ',', 'Ġspecializing', 'Ġin', 'Ġelectric', 'Ġbass', ',', 'ĠChapman', 'ĠStick', 'Ġand', 'Ġupright', 'Ġbass', '.', 'Ġ', '<s>', 'ĠHe', 'Ġalso', 'Ġsings', 'Ġand', 'Ġplays', 'Ġsynthes', 'izer', '.', 'Ġ', '<s>', 'ĠLevin', 'Ġis', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġwork', 'Ġwith', 'ĠKing', 'ĠCrimson', 'Ġand', 'ĠPeter', 'ĠGabriel', '.', 'Ġ', '<s>', 'ĠHe', 'Ġwas', 'Ġalso', 'Ġa', 'Ġmember', 'Ġof', 'ĠLiquid', 'ĠT', 'ension', 'ĠExperiment', ',', 'ĠBru', 'ford', 'ĠLevin', 'ĠUpper', 'ĠExtrem', 'ities', ',', 'ĠPro', 'je', 'K', 'ct', 'ĠOne', ',', 'Ġand', 'ĠPro', 'je', 'K', 'ct', 'ĠFour', '.', 'Ġ', '<s>', 'ĠHe', 'Ġhas', 'Ġled', 'Ġhis', 'Ġown', 'Ġband', ',', 'ĠStick', 'ĠMen', '.', '<p>', 'ĠGabriel', 'ĠLevin', 'Ġ(', 'Born', 'Ġ1948', ',', 'ĠParis', ')', 'Ġis', 'Ġa', 'Ġpoet', ',', 'Ġtranslator', 'Ġand', 'Ġessay', 'ist', '.', 'Ġ', '<s>', 'ĠHe', 'Ġlives', 'Ġin', 'ĠJerusalem', 'Ġwith', 'Ġhis', 'Ġwife', 'Ġand', 'Ġchildren', '.', 'Ġ', '<s>', 'ĠLevin', 'Ġis', 'Ġone', 'Ġof', 'Ġthe', 'Ġfounding', 'Ġeditors', 'Ġof', 'ĠIb', 'is', 'ĠEd', 'itions', ',', 'Ġa', 'Ġsmall', 'Ġnon', '-', 'profit', 'Ġpress', 'Ġdevoted', 'Ġto', 'Ġthe', 'Ġpublication', 'Ġof', 'Ġthe', 'Ġliterature', 'Ġof', 'Ġthe', 'ĠLevant', ',', 'Ġand', 'Ġserves', 'Ġas', 'Ġits', 'ĠEditor', '-', 'at', '-', 'large', '.', 'Ġ', '<s>', 'ĠLevin', \"'s\", 'Ġwork', 'Ġhas', 'Ġappeared', 'Ġin', 'Ġnumerous', 'Ġliterary', 'Ġmagazines', ',', 'Ġincluding', 'ĠP', 'N', 'ĠReview', ',', 'ĠThe', 'ĠTimes', 'ĠLiterary', 'ĠSupplement', ',', 'Ġthe', 'ĠChicago', 'ĠReview', ',', 'ĠR', 'ar', 'itan', 'Ġand', 'ĠP', 'arn', 'ass', 'us', '.', 'Ġ', '<s>', 'Ġ\"', 'To', 'Ġthese', 'ĠDark', 'ĠSteps', '\",', 'Ġa', 'Ġvolume', 'Ġwritten', 'Ġin', 'Ġresponse', 'Ġto', 'Ġoperation', 'Ġ\"', 'Cast', 'ĠLead', '\"', 'Ġ(', '2008', '),', 'Ġwas', 'Ġset', 'Ġby', 'ĠBritish', 'Ġcomposer', 'ĠAlexander', 'ĠGo', 'e', 'hr', 'Ġfor', 'Ġten', 'or', ',', 'Ġchildren', \"'s\", 'Ġchoir', ',', 'Ġand', 'Ġensemble', 'Ġand', 'Ġpremiered', 'ĠSeptember', 'Ġ2012', 'Ġat', 'Ġthe', 'ĠCBS', 'O', 'ĠCentre', 'Ġin', 'ĠBirmingham', '.', 'Ġ', '<s>', 'ĠLevin', 'Ġis', 'Ġthe', 'Ġson', 'Ġof', 'Ġthe', 'ĠAmerican', 'Ġnovelist', 'ĠMeyer', 'ĠLevin', 'Ġ(', 'best', 'Ġknown', 'Ġfor', 'Ġ\"', 'Comp', 'ulsion', '\",', 'Ġthe', 'Ġfirst', 'Ġ\"', 'non', '-', 'fiction', 'Ġnovel', '\")', 'Ġand', 'ĠFrench', 'Ġnovelist', 'ĠTe', 'res', 'ka', 'ĠTorres', '.', '<p>', 'ĠLeon', 'id', 'ĠAnat', 'ol', 'iev', 'ich', 'ĠLevin', 'Ġ(', 'Ġ;', 'ĠRussian', ':', 'ĠÐ', 'Ľ', 'Ðµ', 'Ð¾', 'Ð½', 'Ð¸', 'Ì', 'ģ', 'Ð´', 'ĠÐ', 'Ĳ', 'Ð½', 'Ð°', 'ÑĤ', 'Ð¾', 'Ì', 'ģ', 'Ð»', 'ÑĮ', 'Ðµ', 'Ð²', 'Ð¸', 'Ñ', 'ĩ', 'ĠÐ', 'Ľ', 'Ðµ', 'Ì', 'ģ', 'Ð²', 'Ð¸', 'Ð½', 'Ġ;', 'ĠUkrainian', ':', 'ĠÐ', 'Ľ', 'Ðµ', 'Ð¾', 'Ð½', 'Ñ', 'ĸ', 'Ì', 'ģ', 'Ð´', 'ĠÐ', 'Ĳ', 'Ð½', 'Ð°', 'ÑĤ', 'Ð¾', 'Ì', 'ģ', 'Ð»', 'Ñ', 'ĸ', 'Ð', '¹', 'Ð¾Ð', '²', 'Ð¸', 'Ñ', 'ĩ', 'ĠÐ', 'Ľ', 'Ðµ', 'Ì', 'ģ', 'Ð²', 'Ñ', 'ĸ', 'Ð½', 'Ġ;', 'Ġborn', 'ĠNovember', 'Ġ2', ',', 'Ġ1948', ')', 'Ġis', 'Ġa', 'ĠSoviet', '-', 'American', 'Ġcomputer', 'Ġscientist', '.', '<p>', 'ĠPavel', 'ĠSam', 'u', 'il', 'ovich', 'ĠU', 'ry', 'so', 'hn', 'Ġ(', 'Ð', 'Ł', 'Ð°', 'Ì', 'ģ', 'Ð²', 'Ðµ', 'Ð»', 'ĠÐ', '¡', 'Ð°', 'Ð¼', 'Ñĥ', 'Ð¸', 'Ì', 'ģ', 'Ð»', 'Ð¾Ð', '²', 'Ð¸', 'Ñ', 'ĩ', 'ĠÐ', '£', 'ÑĢ', 'Ñĭ', 'Ñģ', 'Ð¾', 'Ì', 'ģ', 'Ð½', 'Ġ)', 'Ġ(', 'February', 'Ġ3', ',', 'Ġ1898', 'ĠâĢĵ', 'ĠAugust', 'Ġ17', ',', 'Ġ1924', ')', 'Ġwas', 'Ġa', 'ĠSoviet', 'Ġmathematician', 'Ġof', 'ĠJewish', 'Ġorigin', 'Ġwho', 'Ġis', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġcontributions', 'Ġin', 'Ġdimension', 'Ġtheory', ',', 'Ġand', 'Ġfor', 'Ġdeveloping', 'ĠU', 'ry', 'so', 'hn', \"'s\", 'ĠMet', 'riz', 'ation', 'ĠThe', 'orem', 'Ġand', 'ĠU', 'ry', 'so', 'hn', \"'s\", 'ĠLem', 'ma', ',', 'Ġboth', 'Ġof', 'Ġwhich', 'Ġare', 'Ġfundamental', 'Ġresults', 'Ġin', 'Ġtop', 'ology', '.', 'Ġ', '<s>', 'ĠHis', 'Ġname', 'Ġis', 'Ġalso', 'Ġcommemor', 'ated', 'Ġin', 'Ġthe', 'Ġterms', 'ĠU', 'ry', 'so', 'hn', 'Ġuniversal', 'Ġspace', ',', 'ĠFr', 'Ã©', 'chet', 'âĢĵ', 'U', 'ry', 'so', 'hn', 'Ġspace', ',', 'ĠMen', 'ger', 'âĢĵ', 'U', 'ry', 'so', 'hn', 'Ġdimension', 'Ġand', 'ĠU', 'ry', 'so', 'hn', 'Ġintegral', 'Ġequation', '.', 'Ġ', '<s>', 'ĠHe', 'Ġand', 'ĠPavel', 'ĠAlexand', 'rov', 'Ġformulated', 'Ġthe', 'Ġmodern', 'Ġdefinition', 'Ġof', 'Ġcompact', 'ness', 'Ġin', 'Ġ1923', '.', '<p>', 'ĠMeyer', 'ĠLevin', 'Ġ(', 'October', 'Ġ7', ',', 'Ġ1905', 'ĠâĢĵ', 'ĠJuly', 'Ġ9', ',', 'Ġ1981', ')', 'Ġwas', 'Ġan', 'ĠAmerican', 'Ġnovelist', '.', 'Ġ', '<s>', 'ĠPerhaps', 'Ġbest', 'Ġknown', 'Ġfor', 'Ġhis', 'Ġwork', 'Ġon', 'Ġthe', 'ĠLe', 'op', 'old', 'Ġand', 'ĠLo', 'eb', 'Ġcase', ',', 'ĠLevin', 'Ġworked', 'Ġas', 'Ġa', 'Ġjournalist', 'Ġ(', 'for', 'Ġthe', 'Ġ\"', 'Chicago', 'ĠDaily', 'ĠNews', '\"', 'Ġand', ',', 'Ġfrom', 'Ġ1933', 'âĢĵ', '39', ',', 'Ġas', 'Ġan', 'Ġeditor', 'Ġfor', 'Ġ\"', 'E', 'squ', 'ire', '\").', '<p>', 'ĠLeon', 'id', 'ĠBun', 'im', 'ovich', 'Ġis', 'Ġa', 'ĠSoviet', 'Ġand', 'ĠAmerican', 'Ġmathematician', ',', 'Ġwho', 'Ġspecializes', 'Ġin', 'Ġdynam', 'ical', 'Ġsystems', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġknown', 'Ġfor', 'Ġdiscovery', 'Ġof', 'Ġa', 'Ġfundamental', 'Ġmechanism', 'Ġof', 'Ġchaos', 'Ġ(', 'hyper', 'b', 'olic', 'ity', ')', 'Ġin', 'ĠDynam', 'ical', 'Ġsystems', ',', 'Ġwhich', 'Ġis', 'Ġcalled', 'Ġmechanism', 'Ġof', 'Ġdef', 'ocusing', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmost', 'Ġfamous', 'Ġclass', 'Ġof', 'Ġchaotic', 'Ġdynam', 'ical', 'Ġsystems', 'Ġof', 'Ġthis', 'Ġtype', 'ĠDynam', 'ical', 'Ġbill', 'i', 'ards', 'Ġare', 'Ġfocusing', 'Ġchaotic', 'Ġbill', 'i', 'ards', 'Ġ(', 'e', '.', 'g', '.,', 'Ġthe', 'Ġ\"', 'B', 'un', 'im', 'ovich', 'Ġstadium', '\",\"', 'B', 'un', 'im', 'ovich', 'Ġflowers', '\",', 'Ġetc', '.).', 'Ġ', '<s>', 'ĠMore', 'Ġrecently', 'Ġhe', 'Ġintroduced', 'Ġso', 'Ġcalled', 'ĠBun', 'im', 'ovich', 'Ġmushrooms', ',', 'Ġwhich', 'Ġare', 'Ġvisual', 'Ġexamples', 'Ġof', 'Ġbill', 'i', 'ards', 'Ġwith', 'Ġmixed', 'Ġregular', 'Ġand', 'Ġchaotic', 'Ġdynamics', '.', 'Ġ', '<s>', 'ĠIn', 'Ġmany', 'Ġlabs', 'Ġover', 'Ġthe', 'Ġworld', 'Ġwere', 'Ġbuilt', 'Ġexperimental', 'Ġdevices', 'Ġin', 'Ġthe', 'Ġform', 'Ġof', 'Ġvarious', 'ĠBun', 'im', 'ovich', 'Ġbill', 'i', 'ards', '.', 'Ġ', '<s>', 'ĠHe', 'Ġreceived', 'Ġbachelor', \"'s\", 'Ġdegree', 'Ġin', 'Ġ1967', 'Ġand', 'ĠPhD', 'Ġin', 'Ġ1973', 'Ġfrom', 'Ġthe', 'ĠUniversity', 'Ġof', 'ĠMoscow', '.', 'Ġ', '<s>', 'ĠHis', 'Ġthesis', 'Ġadviser', 'Ġwas', 'ĠYak', 'ov', 'ĠG', '.', 'ĠSinai', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1986', 'Ġhe', 'Ġwas', 'Ġawarded', 'ĠDoctor', 'Ġof', 'ĠSciences', 'Ġdegree', 'Ġin', 'Ġ\"', 'The', 'oret', 'ical', 'Ġand', 'ĠMathemat', 'ical', 'ĠPhysics', '\".']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question text:  Human Error\" is the season finale of the third season of a tv show that aired on what network?\n",
      "orig_answer_text:  Fox\n",
      "orig_answer_text:  Fox\n",
      "answers: [{'text': ' 7, 1905', 'score': tensor([0.7421], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' 7, 1905', 'score': tensor([0.7421], device='cuda:0')}]\n",
      "answer_score: tensor([0.7421], device='cuda:0')\n",
      "answer_text:  7, 1905\n",
      "answer_gold: no\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'How', 'Ġold', 'Ġis', 'Ġthe', 'Ġfemale', 'Ġmain', 'Ġprotagonist', 'Ġof', 'ĠC', 'atching', 'ĠFire', '?', '</q>', '<p>', 'ĠC', 'atching', 'ĠFire', 'Ġis', 'Ġa', 'Ġ2009', 'Ġscience', 'Ġfiction', 'Ġyoung', 'Ġadult', 'Ġnovel', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġnovelist', 'ĠSuzanne', 'ĠCollins', ',', 'Ġthe', 'Ġsecond', 'Ġbook', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', 'Ġtrilogy', '\".', 'Ġ', '<s>', 'ĠAs', 'Ġthe', 'Ġsequel', 'Ġto', 'Ġthe', 'Ġ2008', 'Ġbest', 'seller', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\",', 'Ġit', 'Ġcontinues', 'Ġthe', 'Ġstory', 'Ġof', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', 'Ġand', 'Ġthe', 'Ġpost', '-', 'ap', 'ocalyptic', 'Ġnation', 'Ġof', 'ĠPan', 'em', '.', 'Ġ', '<s>', 'ĠFollowing', 'Ġthe', 'Ġevents', 'Ġof', 'Ġthe', 'Ġprevious', 'Ġnovel', ',', 'Ġa', 'Ġrebellion', 'Ġagainst', 'Ġthe', 'Ġoppressive', 'ĠCapitol', 'Ġhas', 'Ġbegun', ',', 'Ġand', 'ĠKat', 'n', 'iss', 'Ġand', 'Ġfellow', 'Ġtribute', 'ĠPe', 'eta', 'ĠMell', 'ark', 'Ġare', 'Ġforced', 'Ġto', 'Ġreturn', 'Ġto', 'Ġthe', 'Ġarena', 'Ġin', 'Ġa', 'Ġspecial', 'Ġedition', 'Ġof', 'Ġthe', 'ĠHunger', 'ĠGames', '.', '<p>', 'ĠOil', 'Ġwell', 'Ġfires', 'Ġare', 'Ġoil', 'Ġor', 'Ġgas', 'Ġwells', 'Ġthat', 'Ġhave', 'Ġcaught', 'Ġon', 'Ġfire', 'Ġand', 'Ġburn', '.', 'Ġ', '<s>', 'ĠOil', 'Ġwell', 'Ġfires', 'Ġcan', 'Ġbe', 'Ġthe', 'Ġresult', 'Ġof', 'Ġhuman', 'Ġactions', ',', 'Ġsuch', 'Ġas', 'Ġaccidents', 'Ġor', 'Ġarson', ',', 'Ġor', 'Ġnatural', 'Ġevents', ',', 'Ġsuch', 'Ġas', 'Ġlightning', '.', 'Ġ', '<s>', 'ĠThey', 'Ġcan', 'Ġexist', 'Ġon', 'Ġa', 'Ġsmall', 'Ġscale', ',', 'Ġsuch', 'Ġas', 'Ġan', 'Ġoil', 'Ġfield', 'Ġspill', 'Ġcatching', 'Ġfire', ',', 'Ġor', 'Ġon', 'Ġa', 'Ġhuge', 'Ġscale', ',', 'Ġas', 'Ġin', 'Ġge', 'ys', 'er', '-', 'like', 'Ġjets', 'Ġof', 'Ġflames', 'Ġfrom', 'Ġignited', 'Ġhigh', 'Ġpressure', 'Ġwells', '.', 'Ġ', '<s>', 'ĠA', 'Ġfrequent', 'Ġcause', 'Ġof', 'Ġa', 'Ġwell', 'Ġfire', 'Ġis', 'Ġa', 'Ġhigh', '-', 'pressure', 'Ġblow', 'out', 'Ġduring', 'Ġdrilling', 'Ġoperations', '.', '<p>', 'ĠHO', ':', 'ĠFoot', 'prints', 'Ġin', 'Ġthe', 'ĠSand', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġby', 'ĠMak', 'ura', 'Ġthat', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠJune', 'Ġ23', ',', 'Ġ2006', 'Ġfor', 'Ġthe', 'ĠPC', 'Ġas', 'Ġa', 'ĠDVD', ';', 'Ġa', 'Ġversion', 'Ġplayable', 'Ġon', 'Ġthe', 'ĠPlayStation', 'Ġ2', 'Ġunder', 'Ġthe', 'Ġtitle', 'Ġ\"', 'HO', 'Ġ+', '\"', 'Ġfollowed', 'Ġon', 'ĠApril', 'Ġ24', ',', 'Ġ2008', 'Ġwith', 'Ġadult', 'Ġcontent', 'Ġremoved', ',', 'Ġbut', 'Ġin', 'Ġits', 'Ġplace', 'Ġwill', 'Ġbe', 'Ġadditional', 'Ġscenarios', 'Ġand', 'Ġgraphics', 'Ġnot', 'Ġseen', 'Ġin', 'Ġthe', 'Ġoriginal', 'Ġrelease', '.', 'Ġ', '<s>', 'Ġ\"', 'HO', '\"', 'Ġis', 'ĠMak', 'ura', \"'s\", 'Ġfirst', 'Ġgame', ';', 'Ġa', 'Ġsequel', 'Ġnamed', 'Ġ\"', 'Root', 'ĠAfter', 'Ġand', 'ĠAnother', '\"', 'Ġwas', 'Ġlater', 'Ġproduced', 'Ġin', 'ĠOctober', 'Ġ2007', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'HO', '\"', 'Ġfollows', 'Ġa', 'Ġplot', 'Ġline', 'Ġthat', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġthree', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThere', 'Ġare', 'Ġtwo', 'Ġmodes', 'Ġof', 'Ġgameplay', ',', 'Ġthe', 'ĠBlind', 'ness', 'ĠEffect', 'Ġand', 'ĠNormal', 'ĠEffect', ',', 'Ġwhere', 'Ġthe', 'Ġformer', 'Ġplays', 'Ġon', 'Ġthe', 'Ġfact', 'Ġthat', 'Ġthe', 'Ġprotagonist', 'Ġis', 'Ġblind', ',', 'Ġand', 'Ġthe', 'Ġlatter', 'Ġmode', 'Ġremoves', 'Ġthe', 'Ġadded', 'Ġelement', 'Ġof', 'Ġgameplay', 'Ġthe', 'ĠBlind', 'ness', 'ĠEffect', 'Ġhas', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġis', 'Ġbroken', 'Ġinto', 'Ġthree', 'Ġparts', ':', 'Ġthe', 'Ġoriginal', 'Ġintroduction', 'Ġand', 'Ġmeeting', ',', 'Ġfollowing', 'Ġby', 'Ġa', 'Ġseparation', 'Ġand', 'Ġreunion', ',', 'Ġand', 'Ġfinally', 'Ġending', 'Ġwith', 'Ġthe', 'Ġprotagonist', 'Ġchoosing', 'Ġone', 'Ġof', 'Ġthe', 'Ġgirls', 'Ġand', 'Ġspending', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġgame', 'Ġwith', 'Ġher', '.', '<p>', 'ĠTo', 'ĠHeart', 'Ġ2', 'Ġ(', 'ãĥĪ', 'ãĤ', '¥', 'ãĥı', 'ãĥ¼ãĥ', 'Ī', 'ï', '¼', 'Ĵ', 'Ġ,', 'ĠTu', 'ĠH', 'Äģ', 'to', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġstyl', 'ized', 'Ġas', 'ĠTo', 'Heart', '2', ',', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġromance', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠLeaf', 'Ġand', 'Ġpublished', 'Ġby', 'ĠAqua', 'plus', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġfirst', 'Ġreleased', 'Ġfor', 'Ġthe', 'ĠPlayStation', 'Ġ2', 'Ġon', 'ĠDecember', 'Ġ28', ',', 'Ġ2004', 'Ġas', 'Ġan', 'Ġall', '-', 'ages', 'Ġtitle', ',', 'Ġand', 'Ġwas', 'Ġfollowed', 'Ġby', 'Ġan', 'Ġadult', 'Ġversion', 'Ġplayable', 'Ġon', 'ĠMicrosoft', 'ĠWindows', 'Ġand', 'Ġsubsequent', 'Ġall', '-', 'ages', 'Ġversions', 'Ġfor', 'Ġthe', 'ĠPlayStation', 'ĠPortable', 'Ġand', 'ĠPlayStation', 'Ġ3', '.', 'Ġ', '<s>', 'ĠThis', 'Ġdev', 'iated', 'Ġfrom', 'Ġthe', 'Ġrelease', 'Ġhistory', 'Ġof', 'Ġthe', 'Ġgame', \"'s\", 'Ġpredecessor', ',', 'Ġ\"', 'To', 'ĠHeart', '\",', 'Ġwhich', 'Ġwas', 'Ġoriginally', 'Ġreleased', 'Ġwith', 'Ġadult', 'Ġcontent', 'Ġprior', 'Ġto', 'Ġreceiving', 'Ġversions', 'Ġwith', 'Ġsuch', 'Ġcontent', 'Ġremoved', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'To', 'ĠHeart', 'Ġ2', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwith', 'Ġmultiple', 'Ġendings', ',', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġand', 'Ġcourses', 'Ġof', 'Ġinteraction', 'Ġbased', 'Ġon', 'Ġthe', 'Ġplayer', \"'s\", 'Ġdecisions', '.', 'Ġ', '<s>', 'ĠIts', 'Ġstory', 'Ġcenters', 'Ġon', 'Ġthe', 'Ġmale', 'Ġprotagonist', 'ĠT', 'aka', 'aki', 'ĠK', 'oun', 'o', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', '<p>', 'ĠThe', 'ĠHunger', 'ĠGames', 'Ġis', 'Ġa', 'Ġ2008', 'Ġdystopian', 'Ġnovel', 'Ġby', 'Ġthe', 'ĠAmerican', 'Ġwriter', 'ĠSuzanne', 'ĠCollins', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġwritten', 'Ġin', 'Ġthe', 'Ġvoice', 'Ġof', 'Ġ16', '-', 'year', '-', 'old', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', ',', 'Ġwho', 'Ġlives', 'Ġin', 'Ġthe', 'Ġfuture', ',', 'Ġpost', '-', 'ap', 'ocalyptic', 'Ġnation', 'Ġof', 'ĠPan', 'em', 'Ġin', 'ĠNorth', 'ĠAmerica', '.', 'Ġ', '<s>', 'ĠThe', 'ĠCapitol', ',', 'Ġa', 'Ġhighly', 'Ġadvanced', 'Ġmet', 'ropolis', ',', 'Ġexercises', 'Ġpolitical', 'Ġcontrol', 'Ġover', 'Ġthe', 'Ġrest', 'Ġof', 'Ġthe', 'Ġnation', '.', 'Ġ', '<s>', 'ĠThe', 'ĠHunger', 'ĠGames', 'Ġis', 'Ġan', 'Ġannual', 'Ġevent', 'Ġin', 'Ġwhich', 'Ġone', 'Ġboy', 'Ġand', 'Ġone', 'Ġgirl', 'Ġaged', 'Ġ12', 'âĢĵ', '18', 'Ġfrom', 'Ġeach', 'Ġof', 'Ġthe', 'Ġtwelve', 'Ġdistricts', 'Ġsurrounding', 'Ġthe', 'ĠCapitol', 'Ġare', 'Ġselected', 'Ġby', 'Ġlottery', 'Ġto', 'Ġcompete', 'Ġin', 'Ġa', 'Ġtelevised', 'Ġbattle', 'Ġto', 'Ġthe', 'Ġdeath', '.', '<p>', 'ĠMoon', 'Ġ(', 'sty', 'led', 'Ġas', 'ĠMoon', '.)', 'Ġ', '<s>', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠTactics', ',', 'Ġa', 'Ġbrand', 'Ġof', 'ĠNext', 'on', ',', 'Ġreleased', 'Ġon', 'ĠNovember', 'Ġ21', ',', 'Ġ1997', 'Ġplayable', 'Ġon', 'ĠWindows', 'ĠPCs', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġdescribed', 'Ġby', 'Ġthe', 'Ġdevelopment', 'Ġteam', 'Ġas', 'Ġa', 'Ġ\"', 'Re', 'aching', 'Ġthe', 'ĠHeart', 'ĠAVG', '\"', 'Ġ(', 'å¿', 'ĥ', 'ãģ«', 'å', '±', 'Ĭ', 'ãģı', 'AV', 'G', 'Ġ,', 'ĠKok', 'oro', 'Ġni', 'ĠT', 'od', 'oku', 'ĠAVG', 'Ġ)', 'Ġ.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġfollows', 'Ġthe', 'Ġprotagonist', 'ĠIk', 'umi', 'ĠAm', 'as', 'awa', ',', 'Ġa', 'Ġgirl', 'Ġwho', 'Ġjoins', 'Ġan', 'Ġorganization', 'Ġcalled', 'ĠFargo', 'Ġin', 'Ġthe', 'Ġhopes', 'Ġof', 'Ġdiscovering', 'Ġwhy', 'Ġand', 'Ġhow', 'Ġher', 'Ġmother', 'Ġdied', ',', 'Ġwho', 'Ġwas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'Ġsame', 'Ġgroup', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'Moon', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġthree', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġranked', 'Ġtwice', 'Ġin', 'Ġthe', 'Ġnational', 'Ġtop', 'Ġ50', 'Ġfor', 'Ġbest', '-', 'selling', 'ĠPC', 'Ġgames', 'Ġsold', 'Ġin', 'ĠJapan', '.', '<p>', 'ĠD', 'Åį', 'sei', 'Ġ(', 'åĲ', 'Į', 'æ', '£', '²', 'Ġ,', 'Ġlit', '.', 'Ġ\"', 'Ġ', '<s>', 'ĠCoh', 'ab', 'itation', '\")', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġsocial', 'Ġsimulation', 'Ġgame', 'Ġdeveloped', 'Ġby', 'ĠTactics', ',', 'Ġa', 'Ġbrand', 'Ġof', 'ĠNext', 'on', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠMay', 'Ġ23', ',', 'Ġ1997', 'Ġfor', 'ĠWindows', 'ĠPCs', ',', 'Ġthe', 'Ġsame', 'Ġday', 'Ġas', 'Ġ\"', 'To', 'ĠHeart', '\"', 'Ġby', 'ĠLeaf', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'D', 'Åį', 'sei', '\"', 'Ġfollows', 'Ġa', 'Ġbranching', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġsole', 'Ġfemale', 'Ġmain', 'Ġcharacter', 'ĠMan', 'ami', 'ĠMin', 'ase', '.', 'Ġ', '<s>', 'ĠThe', 'Ġplayer', 'Ġassumes', 'Ġthe', 'Ġrole', 'Ġof', 'Ġprotagonist', 'ĠMas', 'aki', 'ĠYam', 'ada', 'Ġwho', 'Ġis', 'Ġliving', 'Ġwith', 'ĠMan', 'ami', 'Ġshortly', 'Ġafter', 'Ġthey', 'Ġhave', 'Ġgraduated', 'Ġfrom', 'Ġhigh', 'Ġschool', '.', 'Ġ', '<s>', 'ĠMas', 'aki', 'Ġearns', 'Ġmoney', 'Ġat', 'Ġa', 'Ġjob', ',', 'Ġand', 'Ġwhen', 'Ġhe', 'Ġreturns', 'Ġhome', 'Ġwill', 'Ġhave', 'Ġsex', 'Ġwith', 'ĠMan', 'ami', 'Ġoften', ';', 'Ġthis', 'Ġprocess', 'Ġof', 'Ġwork', 'Ġin', 'Ġthe', 'Ġday', ',', 'Ġand', 'Ġsex', 'Ġat', 'Ġnight', 'Ġrepeats', 'Ġmany', 'Ġtimes', 'Ġthroughout', 'Ġgameplay', '.', '<p>', 'ĠThe', 'ĠHunger', 'ĠGames', ':', 'ĠC', 'atching', 'ĠFire', 'Ġis', 'Ġa', 'Ġ2013', 'ĠAmerican', 'Ġdystopian', 'Ġscience', 'Ġfiction', 'Ġadventure', 'Ġfilm', 'Ġbased', 'Ġon', 'ĠSuzanne', 'ĠCollins', \"'\", 'Ġdystopian', 'Ġnovel', ',', 'Ġ\"', 'C', 'atching', 'ĠFire', '\"', 'Ġ(', '2009', '),', 'Ġthe', 'Ġsecond', 'Ġinstallment', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġtrilogy', '.', 'Ġ', '<s>', 'ĠThe', 'Ġfilm', 'Ġis', 'Ġthe', 'Ġsequel', 'Ġto', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġ(', '2012', ')', 'Ġand', 'Ġthe', 'Ġsecond', 'Ġinstallment', 'Ġin', 'Ġ\"', 'The', 'ĠHunger', 'ĠGames', '\"', 'Ġfilm', 'Ġseries', ',', 'Ġproduced', 'Ġby', 'ĠNina', 'ĠJacob', 'son', 'Ġand', 'ĠJon', 'ĠKil', 'ik', ',', 'Ġand', 'Ġdistributed', 'Ġby', 'ĠLions', 'gate', '.', 'Ġ', '<s>', 'ĠFrancis', 'ĠLawrence', 'Ġdirected', 'Ġthe', 'Ġfilm', ',', 'Ġwith', 'Ġa', 'Ġscreenplay', 'Ġby', 'ĠSimon', 'ĠBeau', 'f', 'oy', 'Ġand', 'ĠMichael', 'ĠAr', 'nd', 't', '.', 'Ġ', '<s>', 'ĠAdding', 'Ġto', 'Ġthe', 'Ġexisting', 'Ġcast', ',', 'Ġthe', 'Ġsupporting', 'Ġcast', 'Ġwas', 'Ġfilled', 'Ġout', 'Ġwith', 'ĠPhilip', 'ĠSeymour', 'ĠHoffman', ',', 'ĠJeffrey', 'ĠWright', ',', 'ĠJ', 'ena', 'ĠMalone', ',', 'ĠSam', 'ĠCl', 'af', 'lin', ',', 'ĠLynn', 'ĠCohen', ',', 'ĠAmanda', 'ĠPl', 'ummer', ',', 'ĠAlan', 'ĠR', 'itch', 'son', ',', 'Ġand', 'ĠMeta', 'ĠGold', 'ing', '.', 'Ġ', '<s>', 'ĠFil', 'ming', 'Ġbegan', 'Ġon', 'ĠSeptember', 'Ġ10', ',', 'Ġ2012', ',', 'Ġin', 'ĠAtlanta', ',', 'ĠGeorgia', ',', 'Ġbefore', 'Ġmoving', 'Ġto', 'ĠHawaii', '.', 'Ġ', '<s>', 'ĠThe', 'Ġplot', 'Ġof', 'Ġ\"', 'C', 'atching', 'ĠFire', '\"', 'Ġtakes', 'Ġplace', 'Ġa', 'Ġfew', 'Ġmonths', 'Ġafter', 'Ġthe', 'Ġprevious', 'Ġinstallment', ';', 'ĠKat', 'n', 'iss', 'ĠEver', 'deen', 'Ġand', 'Ġfellow', 'ĠDistrict', 'Ġ12', 'Ġtribute', 'ĠPe', 'eta', 'ĠMell', 'ark', 'Ġhave', 'Ġreturned', 'Ġhome', 'Ġsafely', 'Ġafter', 'Ġwinning', 'Ġthe', 'Ġ74', 'th', 'ĠAnnual', 'ĠHunger', 'ĠGames', '.', 'Ġ', '<s>', 'ĠThroughout', 'Ġthe', 'Ġstory', ',', 'ĠKat', 'n', 'iss', 'Ġsenses', 'Ġthat', 'Ġa', 'Ġrebellion', 'Ġagainst', 'Ġthe', 'Ġoppressive', 'ĠCapitol', 'Ġis', 'Ġsimmer', 'ing', 'Ġthroughout', 'Ġthe', 'Ġdistricts', '.', '<p>', 'ĠTens', 'hin', 'ĠRan', 'man', ':', 'ĠLucky', 'Ġor', 'ĠUn', 'l', 'ucky', '!?', 'Ġ', '<s>', 'Ġ(', 'å¤©', 'ç¥ŀ', 'ä¹', '±', 'æ', '¼', '«', 'Ġ-', 'L', 'UCK', 'Y', 'Ġor', 'ĠUN', 'L', 'UCK', 'Y', '!?', 'Ġ', '<s>', 'Ġ-', 'Ġ)', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġby', 'ĠY', 'uz', 'us', 'oft', ',', 'Ġand', 'Ġreleased', 'Ġfor', 'Ġthe', 'ĠPC', 'Ġon', 'ĠMay', 'Ġ29', ',', 'Ġ2009', '.', 'Ġ', '<s>', 'ĠThe', 'Ġgame', 'Ġwas', 'Ġlater', 'Ġported', 'Ġto', 'Ġthe', 'ĠPlayStation', 'ĠPortable', 'Ġconsole', 'Ġby', 'ĠRussell', 'Ġon', 'ĠMarch', 'Ġ25', ',', 'Ġ2010', ',', 'Ġunder', 'Ġthe', 'Ġtitle', 'Ġ\"', 'T', 'ens', 'hin', 'ĠRan', 'man', 'Ġ-', 'ĠHappy', 'ĠGo', 'ĠLucky', '!!\"', 'Ġ', '<s>', 'Ġ.', 'Ġ', '<s>', 'ĠThe', 'Ġgameplay', 'Ġin', 'Ġ\"', 'T', 'ens', 'hin', 'ĠRan', 'man', '\"', 'Ġfollows', 'Ġa', 'Ġplot', 'Ġline', 'Ġwhich', 'Ġoffers', 'Ġpre', '-', 'd', 'etermined', 'Ġscenarios', 'Ġwith', 'Ġcourses', 'Ġof', 'Ġinteraction', ',', 'Ġand', 'Ġfocuses', 'Ġon', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfour', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġrevolves', 'Ġaround', 'ĠHar', 'uki', 'ĠCh', 'it', 'ose', ',', 'Ġthe', 'Ġvery', 'Ġunfortunate', 'Ġprotagonist', ',', 'Ġand', 'Ġolder', 'Ġbrother', 'Ġof', 'ĠSana', 'ĠCh', 'it', 'ose', '.', 'Ġ', '<s>', 'ĠOne', 'Ġday', ',', 'Ġhe', 'Ġreceives', 'Ġa', 'Ġparcel', 'Ġcontaining', 'Ġsomething', 'Ġhe', 'Ġwould', 'Ġnever', 'Ġhave', 'Ġthought', '.', '<p>', 'ĠHello', ',', 'ĠGood', '-', 'bye', 'Ġ(', 'ãĥı', 'ãĥŃ', 'ãĥ¼', 'ãĤ°', 'ãĥĥãĥī', 'ãĥĲ', 'ãĤ¤', 'Ġ,', 'ĠHar', 'Åį', 'ĠG', 'udd', 'ob', 'ai', 'Ġ)', 'Ġis', 'Ġa', 'ĠJapanese', 'Ġadult', 'Ġvisual', 'Ġnovel', 'Ġdeveloped', 'Ġand', 'Ġpublished', 'Ġby', 'ĠLump', 'Ġof', 'ĠSugar', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġreleased', 'Ġon', 'ĠDecember', 'Ġ17', ',', 'Ġ2010', 'Ġfor', 'ĠWindows', 'Ġas', 'ĠLump', 'Ġof', 'ĠSugar', \"'s\", 'Ġsixth', 'Ġtitle', '.', 'Ġ', '<s>', 'ĠA', 'Ġtrial', 'Ġedition', 'Ġwas', 'Ġreleased', 'Ġin', 'ĠOctober', 'Ġ2010', 'Ġrated', 'Ġfor', 'Ġall', 'Ġages', '.', 'Ġ', '<s>', 'ĠThe', 'Ġprimary', 'Ġfocus', 'Ġof', 'Ġthe', 'Ġgame', 'Ġis', 'Ġthe', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġfour', 'Ġfemale', 'Ġmain', 'Ġcharacters', '.', 'Ġ', '<s>', 'ĠThe', 'Ġstory', 'Ġresolves', 'Ġaround', 'Ġthe', 'Ġprotagonist', ',', 'ĠK', 'aito', 'ĠTou', 'bu', ',', 'Ġwho', 'Ġis', 'Ġactually', 'Ġa', 'Ġsecret', 'Ġagent', 'Ġwith', 'Ġthe', 'Ġability', 'Ġto', 'Ġexperience', 'Ġtime', 'Ġloops', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers: [{'text': ' school', 'score': tensor([0.7640], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' school', 'score': tensor([0.7640], device='cuda:0')}]\n",
      "answer_score: tensor([0.7640], device='cuda:0')\n",
      "answer_text:  school\n",
      "answer_gold_token_ids: tensor([545,  12, 180,  12, 279], device='cuda:0')\n",
      "answer_gold_tokens: ['Ġ16', '-', 'year', '-', 'old']\n",
      "answer_gold:  16-year-old\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Ch', 'ang', 'ĠU', 'c', 'chin', 'Ġwas', 'Ġborn', 'Ġin', 'Ġk', 'orea', 'Ġduring', 'Ġa', 'Ġtime', 'Ġthat', 'Ġended', 'Ġwith', 'Ġthe', 'Ġconclusion', 'Ġof', 'Ġwhat', '?', 'Ġ', '</q>', '<p>', 'ĠThe', 'ĠMay', 'Ġ16', 'Ġcoup', 'Ġ(', 'H', 'ang', 'ul', ':', 'Âł', '5', '.', '16', 'Ġ', 'ê', 'µ', '°', 'ì', 'Ĥ¬', 'ì', 'ł', 'ķ', 'ë', '³', 'Ģ', 'Ġ;', 'ĠHan', 'ja', ':', 'Âł', 'äºĶ', 'ä¸Ģ', 'åħ', 'Ń', 'è»', 'į', 'äº', 'ĭ', 'æ', 'Ķ', '¿', 'è', '®', 'Ĭ', 'Ġ;', 'ĠRR', ':', 'Âł', '\"', 'O', '-', 'illy', 'uk', 'Ġguns', 'a', '-', 'je', 'ong', 'bye', 'on', 'Ġ\"', 'Ġ)', 'Ġwas', 'Ġa', 'Ġmilitary', 'Ġcoup', 'Ġd', \"'\", 'Ã©t', 'at', 'Ġin', 'ĠSouth', 'ĠKorea', 'Ġin', 'Ġ1961', ',', 'Ġorganized', 'Ġand', 'Ġcarried', 'Ġout', 'Ġby', 'ĠPark', 'ĠChung', '-', 'hee', 'Ġand', 'Ġhis', 'Ġallies', 'Ġwho', 'Ġformed', 'Ġthe', 'ĠMilitary', 'ĠRevolutionary', 'ĠCommittee', ',', 'Ġnom', 'inally', 'Ġled', 'Ġby', 'ĠArmy', 'ĠChief', 'Ġof', 'ĠStaff', 'ĠChang', 'ĠDo', '-', 'y', 'ong', 'Ġafter', 'Ġthe', 'Ġlatter', \"'s\", 'Ġacquies', 'cence', 'Ġon', 'Ġthe', 'Ġday', 'Ġof', 'Ġthe', 'Ġcoup', '.', 'Ġ', '<s>', 'ĠThe', 'Ġcoup', 'Ġrendered', 'Ġpowerless', 'Ġthe', 'Ġdemocratically', 'Ġelected', 'Ġgovernment', 'Ġof', 'ĠYun', 'ĠBo', '-', 'se', 'on', 'Ġand', 'Ġended', 'Ġthe', 'ĠSecond', 'ĠRepublic', ',', 'Ġinstalling', 'Ġa', 'Ġreform', 'ist', 'Ġmilitary', 'ĠSupreme', 'ĠCouncil', 'Ġfor', 'ĠNational', 'ĠReconstruction', 'Ġeffectively', 'Ġled', 'Ġby', 'ĠPark', ',', 'Ġwho', 'Ġtook', 'Ġover', 'Ġas', 'ĠChairman', 'Ġafter', 'ĠGeneral', 'ĠChang', \"'s\", 'Ġarrest', 'Ġin', 'ĠJuly', '.', '<p>', 'ĠHan', 'ĠMy', 'e', 'ong', '-', 's', 'ook', 'Ġ(', 'born', 'ĠMarch', 'Ġ24', ',', 'Ġ1944', ';', 'ĠKorean', ':', 'Ġ', 'íķ', 'ľ', 'ë', 'ª', 'ħ', 'ì', 'Ī', 'Ļ', 'Ġ]', 'Ġ)', 'Ġwas', 'Ġthe', 'ĠPrime', 'ĠMinister', 'Ġof', 'ĠSouth', 'ĠKorea', 'Ġfrom', 'ĠApril', 'Ġ2006', 'Ġto', 'ĠMarch', 'Ġ2007', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'ĠSouth', 'ĠKorea', \"'s\", 'Ġfirst', 'Ġfemale', 'Ġprime', 'Ġminister', 'Ġ(', 'second', 'Ġfemale', 'Ġprime', 'Ġminister', 'Ġoverall', 'Ġif', 'Ġthe', 'Ġacting', 'Ġprem', 'iership', 'Ġof', 'ĠChang', 'ĠSang', 'Ġis', 'Ġincluded', ').', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġfrom', 'Ġthe', 'ĠUnited', 'ĠNew', 'ĠDemocratic', 'ĠParty', 'Ġ(', 'UN', 'DP', ')', 'Ġas', 'Ġa', 'Ġmember', 'Ġof', 'Ġthe', 'ĠKorean', 'ĠNational', 'ĠAssembly', 'Ġ(', 'represent', 'ative', ')', 'Ġfor', 'ĠI', 'ls', 'an', '-', 'g', 'ab', ',', 'Ġand', 'Ġis', 'Ġa', 'Ġgraduate', 'Ġof', 'ĠE', 'wh', 'a', 'ĠW', 'om', 'ans', 'ĠUniversity', 'Ġin', 'ĠSeoul', 'Ġwith', 'Ġa', 'Ġdegree', 'Ġin', 'ĠFrench', 'Ġliterature', '.', 'Ġ', '<s>', 'ĠShe', 'Ġresigned', 'Ġas', 'ĠPrime', 'ĠMinister', 'Ġon', 'ĠMarch', 'Ġ7', ',', 'Ġ2007', 'Ġand', 'Ġdeclared', 'Ġher', 'Ġpresidential', 'Ġcandidacy', '.', 'Ġ', '<s>', 'ĠBut', 'Ġshe', 'Ġdid', 'Ġnot', 'Ġsucceed', 'Ġin', 'Ġthe', 'Ġnominations', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ2008', 'Ġshe', 'Ġran', 'Ġfor', 'Ġparliament', ',', 'Ġbut', 'Ġwas', 'Ġnot', 'Ġelected', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġin', 'ĠJanuary', 'Ġ2012', 'Ġshe', 'Ġwas', 'Ġelected', 'Ġleader', 'Ġof', 'Ġthe', 'Ġmain', 'Ġoppos', 'itional', 'ĠDemocratic', 'ĠUnited', 'ĠParty', 'Ġ(', 'D', 'UP', ')', 'Ġbefore', 'Ġthe', 'ĠApril', 'Ġlegislative', 'Ġelections', 'Ġand', 'Ġbecame', 'Ġa', 'Ġmember', 'Ġof', 'Ġparliament', '.', 'Ġ', '<s>', 'ĠBut', 'Ġthe', 'Ġliberals', 'Ġdid', 'Ġnot', 'Ġmanage', 'Ġto', 'Ġdefeat', 'Ġthe', 'Ġruling', 'ĠSa', 'en', 'uri', 'ĠParty', 'Ġand', 'ĠHan', 'Ġstepped', 'Ġdown', 'Ġas', 'Ġparty', 'Ġleader', 'Ġin', 'ĠApril', 'Ġ2012', '.', 'Ġ', '<s>', 'ĠIn', 'ĠAugust', 'Ġ2015', ',', 'ĠHan', 'Ġwas', 'Ġconvicted', 'Ġof', 'Ġreceiving', 'Ġillegal', 'Ġdonations', 'Ġat', 'Ġthe', 'Ġamount', 'Ġof', 'Ġ900', 'Ġmillion', 'ĠKR', 'W', ',', 'Ġand', 'Ġsentence', 'Ġto', 'Ġtwo', 'Ġyears', 'Ġin', 'Ġprison', '.', 'Ġ', '<s>', 'ĠShe', 'Ġis', 'Ġineligible', 'Ġto', 'Ġrun', 'Ġfor', 'Ġpublic', 'Ġoffice', 'Ġfor', 'Ġten', 'Ġyears', 'Ġafter', 'Ġher', 'Ġprison', 'Ġterm', '.', 'Ġ', '<s>', 'ĠShe', 'Ġbecame', 'Ġthe', 'Ġfirst', 'Ġformer', 'Ġprime', 'Ġminister', 'Ġof', 'Ġthe', 'ĠRepublic', 'Ġof', 'ĠKorea', 'Ġto', 'Ġserve', 'Ġa', 'Ġprison', 'Ġtime', '.', '<p>', 'ĠChang', 'ĠD', 'ae', '-', 'h', 'wan', 'Ġ(', 'also', 'ĠChang', 'ĠD', 'ae', '-', 'wh', 'an', ';', 'Ġborn', 'Ġ21', 'ĠMarch', 'Ġ1952', ')', 'Ġis', 'Ġa', 'ĠSouth', 'ĠKorean', 'Ġbusinessman', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġbest', 'Ġknown', 'Ġas', 'Ġthe', 'Ġpresident', 'Ġof', 'Ġthe', 'Ġ\"', 'M', 'ae', 'il', 'ĠBusiness', 'ĠNewspaper', '\",', 'ĠSouth', 'ĠKorea', \"'s\", 'Ġmain', 'Ġbusiness', 'Ġdaily', '.', 'Ġ', '<s>', 'ĠHe', 'Ġalso', 'Ġserved', 'Ġa', 'Ġbrief', 'Ġstint', 'Ġas', 'ĠSouth', 'ĠKorea', \"'s\", 'Ġacting', 'Ġprime', 'Ġminister', 'Ġin', 'ĠAugust', 'Ġ2002', 'Ġunder', 'Ġpresident', 'ĠKim', 'ĠD', 'ae', '-', 'j', 'ung', ',', 'Ġbut', 'Ġthe', 'ĠNational', 'ĠAssembly', 'Ġvoted', 'Ġnot', 'Ġto', 'Ġconfirm', 'Ġhim', '.', '<p>', 'ĠChang', 'ĠWon', '-', 'jun', 'Ġ(', 'H', 'ang', 'ul', ':', 'Ġì', 'ŀ', '¥', 'ì', 'Ľ', 'Ĳ', 'ì', '¤', 'Ģ', ',', 'ĠHan', 'ja', ':', 'Ġå', '¼', 'µ', 'åħ', 'ĥ', 'æ', 'º', 'ĸ', ')', 'Ġ(', 'born', 'ĠJuly', 'Ġ31', ',', 'Ġ1985', 'Ġin', 'ĠSeoul', ')', 'Ġis', 'Ġa', 'ĠSouth', 'ĠKorean', 'Ġstarting', 'Ġpitcher', 'Ġwho', 'Ġcurrently', 'Ġplays', 'Ġfor', 'Ġthe', 'ĠDo', 'os', 'an', 'ĠBears', '.', 'Ġ', '<s>', 'ĠChang', 'Ġplayed', 'Ġfor', 'Ġthe', 'ĠL', 'otte', 'ĠGiants', 'Ġin', 'Ġthe', 'ĠKorea', 'ĠBaseball', 'ĠOrganization', 'Ġfrom', 'Ġ2004', 'Ġto', 'Ġ2011', '.', 'Ġ', '<s>', 'ĠHe', 'Ġbats', 'Ġand', 'Ġthrows', 'Ġleft', '-', 'handed', '.', '<p>', 'ĠKorea', 'Ġunder', 'ĠJapanese', 'Ġrule', 'Ġbegan', 'Ġwith', 'Ġthe', 'Ġend', 'Ġof', 'Ġthe', 'Ġshort', '-', 'lived', 'ĠKorean', 'ĠEmpire', 'Ġin', 'Ġ1910', 'Ġand', 'Ġended', 'Ġat', 'Ġthe', 'Ġconclusion', 'Ġof', 'ĠWorld', 'ĠWar', 'ĠII', 'Ġin', 'Ġ1945', '.', 'Ġ', '<s>', 'ĠJapanese', 'Ġrule', 'Ġof', 'ĠKorea', 'Ġwas', 'Ġthe', 'Ġoutcome', 'Ġof', 'Ġa', 'Ġprocess', 'Ġthat', 'Ġbegan', 'Ġwith', 'Ġthe', 'ĠJapan', 'âĢĵ', 'K', 'orea', 'ĠTreaty', 'Ġof', 'Ġ18', '76', ',', 'Ġwhereby', 'Ġa', 'Ġcomplex', 'Ġcoalition', 'Ġof', 'Ġthe', 'ĠMe', 'iji', 'Ġgovernment', ',', 'Ġmilitary', ',', 'Ġand', 'Ġbusiness', 'Ġofficials', 'Ġsought', 'Ġto', 'Ġintegrate', 'ĠKorea', 'Ġboth', 'Ġpolitically', 'Ġand', 'Ġeconomically', 'Ġinto', 'Ġthe', 'ĠEmpire', 'Ġof', 'ĠJapan', '.', 'Ġ', '<s>', 'ĠA', 'Ġmajor', 'Ġstepping', '-', 'stone', 'Ġtowards', 'Ġthe', 'ĠJapanese', 'Ġoccupation', 'Ġof', 'ĠKorea', 'Ġwas', 'Ġthe', 'ĠJapan', 'âĢĵ', 'K', 'orea', 'ĠTreaty', 'Ġof', 'Ġ1905', ',', 'Ġin', 'Ġwhich', 'Ġthe', 'Ġthen', '-', 'K', 'orean', 'ĠEmpire', 'Ġwas', 'Ġdeclared', 'Ġa', 'Ġprotect', 'orate', 'Ġof', 'ĠJapan', '.', 'Ġ', '<s>', 'ĠThe', 'Ġannexation', 'Ġof', 'ĠKorea', 'Ġby', 'ĠJapan', 'Ġwas', 'Ġset', 'Ġup', 'Ġin', 'Ġthe', 'ĠJapan', 'âĢĵ', 'K', 'orea', 'ĠTreaty', 'Ġof', 'Ġ1910', ',', 'Ġwhich', 'Ġwas', 'Ġnever', 'Ġactually', 'Ġsigned', 'Ġby', 'Ġthe', 'ĠKorean', 'ĠReg', 'ent', ',', 'ĠGo', 'jong', '.', '<p>', 'ĠBorn', 'Ġand', 'Ġraised', 'Ġin', 'ĠKy', 'ong', 'ĠKi', 'ĠDo', ',', 'ĠSouth', 'ĠKorea', ',', 'ĠMaster', 'ĠTommy', 'ĠChang', 'Ġis', 'Ġa', 'ĠKorean', '-', 'Canadian', 'Ġworld', '-', 'ren', 'owned', 'Ġ7', 'th', 'Ġdegree', 'ĠTa', 'ek', 'w', 'ondo', 'Ġand', 'Ġ8', 'Th', 'ĠDegree', 'ĠH', 'ap', 'k', 'ido', 'Ġinstructor', 'Ġand', 'ĠGrand', 'master', ',', 'Ġactor', ',', 'Ġstunt', 'Ġperformer', ',', 'Ġstunt', 'Ġcoordinator', 'Ġand', 'Ġproducer', '.', 'Ġ', '<s>', 'ĠWith', 'Ġover', 'Ġ40', 'Ġyears', 'Ġof', 'Ġtraining', 'Ġand', 'Ġexperience', 'Ġin', 'ĠTa', 'ek', 'w', 'ondo', 'Ġand', 'ĠH', 'ap', 'k', 'ido', ',', 'ĠMaster', 'ĠChang', 'Ġalso', 'Ġtrained', 'Ġextensively', 'Ġin', 'ĠIT', 'F', '/', 'W', 'TF', 'ĠT', 'K', 'D', ',', 'ĠM', 'oo', 'ĠD', 'uk', 'ĠK', 'wan', ',', 'Ġand', 'ĠJud', 'o', '.', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġalso', 'Ġan', 'Ġ8', 'th', 'ĠDegree', 'ĠBlack', 'ĠBelt', 'Ġin', 'ĠH', 'ap', 'ĠKi', '-', 'Do', ',', 'Ġspecializing', 'Ġin', 'Ġpressure', 'Ġpoints', ',', 'Ġtake', '-', 'downs', 'Ġand', 'Ġgrappling', '.', 'Ġ', '<s>', 'ĠHis', 'Ġmartial', 'Ġarts', 'Ġexpertise', 'Ġalso', 'Ġencompasses', 'Ġmastery', 'Ġof', 'Ġseveral', 'Ġweapons', '.', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', ',', 'Ġhe', 'Ġis', 'Ġa', 'ĠW', 'TF', '-', 'cert', 'ified', 'ĠMaster', 'ĠInstructor', 'Ġof', 'ĠTa', 'ek', 'w', 'ondo', 'Ġand', 'Ġa', 'ĠCanadian', 'ĠNational', 'ĠRef', 'eree', 'Ġ(', '1', 'st', 'ĠClass', ').', '<p>', 'ĠAt', 'Ġthe', 'Ġconclusion', 'Ġof', 'ĠWorld', 'ĠWar', 'ĠII', 'Ġthe', 'ĠAllied', 'Ġnations', 'Ġbegan', 'Ġthe', 'Ġprocess', 'Ġof', 'Ġdisarm', 'ament', 'Ġof', 'ĠAxis', 'Ġcontrolled', 'Ġregions', '.', 'Ġ', '<s>', 'ĠJapan', 'Ġoccupied', 'ĠKorea', 'Ġat', 'Ġthis', 'Ġtime', 'Ġand', 'Ġhad', 'Ġbeen', 'Ġin', 'Ġcontrol', 'Ġsince', 'Ġ1910', '.', 'Ġ', '<s>', 'ĠIn', 'Ġ1945', ',', 'Ġthe', 'Ġdecision', 'Ġwas', 'Ġmade', 'Ġto', 'Ġhave', 'ĠAmerican', 'ĠMarines', 'Ġforces', 'Ġoversee', 'ĠJapanese', 'Ġsurrender', 'Ġand', 'Ġdisarm', 'ament', 'Ġsouth', 'Ġof', 'Ġthe', 'Ġ38', 'th', 'Ġparallel', 'Ġand', 'Ġthe', 'ĠSoviet', 'ĠUnion', 'Ġwould', 'Ġfacilitate', 'Ġthe', 'Ġchange', 'Ġof', 'Ġpower', 'Ġto', 'Ġthe', 'Ġnorth', '.', 'Ġ', '<s>', 'ĠAt', 'Ġthe', 'Ġtime', 'Ġthere', 'Ġwas', 'Ġno', 'Ġpolitical', 'Ġmotivation', 'Ġand', 'Ġseemed', 'Ġto', 'Ġbe', 'Ġa', 'Ġlogical', 'Ġand', 'Ġconvenient', 'Ġplan', 'Ġof', 'Ġaction', '.', 'Ġ', '<s>', 'ĠThe', 'Ġoriginal', 'Ġagreement', 'Ġand', 'Ġintent', 'Ġwas', 'Ġto', 'Ġcreate', 'Ġa', 'Ġunified', 'Ġand', 'Ġindependent', 'ĠKorea', 'Ġout', 'Ġof', 'Ġthe', 'Ġpost', 'ĠJapanese', 'Ġoccupation', 'Ġera', '.', 'Ġ', '<s>', 'ĠInstead', 'Ġeach', 'Ġside', 'Ġof', 'Ġthe', 'Ġ38', 'th', 'Ġparallel', 'Ġestablished', 'Ġits', 'Ġown', 'Ġgovernment', 'Ġunder', 'Ġthe', 'Ġinfluence', 'Ġof', 'Ġthe', 'Ġoccupational', 'Ġcountry', ';', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġin', 'ĠSouth', 'ĠKorea', 'Ġand', 'Ġthe', 'ĠSoviet', 'ĠUnion', 'Ġin', 'ĠNorth', 'ĠKorea', '.', 'Ġ', '<s>', 'ĠBoth', 'Ġnew', 'ĠKorean', 'Ġgovernments', 'Ġdiscredited', 'Ġthe', 'Ġother', 'Ġand', 'Ġclaimed', 'Ġto', 'Ġbe', 'Ġthe', 'Ġonly', 'Ġlegitimate', 'Ġpolitical', 'Ġsystem', '.', 'Ġ', '<s>', 'ĠT', 'ensions', 'Ġbetween', 'Ġthe', 'ĠNorth', 'Ġand', 'ĠSouth', 'Ġescalated', 'Ġand', 'Ġeach', 'Ġside', 'Ġbegan', 'Ġto', 'Ġpetition', 'Ġforeign', 'Ġpowers', 'Ġfor', 'Ġresources', 'Ġand', 'Ġsupport', '.', 'Ġ', '<s>', 'ĠSouth', 'ĠKorea', 'Ġwanted', 'Ġweapons', 'Ġand', 'Ġsupplies', 'Ġfrom', 'ĠTruman', 'Ġand', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġgovernment', 'Ġwhile', 'ĠNorth', 'ĠKorea', 'Ġsought', 'Ġhelp', 'Ġfrom', 'ĠStalin', 'Ġand', 'Ġthe', 'ĠSoviet', 'ĠUnion', '.', 'Ġ', '<s>', 'ĠThe', 'ĠUnited', 'ĠStates', 'Ġwas', 'Ġstill', 'Ġwar', 'Ġweary', 'Ġfrom', 'Ġthe', 'Ġdisruptive', 'ĠWorld', 'ĠWar', 'ĠII', 'Ġcampaign', 'Ġand', 'Ġrefused', 'ĠSouth', 'ĠKorea', \"'s\", 'Ġrequest', 'Ġfor', 'Ġweapons', 'Ġand', 'Ġtroops', '.', 'Ġ', '<s>', 'ĠNorth', 'ĠKorea', 'Ġconvinced', 'Ġthe', 'ĠSoviet', 'ĠUnion', 'Ġto', 'Ġsupply', 'Ġthem', 'Ġwith', 'Ġthe', 'Ġweapons', 'Ġand', 'Ġsupport', 'Ġthey', 'Ġrequested', '.', 'Ġ', '<s>', 'ĠThis', 'Ġdecision', 'Ġcoincided', 'Ġwith', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġwithdrawing', 'Ġthe', 'Ġlast', 'Ġremaining', 'Ġcombat', 'Ġtroops', 'Ġfrom', 'ĠSouth', 'ĠKorea', '.', 'Ġ', '<s>', 'ĠNorth', 'ĠKorea', 'Ġsaw', 'Ġits', 'Ġopportunity', 'Ġand', 'Ġattacked', 'ĠSouth', 'ĠKorean', 'Ġforces', 'Ġat', 'Ġthe', 'Ġ38', 'th', 'Ġparallel', 'Ġon', 'ĠJune', 'Ġ25', ',', 'Ġ1950', 'Ġand', 'Ġthus', 'Ġinitiating', 'Ġthe', 'ĠKorean', 'ĠWar', '.', '<p>', 'ĠChang', 'ĠMi', '-', 'hee', 'Ġ(', 'born', 'ĠDecember', 'Ġ8', ',', 'Ġ1958', ')', 'Ġis', 'Ġa', 'ĠSouth', 'ĠKorean', 'Ġactress', 'Ġactive', 'Ġsince', 'Ġ1976', '.', 'Ġ', '<s>', 'ĠShe', 'Ġwas', 'Ġborn', 'ĠLee', 'ĠYun', '-', 'h', 'ui', 'Ġin', 'ĠSeoul', ',', 'ĠSouth', 'ĠKorea', 'Ġin', 'Ġ1957', '.', 'Ġ', '<s>', 'ĠChang', 'Ġdebuted', 'Ġas', 'Ġan', 'Ġactress', 'Ġin', 'Ġ1976', 'Ġas', 'Ġstarring', 'Ġin', 'Ġ\"', 'Se', 'ong', 'ĠChun', '-', 'hy', 'ang', 'Ġje', 'on', '\"', 'Ġdirected', 'Ġby', 'ĠPark', 'ĠT', 'ae', '-', 'won', 'Ġand', 'ĠT', 'BC', 'ĠTV', 'Ġdrama', ',', 'Ġ\"', 'Ha', 'en', 'ye', 'o', 'ĠD', 'ang', '-', 'sil', '\"', 'Ġ(', 'Sea', 'ĠWoman', 'ĠD', 'ang', '-', 'sil', ').', 'Ġ', '<s>', 'ĠChang', 'Ġwas', 'Ġcommonly', 'Ġreferred', 'Ġto', 'Ġas', 'Ġ\"', 'New', 'ĠTro', 'ika', '\"', 'Ġor', 'Ġ\"', 'Second', 'ĠTro', 'ika', '\"', 'Ġalong', 'Ġwith', 'Ġher', 'Ġrival', 'Ġactresses', ',', 'ĠJe', 'ong', 'ĠYun', '-', 'h', 'ui', 'Ġand', 'ĠYu', 'ĠJi', '-', 'in', 'Ġof', 'Ġthe', 'Ġ1970', 's', 'Ġand', 'Ġ1980', 's', 'Ġafter', 'Ġthe', 'Ġ\"', 'First', 'ĠTro', 'ika', '\",', 'ĠMoon', 'ĠHe', 'e', ',', 'ĠNam', 'ĠJe', 'ong', '-', 'im', ',', 'Ġand', 'ĠY', 'oon', 'ĠJe', 'ong', '-', 'hee', 'Ġof', 'Ġthe', 'Ġ1960', 's', '.', '<p>', 'ĠChang', 'ĠYong', '-', 'hak', 'Ġ(', '25', 'ĠApril', 'Ġ1921', 'ĠâĢĵ', 'Ġ31', 'ĠAugust', 'Ġ1999', ')', 'Ġwas', 'Ġa', 'ĠKorean', 'Ġwriter', '.', 'Ġ', '<s>', 'ĠChang', 'Ġwas', 'Ġborn', 'Ġin', 'ĠHam', 'ye', 'ong', 'ĠBuk', '-', 'do', 'Ġin', 'Ġwhat', 'Ġis', 'Ġnow', 'ĠNorth', 'ĠKorea', '.', 'Ġ', '<s>', 'ĠHe', 'Ġstudied', 'Ġat', 'ĠW', 'ased', 'a', 'ĠUniversity', 'Ġin', 'ĠJapan', ',', 'Ġbefore', 'Ġbeing', 'Ġdrafted', 'Ġinto', 'Ġthe', 'ĠJapanese', 'Ġarmy', '.', 'Ġ', '<s>', 'ĠAfter', 'Ġthe', 'Ġend', 'Ġof', 'ĠWorld', 'ĠWar', 'ĠTwo', ',', 'Ġhe', 'Ġtaught', 'Ġhigh', 'Ġschool', 'Ġin', 'ĠKorea', ',', 'Ġwriting', 'Ġfiction', 'Ġon', 'Ġthe', 'Ġside', '.', '<p>', 'ĠChang', 'ĠU', 'c', 'chin', 'Ġ(', '26', 'ĠNovember', 'Ġ1917', 'ĠâĢĵ', 'Ġ27', 'ĠDecember', 'Ġ1990', ')', 'Ġis', 'Ġone', 'Ġof', 'Ġthe', 'Ġrepresentatives', 'Ġof', 'Ġmodern', 'ĠKorean', 'Ġfine', 'Ġart', '.', 'Ġ', '<s>', 'ĠChang', 'Ġwas', 'Ġborn', 'Ġwhen', 'ĠKorea', 'Ġwas', 'Ġstill', 'Ġunder', 'ĠJapanese', 'Ġcolonial', 'Ġrule', '.', 'Ġ', '<s>', 'ĠHe', 'Ġstudied', 'Ġwestern', 'Ġart', 'Ġat', 'ĠTokyo', \"'s\", 'ĠImperial', 'ĠSchool', 'Ġof', 'ĠArt', '.', 'Ġ', '<s>', 'ĠHe', 'Ġbecame', 'Ġa', 'Ġprofessor', 'Ġof', 'Ġfine', 'Ġarts', 'Ġat', 'ĠSeoul', 'ĠNational', 'ĠUniversity', 'Ġin', 'Ġ1954', ',', 'Ġbut', 'Ġresigned', 'Ġto', 'Ġpaint', 'Ġfull', '-', 'time', 'Ġfrom', 'Ġ1960', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers: [{'text': ' was no political motivation and seemed', 'score': tensor([0.7610], device='cuda:0')}]\n",
      "answers_pred: [{'text': ' was no political motivation and seemed', 'score': tensor([0.7610], device='cuda:0')}]\n",
      "answer_score: tensor([0.7610], device='cuda:0')\n",
      "answer_text:  was no political motivation and seemed\n",
      "answer_gold_token_ids: tensor([ 623, 1771, 3082], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠWorld', 'ĠWar', 'ĠII']\n",
      "answer_gold:  World War II\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_step\n",
      "input:  ['<cls>', '<q>', 'Human', 'ĠError', '\"', 'Ġis', 'Ġthe', 'Ġseason', 'Ġfinale', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġof', 'Ġa', 'Ġtv', 'Ġshow', 'Ġthat', 'Ġaired', 'Ġon', 'Ġwhat', 'Ġnetwork', '?', '</q>', '<p>', 'Ġ\"', 'My', 'ĠFin', 'ale', '\"', 'Ġis', 'Ġthe', 'Ġhour', '-', 'long', 'Ġseason', 'Ġfinale', 'Ġfor', 'Ġseason', 'Ġeight', 'Ġof', 'Ġthe', 'ĠAmerican', 'Ġsitcom', 'Ġ\"', 'Sc', 'r', 'ubs', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġoriginally', 'Ġbroadcast', 'Ġas', 'Ġepisodes', 'Ġ18', 'Ġand', 'Ġ19', 'Ġof', 'Ġseason', 'Ġeight', 'Ġon', 'ĠMay', 'Ġ6', ',', 'Ġ2009', ',', 'Ġand', 'Ġwas', 'Ġintended', 'Ġto', 'Ġbe', 'Ġthe', 'Ġseries', 'Ġfinale', 'Ġduring', 'Ġproduction', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġthe', 'Ġepisode', 'Ġwas', 'Ġbilled', 'Ġas', 'Ġthe', 'Ġ\"', 'Sc', 'r', 'ubs', 'Ġfinale', '\"', 'Ġas', 'Ġat', 'Ġthe', 'Ġtime', 'Ġof', 'Ġairing', 'Ġit', 'Ġwas', 'Ġunknown', 'Ġwhether', 'Ġthis', 'Ġwould', 'Ġbe', 'Ġthe', 'Ġseries', 'Ġfinale', 'Ġor', 'Ġthe', 'Ġseason', 'Ġfinale', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġended', 'Ġup', 'Ġreturning', 'Ġfor', 'Ġa', 'Ġninth', 'Ġseason', '.', 'Ġ', '<s>', 'ĠAs', 'Ġthe', 'Ġshow', 'Ġunderwent', 'Ġmany', 'Ġchanges', 'Ġfor', 'Ġthe', 'Ġninth', 'Ġand', 'Ġfinal', 'Ġseason', ',', 'Ġthis', 'Ġis', 'Ġthe', 'Ġlast', 'Ġepisode', 'Ġin', 'Ġwhich', 'Ġall', 'Ġof', 'Ġthe', 'Ġmain', 'Ġcast', 'Ġappear', 'Ġas', 'Ġseries', 'Ġregulars', '.', '<p>', 'ĠThe', 'Ġsecond', 'Ġseason', 'Ġof', 'Ġthe', 'ĠAmerican', 'Ġdram', 'edy', '-', 'my', 'stery', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Des', 'perate', 'ĠHouse', 'wives', '\"', 'Ġcommenced', 'Ġairing', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġon', 'ĠSeptember', 'Ġ25', ',', 'Ġ2005', 'Ġand', 'Ġconcluded', 'Ġon', 'ĠMay', 'Ġ21', ',', 'Ġ2006', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġcontinues', 'Ġthe', 'Ġstory', 'Ġof', 'Ġthe', 'ĠW', 'ister', 'ia', 'ĠLane', 'Ġresidents', ',', 'Ġwhile', 'Ġtheir', 'Ġseemingly', 'Ġperfect', 'Ġlives', 'Ġin', 'Ġthe', 'Ġsuburban', 'Ġneighborhood', 'Ġare', 'Ġshaken', 'Ġby', 'Ġthe', 'Ġarrival', 'Ġof', 'Ġthe', 'Ġmysterious', 'ĠBetty', 'ĠApple', 'white', '.', 'Ġ', '<s>', 'ĠBroadcast', 'Ġin', 'Ġthe', 'ĠSunday', 'Ġnight', 'Ġtime', 'Ġslot', 'Ġat', 'Ġ9', '.', '00', 'ĠET', ',', 'Ġthe', 'Ġseason', 'Ġaired', 'Ġtwenty', '-', 'four', 'Ġregular', 'Ġepisodes', ',', 'Ġincluding', 'Ġa', 'Ġtwo', '-', 'part', 'Ġseason', 'Ġfinale', '.', 'Ġ', '<s>', 'ĠIn', 'Ġaddition', ',', 'Ġthree', 'Ġclip', 'Ġshows', 'Ġwere', 'Ġproduced', 'Ġfor', 'Ġthe', 'Ġseason', ',', 'Ġin', 'Ġorder', 'Ġto', 'Ġput', 'Ġthe', 'Ġprevious', 'Ġevents', 'Ġof', 'Ġthe', 'Ġshow', 'Ġin', 'Ġperspective', '.', 'Ġ\"', 'Ġ', '<s>', 'ĠAll', 'Ġthe', 'ĠJu', 'icy', 'ĠDetails', '\"', 'Ġaired', 'Ġbefore', 'Ġthe', 'Ġele', 'venth', 'Ġepisode', ',', 'Ġdetailing', 'Ġthe', 'Ġmost', 'Ġmemorable', 'Ġevents', 'Ġof', 'Ġthe', 'Ġseason', \"'s\", 'Ġfirst', 'Ġhalf', ',', 'Ġwhereas', 'Ġ\"', 'The', 'ĠMore', 'ĠYou', 'ĠKnow', ',', 'ĠThe', 'ĠJu', 'ic', 'ier', 'ĠIt', 'ĠGets', '\",', 'Ġwhich', 'Ġaired', 'Ġbefore', 'Ġthe', 'Ġtwentieth', 'Ġepisode', ',', 'Ġprepared', 'Ġthe', 'Ġviewers', 'Ġfor', 'Ġthe', 'Ġhighly', 'Ġanticipated', 'Ġseason', 'Ġfinale', '.', 'Ġ\"', 'Ġ', '<s>', 'ĠTime', 'Ġto', 'ĠCome', 'ĠClean', '\"', 'Ġaired', 'Ġthree', 'Ġweeks', 'Ġbefore', 'Ġthe', 'Ġinception', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', ',', 'Ġand', 'Ġreviewed', 'Ġthe', 'Ġprevious', 'Ġmysteries', 'Ġof', 'Ġthe', 'Ġseries', 'Ġbefore', 'Ġintroducing', 'Ġthe', 'Ġnew', 'Ġstory', 'Ġlines', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsecond', 'Ġseason', 'Ġhad', 'Ġfourteen', 'Ġroles', 'Ġreceiving', 'Ġstar', 'Ġbilling', ',', 'Ġout', 'Ġof', 'Ġwhom', 'Ġeleven', 'Ġwere', 'Ġpart', 'Ġof', 'Ġthe', 'Ġfirst', 'Ġseason', \"'s\", 'Ġmain', 'Ġcast', '.', 'Ġ', '<s>', 'ĠThe', 'Ġmain', 'Ġstory', 'Ġlines', 'Ġof', 'Ġthe', 'Ġseason', 'Ġwere', 'ĠSusan', 'ĠMayer', \"'s\", 'Ġrelationship', 'Ġwith', 'Ġher', 'Ġformer', 'Ġhusband', ',', 'ĠGabriel', 'le', 'ĠSol', 'is', \"'\", 'Ġupcoming', 'Ġmother', 'hood', ',', 'ĠLyn', 'ette', 'ĠSc', 'av', 'o', \"'s\", 'Ġreturn', 'Ġto', 'Ġwork', 'Ġand', 'Ġthe', 'Ġdeath', 'Ġof', 'ĠBree', 'ĠVan', 'Ġde', 'ĠKamp', \"'s\", 'Ġhusband', '.', '<p>', 'ĠThis', 'Ġis', 'Ġa', 'Ġlist', 'Ġof', 'Ġepisodes', 'Ġfor', 'Ġthe', 'ĠCanadian', 'Ġcrime', 'Ġseries', 'Ġ\"', 'Republic', 'Ġof', 'ĠDoyle', '\".', 'Ġ', '<s>', 'ĠThe', 'Ġseries', 'Ġdebuted', 'Ġon', 'ĠCBC', 'ĠTelevision', 'Ġon', 'ĠJanuary', 'Ġ6', ',', 'Ġ2010', 'Ġwith', 'Ġ9', '69', ',', '000', 'Ġviewers', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġfinale', 'Ġaired', 'Ġon', 'ĠApril', 'Ġ7', ',', 'Ġ2010', 'Ġand', 'Ġdrew', 'Ġ1', ',', '120', ',', '000', 'Ġviewers', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsecond', 'Ġseason', 'Ġdebuted', 'Ġon', 'ĠJanuary', 'Ġ12', ',', 'Ġ2011', 'Ġwith', 'Ġ1', ',', '0', '38', ',', '000', 'Ġviewers', '.', 'Ġ', '<s>', 'ĠThe', 'Ġsecond', '-', 'season', 'Ġfinale', 'Ġaired', 'Ġon', 'ĠApril', 'Ġ6', ',', 'Ġ2011', 'Ġand', 'Ġdrew', 'Ġ1', ',', '265', ',', '000', 'Ġviewers', '.', 'Ġ', '<s>', 'ĠThe', 'Ġthird', 'Ġseason', 'Ġdebuted', 'Ġon', 'ĠJanuary', 'Ġ11', ',', 'Ġ2012', 'Ġwith', 'Ġ1', ',', '361', ',', '000', 'Ġviewers', ',', 'Ġand', 'Ġthe', 'Ġseason', 'Ġfinale', 'Ġdrew', 'Ġ9', '68', ',', '000', 'Ġviewers', '.', '<p>', 'Ġ\"', 'Human', 'ĠError', '\"', 'Ġis', 'Ġthe', 'Ġtwenty', '-', 'fourth', 'Ġepisode', 'Ġand', 'Ġseason', 'Ġfinale', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġof', 'Ġ\"', 'House', '\"', 'Ġand', 'Ġthe', 'Ġsevent', 'ieth', 'Ġepisode', 'Ġoverall', '.', '<p>', 'Ġ\"', 'The', 'ĠPrice', 'Ġof', 'ĠFree', 'Ġand', 'ĠFair', 'ĠElections', '\"', 'Ġis', 'Ġthe', 'Ġ18', 'th', 'Ġepisode', 'Ġand', 'Ġseason', 'Ġfinale', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġof', 'Ġthe', 'ĠAmerican', 'Ġpolitical', 'Ġthriller', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Sc', 'andal', '\",', 'Ġand', 'Ġis', 'Ġthe', 'Ġ47', 'th', 'Ġoverall', 'Ġepisode', '.', 'Ġ', '<s>', 'ĠIt', 'Ġaired', 'Ġon', 'ĠApril', 'Ġ17', ',', 'Ġ2014', 'Ġon', 'ĠABC', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠThe', 'Ġepisode', 'Ġwas', 'Ġwritten', 'Ġby', 'Ġshow', 'runner', 'ĠSh', 'onda', 'ĠRh', 'imes', 'Ġand', 'Ġexecutive', 'Ġproducer', 'ĠMark', 'ĠWild', 'ing', 'Ġand', 'Ġdirected', 'Ġby', 'Ġexecutive', 'Ġproducer', 'ĠTom', 'ĠVer', 'ica', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġfinale', 'Ġwas', 'Ġoriginally', 'Ġsupposed', 'Ġto', 'Ġbe', 'Ġthe', 'Ġ22', 'nd', 'Ġepisode', ',', 'Ġbut', 'Ġbecause', 'Ġof', 'Ġthe', 'Ġshow', \"'s\", 'Ġlead', 'ĠKerry', 'ĠWashington', \"'s\", 'Ġpregnancy', ',', 'Ġthe', 'Ġepisode', 'Ġcount', 'Ġwas', 'Ġtrimmed', 'Ġby', 'ĠABC', 'Ġby', 'Ġfour', 'Ġepisodes', ',', 'Ġleading', 'Ġthe', 'Ġseason', 'Ġfinale', 'Ġto', 'Ġbe', 'Ġthe', 'Ġ18', 'th', 'Ġepisode', '.', '<p>', 'ĠRobert', 'ĠChase', ',', 'ĠMB', 'BS', 'Ġis', 'Ġa', 'Ġfictional', 'Ġcharacter', 'Ġon', 'Ġthe', 'ĠFox', 'Ġmedical', 'Ġdrama', 'Ġ\"', 'House', '\".', 'Ġ', '<s>', 'ĠHe', 'Ġis', 'Ġportrayed', 'Ġby', 'ĠJesse', 'ĠSpencer', '.', 'Ġ', '<s>', 'ĠHis', 'Ġcharacter', 'Ġwas', 'Ġa', 'Ġpart', 'Ġof', 'Ġthe', 'Ġteam', 'Ġof', 'Ġdiagn', 'ost', 'icians', 'Ġwho', 'Ġworked', 'Ġunder', 'ĠGregory', 'ĠHouse', 'Ġuntil', 'Ġthe', 'Ġend', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġwhen', 'ĠHouse', 'Ġfires', 'Ġhim', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġhe', 'Ġresumed', 'Ġwork', 'Ġat', 'Ġthe', 'Ġhospital', 'Ġas', 'Ġa', 'Ġsurgeon', ',', 'Ġand', 'Ġwas', 'Ġre', '-', 'h', 'ired', 'Ġby', 'ĠHouse', 'Ġin', 'Ġseason', 'Ġ6', '.', 'Ġ', '<s>', 'ĠRobert', 'ĠChase', 'Ġis', 'Ġthe', 'Ġlongest', '-', 'serving', 'Ġmember', 'Ġof', 'ĠHouse', \"'s\", 'Ġstaff', '.', 'Ġ', '<s>', 'ĠChase', 'Ġhas', 'Ġbeen', 'Ġattracted', 'Ġto', 'ĠAllison', 'ĠCameron', 'Ġsince', 'Ġthe', 'Ġbeginning', 'Ġof', 'Ġthe', 'Ġshow', 'Ġand', 'Ġemb', 'arks', 'Ġon', 'Ġa', 'Ġromantic', 'Ġrelationship', 'Ġwith', 'Ġher', 'Ġin', 'Ġ\"', 'Human', 'ĠError', '.\"', 'Ġ', '<s>', 'ĠIn', 'Ġ\"', 'Post', 'ĠMort', 'em', ',\"', 'Ġhe', 'Ġleft', 'Ġthe', 'ĠDiagn', 'ostic', 'ĠTeam', 'Ġafter', 'Ġrealizing', 'Ġhe', 'Ġwas', 'Ġin', 'Ġthe', 'Ġsame', 'Ġposition', 'Ġas', 'Ġhe', 'Ġwas', 'Ġ10', 'Ġyears', 'Ġearlier', ',', 'Ġunlike', 'Ġall', 'Ġof', 'Ġthe', 'Ġother', 'Ġformer', 'Ġmembers', 'Ġof', 'Ġthe', 'Ġteam', '.', 'Ġ', '<s>', 'ĠHowever', ',', 'Ġin', 'Ġthe', 'Ġseries', 'Ġfinale', ',', 'Ġhe', 'Ġrejo', 'ins', 'Ġthe', 'Ġhospital', 'Ġas', 'Ġthe', 'Ġnew', 'ĠHead', 'Ġof', 'ĠDiagn', 'ostic', 'ĠMedicine', ',', 'Ġreplacing', 'ĠHouse', ',', 'Ġwho', 'Ġis', 'Ġthought', 'Ġto', 'Ġhave', 'Ġdied', '.', '<p>', 'ĠThe', 'ĠVoice', 'ĠPortugal', 'Ġ(', 'A', 'ĠV', 'oz', 'Ġde', 'ĠPortugal', 'Ġin', 'Ġthe', 'Ġfirst', 'Ġseason', ')', 'Ġis', 'Ġa', 'ĠPortuguese', 'Ġreality', 'Ġsinging', 'Ġcompetition', 'Ġand', 'Ġlocal', 'Ġversion', 'Ġof', 'ĠThe', 'ĠVoice', 'Ġoriginally', 'Ġbroadcast', 'Ġas', 'ĠThe', 'ĠVoice', 'Ġof', 'ĠHolland', '.', 'Ġ', '<s>', 'ĠIt', 'Ġpremiered', 'Ġon', 'Ġ29', 'ĠOctober', 'Ġ2011', ',', 'Ġon', 'ĠR', 'TP', '1', ',', 'Ġwith', 'Ġthe', 'Ġfirst', 'Ġseason', 'Ġfinale', 'Ġairing', 'Ġon', 'ĠFebruary', 'Ġ25', ',', 'Ġ2012', ',', 'Ġcrown', 'ing', 'ĠDenis', 'ĠF', 'ili', 'pe', 'Ġas', 'Ġthe', 'Ġwinner', '.', 'Ġ', '<s>', 'ĠThe', 'Ġshow', 'Ġcame', 'Ġback', 'Ġin', 'Ġ2014', 'Ġwith', 'Ġits', 'Ġsecond', 'Ġseason', 'Ġwith', 'Ġnew', 'Ġjudges', ',', 'Ġa', 'Ġnew', 'Ġco', '-', 'host', ',', 'Ġa', 'Ġnew', 'Ġshow', 'Ġname', ',', 'Ġand', 'Ġnew', 'Ġ\"', 'Rep', 'Ã³', 'r', 'te', 'res', 'ĠV', '\"', 'Ġ(', 'back', 'stage', 'Ġhosts', ').', 'Ġ', '<s>', 'ĠThe', 'Ġwinner', 'Ġof', 'Ġthe', 'Ġsecond', 'Ġseason', 'Ġwas', 'ĠR', 'ui', 'ĠDrum', 'mond', '.', 'Ġ', '<s>', 'ĠR', 'TP', '1', 'Ġlater', 'Ġannounced', 'Ġthe', 'Ġfirst', 'Ġseason', 'Ġof', 'Ġ\"', 'The', 'ĠVoice', 'ĠKids', 'ĠPortugal', '\"', 'Ġand', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġof', 'Ġthe', 'Ġmain', 'Ġshow', '.', 'Ġ', '<s>', 'ĠThe', 'Ġthird', 'Ġseason', 'Ġpremiered', 'ĠOctober', 'Ġ11', ',', 'Ġ2015', 'Ġwith', 'Ġnew', 'Ġjudge', ',', 'ĠAure', 'a', '.', 'Ġ', '<s>', 'ĠIn', 'Ġits', 'Ġthird', 'Ġseason', ',', 'Ġthe', 'Ġshow', 'Ġproved', 'Ġto', 'Ġbe', 'Ġa', 'Ġhit', 'Ġand', 'Ġwas', 'Ġsubsequently', 'Ġrenewed', 'Ġfor', 'Ġa', 'Ġfourth', 'Ġseason', ',', 'Ġwhich', 'Ġwas', 'Ġpremiered', 'Ġin', 'Ġ2016', '.', '<p>', 'ĠHouse', 'Ġ(', 'also', 'Ġcalled', 'ĠHouse', ',', 'ĠM', '.', 'D', '.)', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġtelevision', 'Ġmedical', 'Ġdrama', 'Ġthat', 'Ġoriginally', 'Ġran', 'Ġon', 'Ġthe', 'ĠFox', 'Ġnetwork', 'Ġfor', 'Ġeight', 'Ġseasons', ',', 'Ġfrom', 'ĠNovember', 'Ġ16', ',', 'Ġ2004', 'Ġto', 'ĠMay', 'Ġ21', ',', 'Ġ2012', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', \"'\", 'Ġmain', 'Ġcharacter', 'Ġis', 'ĠDr', '.', 'ĠGregory', 'ĠHouse', 'Ġ(', 'H', 'ugh', 'ĠLaurie', '),', 'Ġan', 'Ġunconventional', ',', 'Ġmis', 'anthrop', 'ic', 'Ġmedical', 'Ġgenius', 'Ġwho', ',', 'Ġdespite', 'Ġhis', 'Ġdependence', 'Ġon', 'Ġpain', 'Ġmedication', ',', 'Ġleads', 'Ġa', 'Ġteam', 'Ġof', 'Ġdiagn', 'ost', 'icians', 'Ġat', 'Ġthe', 'Ġfictional', 'ĠPrinceton', 'âĢĵ', 'Pl', 'ains', 'boro', 'ĠTeaching', 'ĠHospital', 'Ġ(', 'PP', 'TH', ')', 'Ġin', 'ĠNew', 'ĠJersey', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', \"'\", 'Ġpremise', 'Ġoriginated', 'Ġwith', 'ĠPaul', 'ĠAtt', 'anas', 'io', ',', 'Ġwhile', 'ĠDavid', 'ĠShore', ',', 'Ġwho', 'Ġis', 'Ġcredited', 'Ġas', 'Ġcreator', ',', 'Ġwas', 'Ġprimarily', 'Ġresponsible', 'Ġfor', 'Ġthe', 'Ġconception', 'Ġof', 'Ġthe', 'Ġtitle', 'Ġcharacter', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseries', \"'\", 'Ġexecutive', 'Ġproducers', 'Ġincluded', 'ĠShore', ',', 'ĠAtt', 'anas', 'io', ',', 'ĠAtt', 'anas', 'io', \"'s\", 'Ġbusiness', 'Ġpartner', 'ĠKatie', 'ĠJacobs', ',', 'Ġand', 'Ġfilm', 'Ġdirector', 'ĠBryan', 'ĠSinger', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġfilmed', 'Ġlargely', 'Ġin', 'ĠCentury', 'ĠCity', '.', '<p>', 'Ġ\"', 'Through', 'Ġthe', 'ĠLooking', 'ĠGlass', '\"', 'Ġis', 'Ġthe', 'Ġthird', 'Ġseason', 'Ġfinale', 'Ġof', 'Ġthe', 'ĠABC', 'Ġtelevision', 'Ġseries', 'Ġ\"', 'Lost', '\",', 'Ġconsisting', 'Ġof', 'Ġthe', 'Ġ22', 'nd', 'Ġand', 'Ġ23', 'rd', 'Ġepisodes', 'Ġof', 'Ġthe', 'Ġthird', 'Ġseason', '.', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġalso', 'Ġthe', 'Ġ71', 'st', 'Ġand', 'Ġ72', 'nd', 'Ġepisodes', 'Ġoverall', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġwritten', 'Ġby', 'Ġco', '-', 'creator', '/', 'exec', 'utive', 'Ġproducer', 'ĠDamon', 'ĠLind', 'el', 'of', 'Ġand', 'Ġexecutive', 'Ġproducer', 'ĠCarlton', 'ĠC', 'use', ',', 'Ġand', 'Ġdirected', 'Ġby', 'Ġexecutive', 'Ġproducer', 'ĠJack', 'ĠBender', '.', 'Ġ', '<s>', 'ĠWhen', 'Ġfirst', 'Ġaired', 'Ġon', 'ĠMay', 'Ġ23', ',', 'Ġ2007', ',', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', 'Ġand', 'ĠCanada', ',', 'Ġit', 'Ġwas', 'Ġwatched', 'Ġby', 'Ġan', 'Ġaverage', 'Ġof', 'Ġ14', 'Ġmillion', 'ĠAmerican', 'Ġviewers', '.', 'Ġ', '<s>', 'ĠLike', 'Ġthe', 'Ġprevious', 'Ġtwo', 'Ġseason', 'Ġfin', 'ales', ',', 'Ġit', 'Ġwas', 'Ġtwo', 'Ġhours', 'Ġlong', 'Ġwith', 'Ġadvertisements', ',', 'Ġtwice', 'Ġthe', 'Ġlength', 'Ġof', 'Ġa', 'Ġnormal', 'Ġepisode', '.', 'Ġ', '<s>', 'ĠIt', 'Ġwas', 'Ġedited', 'Ġinto', 'Ġtwo', 'Ġindividual', 'Ġepisodes', 'Ġwhen', 'Ġreleased', 'Ġon', 'ĠDVD', '.', 'Ġ', '<s>', 'ĠThe', 'Ġseason', 'Ġfinale', 'Ġis', 'Ġconsidered', 'Ġby', 'Ġsome', 'Ġto', 'Ġbe', 'Ġone', 'Ġof', 'Ġthe', 'Ġbest', 'Ġepisodes', 'Ġof', 'Ġtelevision', 'Ġever', 'Ġbroadcast', '.', 'Ġ', '<s>', 'ĠThe', 'Ġepisode', 'Ġgarnered', 'Ġa', 'Ġnumber', 'Ġof', 'Ġawards', 'Ġand', 'Ġnominations', ',', 'Ġincluding', 'Ġthree', 'ĠPrim', 'etime', 'ĠEmmy', 'ĠAwards', 'Ġnominations', 'Ġand', 'Ġa', 'ĠDirectors', 'ĠGuild', 'Ġof', 'ĠAmerica', 'ĠAward', 'Ġnomination', '.', '<p>', 'Ġ\"', 'Mr', '.', 'ĠYin', 'ĠPresents', '\"', 'Ġ(', 'st', 'yl', 'ized', 'Ġas', 'Ġ\"', 'Mr', '.', 'ĠYin', 'ĠPresents', '...\"', ')', 'Ġis', 'Ġthe', 'Ġsix', 'teenth', 'Ġand', 'Ġfinal', 'Ġepisode', 'Ġof', 'Ġthe', 'ĠFourth', 'Ġseason', 'Ġof', 'Ġ\"', 'Psych', '\",', 'Ġand', 'Ġthe', 'Ġ63', 'rd', 'Ġepisode', 'Ġin', 'Ġthe', 'Ġseries', 'Ġoverall', '.', 'Ġ', '<s>', 'ĠIt', 'Ġpremiered', 'Ġon', 'ĠMarch', 'Ġ10', ',', 'Ġ2010', 'Ġon', 'ĠUSA', 'ĠNetwork', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.', 'Ġ', '<s>', 'ĠThe', 'Ġepisode', 'Ġserves', 'Ġas', 'Ġthe', 'Ġseason', 'Ġ4', 'Ġfinale', 'Ġand', 'Ġis', 'Ġthe', 'Ġsequel', 'Ġto', 'Ġthe', 'Ġthird', 'Ġseason', \"'s\", 'Ġfinale', ',', 'Ġ\"', 'An', 'ĠEvening', 'Ġwith', 'ĠMr', '.', 'ĠYang', '\".', 'Ġ', '<s>', 'ĠIt', 'Ġis', 'Ġan', 'Ġimportant', 'Ġinstallment', 'Ġin', 'Ġone', 'Ġof', 'Ġthe', 'Ġseries', \"'\", 'Ġfew', 'Ġstory', 'Ġarcs', '.', 'Ġ', '<s>', 'ĠA', 'Ġthird', 'Ġand', 'Ġfinal', 'Ġinstallment', 'Ġof', 'Ġthe', 'ĠYin', '/', 'Yang', 'Ġseries', ',', 'Ġentitled', 'Ġ\"', 'Yang', 'Ġ3', 'Ġin', 'Ġ2', 'D', '\",', 'Ġaired', 'Ġas', 'Ġthe', 'Ġfifth', 'Ġseason', 'Ġfinale', '.']\n",
      "decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers: [{'text': 'mystery television series \"Desperate Housewives\" commenced airing in the United States on September 25, 2005 and concluded on May', 'score': tensor([0.7656], device='cuda:0')}]\n",
      "answers_pred: [{'text': 'mystery television series \"Desperate Housewives\" commenced airing in the United States on September 25, 2005 and concluded on May', 'score': tensor([0.7656], device='cuda:0')}]\n",
      "answer_score: tensor([0.7656], device='cuda:0')\n",
      "answer_text: mystery television series \"Desperate Housewives\" commenced airing in the United States on September 25, 2005 and concluded on May\n",
      "answer_gold_token_ids: tensor([2063], device='cuda:0')\n",
      "answer_gold_tokens: ['ĠFox']\n",
      "answer_gold:  Fox\n",
      "f1: 0\n",
      "prec: 0\n",
      "recall: 0\n",
      "em: 0\n",
      "validation_end\n",
      "before sync --> sizes: 13, 13, 13, 13\n",
      "after sync --> sizes: 13, 13, 13, 13\n",
      "answer_scores:  [tensor([0.7530], device='cuda:0'), tensor([0.7522], device='cuda:0'), tensor([0.7622], device='cuda:0'), tensor([0.7569], device='cuda:0'), tensor([0.7587], device='cuda:0'), tensor([0.7647], device='cuda:0'), tensor([0.7453], device='cuda:0'), tensor([0.7660], device='cuda:0'), tensor([0.7564], device='cuda:0'), tensor([0.7421], device='cuda:0'), tensor([0.7640], device='cuda:0'), tensor([0.7610], device='cuda:0'), tensor([0.7656], device='cuda:0')]\n",
      "f1_scores:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "em_scores:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "avg_loss:  tensor(2.6846, device='cuda:0')\tavg_answer_loss:  tensor(0.9974, device='cuda:0')\tavg_type_loss:  tensor(0.5886, device='cuda:0')\tavg_sp_para_loss:  tensor(0.5685, device='cuda:0')\tavg_sp_sent_loss:  tensor(0.5300, device='cuda:0')\tlen(f1_scores):  13\n",
      "avg_val_f1:  0.0\n",
      "avg_val_em:  0.0\n",
      "avg_val_prec:  0.0\n",
      "avg_val_recall:  0.0\n",
      "avg_val_sp_sent_f1:  0.23846153846153845\n",
      "avg_val_sp_sent_em:  0.0\n",
      "avg_val_sp_sent_prec:  0.21794871794871792\n",
      "avg_val_sp_sent_recall:  0.2692307692307692\n",
      "avg_val_joint_f1:  0.0\n",
      "avg_val_joint_em:  0.0\n",
      "avg_val_joint_prec:  0.0\n",
      "avg_val_joint_recall:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Epoch 00005: avg_val_f1 reached 0.00000 (best 0.00000), saving model to jupyter-hotpotqa/hotpotqa-longformer/checkpoints/_ckpt_epoch_5_v0.ckpt as top 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     if not args.test:\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# import torch\n",
    "# torch.__version__\n",
    "# device = torch.device(\"cuda\")\n",
    "# torch.rand(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('save_dir', 'jupyter-hotpotqa')\n",
      "('save_prefix', 'hotpotqa-longformer')\n",
      "('train_dataset', 'small.json')\n",
      "('dev_dataset', 'small_dev.json')\n",
      "('batch_size', 2)\n",
      "('gpus', '0')\n",
      "('warmup', 1000)\n",
      "('lr', 5e-05)\n",
      "('val_every', 0.2)\n",
      "('val_percent_check', 1.0)\n",
      "('num_workers', 1)\n",
      "('seed', 1234)\n",
      "('epochs', 6)\n",
      "('max_seq_len', 4096)\n",
      "('max_doc_len', 4096)\n",
      "('max_num_answers', 64)\n",
      "('max_question_len', 55)\n",
      "('doc_stride', -1)\n",
      "('ignore_seq_with_no_answers', False)\n",
      "('disable_checkpointing', False)\n",
      "('n_best_size', 20)\n",
      "('max_answer_length', 30)\n",
      "('regular_softmax_loss', False)\n",
      "('test', True)\n",
      "('model_path', '/Users/fan/Downloads/longformer-base-4096')\n",
      "('no_progress_bar', False)\n",
      "('attention_mode', 'sliding_chunks')\n",
      "('fp32', False)\n",
      "('train_percent', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# debug: check args\n",
    "import shlex\n",
    "argString ='--train_dataset small.json --dev_dataset small_dev.json  \\\n",
    "    --gpus 0 --num_workers 1 \\\n",
    "    --max_seq_len 4096 --doc_stride -1  \\\n",
    "    --save_prefix hotpotqa-longformer  --model_path /Users/fan/Downloads/longformer-base-4096 --test '\n",
    "# hotpot_dev_distractor_v1.json\n",
    "\n",
    "import argparse \n",
    "if __name__ == \"__main__\":\n",
    "    main_arg_parser = argparse.ArgumentParser(description=\"hotpotqa\")\n",
    "    parser = hotpotqa.add_model_specific_args(main_arg_parser, os.getcwd())\n",
    "    args = parser.parse_args(shlex.split(argString)) \n",
    "    for arg in vars(args):\n",
    "        print((arg, getattr(args, arg)))\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotpotqa",
   "language": "python",
   "name": "hotpotqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
